         GPU 0/0  GPU 1/0  GPU 2/0  GPU 3/0  GPU 4/0  GPU 5/0  GPU 6/0  GPU 7/0  CPU Affinity
GPU 0/0  S        XL8      XL8      XL8      SYS      SYS      SYS      SYS      0-47,96-143
GPU 1/0  XL8      S        XL8      XL8      SYS      SYS      SYS      SYS      0-47,96-143
GPU 2/0  XL8      XL8      S        XL8      SYS      SYS      SYS      SYS      0-47,96-143
GPU 3/0  XL8      XL8      XL8      S        SYS      SYS      SYS      SYS      0-47,96-143
GPU 4/0  SYS      SYS      SYS      SYS      S        XL8      XL8      XL8      48-95,144-191
GPU 5/0  SYS      SYS      SYS      SYS      XL8      S        XL8      XL8      48-95,144-191
GPU 6/0  SYS      SYS      SYS      SYS      XL8      XL8      S        XL8      48-95,144-191
GPU 7/0  SYS      SYS      SYS      SYS      XL8      XL8      XL8      S        48-95,144-191
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 09:56:20.710] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 8 items
Running 8 items in this shard

../../../../test/distributed/fsdp/test_checkpoint_wrapper.py::CheckpointWrapperTest::test_apply_activation_checkpointing PASSED [0.2058s] [ 12%]
../../../../test/distributed/fsdp/test_checkpoint_wrapper.py::CheckpointWrapperTest::test_checkpoint_wrapper_args_kwargs PASSED [0.0013s] [ 25%]
../../../../test/distributed/fsdp/test_checkpoint_wrapper.py::CheckpointWrapperTest::test_checkpoint_wrapper_cpu_offload PASSED [0.0711s] [ 37%]
../../../../test/distributed/fsdp/test_checkpoint_wrapper.py::CheckpointWrapperTest::test_checkpoint_wrapper_kwarg_support PASSED [0.0038s] [ 50%]
../../../../test/distributed/fsdp/test_checkpoint_wrapper.py::CheckpointWrapperTest::test_checkpoint_wrapper_parity SKIPPED [0.0002s] [ 62%]
../../../../test/distributed/fsdp/test_checkpoint_wrapper.py::CheckpointWrapperTest::test_forward_missing_attributes PASSED [0.0007s] [ 75%]
../../../../test/distributed/fsdp/test_checkpoint_wrapper.py::CheckpointWrapperTest::test_fqn PASSED [0.0005s] [ 87%]
../../../../test/distributed/fsdp/test_checkpoint_wrapper.py::CheckpointWrapperTest::test_load_activation_checkpointed_module PASSED [0.0012s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_checkpoint_wrapper.py.xml -
========================= 7 passed, 1 skipped in 2.16s =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 09:56:23.943] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/fsdp/test_distributed_checkpoint.py::TestDistributedCheckpointXPU::test_distributed_checkpoint_state_dict_type0_xpu [2025-09-12 09:56:26.102] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 09:56:26.131] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-09:56:26:863752 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:56:26:863752 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-09:56:26:863753 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:56:26:863753 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
Using temp directory: /tmp/tmp3ttilnwn
PASSED [15.6289s] [ 50%]
../../../../test/distributed/fsdp/test_distributed_checkpoint.py::TestDistributedCheckpointXPU::test_distributed_checkpoint_state_dict_type1_xpu [2025-09-12 09:56:41.722] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 09:56:41.743] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-09:56:42:863905 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:56:42:863905 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-09:56:42:863904 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:56:42:863904 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
Using temp directory: /tmp/tmp5flpeqjm
PASSED [15.6228s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_distributed_checkpoint.py.xml -
============================== 2 passed in 33.42s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 09:56:58.186] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 3 items
Running 3 items in this shard

../../../../test/distributed/fsdp/test_fsdp_apply.py::TestApplyXPU::test_apply_in_summon_raises_error_xpu [2025-09-12 09:57:00.290] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 09:57:00.330] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-09:57:00:864129 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:57:00:864129 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-09:57:00:864130 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:57:00:864130 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
Asserting FSDP instance is: FullyShardedDataParallel(
  (_fsdp_wrapped_module): TransformerWithSharedParams(
    (embed_tokens): Embedding(23, 16)
    (transformer): Transformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x FullyShardedDataParallel(
            (_fsdp_wrapped_module): TransformerEncoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)
              )
              (linear1): Linear(in_features=16, out_features=8, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=8, out_features=16, bias=True)
              (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
      )
      (decoder): TransformerDecoder(
        (layers): ModuleList(
          (0-1): 2 x FullyShardedDataParallel(
            (_fsdp_wrapped_module): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)
              )
              (linear1): Linear(in_features=16, out_features=8, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=8, out_features=16, bias=True)
              (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_proj): Linear(in_features=16, out_features=23, bias=True)
    (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
ERROR: expected to be in states [<TrainingState.IDLE: 1>] but current state is TrainingState.SUMMON_FULL_PARAMS
PASSED [15.2211s] [ 33%]
../../../../test/distributed/fsdp/test_fsdp_apply.py::TestApplyXPU::test_nested_module_apply_xpu [2025-09-12 09:57:15.543] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 09:57:15.550] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-09:57:15:864284 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:57:15:864284 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-09:57:15:864283 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:57:15:864283 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.7261s] [ 66%]
../../../../test/distributed/fsdp/test_fsdp_apply.py::TestApplyXPU::test_transformer_module_apply_xpu [2025-09-12 09:57:31.238] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 09:57:31.258] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-09:57:31:864435 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:57:31:864435 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-09:57:31:864436 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:57:31:864436 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.9267s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_apply.py.xml -
============================== 3 passed in 48.90s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 09:57:48.109] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 1 item
Running 1 items in this shard

../../../../test/distributed/fsdp/test_fsdp_backward_prefetch.py::TestBackwardPrefetch::test_backward_prefetch [2025-09-12 09:57:50.386] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 09:57:50.396] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-09:57:50:864660 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:57:50:864660 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-09:57:50:864661 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:57:50:864661 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [37.0495s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_backward_prefetch.py.xml -
============================== 1 passed in 39.02s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 09:58:27.922] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 17 items
Running 17 items in this shard

../../../../test/distributed/fsdp/test_fsdp_checkpoint.py::TestFSDPCheckpoint::test_basic_checkpoint_end_to_end_cpu_offload0_offload_activations_False_use_orig_params_False [2025-09-12 09:58:30.064] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 09:58:30.078] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 09:58:30.098] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 09:58:30.099] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-09:58:30:864895 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:58:30:864895 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-09:58:30:864896 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:58:30:864896 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-09:58:30:864893 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:58:30:864893 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-09:58:30:864894 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:58:30:864894 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
PASSED [31.3569s] [  5%]
../../../../test/distributed/fsdp/test_fsdp_checkpoint.py::TestFSDPCheckpoint::test_basic_checkpoint_end_to_end_cpu_offload0_offload_activations_False_use_orig_params_True [2025-09-12 09:59:01.463] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 09:59:01.466] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 09:59:01.606] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 09:59:01.619] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-09:59:01:865215 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:59:01:865215 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-09:59:01:865212 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:59:01:865212 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-09:59:02:865213 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:59:02:865213 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-09:59:02:865214 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:59:02:865214 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [31.6526s] [ 11%]
../../../../test/distributed/fsdp/test_fsdp_checkpoint.py::TestFSDPCheckpoint::test_basic_checkpoint_end_to_end_cpu_offload0_offload_activations_True_use_orig_params_False [2025-09-12 09:59:33.131] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 09:59:33.134] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 09:59:33.134] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 09:59:33.150] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-09:59:33:865535 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:59:33:865535 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-09:59:33:865532 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:59:33:865532 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-09:59:33:865533 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:59:33:865533 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-09:59:33:865534 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-09:59:33:865534 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [31.4549s] [ 17%]
../../../../test/distributed/fsdp/test_fsdp_checkpoint.py::TestFSDPCheckpoint::test_basic_checkpoint_end_to_end_cpu_offload0_offload_activations_True_use_orig_params_True [2025-09-12 10:00:04.594] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:00:04.594] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:00:04.606] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:00:04.607] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:00:04:865857 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:00:04:865857 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:00:05:865855 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:00:05:865855 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:00:05:865856 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:00:05:865856 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:00:05:865854 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:00:05:865854 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [31.3556s] [ 23%]
../../../../test/distributed/fsdp/test_fsdp_checkpoint.py::TestFSDPCheckpoint::test_basic_checkpoint_end_to_end_cpu_offload1_offload_activations_False_use_orig_params_False [2025-09-12 10:00:35.909] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:00:35.930] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:00:35.966] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:00:35.974] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:00:36:866173 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:00:36:866173 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:00:36:866176 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:00:36:866176 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:00:36:866175 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:00:36:866175 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:00:36:866174 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:00:36:866174 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [31.3541s] [ 29%]
../../../../test/distributed/fsdp/test_fsdp_checkpoint.py::TestFSDPCheckpoint::test_basic_checkpoint_end_to_end_cpu_offload1_offload_activations_False_use_orig_params_True [2025-09-12 10:01:07.278] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:01:07.282] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:01:07.305] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:01:07.306] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:01:07:866494 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:01:07:866494 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:01:07:866493 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:01:07:866493 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:01:07:866491 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:01:07:866491 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:01:07:866492 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:01:07:866492 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [31.3552s] [ 35%]
../../../../test/distributed/fsdp/test_fsdp_checkpoint.py::TestFSDPCheckpoint::test_basic_checkpoint_end_to_end_cpu_offload1_offload_activations_True_use_orig_params_False [2025-09-12 10:01:38.655] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:01:38.656] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:01:38.662] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:01:38.678] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:01:39:866812 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:01:39:866812 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:01:39:866813 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:01:39:866813 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:01:39:866811 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:01:39:866811 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:01:39:866814 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:01:39:866814 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [31.7560s] [ 41%]
../../../../test/distributed/fsdp/test_fsdp_checkpoint.py::TestFSDPCheckpoint::test_basic_checkpoint_end_to_end_cpu_offload1_offload_activations_True_use_orig_params_True [2025-09-12 10:02:10.380] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:02:10.398] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:02:10.417] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:02:10.434] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:02:10:867132 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:02:10:867132 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:02:10:867133 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:02:10:867133 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:02:10:867131 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:02:10:867131 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:02:10:867130 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:02:10:867130 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
PASSED [31.7567s] [ 47%]
../../../../test/distributed/fsdp/test_fsdp_checkpoint.py::TestFSDPCheckpoint::test_checkpoint_fsdp_wrapping_cpu_offload0_offload_activations_False_use_orig_params_False [2025-09-12 10:02:42.138] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:02:42.172] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:02:42.173] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:02:42.176] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:02:42:867457 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:02:42:867457 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:02:42:867456 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:02:42:867456 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:02:42:867454 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:02:42:867454 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:02:42:867455 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:02:42:867455 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.3550s] [ 52%]
../../../../test/distributed/fsdp/test_fsdp_checkpoint.py::TestFSDPCheckpoint::test_checkpoint_fsdp_wrapping_cpu_offload0_offload_activations_False_use_orig_params_True [2025-09-12 10:03:13.561] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:03:13.578] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:03:13.594] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:03:13.598] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:03:13:867778 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:03:13:867778 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:03:13:867776 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:03:13:867776 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:03:14:867777 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:03:14:867777 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:03:14:867779 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:03:14:867779 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
PASSED [31.5554s] [ 58%]
../../../../test/distributed/fsdp/test_fsdp_checkpoint.py::TestFSDPCheckpoint::test_checkpoint_fsdp_wrapping_cpu_offload0_offload_activations_True_use_orig_params_False [2025-09-12 10:03:45.128] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:03:45.128] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:03:45.130] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:03:45.159] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:03:45:868095 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:03:45:868095 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:03:45:868094 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:03:45:868094 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:03:45:868097 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:03:45:868097 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:03:45:868096 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:03:45:868096 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [31.5498s] [ 64%]
../../../../test/distributed/fsdp/test_fsdp_checkpoint.py::TestFSDPCheckpoint::test_checkpoint_fsdp_wrapping_cpu_offload0_offload_activations_True_use_orig_params_True [2025-09-12 10:04:16.614] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:04:16.648] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:04:16.666] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:04:16.666] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:04:17:868415 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:04:17:868415 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:04:17:868413 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:04:17:868413 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:04:17:868414 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:04:17:868414 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:04:17:868412 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:04:17:868412 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [31.4554s] [ 70%]
../../../../test/distributed/fsdp/test_fsdp_checkpoint.py::TestFSDPCheckpoint::test_checkpoint_fsdp_wrapping_cpu_offload1_offload_activations_False_use_orig_params_False [2025-09-12 10:04:48.082] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:04:48.084] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:04:48.084] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:04:48.086] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:04:48:868734 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:04:48:868734 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:04:48:868732 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:04:48:868732 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:04:48:868731 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:04:48:868731 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:04:48:868733 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:04:48:868733 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.4555s] [ 76%]
../../../../test/distributed/fsdp/test_fsdp_checkpoint.py::TestFSDPCheckpoint::test_checkpoint_fsdp_wrapping_cpu_offload1_offload_activations_False_use_orig_params_True [2025-09-12 10:05:19.474] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:05:19.499] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:05:19.540] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:05:19.542] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:05:19:869050 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:05:19:869050 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:05:19:869053 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:05:19:869053 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:05:20:869051 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:05:20:869051 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:05:20:869052 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:05:20:869052 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [31.3555s] [ 82%]
../../../../test/distributed/fsdp/test_fsdp_checkpoint.py::TestFSDPCheckpoint::test_checkpoint_fsdp_wrapping_cpu_offload1_offload_activations_True_use_orig_params_False [2025-09-12 10:05:50.873] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:05:50.874] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:05:50.880] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:05:50.907] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:05:51:869372 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:05:51:869372 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:05:51:869369 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:05:51:869369 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:05:51:869370 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:05:51:869370 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:05:51:869371 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:05:51:869371 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [31.3556s] [ 88%]
../../../../test/distributed/fsdp/test_fsdp_checkpoint.py::TestFSDPCheckpoint::test_checkpoint_fsdp_wrapping_cpu_offload1_offload_activations_True_use_orig_params_True [2025-09-12 10:06:22.213] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:06:22.214] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:06:22.216] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:06:22.230] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:06:22:869689 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:06:22:869689 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:06:22:869688 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:06:22:869688 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:06:22:869687 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:06:22:869687 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:06:22:869686 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:06:22:869686 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [31.4539s] [ 94%]
../../../../test/distributed/fsdp/test_fsdp_checkpoint.py::TestFSDPCheckpointSubmoduleXPU::test_checkpoint_submodule_use_reentrant_False_xpu [2025-09-12 10:06:53.712] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:06:53.726] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:06:53.734] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:06:53.735] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:06:54:870009 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:06:54:870009 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:06:54:870008 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:06:54:870008 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:06:54:870010 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:06:54:870010 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:06:54:870007 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:06:54:870007 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [17.4309s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_checkpoint.py.xml -
======================== 17 passed in 523.06s (0:08:43) ========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 10:07:12.019] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 4 items
Running 4 items in this shard

../../../../test/distributed/fsdp/test_fsdp_clip_grad_norm.py::TestClipGradNormXPU::test_ddp_parity_xpu [2025-09-12 10:07:14.192] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:07:14.215] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:07:14.216] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:07:14.217] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:07:14:870399 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:07:14:870399 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:07:14:870398 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:07:14:870398 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:07:14:870400 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:07:14:870400 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:07:14:870397 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:07:14:870397 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
FAILED [31.6584s] [ 25%]
../../../../test/distributed/fsdp/test_fsdp_clip_grad_norm.py::TestClipGradNormXPU::test_low_precision_grads_xpu [2025-09-12 10:07:45.898] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:07:45.907] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:07:45.974] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:07:46.003] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:07:46:870717 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:07:46:870717 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:07:46:870718 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:07:46:870718 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:07:46:870716 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:07:46:870716 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:07:46:870719 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:07:46:870719 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
PASSED [16.8238s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_clip_grad_norm.py::TestClipGradNormXPU::test_no_gradients_xpu [2025-09-12 10:08:02.651] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:08:02.670] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:08:02.708] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:08:02.710] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:08:03:871036 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:08:03:871036 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:08:03:871035 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:08:03:871035 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:08:03:871037 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:08:03:871037 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:08:03:871038 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:08:03:871038 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [15.8288s] [ 75%]
../../../../test/distributed/fsdp/test_fsdp_clip_grad_norm.py::TestClipGradNormXPU::test_non_root_xpu [2025-09-12 10:08:18.531] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:08:18.531] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:08:18.549] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:08:18.554] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:08:18:871338 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:08:18:871338 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:08:18:871337 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:08:18:871337 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:08:19:871339 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:08:19:871339 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:08:19:871336 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:08:19:871336 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [31.1554s] [100%]

=================================== FAILURES ===================================
___________________ TestClipGradNormXPU.test_ddp_parity_xpu ____________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_clip_grad_norm.py", line 78, in test_ddp_parity
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_clip_grad_norm.py", line 236, in _test_ddp_parity
    self.assertEqual(ddp_total_norm, fsdp_total_norm)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Scalars are not close!

Expected 23668.390625 but got 23686.31640625.
Absolute difference: 17.92578125 (up to 1e-05 allowed)
Relative difference: 0.0007573722072621911 (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_clip_grad_norm.py TestClipGradNormXPU.test_ddp_parity_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 3 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 10:07:12.329000 870325 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 870397
I0912 10:07:12.329000 870325 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 870398
I0912 10:07:12.330000 870325 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 870399
I0912 10:07:12.330000 870325 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 870400
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_clip_grad_norm.py.xml -
=========================== short test summary info ============================
FAILED [31.6584s] ../../../../test/distributed/fsdp/test_fsdp_clip_grad_norm.py::TestClipGradNormXPU::test_ddp_parity_xpu - RuntimeError: Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_clip_grad_norm.py", line 78, in test_ddp_parity
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_clip_grad_norm.py", line 236, in _test_ddp_parity
    self.assertEqual(ddp_total_norm, fsdp_total_norm)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Scalars are not close!

Expected 23668.390625 but got 23686.31640625.
Absolute difference: 17.92578125 (up to 1e-05 allowed)
Relative difference: 0.0007573722072621911 (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_clip_grad_norm.py TestClipGradNormXPU.test_ddp_parity_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
==================== 1 failed, 3 passed in 97.63s (0:01:37) ====================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 10:08:50.603] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 10 items
Running 10 items in this shard

../../../../test/distributed/fsdp/test_fsdp_comm.py::TestCommunicationXPU::test_communication_nested_model_False_use_no_sync_False_sharding_strategy0_xpu [2025-09-12 10:08:52.856] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:08:52.879] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:08:52.950] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:08:52.978] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:08:53:871730 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:08:53:871730 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:08:53:871731 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:08:53:871731 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:08:53:871729 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:08:53:871729 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:08:53:871732 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:08:53:871732 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [16.3234s] [ 10%]
../../../../test/distributed/fsdp/test_fsdp_comm.py::TestCommunicationXPU::test_communication_nested_model_False_use_no_sync_False_sharding_strategy1_xpu [2025-09-12 10:09:09.101] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:09:09.122] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:09:09.125] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:09:09.137] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:09:09:872048 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:09:09:872048 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:09:09:872046 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:09:09:872046 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:09:09:872047 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:09:09:872047 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:09:09:872049 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:09:09:872049 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [16.3310s] [ 20%]
../../../../test/distributed/fsdp/test_fsdp_comm.py::TestCommunicationXPU::test_communication_nested_model_False_use_no_sync_True_sharding_strategy0_xpu [2025-09-12 10:09:25.506] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:09:25.508] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:09:25.543] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:09:25.544] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:09:25:872363 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:09:25:872363 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:09:25:872364 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:09:25:872364 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:09:26:872366 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:09:26:872366 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:09:26:872365 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:09:26:872365 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [16.3307s] [ 30%]
../../../../test/distributed/fsdp/test_fsdp_comm.py::TestCommunicationXPU::test_communication_nested_model_False_use_no_sync_True_sharding_strategy1_xpu [2025-09-12 10:09:41.778] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:09:41.821] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:09:41.821] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:09:41.826] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:09:42:872680 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:09:42:872680 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:09:42:872683 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:09:42:872683 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:09:42:872682 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:09:42:872682 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:09:42:872681 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:09:42:872681 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [16.3306s] [ 40%]
../../../../test/distributed/fsdp/test_fsdp_comm.py::TestCommunicationXPU::test_communication_nested_model_True_use_no_sync_False_sharding_strategy0_xpu [2025-09-12 10:09:58.186] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:09:58.204] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:09:58.228] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:09:58.228] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:09:58:872997 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:09:58:872997 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:09:58:872996 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:09:58:872996 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:09:58:872999 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:09:58:872998 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:09:58:872999 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:09:58:872998 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [16.2304s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_comm.py::TestCommunicationXPU::test_communication_nested_model_True_use_no_sync_False_sharding_strategy1_xpu [2025-09-12 10:10:14.350] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:10:14.367] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:10:14.369] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:10:14.386] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:10:14:873313 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:10:14:873313 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:10:14:873315 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:10:14:873315 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:10:14:873316 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:10:14:873316 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:10:14:873314 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:10:14:873314 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [16.0301s] [ 60%]
../../../../test/distributed/fsdp/test_fsdp_comm.py::TestCommunicationXPU::test_communication_nested_model_True_use_no_sync_True_sharding_strategy0_xpu [2025-09-12 10:10:30.454] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:10:30.473] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:10:30.480] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:10:30.480] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:10:30:873633 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:10:30:873633 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:10:30:873632 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:10:30:873632 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:10:30:873630 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:10:30:873630 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:10:31:873631 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:10:31:873631 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [16.2290s] [ 70%]
../../../../test/distributed/fsdp/test_fsdp_comm.py::TestCommunicationXPU::test_communication_nested_model_True_use_no_sync_True_sharding_strategy1_xpu [2025-09-12 10:10:46.633] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:10:46.634] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:10:46.645] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:10:46.654] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:10:47:873949 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:10:47:873949 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:10:47:873947 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:10:47:873947 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:10:47:873950 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:10:47:873950 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:10:47:873948 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:10:47:873948 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [16.0292s] [ 80%]
../../../../test/distributed/fsdp/test_fsdp_comm.py::TestExplicitUnshardXPU::test_unshard_async_use_orig_params_False_xpu [2025-09-12 10:11:02.666] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:11:02.683] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:11:03:874265 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:11:03:874265 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:11:03:874264 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:11:03:874264 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.1458s] [ 90%]
../../../../test/distributed/fsdp/test_fsdp_comm.py::TestExplicitUnshardXPU::test_unshard_async_use_orig_params_True_xpu [2025-09-12 10:11:32.836] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:11:32.854] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:11:33:874424 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:11:33:874424 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:11:33:874423 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:11:33:874423 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.5486s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_comm.py.xml -
======================== 10 passed in 192.70s (0:03:12) ========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 10:12:04.227] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 28 items
Running 28 items in this shard

../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_bf16_hook_has_wrapping_False_sharding_strategy0 [2025-09-12 10:12:06.400] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:12:06.410] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:12:06.442] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:12:06.458] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:12:06:874658 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:12:06:874658 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:12:06:874656 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:12:06:874656 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:12:06:874655 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:12:06:874655 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:12:06:874657 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:12:06:874657 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [16.1139s] [  3%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_bf16_hook_has_wrapping_False_sharding_strategy1 [2025-09-12 10:12:22.372] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:12:22.372] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:12:22.372] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:12:22.382] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:12:22:874974 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:12:22:874974 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:12:22:874975 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:12:22:874975 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:12:22:874973 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:12:22:874973 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:12:22:874972 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:12:22:874972 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
PASSED [27.9428s] [  7%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_bf16_hook_has_wrapping_False_sharding_strategy2 [2025-09-12 10:12:50.308] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:12:50.321] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:12:50.321] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:12:50.330] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:12:50:875290 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:12:50:875290 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:12:50:875292 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:12:50:875292 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:12:50:875291 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:12:50:875291 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:12:50:875293 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:12:50:875293 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
PASSED [27.4486s] [ 10%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_bf16_hook_has_wrapping_True_sharding_strategy0 [2025-09-12 10:13:17.736] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:13:17.758] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:13:17.766] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:13:17.774] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:13:17:875611 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:13:17:875611 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:13:17:875608 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:13:17:875608 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:13:17:875610 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:13:17:875610 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:13:18:875609 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:13:18:875609 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [15.7298s] [ 14%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_bf16_hook_has_wrapping_True_sharding_strategy1 [2025-09-12 10:13:33.462] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:13:33.478] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:13:33.488] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:13:33.488] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:13:33:875928 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:13:33:875927 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:13:33:875928 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:13:33:875927 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:13:33:875925 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:13:33:875925 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:13:33:875926 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:13:33:875926 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
PASSED [42.1696s] [ 17%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_bf16_hook_has_wrapping_True_sharding_strategy2 [2025-09-12 10:14:15.636] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:14:15.637] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:14:15.650] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:14:15.678] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:14:15:876245 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:14:15:876245 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:14:15:876247 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:14:15:876247 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:14:15:876246 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:14:15:876246 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:14:15:876244 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:14:15:876244 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [42.6656s] [ 21%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_default_communication_hook_behavior_sharding_strategy0 [2025-09-12 10:14:58.312] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:14:58.312] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:14:58.328] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:14:58.334] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:14:58:876562 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:14:58:876562 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:14:58:876561 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:14:58:876561 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:14:58:876563 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:14:58:876563 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:14:58:876564 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:14:58:876564 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [15.6274s] [ 25%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_default_communication_hook_behavior_sharding_strategy1 [2025-09-12 10:15:13.921] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:15:13.924] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:15:13.930] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:15:13.958] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:15:14:876884 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:15:14:876884 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:15:14:876882 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:15:14:876882 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:15:14:876881 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:15:14:876881 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:15:14:876883 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:15:14:876883 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [30.9519s] [ 28%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_default_communication_hook_behavior_sharding_strategy2 [2025-09-12 10:15:44.879] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:15:44.879] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:15:44.879] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:15:44.886] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:15:45:877201 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:15:45:877201 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:15:45:877202 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:15:45:877202 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:15:45:877199 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:15:45:877199 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:15:45:877200 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:15:45:877200 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [31.1542s] [ 32%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_default_communication_hook_initialization_has_wrapping_False_sharding_strategy0 [2025-09-12 10:16:16.029] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:16:16.034] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:16:16.046] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:16:16.061] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:16:16:877516 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:16:16:877516 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:16:16:877519 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:16:16:877519 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:16:16:877518 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:16:16:877518 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:16:16:877517 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:16:16:877517 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [15.2283s] [ 35%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_default_communication_hook_initialization_has_wrapping_False_sharding_strategy1 [2025-09-12 10:16:31.322] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:16:31.338] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:16:31.338] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:16:31.338] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:16:31:877818 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:16:31:877818 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:16:31:877820 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:16:31:877820 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:16:31:877817 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:16:31:877817 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:16:31:877819 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:16:31:877819 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [15.6293s] [ 39%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_default_communication_hook_initialization_has_wrapping_False_sharding_strategy2 [2025-09-12 10:16:46.950] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:16:46.951] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:16:46.951] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:16:46.974] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:16:47:878122 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:16:47:878122 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:16:47:878119 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:16:47:878119 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:16:47:878120 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:16:47:878120 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:16:47:878121 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:16:47:878121 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [15.6301s] [ 42%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_default_communication_hook_initialization_has_wrapping_True_sharding_strategy0 [2025-09-12 10:17:02.482] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:17:02.513] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:17:02.526] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:17:02.542] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:17:02:878420 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:17:02:878420 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:17:02:878419 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:17:02:878419 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:17:02:878422 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:17:02:878422 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:17:02:878421 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:17:02:878421 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [15.4278s] [ 46%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_default_communication_hook_initialization_has_wrapping_True_sharding_strategy1 [2025-09-12 10:17:17.930] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:17:17.992] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:17:17.992] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:17:17.993] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:17:18:878724 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:17:18:878724 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:17:18:878723 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:17:18:878723 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:17:18:878725 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:17:18:878725 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:17:18:878726 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:17:18:878726 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [15.5284s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_default_communication_hook_initialization_has_wrapping_True_sharding_strategy2 [2025-09-12 10:17:33.479] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:17:33.479] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:17:33.490] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:17:33.504] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:17:33:879025 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:17:33:879025 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:17:33:879026 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:17:33:879026 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:17:33:879024 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:17:33:879024 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:17:33:879027 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:17:33:879027 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [15.5286s] [ 53%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_fp16_hook_has_wrapping_False_sharding_strategy0 [2025-09-12 10:17:48.998] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:17:49.010] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:17:49.042] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:17:49.054] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:17:49:879326 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:17:49:879326 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:17:49:879328 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:17:49:879328 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:17:49:879327 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:17:49:879327 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:17:49:879325 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:17:49:879325 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [16.0292s] [ 57%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_fp16_hook_has_wrapping_False_sharding_strategy1 [2025-09-12 10:18:05.047] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:18:05.070] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:18:05.098] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:18:05.110] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:18:05:879644 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:18:05:879644 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:18:05:879642 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:18:05:879642 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:18:05:879641 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:18:05:879641 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:18:05:879643 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:18:05:879643 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [16.2277s] [ 60%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_fp16_hook_has_wrapping_False_sharding_strategy2 [2025-09-12 10:18:21.336] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:18:21.336] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:18:21.337] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:18:21.358] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:18:21:879960 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:18:21:879960 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:18:21:879959 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:18:21:879959 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:18:21:879958 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:18:21:879958 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:18:21:879957 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:18:21:879957 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [16.1285s] [ 64%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_fp16_hook_has_wrapping_True_sharding_strategy0 [2025-09-12 10:18:37.414] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:18:37.452] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:18:37.452] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:18:37.452] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:18:37:880277 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:18:37:880277 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:18:37:880275 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:18:37:880275 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:18:37:880276 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:18:37:880276 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:18:37:880274 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:18:37:880274 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [16.0269s] [ 67%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_fp16_hook_has_wrapping_True_sharding_strategy1 [2025-09-12 10:18:53.451] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:18:53.466] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:18:53.470] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:18:53.474] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:18:53:880594 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:18:53:880594 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:18:53:880597 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:18:53:880597 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:18:53:880595 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:18:53:880595 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:18:53:880596 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:18:53:880596 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [16.0301s] [ 71%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_fp16_hook_has_wrapping_True_sharding_strategy2 [2025-09-12 10:19:09.531] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:19:09.542] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:19:09.554] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:19:09.570] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:19:09:880912 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:19:09:880912 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:19:09:880911 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:19:09:880911 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:19:09:880913 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:19:09:880913 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:19:09:880910 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:19:09:880910 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [16.1307s] [ 75%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_registering_hook_hybrid_strategy [2025-09-12 10:19:25.598] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:19:25.610] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:19:25.623] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:19:25.623] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:19:25:881227 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:19:25:881227 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:19:25:881228 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:19:25:881228 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:19:25:881229 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:19:25:881229 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:19:25:881230 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:19:25:881230 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [15.5277s] [ 78%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_registering_hook_non_root_sharding_strategy0 [2025-09-12 10:19:41.087] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:19:41.110] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:19:41.157] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:19:41.157] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:19:41:881544 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:19:41:881544 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:19:41:881546 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:19:41:881546 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:19:41:881545 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:19:41:881545 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:19:41:881543 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:19:41:881543 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [15.6302s] [ 82%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_registering_hook_non_root_sharding_strategy1 [2025-09-12 10:19:56.763] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:19:56.778] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:19:56.793] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:19:56.814] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:19:56:881846 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:19:56:881846 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:19:56:881845 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:19:56:881845 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:19:57:881843 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:19:57:881843 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:19:57:881844 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:19:57:881844 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [15.6263s] [ 85%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_registering_hook_non_root_sharding_strategy2 [2025-09-12 10:20:12.482] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:20:12.489] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:20:12.505] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:20:12.522] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:20:12:882148 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:20:12:882148 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:20:12:882147 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:20:12:882147 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:20:12:882149 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:20:12:882149 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:20:12:882146 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:20:12:882146 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [15.7291s] [ 89%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_registering_hook_submodules_sharding_strategy0 [2025-09-12 10:20:28.127] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:20:28.128] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:20:28.137] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:20:28.150] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:20:28:882450 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:20:28:882450 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:20:28:882448 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:20:28:882448 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:20:28:882447 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:20:28:882447 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:20:28:882449 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:20:28:882449 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [15.4295s] [ 92%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_registering_hook_submodules_sharding_strategy1 [2025-09-12 10:20:43.555] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:20:43.578] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:20:43.588] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:20:43.589] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:20:43:882750 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:20:43:882750 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:20:43:882751 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:20:43:882751 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:20:43:882749 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:20:43:882749 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:20:43:882748 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:20:43:882748 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [15.5274s] [ 96%]
../../../../test/distributed/fsdp/test_fsdp_comm_hooks.py::TestCommunicationHooks::test_registering_hook_submodules_sharding_strategy2 [2025-09-12 10:20:59.082] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:20:59.116] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:20:59.122] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:20:59.133] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:20:59:883051 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:20:59:883051 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:20:59:883052 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:20:59:883052 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:20:59:883049 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:20:59:883049 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:20:59:883050 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:20:59:883050 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
PASSED [15.6294s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_comm_hooks.py.xml -
======================== 28 passed in 550.45s (0:09:10) ========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 10:21:15.618] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 60 items
Running 60 items in this shard

../../../../test/distributed/fsdp/test_fsdp_core.py::TestHooksXPU::test_pre_backward_hook_registration_after_state_dict_xpu [2025-09-12 10:21:17.890] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:21:17.918] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:21:18.027] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:21:18.032] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:21:18:883423 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:21:18:883423 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:21:18:883424 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:21:18:883424 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:21:18:883422 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:21:18:883422 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:21:18:883425 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:21:18:883425 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.6580s] [  1%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestHooksXPU::test_pre_backward_hook_registration_cuda_first_False_xpu [2025-09-12 10:21:49.506] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:21:49.506] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:21:49.515] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:21:49.534] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:21:49:883740 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:21:49:883740 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:21:49:883739 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:21:49:883739 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:21:49:883741 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:21:49:883741 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:21:50:883742 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:21:50:883742 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [31.4547s] [  3%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestHooksXPU::test_pre_backward_hook_registration_cuda_first_True_xpu [2025-09-12 10:22:20.950] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:22:20.966] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:22:20.974] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:22:20.984] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:22:21:884058 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:22:21:884058 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:22:21:884059 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:22:21:884059 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:22:21:884060 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:22:21:884060 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:22:21:884061 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:22:21:884061 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [31.7566s] [  5%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestHooksXPU::test_register_functions_called_cuda_first_False_mixed_precision_False_xpu [2025-09-12 10:22:52.723] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:22:52.735] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:22:52.735] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:22:52.742] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:22:53:884376 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:22:53:884376 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:22:53:884377 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:22:53:884377 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:22:53:884375 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:22:53:884375 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:22:53:884378 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:22:53:884378 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [16.1293s] [  6%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestHooksXPU::test_register_functions_called_cuda_first_False_mixed_precision_True_xpu [2025-09-12 10:23:08.842] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:23:08.844] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:23:08.870] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:23:08.906] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:23:09:884680 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:23:09:884680 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:23:09:884677 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:23:09:884677 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:23:09:884679 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:23:09:884679 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:23:09:884678 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:23:09:884678 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [16.2293s] [  8%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestHooksXPU::test_register_functions_called_cuda_first_True_mixed_precision_False_xpu [2025-09-12 10:23:25.063] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:23:25.074] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:23:25.104] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:23:25.104] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:23:25:884980 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:23:25:884980 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:23:25:884979 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:23:25:884979 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:23:25:884978 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:23:25:884978 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:23:25:884977 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:23:25:884977 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [16.0299s] [ 10%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestHooksXPU::test_register_functions_called_cuda_first_True_mixed_precision_True_xpu [2025-09-12 10:23:41.186] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:23:41.198] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:23:41.220] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:23:41.221] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:23:41:885280 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:23:41:885280 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:23:41:885278 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:23:41:885278 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:23:41:885281 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:23:41:885281 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:23:41:885279 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:23:41:885279 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [16.3288s] [ 11%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_delayed_optim_step_offload_false_no_shard_xpu [2025-09-12 10:23:57.435] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:23:57.446] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:23:57.563] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:23:57.592] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:23:57:885580 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:23:57:885580 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:23:57:885579 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:23:57:885579 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:23:58:885578 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:23:58:885578 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:23:58:885581 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:23:58:885581 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [41.0640s] [ 13%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_delayed_optim_step_offload_false_none_xpu [2025-09-12 10:24:38.500] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:24:38.501] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:24:38.509] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:24:38.522] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:24:38:885896 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:24:38:885896 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:24:38:885899 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:24:38:885899 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:24:39:885897 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:24:39:885897 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:24:39:885898 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:24:39:885898 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
FAILED [32.6571s] [ 15%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_delayed_optim_step_offload_false_shard_grad_op_xpu [2025-09-12 10:25:11.187] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:25:11.190] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:25:11.201] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:25:11.201] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:25:11:886215 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:25:11:886215 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:25:11:886214 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:25:11:886214 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:25:11:886217 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:25:11:886217 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:25:11:886216 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:25:11:886216 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [56.4900s] [ 16%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_delayed_optim_step_offload_true_no_shard_xpu [2025-09-12 10:26:07.654] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:26:07.661] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:26:07.678] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:26:07.690] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:26:08:886537 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:26:08:886537 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:26:08:886535 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:26:08:886535 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:26:08:886538 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:26:08:886538 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:26:08:886536 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:26:08:886536 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [47.2754s] [ 18%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_delayed_optim_step_offload_true_none_xpu [2025-09-12 10:26:54.940] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:26:54.962] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:26:54.963] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:26:54.964] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:26:55:886853 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:26:55:886853 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:26:55:886854 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:26:55:886854 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:26:55:886852 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:26:55:886852 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:26:55:886855 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:26:55:886855 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
FAILED [39.5670s] [ 20%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_delayed_optim_step_offload_true_shard_grad_op_xpu [2025-09-12 10:27:34.510] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:27:34.520] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:27:34.520] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:27:34.535] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:27:34:887171 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:27:34:887171 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:27:34:887173 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:27:34:887173 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:27:35:887174 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:27:35:887174 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:27:35:887172 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:27:35:887172 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [62.7993s] [ 21%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_delayed_reduce_scatter_offload_false_no_shard_xpu [2025-09-12 10:28:37.302] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:28:37.314] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:28:37.320] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:28:37.324] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:28:37:887490 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:28:37:887490 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:28:37:887489 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:28:37:887489 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:28:37:887492 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:28:37:887492 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:28:37:887491 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:28:37:887491 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [16.9292s] [ 23%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_delayed_reduce_scatter_offload_false_none_xpu [2025-09-12 10:28:54.253] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:28:54.270] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:28:54.274] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:28:54.282] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:28:54:887808 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:28:54:887808 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:28:54:887806 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:28:54:887806 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:28:54:887805 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:28:54:887805 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:28:54:887807 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:28:54:887807 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
FAILED [33.5584s] [ 25%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_delayed_reduce_scatter_offload_false_shard_grad_op_xpu [2025-09-12 10:29:27.772] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:29:27.790] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:29:27.798] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:29:27.851] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:29:28:888122 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:29:28:888122 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:29:28:888125 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:29:28:888125 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:29:28:888123 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:29:28:888123 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:29:28:888124 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:29:28:888124 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [80.1216s] [ 26%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_delayed_reduce_scatter_offload_true_no_shard_xpu [2025-09-12 10:30:47.902] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:30:47.930] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:30:47.931] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:30:47.933] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:30:48:888442 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:30:48:888442 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:30:48:888443 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:30:48:888443 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:30:48:888444 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:30:48:888444 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:30:48:888441 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:30:48:888441 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [17.2314s] [ 28%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_delayed_reduce_scatter_offload_true_none_xpu [2025-09-12 10:31:05.136] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:31:05.154] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:31:05.198] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:31:05.198] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:31:05:888761 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:31:05:888761 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:31:05:888762 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:31:05:888762 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:31:05:888763 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:31:05:888763 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:31:05:888760 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:31:05:888760 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
FAILED [33.7597s] [ 30%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_delayed_reduce_scatter_offload_true_shard_grad_op_xpu [2025-09-12 10:31:38.935] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:31:38.946] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:31:38.946] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:31:38.964] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:31:39:889082 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:31:39:889082 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:31:39:889083 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:31:39:889083 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:31:39:889081 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:31:39:889081 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:31:39:889084 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:31:39:889084 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [80.5214s] [ 31%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_mixture_of_experts_offload_false_no_shard_xpu [2025-09-12 10:32:59.480] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:32:59.494] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:32:59.503] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:32:59.520] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:32:59:889403 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:32:59:889403 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:32:59:889402 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:32:59:889402 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:33:00:889401 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:33:00:889400 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:33:00:889401 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:33:00:889400 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:33:12:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:12:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:12:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:12:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:13:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:13:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:13:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:13:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:13:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:13:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:13:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:13:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:13:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:13:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:13:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:13:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:14:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:14:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:14:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:14:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:14:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:14:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:14:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:14:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:14:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:14:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:14:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:14:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:15:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:15:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:15:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:15:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:15:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:15:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:15:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:15:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:15:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:15:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:15:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:15:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:16:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:16:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:16:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:16:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:16:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:16:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:16:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:16:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:16:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:16:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:16:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:16:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:16:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:16:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:16:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:16:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:17:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:17:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:17:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:17:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:17:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:17:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:17:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:17:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:17:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:17:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:17:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:17:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:18:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:18:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:18:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:18:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:18:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:18:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:18:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:18:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:18:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:18:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:18:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:18:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:19:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:19:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:19:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:19:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:19:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:19:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:19:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:19:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:19:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:19:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:19:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:19:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:19:889701:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:19:889708:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:19:889710:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:19:889715:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [23.2403s] [ 33%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_mixture_of_experts_offload_false_none_xpu [2025-09-12 10:33:22.706] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:33:22.709] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:33:22.722] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:33:22.726] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:33:23:889912 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:33:23:889912 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:33:23:889910 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:33:23:889910 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:33:23:889911 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:33:23:889911 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:33:23:889913 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:33:23:889913 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:33:36:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:36:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:36:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:36:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:51:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:51:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:51:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:51:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:52:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:52:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:52:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:52:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:52:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:52:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:52:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:52:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:52:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:52:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:52:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:52:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:52:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:52:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:52:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:52:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:53:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:53:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:53:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:53:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:53:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:53:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:53:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:53:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:53:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:53:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:53:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:53:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:54:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:54:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:54:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:54:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:54:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:54:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:54:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:54:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:54:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:54:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:54:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:54:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:55:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:55:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:55:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:55:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:55:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:55:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:55:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:55:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:55:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:55:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:55:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:55:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:55:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:55:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:55:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:55:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:56:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:56:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:56:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:56:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:56:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:56:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:56:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:56:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:56:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:56:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:56:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:56:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:57:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:57:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:57:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:57:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:57:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:57:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:57:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:57:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:57:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:57:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:57:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:57:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:58:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:58:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:58:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:58:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:58:890213:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:58:890228:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:58:890223:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:33:58:890218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [38.4658s] [ 35%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_mixture_of_experts_offload_false_shard_grad_op_xpu [2025-09-12 10:34:01.121] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:34:01.142] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:34:01.155] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:34:01.159] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:34:01:890427 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:34:01:890427 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:34:01:890425 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:34:01:890425 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:34:01:890428 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:34:01:890428 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:34:01:890426 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:34:01:890426 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:34:14:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:14:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:14:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:14:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:30:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:30:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:30:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:30:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:30:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:30:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:30:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:30:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:31:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:31:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:31:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:31:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:31:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:31:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:31:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:31:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:31:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:31:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:31:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:31:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:32:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:32:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:32:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:32:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:32:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:32:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:32:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:32:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:32:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:32:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:32:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:32:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:32:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:32:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:32:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:32:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:33:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:33:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:33:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:33:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:33:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:33:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:33:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:33:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:33:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:33:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:33:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:33:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:34:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:34:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:34:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:34:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:34:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:34:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:34:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:34:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:34:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:34:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:34:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:34:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:35:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:35:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:35:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:35:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:35:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:35:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:35:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:35:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:35:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:35:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:35:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:35:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:35:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:35:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:35:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:35:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:36:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:36:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:36:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:36:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:36:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:36:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:36:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:36:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:36:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:36:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:36:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:36:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:37:890732:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:37:890725:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:37:890738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:37:890735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
PASSED [38.7653s] [ 36%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_mixture_of_experts_offload_true_no_shard_xpu [2025-09-12 10:34:39.892] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:34:39.893] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:34:39.914] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:34:39.921] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:34:40:890935 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:34:40:890935 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:34:40:890936 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:34:40:890936 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:34:40:890938 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:34:40:890938 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:34:40:890937 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:34:40:890937 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:34:53:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:53:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:53:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:53:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:53:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:53:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:53:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:53:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:54:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:54:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:54:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:54:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:54:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:54:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:54:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:54:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:54:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:54:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:54:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:54:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:55:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:55:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:55:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:55:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:55:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:55:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:55:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:55:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:55:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:55:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:55:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:55:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:56:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:56:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:56:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:56:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:56:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:56:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:56:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:56:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:56:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:56:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:56:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:56:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:57:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:57:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:57:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:57:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:57:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:57:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:57:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:57:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:57:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:57:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:57:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:57:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:58:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:58:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:58:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:58:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:58:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:58:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:58:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:58:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:58:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:58:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:58:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:58:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:59:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:59:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:59:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:59:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:59:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:59:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:59:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:59:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:59:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:59:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:59:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:59:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:59:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:59:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:59:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:34:59:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:00:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:00:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:00:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:00:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:00:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:00:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:00:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:00:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:00:891246:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:00:891236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:00:891247:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:00:891241:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [23.9416s] [ 38%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_mixture_of_experts_offload_true_none_xpu [2025-09-12 10:35:03.802] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:35:03.814] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:35:03.849] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:35:03.850] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:35:04:891494 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:35:04:891494 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:35:04:891492 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:35:04:891492 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:35:04:891493 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:35:04:891493 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:35:04:891491 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:35:04:891491 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:35:17:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:17:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:17:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:17:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:33:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:33:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:33:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:33:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:33:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:33:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:33:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:33:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:33:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:33:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:33:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:33:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:34:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:34:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:34:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:34:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:34:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:34:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:34:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:34:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:34:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:34:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:34:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:34:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:34:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:34:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:34:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:34:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:35:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:35:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:35:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:35:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:35:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:35:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:35:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:35:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:35:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:35:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:35:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:35:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:36:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:36:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:36:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:36:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:36:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:36:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:36:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:36:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:36:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:36:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:36:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:36:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:37:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:37:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:37:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:37:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:37:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:37:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:37:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:37:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:37:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:37:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:37:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:37:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:38:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:38:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:38:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:38:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:38:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:38:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:38:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:38:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:38:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:38:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:38:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:38:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:38:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:38:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:38:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:38:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:39:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:39:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:39:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:39:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:39:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:39:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:39:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:39:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:39:891807:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:39:891801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:39:891796:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:39:891798:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
PASSED [38.8656s] [ 40%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_mixture_of_experts_offload_true_shard_grad_op_xpu [2025-09-12 10:35:42.710] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:35:42.720] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:35:42.812] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:35:42.851] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:35:43:892055 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:35:43:892055 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:35:43:892054 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:35:43:892054 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:35:43:892053 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:35:43:892053 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:35:43:892052 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:35:43:892052 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:35:56:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:56:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:56:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:35:56:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:12:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:12:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:12:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:12:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:12:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:12:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:12:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:12:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:12:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:12:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:12:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:12:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:13:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:13:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:13:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:13:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:13:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:13:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:13:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:13:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:13:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:13:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:13:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:13:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:14:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:14:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:14:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:14:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:14:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:14:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:14:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:14:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:14:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:14:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:14:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:14:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:14:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:14:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:14:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:14:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:15:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:15:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:15:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:15:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:15:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:15:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:15:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:15:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:15:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:15:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:15:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:15:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:16:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:16:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:16:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:16:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:16:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:16:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:16:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:16:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:16:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:16:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:16:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:16:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:17:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:17:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:17:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:17:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:17:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:17:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:17:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:17:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:17:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:17:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:17:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:17:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:17:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:17:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:17:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:17:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:18:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:18:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:18:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:18:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:18:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:18:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:18:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:18:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:18:892357:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:18:892352:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:18:892367:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:18:892362:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [39.0659s] [ 41%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_mixture_of_experts_with_delay_before_free_offload_false_no_shard_xpu [2025-09-12 10:36:21.768] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:36:21.786] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:36:21.794] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:36:21.810] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:36:22:892611 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:36:22:892611 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:36:22:892610 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:36:22:892610 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:36:22:892613 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:36:22:892613 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:36:22:892612 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:36:22:892612 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:36:35:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:35:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:35:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:35:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:37:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:37:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:37:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:37:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:38:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:38:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:38:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:38:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:39:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:39:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:39:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:39:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:41:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:41:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:41:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:41:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:42:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:42:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:42:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:42:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:43:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:43:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:43:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:43:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:44:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:44:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:44:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:44:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:46:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:46:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:46:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:46:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:47:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:47:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:47:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:47:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:48:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:48:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:48:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:48:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:50:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:50:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:50:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:50:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:51:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:51:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:51:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:51:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:52:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:52:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:52:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:52:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:54:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:54:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:54:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:54:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:55:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:55:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:55:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:55:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:56:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:56:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:56:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:56:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:57:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:57:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:57:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:57:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:59:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:59:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:59:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:36:59:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:00:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:00:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:00:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:00:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:01:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:01:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:01:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:01:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:03:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:03:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:03:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:03:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:04:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:04:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:04:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:04:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:05:892922:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:05:892917:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:05:892912:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:05:892923:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [47.4746s] [ 43%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_mixture_of_experts_with_delay_before_free_offload_false_none_xpu [2025-09-12 10:37:09.208] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:37:09.231] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:37:09.237] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:37:09.256] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:37:09:893124 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:37:09:893124 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:37:09:893123 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:37:09:893123 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:37:09:893122 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:37:09:893122 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:37:09:893125 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:37:09:893125 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:37:23:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:23:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:23:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:23:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:39:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:39:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:39:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:39:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:40:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:40:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:40:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:40:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:42:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:42:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:42:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:42:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:43:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:43:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:43:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:43:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:44:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:44:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:44:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:44:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:46:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:46:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:46:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:46:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:47:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:47:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:47:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:47:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:48:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:48:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:48:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:48:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:50:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:50:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:50:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:50:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:51:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:51:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:51:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:51:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:52:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:52:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:52:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:52:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:54:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:54:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:54:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:54:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:55:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:55:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:55:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:55:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:56:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:56:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:56:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:56:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:57:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:57:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:57:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:57:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:59:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:59:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:59:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:37:59:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:00:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:00:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:00:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:00:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:01:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:01:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:01:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:01:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:03:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:03:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:03:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:03:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:04:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:04:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:04:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:04:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:05:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:05:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:05:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:05:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:07:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:07:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:07:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:07:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:08:893432:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:08:893437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:08:893431:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:08:893426:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [62.3983s] [ 45%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_mixture_of_experts_with_delay_before_free_offload_false_shard_grad_op_xpu [2025-09-12 10:38:11.642] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:38:11.647] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:38:11.654] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:38:11.676] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:38:12:893636 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:38:12:893636 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:38:12:893635 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:38:12:893635 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:38:12:893638 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:38:12:893638 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:38:12:893637 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:38:12:893637 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:38:25:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:25:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:25:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:25:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:42:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:42:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:42:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:42:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:43:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:43:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:43:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:43:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:44:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:44:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:44:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:44:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:46:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:46:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:46:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:46:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:47:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:47:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:47:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:47:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:48:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:48:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:48:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:48:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:50:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:50:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:50:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:50:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:51:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:51:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:51:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:51:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:52:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:52:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:52:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:52:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:53:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:53:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:53:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:53:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:55:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:55:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:55:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:55:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:56:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:56:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:56:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:56:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:57:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:57:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:57:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:57:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:59:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:59:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:59:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:38:59:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:00:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:00:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:00:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:00:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:01:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:01:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:01:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:01:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:03:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:03:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:03:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:03:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:04:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:04:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:04:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:04:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:05:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:05:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:05:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:05:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:07:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:07:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:07:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:07:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:08:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:08:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:08:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:08:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:09:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:09:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:09:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:09:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:10:893949:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:10:893935:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:10:893944:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:10:893942:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
PASSED [62.5994s] [ 46%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_mixture_of_experts_with_delay_before_free_offload_true_no_shard_xpu [2025-09-12 10:39:14.267] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:39:14.278] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:39:14.282] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:39:14.305] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:39:14:894148 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:39:14:894148 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:39:14:894146 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:39:14:894146 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:39:14:894145 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:39:14:894145 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:39:14:894147 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:39:14:894147 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:39:28:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:28:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:28:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:28:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:29:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:29:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:29:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:29:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:31:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:31:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:31:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:31:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:32:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:32:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:32:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:32:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:33:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:33:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:33:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:33:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:35:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:35:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:35:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:35:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:36:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:36:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:36:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:36:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:37:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:37:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:37:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:37:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:39:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:39:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:39:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:39:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:40:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:40:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:40:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:40:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:41:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:41:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:41:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:41:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:42:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:42:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:42:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:42:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:44:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:44:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:44:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:44:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:45:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:45:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:45:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:45:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:46:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:46:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:46:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:46:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:48:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:48:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:48:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:48:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:49:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:49:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:49:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:49:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:50:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:50:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:50:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:50:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:52:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:52:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:52:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:52:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:53:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:53:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:53:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:53:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:54:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:54:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:54:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:54:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:55:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:55:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:55:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:55:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:57:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:57:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:57:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:57:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:58:894446:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:58:894452:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:58:894461:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:39:58:894455:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
PASSED [47.7745s] [ 48%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_mixture_of_experts_with_delay_before_free_offload_true_none_xpu [2025-09-12 10:40:01.979] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:40:02.034] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:40:02.040] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:40:02.046] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:40:02:894706 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:40:02:894706 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:40:02:894704 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:40:02:894704 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:40:02:894703 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:40:02:894703 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:40:02:894705 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:40:02:894705 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:40:16:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:16:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:16:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:16:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:32:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:32:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:32:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:32:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:34:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:34:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:34:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:34:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:35:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:35:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:35:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:35:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:36:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:36:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:36:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:36:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:38:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:38:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:38:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:38:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:39:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:39:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:39:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:39:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:40:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:40:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:40:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:40:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:41:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:41:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:41:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:41:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:43:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:43:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:43:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:43:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:44:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:44:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:44:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:44:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:45:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:45:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:45:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:45:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:47:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:47:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:47:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:47:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:48:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:48:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:48:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:48:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:49:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:49:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:49:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:49:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:51:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:51:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:51:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:51:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:52:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:52:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:52:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:52:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:53:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:53:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:53:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:53:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:55:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:55:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:55:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:55:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:56:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:56:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:56:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:56:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:57:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:57:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:57:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:57:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:58:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:58:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:58:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:40:58:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:00:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:00:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:00:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:00:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:01:895017:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:01:895014:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:01:895011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:01:895004:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [62.8995s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_mixture_of_experts_with_delay_before_free_offload_true_shard_grad_op_xpu [2025-09-12 10:41:04.906] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:41:04.914] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:41:04.925] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:41:04.942] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:41:05:895265 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:41:05:895265 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:41:05:895267 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:41:05:895267 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:41:05:895266 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:41:05:895266 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:41:05:895264 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:41:05:895264 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:41:19:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:19:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:19:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:19:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:35:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:35:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:35:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:35:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:36:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:36:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:36:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:36:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:38:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:38:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:38:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:38:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:39:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:39:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:39:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:39:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:40:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:40:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:40:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:40:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:42:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:42:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:42:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:42:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:43:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:43:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:43:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:43:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:44:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:44:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:44:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:44:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:46:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:46:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:46:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:46:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:47:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:47:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:47:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:47:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:48:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:48:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:48:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:48:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:50:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:50:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:50:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:50:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:51:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:51:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:51:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:51:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:52:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:52:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:52:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:52:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:54:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:54:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:54:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:54:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:55:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:55:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:55:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:55:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:56:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:56:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:56:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:56:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:57:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:57:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:57:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:57:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:59:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:59:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:59:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:41:59:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:42:00:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:42:00:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:42:00:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:42:00:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:42:01:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:42:01:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:42:01:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:42:01:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:42:03:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:42:03:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:42:03:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:42:03:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:42:04:895564:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:42:04:895574:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:42:04:895577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-10:42:04:895571:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [62.9000s] [ 51%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_always_wrap_model_offload_false_no_shard_xpu [2025-09-12 10:42:07.808] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:42:07.830] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:42:07.846] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:42:07.855] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:42:08:895822 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:42:08:895822 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:42:08:895824 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:42:08:895824 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:42:08:895823 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:42:08:895823 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:42:08:895825 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:42:08:895825 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [17.0316s] [ 53%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_always_wrap_model_offload_false_none_xpu [2025-09-12 10:42:24.797] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:42:24.876] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:42:24.876] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:42:24.942] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:42:25:896140 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:42:25:896140 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:42:25:896139 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:42:25:896139 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:42:25:896142 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:42:25:896142 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:42:25:896141 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:42:25:896141 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [32.6564s] [ 55%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_always_wrap_model_offload_false_shard_grad_op_xpu [2025-09-12 10:42:57.510] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:42:57.515] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:42:57.517] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:42:57.538] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:42:57:896458 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:42:57:896458 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:42:57:896460 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:42:57:896460 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:42:57:896459 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:42:57:896459 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:42:58:896457 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:42:58:896457 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [32.9577s] [ 56%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_always_wrap_model_offload_true_no_shard_xpu [2025-09-12 10:43:30.438] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:43:30.499] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:43:30.499] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:43:30.522] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:43:30:896777 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:43:30:896777 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:43:30:896778 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:43:30:896778 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:43:31:896779 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:43:31:896779 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:43:31:896776 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:43:31:896776 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [17.4322s] [ 58%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_always_wrap_model_offload_true_none_xpu [2025-09-12 10:43:47.854] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:43:47.914] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:43:47.922] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:43:47.942] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:43:48:897095 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:43:48:897095 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:43:48:897097 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:43:48:897097 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:43:48:897096 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:43:48:897096 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:43:48:897094 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:43:48:897094 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [33.2504s] [ 60%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_always_wrap_model_offload_true_shard_grad_op_xpu [2025-09-12 10:44:21.122] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:44:21.158] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:44:21.180] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:44:21.194] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:44:21:897411 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:44:21:897411 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:44:21:897414 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:44:21:897414 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:44:21:897413 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:44:21:897413 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:44:21:897412 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:44:21:897412 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
PASSED [32.8516s] [ 61%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_wrapped_model_offload_false_no_shard_xpu [2025-09-12 10:44:53.990] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:44:53.994] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:44:54.009] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:44:54.030] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:44:54:897732 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:44:54:897732 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:44:54:897729 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:44:54:897729 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:44:54:897731 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:44:54:897731 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:44:54:897730 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:44:54:897730 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [16.8312s] [ 63%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_wrapped_model_offload_false_none_xpu [2025-09-12 10:45:10.808] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:45:10.826] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:45:10.837] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:45:10.858] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:45:11:898048 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:45:11:898048 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:45:11:898049 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:45:11:898049 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:45:11:898047 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:45:11:898047 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:45:11:898046 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:45:11:898046 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
FAILED [31.8572s] [ 65%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_wrapped_model_offload_false_shard_grad_op_xpu [2025-09-12 10:45:42.710] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:45:42.726] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:45:42.738] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:45:42.754] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:45:43:898364 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:45:43:898364 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:45:43:898363 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:45:43:898363 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:45:43:898366 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:45:43:898366 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:45:43:898365 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:45:43:898365 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [32.7505s] [ 66%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_wrapped_model_offload_true_no_shard_xpu [2025-09-12 10:46:15.426] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:46:15.427] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:46:15.427] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:46:15.442] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:46:15:898684 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:46:15:898684 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:46:15:898682 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:46:15:898682 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:46:15:898681 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:46:15:898681 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:46:15:898683 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:46:15:898683 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [17.2260s] [ 68%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_wrapped_model_offload_true_none_xpu [2025-09-12 10:46:32.670] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:46:32.670] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:46:32.678] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:46:32.690] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:46:33:898998 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:46:33:898998 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:46:33:899001 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:46:33:899001 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:46:33:898999 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:46:33:898999 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:46:33:899000 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:46:33:899000 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
FAILED [31.4497s] [ 70%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_wrapped_model_offload_true_shard_grad_op_xpu [2025-09-12 10:47:04.098] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:47:04.144] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:47:04.170] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:47:04.171] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:47:04:899316 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:47:04:899316 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:47:04:899317 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:47:04:899317 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:47:04:899315 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:47:04:899315 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:47:04:899318 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:47:04:899318 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [32.5573s] [ 71%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_wrapped_model_single_iteration_mixed_precision_offload_false_no_shard_xpu [2025-09-12 10:47:36.654] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:47:36.692] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:47:36.712] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:47:36.774] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:47:37:899634 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:47:37:899634 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:47:37:899635 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:47:37:899635 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:47:37:899637 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:47:37:899637 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:47:37:899636 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:47:37:899636 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [16.6317s] [ 73%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_wrapped_model_single_iteration_mixed_precision_offload_false_none_xpu [2025-09-12 10:47:53.326] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:47:53.338] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:47:53.353] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:47:53.358] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:47:53:899951 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:47:53:899951 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:47:53:899952 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:47:53:899952 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:47:53:899950 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:47:53:899950 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:47:53:899953 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:47:53:899953 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [17.0248s] [ 75%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_wrapped_model_single_iteration_mixed_precision_offload_false_shard_grad_op_xpu [2025-09-12 10:48:10.320] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:48:10.338] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:48:10.347] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:48:10.348] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:48:10:900267 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:48:10:900267 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:48:10:900269 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:48:10:900269 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:48:10:900266 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:48:10:900266 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:48:10:900268 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:48:10:900268 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [17.1310s] [ 76%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_wrapped_model_single_iteration_mixed_precision_offload_true_no_shard_xpu [2025-09-12 10:48:27.461] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:48:27.484] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:48:27.506] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:48:27.540] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:48:27:900582 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:48:27:900583 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:48:27:900582 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:48:27:900583 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:48:27:900585 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:48:27:900585 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:48:27:900584 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:48:27:900584 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [16.9317s] [ 78%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_wrapped_model_single_iteration_mixed_precision_offload_true_none_xpu [2025-09-12 10:48:44.376] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:48:44.394] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:48:44.402] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:48:44.427] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:48:44:900899 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:48:44:900899 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:48:44:900902 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:48:44:900902 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:48:44:900901 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:48:44:900901 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:48:44:900900 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:48:44:900900 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [17.0323s] [ 80%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_wrapped_model_single_iteration_mixed_precision_offload_true_shard_grad_op_xpu [2025-09-12 10:49:01.406] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:49:01.482] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:49:01.486] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:49:01.495] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:49:01:901216 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:49:01:901216 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:49:01:901217 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:49:01:901217 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:49:02:901218 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:49:02:901218 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:49:02:901215 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:49:02:901215 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
PASSED [16.9307s] [ 81%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_transformer_offload_false_no_shard_xpu [2025-09-12 10:49:18.358] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:49:18.374] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:49:18.378] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:49:18.390] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:49:18:901533 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:49:18:901533 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:49:18:901534 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:49:18:901534 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:49:18:901535 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:49:18:901535 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:49:18:901532 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:49:18:901532 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [19.3350s] [ 83%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_transformer_offload_false_none_xpu [2025-09-12 10:49:37.694] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:49:37.694] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:49:37.716] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:49:37.738] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:49:38:901849 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:49:38:901849 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:49:38:901851 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:49:38:901851 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:49:38:901850 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:49:38:901850 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:49:38:901852 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:49:38:901852 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
FAILED [31.5541s] [ 85%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_transformer_offload_false_shard_grad_op_xpu [2025-09-12 10:50:09.271] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:50:09.273] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:50:09.290] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:50:09.323] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:50:09:902167 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:50:09:902167 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:50:09:902166 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:50:09:902166 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:50:09:902169 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:50:09:902169 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:50:09:902168 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:50:09:902168 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [34.8424s] [ 86%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_transformer_offload_true_no_shard_xpu [2025-09-12 10:50:44.074] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:50:44.120] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:50:44.126] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:50:44.142] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:50:44:902487 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:50:44:902487 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:50:44:902488 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:50:44:902488 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:50:44:902486 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:50:44:902486 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:50:44:902489 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:50:44:902489 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [20.1357s] [ 88%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_transformer_offload_true_none_xpu [2025-09-12 10:51:04.380] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:51:04.383] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:51:04.403] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:51:04.403] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:51:04:902804 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:51:04:902804 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:51:04:902805 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:51:04:902805 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:51:04:902807 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:51:04:902807 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:51:04:902806 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:51:04:902806 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
FAILED [32.5567s] [ 90%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_transformer_offload_true_shard_grad_op_xpu [2025-09-12 10:51:36.791] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:51:36.804] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:51:36.804] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:51:36.804] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:51:37:903123 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:51:37:903123 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:51:37:903124 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:51:37:903124 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:51:37:903125 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:51:37:903125 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:51:37:903122 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:51:37:903122 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [35.6434s] [ 91%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestNoGradXPU::test_transformer_no_grad_mixed_precision_False_xpu [2025-09-12 10:52:12.410] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:52:12.442] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:52:12.466] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:52:12.467] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:52:12:903443 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:52:12:903443 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:52:12:903442 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:52:12:903442 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:52:12:903441 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:52:12:903441 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:52:12:903440 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:52:12:903440 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [31.7429s] [ 93%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestNoGradXPU::test_transformer_no_grad_mixed_precision_True_xpu [2025-09-12 10:52:44.147] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:52:44.183] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:52:44.193] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:52:44.206] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:52:44:903762 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:52:44:903762 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:52:44:903760 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:52:44:903760 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:52:44:903759 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:52:44:903759 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:52:44:903761 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:52:44:903761 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
FAILED [31.9583s] [ 95%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParamInitXPU::test_param_change_after_init_mixed_precision_False_xpu [2025-09-12 10:53:16.131] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:53:16.146] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:53:16.163] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:53:16.186] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:53:16:904078 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:53:16:904078 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:53:16:904076 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:53:16:904076 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:53:16:904079 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:53:16:904079 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:53:16:904077 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:53:16:904077 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [16.3285s] [ 96%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestParamInitXPU::test_param_change_after_init_mixed_precision_True_xpu [2025-09-12 10:53:32.531] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:53:32.531] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:53:32.539] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:53:32.550] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:53:32:904378 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:53:32:904378 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:53:32:904381 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:53:32:904381 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:53:33:904380 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:53:33:904380 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:53:33:904379 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:53:33:904379 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
PASSED [16.2305s] [ 98%]
../../../../test/distributed/fsdp/test_fsdp_core.py::TestAutogradXPU::test_unshard_params_as_tensors_xpu [2025-09-12 10:53:48.746] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:53:48.753] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:53:48.756] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:53:48.774] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:53:49:904681 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:53:49:904681 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:53:49:904678 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:53:49:904678 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:53:49:904680 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:53:49:904680 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:53:49:904679 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:53:49:904679 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
PASSED [32.3577s] [100%]

=================================== FAILURES ===================================
_____ TestParityWithDDPXPU.test_delayed_optim_step_offload_false_none_xpu ______
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 189, in test_delayed_optim_step
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_optim_step_offload_false_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 189, in test_delayed_optim_step
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_optim_step_offload_false_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 189, in test_delayed_optim_step
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_optim_step_offload_false_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 1 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 10:24:36.621000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 885896
I0912 10:24:36.621000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 885897
I0912 10:24:36.622000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 885898
I0912 10:24:36.622000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 885899
______ TestParityWithDDPXPU.test_delayed_optim_step_offload_true_none_xpu ______
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 189, in test_delayed_optim_step
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_optim_step_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 189, in test_delayed_optim_step
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_optim_step_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 189, in test_delayed_optim_step
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_optim_step_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 189, in test_delayed_optim_step
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_optim_step_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 0 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 10:26:53.047000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 886852
I0912 10:26:53.047000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 886853
I0912 10:26:53.048000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 886854
I0912 10:26:53.048000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 886855
___ TestParityWithDDPXPU.test_delayed_reduce_scatter_offload_false_none_xpu ____
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 210, in test_delayed_reduce_scatter
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_reduce_scatter_offload_false_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 210, in test_delayed_reduce_scatter
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_reduce_scatter_offload_false_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 210, in test_delayed_reduce_scatter
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_reduce_scatter_offload_false_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 210, in test_delayed_reduce_scatter
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_reduce_scatter_offload_false_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 0 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 10:28:52.346000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 887805
I0912 10:28:52.346000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 887806
I0912 10:28:52.347000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 887807
I0912 10:28:52.347000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 887808
____ TestParityWithDDPXPU.test_delayed_reduce_scatter_offload_true_none_xpu ____
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 210, in test_delayed_reduce_scatter
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: 0.007877256721258163 at index (1, 0) (up to 1e-05 allowed)
Greatest relative difference: 0.533108115196228 at index (1, 7) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_reduce_scatter_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 210, in test_delayed_reduce_scatter
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: 0.007877256721258163 at index (1, 0) (up to 1e-05 allowed)
Greatest relative difference: 0.533108115196228 at index (1, 7) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_reduce_scatter_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 1 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 10:31:03.261000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 888760
I0912 10:31:03.261000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 888761
I0912 10:31:03.262000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 888762
I0912 10:31:03.262000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 888763
____ TestParityWithDDPXPU.test_nested_wrapped_model_offload_false_none_xpu _____
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 113, in test_nested_wrapped_model
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_nested_wrapped_model_offload_false_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 1 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 10:45:08.968000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 898046
I0912 10:45:08.969000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 898047
I0912 10:45:08.969000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 898048
I0912 10:45:08.970000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 898049
_____ TestParityWithDDPXPU.test_nested_wrapped_model_offload_true_none_xpu _____
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 113, in test_nested_wrapped_model
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_nested_wrapped_model_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 113, in test_nested_wrapped_model
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_nested_wrapped_model_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 1 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 10:46:30.806000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 898998
I0912 10:46:30.806000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 898999
I0912 10:46:30.807000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 899000
I0912 10:46:30.807000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 899001
_________ TestParityWithDDPXPU.test_transformer_offload_false_none_xpu _________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 168, in test_transformer
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1484, in _test_fsdp_parity
    torch.testing.assert_close(ref_loss, fsdp_loss, check_dtype=False)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Scalars are not close!

Expected 17.723793029785156 but got 17.822208404541016.
Absolute difference: 0.09841537475585938 (up to 1e-05 allowed)
Relative difference: 0.0055527264728532175 (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_transformer_offload_false_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 2 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 10:49:35.841000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 901849
I0912 10:49:35.841000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 901850
I0912 10:49:35.842000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 901851
I0912 10:49:35.842000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 901852
_________ TestParityWithDDPXPU.test_transformer_offload_true_none_xpu __________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 168, in test_transformer
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1484, in _test_fsdp_parity
    torch.testing.assert_close(ref_loss, fsdp_loss, check_dtype=False)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Scalars are not close!

Expected 17.804584503173828 but got 17.822208404541016.
Absolute difference: 0.0176239013671875 (up to 1e-05 allowed)
Relative difference: 0.0009898518757371665 (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_transformer_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 168, in test_transformer
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1484, in _test_fsdp_parity
    torch.testing.assert_close(ref_loss, fsdp_loss, check_dtype=False)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Scalars are not close!

Expected 17.804584503173828 but got 17.822208404541016.
Absolute difference: 0.0176239013671875 (up to 1e-05 allowed)
Relative difference: 0.0009898518757371665 (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_transformer_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 1 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 10:51:02.376000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 902804
I0912 10:51:02.377000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 902805
I0912 10:51:02.378000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 902806
I0912 10:51:02.378000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 902807
_______ TestNoGradXPU.test_transformer_no_grad_mixed_precision_True_xpu ________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 434, in test_transformer_no_grad
    self.assertEqual(ref_output, no_grad_output)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 68 / 184 (37.0%)
Greatest absolute difference: 0.01171875 at index (0, 1, 12) (up to 1e-05 allowed)
Greatest relative difference: 0.08544921875 at index (3, 0, 14) (up to 0.001 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestNoGradXPU.test_transformer_no_grad_mixed_precision_True_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 434, in test_transformer_no_grad
    self.assertEqual(ref_output, no_grad_output)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 68 / 184 (37.0%)
Greatest absolute difference: 0.01171875 at index (0, 1, 12) (up to 1e-05 allowed)
Greatest relative difference: 0.08544921875 at index (3, 0, 14) (up to 0.001 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestNoGradXPU.test_transformer_no_grad_mixed_precision_True_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 434, in test_transformer_no_grad
    self.assertEqual(ref_output, no_grad_output)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 68 / 184 (37.0%)
Greatest absolute difference: 0.01171875 at index (0, 1, 12) (up to 1e-05 allowed)
Greatest relative difference: 0.08544921875 at index (3, 0, 14) (up to 0.001 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestNoGradXPU.test_transformer_no_grad_mixed_precision_True_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 434, in test_transformer_no_grad
    self.assertEqual(ref_output, no_grad_output)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 68 / 184 (37.0%)
Greatest absolute difference: 0.01171875 at index (0, 1, 12) (up to 1e-05 allowed)
Greatest relative difference: 0.08544921875 at index (3, 0, 14) (up to 0.001 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestNoGradXPU.test_transformer_no_grad_mixed_precision_True_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 0 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 10:52:42.324000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 903759
I0912 10:52:42.324000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 903760
I0912 10:52:42.325000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 903761
I0912 10:52:42.325000 883350 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 903762
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_core.py.xml -
=========================== short test summary info ============================
FAILED [32.6571s] ../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_delayed_optim_step_offload_false_none_xpu - RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 189, in test_delayed_optim_step
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_optim_step_offload_false_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 189, in test_delayed_optim_step
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_optim_step_offload_false_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 189, in test_delayed_optim_step
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_optim_step_offload_false_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [39.5670s] ../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_delayed_optim_step_offload_true_none_xpu - RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 189, in test_delayed_optim_step
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_optim_step_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 189, in test_delayed_optim_step
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_optim_step_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 189, in test_delayed_optim_step
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_optim_step_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 189, in test_delayed_optim_step
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_optim_step_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [33.5584s] ../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_delayed_reduce_scatter_offload_false_none_xpu - RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 210, in test_delayed_reduce_scatter
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_reduce_scatter_offload_false_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 210, in test_delayed_reduce_scatter
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_reduce_scatter_offload_false_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 210, in test_delayed_reduce_scatter
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_reduce_scatter_offload_false_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 210, in test_delayed_reduce_scatter
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_reduce_scatter_offload_false_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [33.7597s] ../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_delayed_reduce_scatter_offload_true_none_xpu - RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 210, in test_delayed_reduce_scatter
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: 0.007877256721258163 at index (1, 0) (up to 1e-05 allowed)
Greatest relative difference: 0.533108115196228 at index (1, 7) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_reduce_scatter_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 210, in test_delayed_reduce_scatter
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: 0.007877256721258163 at index (1, 0) (up to 1e-05 allowed)
Greatest relative difference: 0.533108115196228 at index (1, 7) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_delayed_reduce_scatter_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [31.8572s] ../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_wrapped_model_offload_false_none_xpu - RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 113, in test_nested_wrapped_model
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_nested_wrapped_model_offload_false_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [31.4497s] ../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_nested_wrapped_model_offload_true_none_xpu - RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 113, in test_nested_wrapped_model
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_nested_wrapped_model_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 113, in test_nested_wrapped_model
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_nested_wrapped_model_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [31.5541s] ../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_transformer_offload_false_none_xpu - RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 168, in test_transformer
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1484, in _test_fsdp_parity
    torch.testing.assert_close(ref_loss, fsdp_loss, check_dtype=False)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Scalars are not close!

Expected 17.723793029785156 but got 17.822208404541016.
Absolute difference: 0.09841537475585938 (up to 1e-05 allowed)
Relative difference: 0.0055527264728532175 (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_transformer_offload_false_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [32.5567s] ../../../../test/distributed/fsdp/test_fsdp_core.py::TestParityWithDDPXPU::test_transformer_offload_true_none_xpu - RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 168, in test_transformer
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1484, in _test_fsdp_parity
    torch.testing.assert_close(ref_loss, fsdp_loss, check_dtype=False)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Scalars are not close!

Expected 17.804584503173828 but got 17.822208404541016.
Absolute difference: 0.0176239013671875 (up to 1e-05 allowed)
Relative difference: 0.0009898518757371665 (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_transformer_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 168, in test_transformer
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1484, in _test_fsdp_parity
    torch.testing.assert_close(ref_loss, fsdp_loss, check_dtype=False)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Scalars are not close!

Expected 17.804584503173828 but got 17.822208404541016.
Absolute difference: 0.0176239013671875 (up to 1e-05 allowed)
Relative difference: 0.0009898518757371665 (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestParityWithDDPXPU.test_transformer_offload_true_none_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [31.9583s] ../../../../test/distributed/fsdp/test_fsdp_core.py::TestNoGradXPU::test_transformer_no_grad_mixed_precision_True_xpu - RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 434, in test_transformer_no_grad
    self.assertEqual(ref_output, no_grad_output)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 68 / 184 (37.0%)
Greatest absolute difference: 0.01171875 at index (0, 1, 12) (up to 1e-05 allowed)
Greatest relative difference: 0.08544921875 at index (3, 0, 14) (up to 0.001 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestNoGradXPU.test_transformer_no_grad_mixed_precision_True_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 434, in test_transformer_no_grad
    self.assertEqual(ref_output, no_grad_output)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 68 / 184 (37.0%)
Greatest absolute difference: 0.01171875 at index (0, 1, 12) (up to 1e-05 allowed)
Greatest relative difference: 0.08544921875 at index (3, 0, 14) (up to 0.001 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestNoGradXPU.test_transformer_no_grad_mixed_precision_True_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 434, in test_transformer_no_grad
    self.assertEqual(ref_output, no_grad_output)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 68 / 184 (37.0%)
Greatest absolute difference: 0.01171875 at index (0, 1, 12) (up to 1e-05 allowed)
Greatest relative difference: 0.08544921875 at index (3, 0, 14) (up to 0.001 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestNoGradXPU.test_transformer_no_grad_mixed_precision_True_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_core.py", line 434, in test_transformer_no_grad
    self.assertEqual(ref_output, no_grad_output)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 68 / 184 (37.0%)
Greatest absolute difference: 0.01171875 at index (0, 1, 12) (up to 1e-05 allowed)
Greatest relative difference: 0.08544921875 at index (3, 0, 14) (up to 0.001 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_core.py TestNoGradXPU.test_transformer_no_grad_mixed_precision_True_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
================== 9 failed, 51 passed in 1985.43s (0:33:05) ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 10:54:22.059] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 15 items
Running 15 items in this shard

../../../../test/distributed/fsdp/test_fsdp_dtensor_state_dict.py::TestFSDPWithDeviceMeshAndDTensorXPU::test_dtensor_sharded_model_load_state_dict_offload_to_cpu_False_is_even_sharded_model_False_xpu [2025-09-12 10:54:24.250] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:54:24.250] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:54:24.262] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:54:24.266] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:54:24:905078 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:54:24:905078 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:54:24:905080 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:54:24:905080 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:54:24:905079 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:54:24:905079 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:54:24:905081 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:54:24:905081 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.6563s] [  6%]
../../../../test/distributed/fsdp/test_fsdp_dtensor_state_dict.py::TestFSDPWithDeviceMeshAndDTensorXPU::test_dtensor_sharded_model_load_state_dict_offload_to_cpu_False_is_even_sharded_model_True_xpu [2025-09-12 10:54:55.858] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:54:55.898] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:54:55.898] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:54:55.918] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:54:56:905398 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:54:56:905398 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:54:56:905397 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:54:56:905396 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:54:56:905396 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:54:56:905397 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:54:56:905395 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:54:56:905395 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.8565s] [ 13%]
../../../../test/distributed/fsdp/test_fsdp_dtensor_state_dict.py::TestFSDPWithDeviceMeshAndDTensorXPU::test_dtensor_sharded_model_load_state_dict_offload_to_cpu_True_is_even_sharded_model_False_xpu [2025-09-12 10:55:27.730] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:55:27.737] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:55:27.750] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:55:27.802] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:55:28:905714 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:55:28:905714 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:55:28:905715 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:55:28:905715 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:55:28:905716 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:55:28:905716 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:55:28:905713 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:55:28:905713 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.7484s] [ 20%]
../../../../test/distributed/fsdp/test_fsdp_dtensor_state_dict.py::TestFSDPWithDeviceMeshAndDTensorXPU::test_dtensor_sharded_model_load_state_dict_offload_to_cpu_True_is_even_sharded_model_True_xpu [2025-09-12 10:55:59.483] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:55:59.490] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:55:59.490] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:55:59.497] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:55:59:906034 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:55:59:906034 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:55:59:906032 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:55:59:906032 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:55:59:906031 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:55:59:906031 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:56:00:906033 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:56:00:906033 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.7472s] [ 26%]
../../../../test/distributed/fsdp/test_fsdp_dtensor_state_dict.py::TestFSDPWithDeviceMeshAndDTensorXPU::test_dtensor_sharded_optim_load_state_dict_offload_to_cpu_False_is_even_sharded_model_False_xpu [2025-09-12 10:56:31.237] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:56:31.258] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:56:31.264] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:56:31.266] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:56:31:906355 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:56:31:906355 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:56:31:906353 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:56:31:906353 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:56:31:906354 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:56:31:906354 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:56:31:906352 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:56:31:906352 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.7559s] [ 33%]
../../../../test/distributed/fsdp/test_fsdp_dtensor_state_dict.py::TestFSDPWithDeviceMeshAndDTensorXPU::test_dtensor_sharded_optim_load_state_dict_offload_to_cpu_False_is_even_sharded_model_True_xpu [2025-09-12 10:57:02.979] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:57:03.002] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:57:03.030] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:57:03.038] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:57:03:906672 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:57:03:906672 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:57:03:906671 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:57:03:906671 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:57:03:906673 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:57:03:906673 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:57:03:906670 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:57:03:906670 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.9569s] [ 40%]
../../../../test/distributed/fsdp/test_fsdp_dtensor_state_dict.py::TestFSDPWithDeviceMeshAndDTensorXPU::test_dtensor_sharded_optim_load_state_dict_offload_to_cpu_True_is_even_sharded_model_False_xpu [2025-09-12 10:57:34.944] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:57:34.962] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:57:34.975] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:57:34.999] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:57:35:906989 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:57:35:906989 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:57:35:906990 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:57:35:906990 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:57:35:906988 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:57:35:906988 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:57:35:906987 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:57:35:906987 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.9566s] [ 46%]
../../../../test/distributed/fsdp/test_fsdp_dtensor_state_dict.py::TestFSDPWithDeviceMeshAndDTensorXPU::test_dtensor_sharded_optim_load_state_dict_offload_to_cpu_True_is_even_sharded_model_True_xpu [2025-09-12 10:58:06.916] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:58:06.916] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:58:06.916] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:58:06.942] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:58:07:907305 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:58:07:907305 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:58:07:907308 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:58:07:907308 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:58:07:907306 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:58:07:907306 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:58:07:907307 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:58:07:907307 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.7560s] [ 53%]
../../../../test/distributed/fsdp/test_fsdp_dtensor_state_dict.py::TestFSDPWithDeviceMeshAndDTensorXPU::test_dtensor_sharded_tensor_state_dict_identical_offload_to_cpu_False_is_even_sharded_model_False_xpu [2025-09-12 10:58:38.678] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:58:38.683] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:58:38.686] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:58:38.702] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:58:39:907628 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:58:39:907628 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:58:39:907626 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:58:39:907626 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:58:39:907625 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:58:39:907625 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:58:39:907627 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:58:39:907627 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.5558s] [ 60%]
../../../../test/distributed/fsdp/test_fsdp_dtensor_state_dict.py::TestFSDPWithDeviceMeshAndDTensorXPU::test_dtensor_sharded_tensor_state_dict_identical_offload_to_cpu_False_is_even_sharded_model_True_xpu [2025-09-12 10:59:10.215] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:59:10.234] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:59:10.237] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:59:10.242] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:59:10:907942 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:59:10:907942 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:59:10:907945 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:59:10:907945 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:59:10:907943 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:59:10:907943 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:59:10:907944 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:59:10:907944 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.5557s] [ 66%]
../../../../test/distributed/fsdp/test_fsdp_dtensor_state_dict.py::TestFSDPWithDeviceMeshAndDTensorXPU::test_dtensor_sharded_tensor_state_dict_identical_offload_to_cpu_True_is_even_sharded_model_False_xpu [2025-09-12 10:59:41.786] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:59:41.798] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:59:41.819] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 10:59:41.866] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-10:59:42:908261 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:59:42:908261 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:59:42:908260 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:59:42:908260 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:59:42:908262 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:59:42:908262 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-10:59:42:908263 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-10:59:42:908263 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.5543s] [ 73%]
../../../../test/distributed/fsdp/test_fsdp_dtensor_state_dict.py::TestFSDPWithDeviceMeshAndDTensorXPU::test_dtensor_sharded_tensor_state_dict_identical_offload_to_cpu_True_is_even_sharded_model_True_xpu [2025-09-12 11:00:13.333] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:00:13.350] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:00:13.354] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:00:13.367] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:00:13:908578 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:00:13:908578 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:00:13:908579 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:00:13:908579 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:00:13:908580 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:00:13:908580 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:00:13:908581 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:00:13:908581 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.2557s] [ 80%]
../../../../test/distributed/fsdp/test_fsdp_dtensor_state_dict.py::TestFSDPWithDeviceMeshAndDTensorXPU::test_fsdp_init_with_device_mesh_is_even_sharded_model_False_xpu [2025-09-12 11:00:44.559] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:00:44.611] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:00:44.611] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:00:44.645] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:00:45:908899 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:00:45:908899 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:00:45:908897 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:00:45:908897 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:00:45:908898 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:00:45:908898 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:00:45:908896 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:00:45:908896 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.5559s] [ 86%]
../../../../test/distributed/fsdp/test_fsdp_dtensor_state_dict.py::TestFSDPWithDeviceMeshAndDTensorXPU::test_fsdp_init_with_device_mesh_is_even_sharded_model_True_xpu [2025-09-12 11:01:16.181] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:01:16.186] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:01:16.187] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:01:16.196] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:01:16:909215 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:01:16:909215 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:01:16:909216 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:01:16:909216 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:01:16:909217 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:01:16:909217 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:01:16:909214 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:01:16:909214 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.4556s] [ 93%]
../../../../test/distributed/fsdp/test_fsdp_dtensor_state_dict.py::TestFSDPWithDeviceMeshAndDTensorXPU::test_raises_warning_or_errors_xpu [2025-09-12 11:01:47.646] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:01:47.654] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:01:47.656] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:01:47.678] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:01:48:909534 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:01:48:909534 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:01:48:909535 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:01:48:909535 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:01:48:909533 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:01:48:909533 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:01:48:909532 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:01:48:909532 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.4579s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_dtensor_state_dict.py.xml -
======================== 15 passed in 477.02s (0:07:57) ========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 11:02:20.023] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 8 items
Running 8 items in this shard

../../../../test/distributed/fsdp/test_fsdp_exec_order.py::TestFSDPExecOrderXPU::test_invalid_first_iter_order_sharding_strategy0_xpu [2025-09-12 11:02:22.199] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:02:22.209] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:02:22.210] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:02:22.218] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:02:22:909925 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:02:22:909925 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:02:22:909928 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:02:22:909928 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:02:22:909926 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:02:22:909926 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:02:22:909927 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:02:22:909927 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [15.9251s] [ 12%]
../../../../test/distributed/fsdp/test_fsdp_exec_order.py::TestFSDPExecOrderXPU::test_invalid_first_iter_order_sharding_strategy1_xpu [2025-09-12 11:02:38.117] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:02:38.138] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:02:38.146] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:02:38.154] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:02:38:910227 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:02:38:910227 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:02:38:910228 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:02:38:910228 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:02:38:910226 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:02:38:910226 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:02:38:910229 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:02:38:910229 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [16.0300s] [ 25%]
../../../../test/distributed/fsdp/test_fsdp_exec_order.py::TestFSDPExecOrderXPU::test_invalid_later_iter_order_sharding_strategy0_iters_before_path_change_1_xpu [2025-09-12 11:02:54.149] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:02:54.170] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:02:54.174] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:02:54.177] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:02:54:910529 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:02:54:910529 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:02:54:910526 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:02:54:910526 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:02:54:910527 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:02:54:910527 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:02:54:910528 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:02:54:910528 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [31.6563s] [ 37%]
../../../../test/distributed/fsdp/test_fsdp_exec_order.py::TestFSDPExecOrderXPU::test_invalid_later_iter_order_sharding_strategy0_iters_before_path_change_3_xpu [2025-09-12 11:03:25.803] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:03:25.803] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:03:25.805] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:03:25.808] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:03:26:910842 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:03:26:910842 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:03:26:910844 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:03:26:910844 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:03:26:910845 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:03:26:910845 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:03:26:910843 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:03:26:910843 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [31.1546s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_exec_order.py::TestFSDPExecOrderXPU::test_invalid_later_iter_order_sharding_strategy1_iters_before_path_change_1_xpu [2025-09-12 11:03:56.967] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:03:56.977] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:03:56.981] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:03:56.996] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:03:57:911162 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:03:57:911162 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:03:57:911161 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:03:57:911161 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:03:57:911164 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:03:57:911164 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:03:57:911163 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:03:57:911163 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [31.7572s] [ 62%]
../../../../test/distributed/fsdp/test_fsdp_exec_order.py::TestFSDPExecOrderXPU::test_invalid_later_iter_order_sharding_strategy1_iters_before_path_change_3_xpu [2025-09-12 11:04:28.718] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:04:28.720] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:04:28.734] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:04:28.738] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:04:29:911481 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:04:29:911481 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:04:29:911480 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:04:29:911480 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:04:29:911483 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:04:29:911483 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:04:29:911482 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:04:29:911482 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.3551s] [ 75%]
../../../../test/distributed/fsdp/test_fsdp_exec_order.py::TestFSDPExecOrderXPU::test_train_eval_sharding_strategy0_xpu [2025-09-12 11:05:00.062] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:05:00.087] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:05:00.094] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:05:00.102] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:05:00:911797 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:05:00:911797 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:05:00:911799 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:05:00:911799 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:05:00:911798 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:05:00:911798 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:05:00:911800 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:05:00:911800 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [31.5561s] [ 87%]
../../../../test/distributed/fsdp/test_fsdp_exec_order.py::TestFSDPExecOrderXPU::test_train_eval_sharding_strategy1_xpu [2025-09-12 11:05:31.655] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:05:31.658] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:05:31.670] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:05:31.678] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:05:32:912116 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:05:32:912116 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:05:32:912117 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:05:32:912117 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:05:32:912115 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:05:32:912115 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:05:32:912114 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:05:32:912114 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [31.4561s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_exec_order.py.xml -
======================== 8 passed in 223.08s (0:03:43) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 11:06:03.922] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 4 items
Running 4 items in this shard

../../../../test/distributed/fsdp/test_fsdp_fine_tune.py::TestFSDPFineTuneXPU::test_backward_reshard_hooks_xpu [2025-09-12 11:06:06.148] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:06:06.166] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:06:06:912508 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:06:06:912508 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:06:06:912507 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:06:06:912507 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.8434s] [ 25%]
../../../../test/distributed/fsdp/test_fsdp_fine_tune.py::TestFSDPFineTuneXPU::test_hooks_multi_traversal_xpu [2025-09-12 11:06:36.934] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:06:36.938] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:06:37:912667 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:06:37:912667 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:06:37:912668 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:06:37:912668 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [33.5411s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_fine_tune.py::TestFSDPFineTuneXPU::test_parity_with_ddp_xpu [2025-09-12 11:07:10.502] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:07:10.522] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:07:10:912826 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:07:10:912826 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:07:10:912825 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:07:10:912825 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.8506s] [ 75%]
../../../../test/distributed/fsdp/test_fsdp_fine_tune.py::TestFSDPFineTuneXPU::test_parity_with_non_frozen_fsdp_xpu [2025-09-12 11:07:41.360] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:07:41.374] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:07:41:912985 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:07:41:912985 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:07:41:912986 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:07:41:912986 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [33.1522s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_fine_tune.py.xml -
======================== 4 passed in 130.48s (0:02:10) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 11:08:15.466] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 14 items
Running 14 items in this shard

../../../../test/distributed/fsdp/test_fsdp_flatten_params.py::TestFlattenParams::test_empty_module [2025-09-12 11:08:17.742] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:08:17:913220 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:08:17:913220 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.2144s] [  7%]
../../../../test/distributed/fsdp/test_fsdp_flatten_params.py::TestFlattenParams::test_flat_param_shard_metadata_aligned_full_precision [2025-09-12 11:08:20.666] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:08:20:913294 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:08:20:913294 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [2.9065s] [ 14%]
../../../../test/distributed/fsdp/test_fsdp_flatten_params.py::TestFlattenParams::test_flat_param_shard_metadata_aligned_mixed_precision [2025-09-12 11:08:23.574] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:08:23:913368 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:08:23:913368 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [2.9064s] [ 21%]
../../../../test/distributed/fsdp/test_fsdp_flatten_params.py::TestFlattenParams::test_flat_param_shard_metadata_unaligned [2025-09-12 11:08:26.478] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:08:26:913442 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:08:26:913442 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.0066s] [ 28%]
../../../../test/distributed/fsdp/test_fsdp_flatten_params.py::TestFlattenParams::test_flat_param_shard_metadata_with_memory_format_memory_format0 [2025-09-12 11:08:29.478] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:08:29:913516 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:08:29:913516 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [2.9062s] [ 35%]
../../../../test/distributed/fsdp/test_fsdp_flatten_params.py::TestFlattenParams::test_flat_param_shard_metadata_with_memory_format_memory_format1 [2025-09-12 11:08:32.398] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:08:32:913590 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:08:32:913590 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.0065s] [ 42%]
../../../../test/distributed/fsdp/test_fsdp_flatten_params.py::TestFlattenParams::test_flatten_nothing [2025-09-12 11:08:35.394] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:08:35:913665 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:08:35:913665 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [2.9062s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_flatten_params.py::TestFlattenParams::test_numel_with_shared_params [2025-09-12 11:08:38.310] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:08:38:913739 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:08:38:913739 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.0067s] [ 57%]
../../../../test/distributed/fsdp/test_fsdp_flatten_params.py::TestFlattenParams::test_numel_without_shared_params [2025-09-12 11:08:41.406] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:08:41:913813 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:08:41:913813 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.1067s] [ 64%]
../../../../test/distributed/fsdp/test_fsdp_flatten_params.py::TestFlattenParams::test_output_with_shared_params [2025-09-12 11:08:44.514] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:08:44:913887 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:08:44:913887 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.5072s] [ 71%]
../../../../test/distributed/fsdp/test_fsdp_flatten_params.py::TestFlattenParams::test_output_without_shared_params [2025-09-12 11:08:47.926] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:08:48:913961 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:08:48:913961 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.4072s] [ 78%]
../../../../test/distributed/fsdp/test_fsdp_flatten_params.py::TestFlattenParams::test_partial_flattening [2025-09-12 11:08:51.430] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:08:51:914035 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:08:51:914035 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.1065s] [ 85%]
../../../../test/distributed/fsdp/test_fsdp_flatten_params.py::TestFlattenParams::test_pnorm_after_step_with_shared_params [2025-09-12 11:08:54.526] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:08:54:914109 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:08:54:914109 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.9079s] [ 92%]
../../../../test/distributed/fsdp/test_fsdp_flatten_params.py::TestFlattenParams::test_writeback_orig_params_no_shard [2025-09-12 11:08:58.446] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:08:58:914187 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:08:58:914187 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.2066s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_flatten_params.py.xml -
============================= 14 passed in 46.13s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 11:09:02.555] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 32 items
Running 32 items in this shard

../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_False_freezing_method_FreezingMethod_GradToNone_freeze_after_wrap_fsdp_False_disable_autograd_False_forward_prefetch_False [2025-09-12 11:09:04.762] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:09:04.766] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:09:04.773] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:09:04.794] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:09:04:914334 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:09:04:914334 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:09:04:914337 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:09:04:914337 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:09:05:914335 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:09:05:914335 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:09:05:914336 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:09:05:914336 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [31.5403s] [  3%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_False_freezing_method_FreezingMethod_GradToNone_freeze_after_wrap_fsdp_False_disable_autograd_False_forward_prefetch_True [2025-09-12 11:09:36.071] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:09:36.072] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:09:36.076] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:09:36.080] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:09:36:914656 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:09:36:914656 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:09:36:914654 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:09:36:914654 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:09:36:914653 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:09:36:914653 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:09:36:914655 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:09:36:914655 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [31.3547s] [  6%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_False_freezing_method_FreezingMethod_GradToNone_freeze_after_wrap_fsdp_False_disable_autograd_True_forward_prefetch_False [2025-09-12 11:10:07.483] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:10:07.490] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:10:07.498] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:10:07.502] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:10:07:914973 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:10:07:914973 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:10:07:914972 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:10:07:914972 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:10:07:914971 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:10:07:914971 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:10:07:914974 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:10:07:914974 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [31.2514s] [  9%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_False_freezing_method_FreezingMethod_GradToNone_freeze_after_wrap_fsdp_False_disable_autograd_True_forward_prefetch_True [2025-09-12 11:10:38.674] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:10:38.694] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:10:38.699] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:10:38.699] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:10:38:915294 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:10:38:915294 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:10:38:915295 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:10:38:915295 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:10:38:915292 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:10:38:915292 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:10:38:915293 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:10:38:915293 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [31.4536s] [ 12%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_False_freezing_method_FreezingMethod_GradToNone_freeze_after_wrap_fsdp_True_disable_autograd_False_forward_prefetch_False [2025-09-12 11:11:10.139] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:11:10.151] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:11:10.152] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:11:10.182] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:11:10:915611 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:11:10:915611 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:11:10:915610 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:11:10:915610 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:11:10:915613 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:11:10:915613 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:11:10:915612 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:11:10:915612 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [31.0546s] [ 15%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_False_freezing_method_FreezingMethod_GradToNone_freeze_after_wrap_fsdp_True_disable_autograd_False_forward_prefetch_True [2025-09-12 11:11:41.218] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:11:41.220] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:11:41.222] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:11:41.222] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:11:41:915928 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:11:41:915928 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:11:41:915929 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:11:41:915929 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:11:41:915931 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:11:41:915931 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:11:41:915930 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:11:41:915930 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.6564s] [ 18%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_False_freezing_method_FreezingMethod_GradToNone_freeze_after_wrap_fsdp_True_disable_autograd_True_forward_prefetch_False [2025-09-12 11:12:12.826] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:12:12.884] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:12:12.894] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:12:12.906] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:12:13:916246 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:12:13:916246 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:12:13:916245 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:12:13:916245 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:12:13:916248 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:12:13:916248 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:12:13:916247 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:12:13:916247 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [31.5562s] [ 21%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_False_freezing_method_FreezingMethod_GradToNone_freeze_after_wrap_fsdp_True_disable_autograd_True_forward_prefetch_True [2025-09-12 11:12:44.398] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:12:44.414] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:12:44.431] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:12:44.454] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:12:44:916568 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:12:44:916568 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:12:44:916565 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:12:44:916565 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:12:44:916566 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:12:44:916566 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:12:44:916567 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:12:44:916567 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
PASSED [31.1550s] [ 25%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_False_freezing_method_FreezingMethod_RequiresGrad_freeze_after_wrap_fsdp_False_disable_autograd_False_forward_prefetch_False [2025-09-12 11:13:15.563] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:13:15.587] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:13:15.587] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:13:15.606] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:13:15:916883 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:13:15:916883 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:13:15:916885 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:13:15:916885 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:13:15:916882 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:13:15:916882 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:13:15:916884 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:13:15:916884 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [31.4561s] [ 28%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_False_freezing_method_FreezingMethod_RequiresGrad_freeze_after_wrap_fsdp_False_disable_autograd_False_forward_prefetch_True [2025-09-12 11:13:47.031] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:13:47.031] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:13:47.031] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:13:47.033] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:13:47:917203 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:13:47:917203 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:13:47:917200 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:13:47:917200 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:13:47:917202 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:13:47:917202 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:13:47:917201 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:13:47:917201 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [31.4563s] [ 31%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_False_freezing_method_FreezingMethod_RequiresGrad_freeze_after_wrap_fsdp_False_disable_autograd_True_forward_prefetch_False [2025-09-12 11:14:18.545] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:14:18.566] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:14:18.569] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:14:18.582] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:14:18:917518 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:14:18:917518 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:14:18:917519 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:14:18:917519 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:14:18:917517 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:14:18:917517 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:14:18:917520 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:14:18:917520 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [31.3554s] [ 34%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_False_freezing_method_FreezingMethod_RequiresGrad_freeze_after_wrap_fsdp_False_disable_autograd_True_forward_prefetch_True [2025-09-12 11:14:49.831] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:14:49.835] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:14:49.836] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:14:49.842] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:14:50:917837 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:14:50:917837 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:14:50:917836 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:14:50:917836 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:14:50:917835 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:14:50:917835 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:14:50:917838 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:14:50:917838 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [30.9549s] [ 37%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_False_freezing_method_FreezingMethod_RequiresGrad_freeze_after_wrap_fsdp_True_disable_autograd_False_forward_prefetch_False [2025-09-12 11:15:20.793] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:15:20.799] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:15:20.806] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:15:20.830] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:15:20:918156 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:15:20:918156 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:15:21:918155 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:15:21:918155 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:15:21:918154 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:15:21:918154 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:15:21:918153 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:15:21:918153 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [31.5563s] [ 40%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_False_freezing_method_FreezingMethod_RequiresGrad_freeze_after_wrap_fsdp_True_disable_autograd_False_forward_prefetch_True [2025-09-12 11:15:52.360] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:15:52.365] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:15:52.366] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:15:52.378] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:15:52:918472 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:15:52:918472 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:15:52:918473 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:15:52:918473 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:15:52:918474 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:15:52:918474 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:15:52:918471 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:15:52:918471 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [31.5560s] [ 43%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_False_freezing_method_FreezingMethod_RequiresGrad_freeze_after_wrap_fsdp_True_disable_autograd_True_forward_prefetch_False [2025-09-12 11:16:23.962] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:16:24.043] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:16:24.043] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:16:24.063] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:16:24:918789 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:16:24:918789 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:16:24:918791 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:16:24:918791 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:16:24:918792 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:16:24:918792 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:16:24:918790 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:16:24:918790 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [31.6565s] [ 46%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_False_freezing_method_FreezingMethod_RequiresGrad_freeze_after_wrap_fsdp_True_disable_autograd_True_forward_prefetch_True [2025-09-12 11:16:55.567] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:16:55.584] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:16:55.584] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:16:55.584] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:16:55:919107 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:16:55:919107 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:16:55:919109 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:16:55:919109 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:16:55:919106 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:16:55:919106 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:16:55:919108 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:16:55:919108 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [31.3560s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_True_freezing_method_FreezingMethod_GradToNone_freeze_after_wrap_fsdp_False_disable_autograd_False_forward_prefetch_False [2025-09-12 11:17:26.923] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:17:26.934] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:17:26.951] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:17:26.970] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:17:27:919429 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:17:27:919429 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:17:27:919428 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:17:27:919428 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:17:27:919427 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:17:27:919427 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:17:27:919430 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:17:27:919430 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
PASSED [31.8566s] [ 53%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_True_freezing_method_FreezingMethod_GradToNone_freeze_after_wrap_fsdp_False_disable_autograd_False_forward_prefetch_True [2025-09-12 11:17:58.786] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:17:58.802] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:17:58.804] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:17:58.838] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:17:58:919748 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:17:58:919748 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:17:59:919747 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:17:59:919747 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:17:59:919745 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:17:59:919745 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:17:59:919746 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:17:59:919746 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [31.8570s] [ 56%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_True_freezing_method_FreezingMethod_GradToNone_freeze_after_wrap_fsdp_False_disable_autograd_True_forward_prefetch_False [2025-09-12 11:18:30.626] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:18:30.627] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:18:30.634] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:18:30.666] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:18:30:920064 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:18:30:920064 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:18:30:920063 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:18:30:920063 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:18:30:920065 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:18:30:920065 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:18:30:920066 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:18:30:920066 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [31.1545s] [ 59%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_True_freezing_method_FreezingMethod_GradToNone_freeze_after_wrap_fsdp_False_disable_autograd_True_forward_prefetch_True [2025-09-12 11:19:01.799] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:19:01.805] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:19:01.814] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:19:01.814] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:19:01:920382 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:19:01:920382 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:19:02:920383 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:19:02:920383 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:19:02:920381 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:19:02:920381 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:19:02:920384 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:19:02:920384 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.5557s] [ 62%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_True_freezing_method_FreezingMethod_GradToNone_freeze_after_wrap_fsdp_True_disable_autograd_False_forward_prefetch_False [2025-09-12 11:19:33.339] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:19:33.345] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:19:33.360] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:19:33.382] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:19:33:920702 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:19:33:920702 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:19:33:920699 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:19:33:920699 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:19:33:920701 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:19:33:920701 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:19:33:920700 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:19:33:920700 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [31.8566s] [ 65%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_True_freezing_method_FreezingMethod_GradToNone_freeze_after_wrap_fsdp_True_disable_autograd_False_forward_prefetch_True [2025-09-12 11:20:05.210] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:20:05.226] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:20:05.235] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:20:05.238] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:20:05:921015 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:20:05:921015 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:20:05:921016 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:20:05:921016 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:20:05:921017 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:20:05:921017 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:20:05:921018 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:20:05:921018 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [31.9568s] [ 68%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_True_freezing_method_FreezingMethod_GradToNone_freeze_after_wrap_fsdp_True_disable_autograd_True_forward_prefetch_False [2025-09-12 11:20:37.155] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:20:37.178] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:20:37.200] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:20:37.206] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:20:37:921336 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:20:37:921336 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:20:37:921335 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:20:37:921335 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:20:37:921333 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:20:37:921333 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:20:37:921334 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:20:37:921334 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [31.2549s] [ 71%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_True_freezing_method_FreezingMethod_GradToNone_freeze_after_wrap_fsdp_True_disable_autograd_True_forward_prefetch_True [2025-09-12 11:21:08.402] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:21:08.461] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:21:08.478] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:21:08.482] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:21:08:921655 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:21:08:921655 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:21:08:921656 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:21:08:921656 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:21:08:921653 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:21:08:921653 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:21:08:921654 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:21:08:921654 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [31.6561s] [ 75%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_True_freezing_method_FreezingMethod_RequiresGrad_freeze_after_wrap_fsdp_False_disable_autograd_False_forward_prefetch_False [2025-09-12 11:21:40.103] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:21:40.103] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:21:40.113] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:21:40.119] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:21:40:921974 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:21:40:921974 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:21:40:921975 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:21:40:921975 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:21:40:921972 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:21:40:921972 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:21:40:921973 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:21:40:921973 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [31.4555s] [ 78%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_True_freezing_method_FreezingMethod_RequiresGrad_freeze_after_wrap_fsdp_False_disable_autograd_False_forward_prefetch_True [2025-09-12 11:22:11.503] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:22:11.565] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:22:11.565] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:22:11.584] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:22:11:922294 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:22:11:922294 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:22:11:922292 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:22:11:922292 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:22:11:922295 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:22:11:922295 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:22:11:922293 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:22:11:922293 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [31.4553s] [ 81%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_True_freezing_method_FreezingMethod_RequiresGrad_freeze_after_wrap_fsdp_False_disable_autograd_True_forward_prefetch_False [2025-09-12 11:22:43.004] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:22:43.020] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:22:43.022] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:22:43.034] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:22:43:922613 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:22:43:922613 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:22:43:922612 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:22:43:922612 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:22:43:922611 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:22:43:922611 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:22:43:922614 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:22:43:922614 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [31.6561s] [ 84%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_True_freezing_method_FreezingMethod_RequiresGrad_freeze_after_wrap_fsdp_False_disable_autograd_True_forward_prefetch_True [2025-09-12 11:23:14.634] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:23:14.687] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:23:14.710] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:23:14.718] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:23:14:922930 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:23:14:922930 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:23:14:922928 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:23:14:922928 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:23:14:922927 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:23:14:922927 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:23:14:922929 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:23:14:922929 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.2551s] [ 87%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_True_freezing_method_FreezingMethod_RequiresGrad_freeze_after_wrap_fsdp_True_disable_autograd_False_forward_prefetch_False [2025-09-12 11:23:45.911] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:23:45.922] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:23:45.923] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:23:45.959] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:23:46:923246 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:23:46:923246 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:23:46:923245 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:23:46:923245 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:23:46:923247 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:23:46:923247 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:23:46:923248 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:23:46:923248 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [31.5498s] [ 90%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_True_freezing_method_FreezingMethod_RequiresGrad_freeze_after_wrap_fsdp_True_disable_autograd_False_forward_prefetch_True [2025-09-12 11:24:17.448] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:24:17.467] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:24:17.470] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:24:17.490] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:24:17:923564 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:24:17:923564 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:24:17:923563 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:24:17:923563 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:24:17:923565 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:24:17:923565 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:24:17:923562 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:24:17:923562 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [31.5495s] [ 93%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_True_freezing_method_FreezingMethod_RequiresGrad_freeze_after_wrap_fsdp_True_disable_autograd_True_forward_prefetch_False [2025-09-12 11:24:49.008] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:24:49.008] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:24:49.014] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:24:49.026] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:24:49:923880 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:24:49:923880 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:24:49:923879 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:24:49:923879 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:24:49:923881 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:24:49:923881 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:24:49:923882 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:24:49:923882 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [31.4568s] [ 96%]
../../../../test/distributed/fsdp/test_fsdp_freezing_weights.py::TestFreezingWeights::test_freezing_weights_with_nested_trunk_True_freezing_method_FreezingMethod_RequiresGrad_freeze_after_wrap_fsdp_True_disable_autograd_True_forward_prefetch_True [2025-09-12 11:25:20.423] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:25:20.496] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:25:20.590] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:25:20:924199 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:25:20:924199 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
[2025-09-12 11:25:20.650] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:25:20:924198 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:25:20:924198 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:25:20:924201 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:25:20:924201 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:25:20:924200 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:25:20:924200 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [31.6536s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_freezing_weights.py.xml -
======================= 32 passed in 1009.58s (0:16:49) ========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 11:25:52.978] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 1 item
Running 1 items in this shard

../../../../test/distributed/fsdp/test_fsdp_fx.py::TestSymbolicTracingXPU::test_symbolic_tracing_outputs_xpu PASSED [0.0144s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_fx.py.xml -
============================== 1 passed in 2.08s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 11:25:55.970] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 6 items
Running 6 items in this shard

../../../../test/distributed/fsdp/test_fsdp_grad_acc.py::TestGradAcc::test_grad_acc_configs0_use_orig_params_False [2025-09-12 11:25:58.138] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:25:58.139] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:25:58:924663 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:25:58:924663 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:25:58:924662 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:25:58:924662 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
FAILED [30.7239s] [ 16%]
../../../../test/distributed/fsdp/test_fsdp_grad_acc.py::TestGradAcc::test_grad_acc_configs0_use_orig_params_True [2025-09-12 11:26:28.683] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:26:28.686] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:26:28:924821 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:26:28:924821 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:26:28:924822 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:26:28:924822 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
FAILED [30.4491s] [ 33%]
../../../../test/distributed/fsdp/test_fsdp_grad_acc.py::TestGradAcc::test_grad_acc_configs1_use_orig_params_False [2025-09-12 11:26:59.130] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:26:59.146] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:26:59:925017 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:26:59:925017 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:26:59:925016 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:26:59:925016 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
FAILED [31.8509s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_grad_acc.py::TestGradAcc::test_grad_acc_configs1_use_orig_params_True [2025-09-12 11:27:30.958] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:27:30.994] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:27:31:925175 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:27:31:925175 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:27:31:925176 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:27:31:925176 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
FAILED [32.2510s] [ 66%]
../../../../test/distributed/fsdp/test_fsdp_grad_acc.py::TestGradAcc::test_grad_acc_cpu_offload_use_orig_params_False [2025-09-12 11:28:03.230] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:28:03.240] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:28:03:925335 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:28:03:925335 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:28:03:925336 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:28:03:925336 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
FAILED [30.4487s] [ 83%]
../../../../test/distributed/fsdp/test_fsdp_grad_acc.py::TestGradAcc::test_grad_acc_cpu_offload_use_orig_params_True [2025-09-12 11:28:33.695] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:28:33.710] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:28:33:925494 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:28:33:925494 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:28:33:925495 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:28:33:925495 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
FAILED [30.4488s] [100%]

=================================== FAILURES ===================================
___________ TestGradAcc.test_grad_acc_configs0_use_orig_params_False ___________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 269, in test_grad_acc
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 192 / 228 (84.2%)
Greatest absolute difference: 0.4939103126525879 at index (105,) (up to 1e-05 allowed)
Greatest relative difference: 4.714433193206787 at index (103,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_configs0_use_orig_params_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 269, in test_grad_acc
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 228 (14.0%)
Greatest absolute difference: 0.9211263656616211 at index (167,) (up to 1e-05 allowed)
Greatest relative difference: 2.343290090560913 at index (159,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_configs0_use_orig_params_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 0 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 11:25:56.286000 924590 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 924662
I0912 11:25:56.287000 924590 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 924663
___________ TestGradAcc.test_grad_acc_configs0_use_orig_params_True ____________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 269, in test_grad_acc
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 52 / 52 (100.0%)
Greatest absolute difference: 0.6520071029663086 at index (33,) (up to 1e-05 allowed)
Greatest relative difference: 0.06336089968681335 at index (14,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_configs0_use_orig_params_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 1 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 11:26:26.841000 924590 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 924821
I0912 11:26:26.842000 924590 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 924822
___________ TestGradAcc.test_grad_acc_configs1_use_orig_params_False ___________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 269, in test_grad_acc
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 668 / 716 (93.3%)
Greatest absolute difference: 3.7239112854003906 at index (519,) (up to 1e-05 allowed)
Greatest relative difference: 33.97804260253906 at index (440,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_configs1_use_orig_params_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 1 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 11:26:57.294000 924590 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 925016
I0912 11:26:57.295000 924590 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 925017
___________ TestGradAcc.test_grad_acc_configs1_use_orig_params_True ____________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 269, in test_grad_acc
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 192 / 228 (84.2%)
Greatest absolute difference: 0.7380075454711914 at index (102,) (up to 1e-05 allowed)
Greatest relative difference: 19.133033752441406 at index (49,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_configs1_use_orig_params_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 269, in test_grad_acc
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 52 / 52 (100.0%)
Greatest absolute difference: 2.3607215881347656 at index (43,) (up to 1e-05 allowed)
Greatest relative difference: 0.0874820202589035 at index (0,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_configs1_use_orig_params_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 0 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 11:27:29.146000 924590 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 925175
I0912 11:27:29.147000 924590 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 925176
_________ TestGradAcc.test_grad_acc_cpu_offload_use_orig_params_False __________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 294, in test_grad_acc_cpu_offload
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 192 / 228 (84.2%)
Greatest absolute difference: 0.49391043186187744 at index (105,) (up to 1e-05 allowed)
Greatest relative difference: 4.816555500030518 at index (119,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_cpu_offload_use_orig_params_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 294, in test_grad_acc_cpu_offload
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 228 (14.0%)
Greatest absolute difference: 0.9211257696151733 at index (167,) (up to 1e-05 allowed)
Greatest relative difference: 8.109031677246094 at index (151,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_cpu_offload_use_orig_params_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 0 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 11:28:01.399000 924590 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 925335
I0912 11:28:01.399000 924590 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 925336
__________ TestGradAcc.test_grad_acc_cpu_offload_use_orig_params_True __________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 294, in test_grad_acc_cpu_offload
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 192 / 228 (84.2%)
Greatest absolute difference: 0.49391043186187744 at index (105,) (up to 1e-05 allowed)
Greatest relative difference: 4.816555500030518 at index (119,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_cpu_offload_use_orig_params_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 294, in test_grad_acc_cpu_offload
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 52 / 52 (100.0%)
Greatest absolute difference: 1.6970481872558594 at index (43,) (up to 1e-05 allowed)
Greatest relative difference: 0.31563687324523926 at index (16,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_cpu_offload_use_orig_params_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 0 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 11:28:31.849000 924590 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 925494
I0912 11:28:31.850000 924590 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 925495
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_grad_acc.py.xml -
=========================== short test summary info ============================
FAILED [30.7239s] ../../../../test/distributed/fsdp/test_fsdp_grad_acc.py::TestGradAcc::test_grad_acc_configs0_use_orig_params_False - RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 269, in test_grad_acc
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 192 / 228 (84.2%)
Greatest absolute difference: 0.4939103126525879 at index (105,) (up to 1e-05 allowed)
Greatest relative difference: 4.714433193206787 at index (103,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_configs0_use_orig_params_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 269, in test_grad_acc
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 228 (14.0%)
Greatest absolute difference: 0.9211263656616211 at index (167,) (up to 1e-05 allowed)
Greatest relative difference: 2.343290090560913 at index (159,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_configs0_use_orig_params_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [30.4491s] ../../../../test/distributed/fsdp/test_fsdp_grad_acc.py::TestGradAcc::test_grad_acc_configs0_use_orig_params_True - RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 269, in test_grad_acc
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 52 / 52 (100.0%)
Greatest absolute difference: 0.6520071029663086 at index (33,) (up to 1e-05 allowed)
Greatest relative difference: 0.06336089968681335 at index (14,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_configs0_use_orig_params_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [31.8509s] ../../../../test/distributed/fsdp/test_fsdp_grad_acc.py::TestGradAcc::test_grad_acc_configs1_use_orig_params_False - RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 269, in test_grad_acc
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 668 / 716 (93.3%)
Greatest absolute difference: 3.7239112854003906 at index (519,) (up to 1e-05 allowed)
Greatest relative difference: 33.97804260253906 at index (440,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_configs1_use_orig_params_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [32.2510s] ../../../../test/distributed/fsdp/test_fsdp_grad_acc.py::TestGradAcc::test_grad_acc_configs1_use_orig_params_True - RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 269, in test_grad_acc
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 192 / 228 (84.2%)
Greatest absolute difference: 0.7380075454711914 at index (102,) (up to 1e-05 allowed)
Greatest relative difference: 19.133033752441406 at index (49,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_configs1_use_orig_params_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 269, in test_grad_acc
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 52 / 52 (100.0%)
Greatest absolute difference: 2.3607215881347656 at index (43,) (up to 1e-05 allowed)
Greatest relative difference: 0.0874820202589035 at index (0,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_configs1_use_orig_params_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [30.4487s] ../../../../test/distributed/fsdp/test_fsdp_grad_acc.py::TestGradAcc::test_grad_acc_cpu_offload_use_orig_params_False - RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 294, in test_grad_acc_cpu_offload
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 192 / 228 (84.2%)
Greatest absolute difference: 0.49391043186187744 at index (105,) (up to 1e-05 allowed)
Greatest relative difference: 4.816555500030518 at index (119,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_cpu_offload_use_orig_params_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 294, in test_grad_acc_cpu_offload
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 228 (14.0%)
Greatest absolute difference: 0.9211257696151733 at index (167,) (up to 1e-05 allowed)
Greatest relative difference: 8.109031677246094 at index (151,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_cpu_offload_use_orig_params_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [30.4488s] ../../../../test/distributed/fsdp/test_fsdp_grad_acc.py::TestGradAcc::test_grad_acc_cpu_offload_use_orig_params_True - RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 294, in test_grad_acc_cpu_offload
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 192 / 228 (84.2%)
Greatest absolute difference: 0.49391043186187744 at index (105,) (up to 1e-05 allowed)
Greatest relative difference: 4.816555500030518 at index (119,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_cpu_offload_use_orig_params_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 294, in test_grad_acc_cpu_offload
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_grad_acc.py", line 212, in _test_grad_acc
    torch.testing.assert_close(ref_grad, acc_grad)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 52 / 52 (100.0%)
Greatest absolute difference: 1.6970481872558594 at index (43,) (up to 1e-05 allowed)
Greatest relative difference: 0.31563687324523926 at index (16,) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_grad_acc.py TestGradAcc.test_grad_acc_cpu_offload_use_orig_params_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
======================== 6 failed in 188.10s (0:03:08) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 11:29:05.091] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 6 items
Running 6 items in this shard

../../../../test/distributed/fsdp/test_fsdp_hybrid_shard.py::TestFSDPHybridShard::test_fsdp_hybrid_shard_basic_setup [2025-09-12 11:29:07.279] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:29:07.294] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:29:07.298] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:29:07.314] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:29:07:925735 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:29:07:925735 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:29:07:925736 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:29:07:925736 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:29:07:925733 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:29:07:925733 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:29:07:925734 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:29:07:925734 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:29:20:925733:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:20:925734:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:20:925735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:20:925736:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:35:926051:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:36:926059:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:36:926054:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:36:926045:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:36:925733:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:36:925736:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:36:925735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:36:925734:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:37:926051:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:37:926045:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:37:926054:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:37:926059:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:37:925735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:37:925733:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:37:925736:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:37:925734:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:37:926051:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:37:926054:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:37:926045:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:37:926059:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:38:925735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:38:925733:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:38:925736:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:38:925734:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:38:926051:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:38:926059:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:38:926045:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:38:926054:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:38:925735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:38:925733:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:38:925734:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:38:925736:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:39:926045:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:39:926059:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:39:926054:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:39:926051:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:39:925735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:39:925733:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:39:925736:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:39:925734:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:39:926051:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:40:926059:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:40:926045:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:40:926054:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:40:925735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:40:925733:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:40:925734:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:40:925736:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:40:926051:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:40:926059:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:40:926054:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:40:926045:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:41:925735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:41:925733:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:41:925734:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:41:925736:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:41:926051:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:41:926059:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:41:926054:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:41:926045:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:41:925735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:41:925733:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:41:925734:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:41:925736:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:42:926045:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:42:926059:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:42:926054:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:42:926051:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:42:925733:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:42:925735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:42:925734:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:42:925736:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:42:926051:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:42:926054:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:42:926045:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:42:926059:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:43:925735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:43:925733:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:43:925734:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:43:925736:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:43:926054:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:43:926059:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:43:926045:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:43:926051:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:44:925735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:44:925733:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:44:925734:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:44:925736:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:44:926051:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:44:926054:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:44:926045:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:44:926059:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:44:925735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:44:925733:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:44:925736:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:44:925734:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:45:926051:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:45:926059:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:45:926045:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:45:926054:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:45:925733:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:45:925735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:45:925734:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:45:925736:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:45:926051:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:45:926059:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:45:926045:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:45:926054:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:46:925735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:46:925733:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:46:925734:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:46:925736:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:46:926051:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:46:926045:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:46:926059:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:46:926054:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:46:925735:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:46:925733:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:46:925734:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:46:925736:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:47:926059:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:47:926045:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:47:926051:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:29:47:926054:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [43.0538s] [ 16%]
../../../../test/distributed/fsdp/test_fsdp_hybrid_shard.py::TestFSDPHybridShard::test_fsdp_hybrid_shard_parity [2025-09-12 11:29:50.116] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:29:50.123] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:29:50.136] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:29:50.146] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:29:50:926309 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:29:50:926309 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:29:50:926310 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:29:50:926310 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:29:50:926308 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:29:50:926308 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:29:50:926307 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:29:50:926307 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:30:19:926308:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:19:926307:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:19:926309:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:19:926310:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:19:926629:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:19:926624:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:19:926622:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:19:926619:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:19:926307:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:19:926308:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:19:926309:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:19:926310:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:20:926629:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:20:926624:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:20:926622:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:20:926619:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:20:926309:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:20:926307:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:20:926310:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:20:926308:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:21:926624:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:21:926622:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:21:926629:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:21:926619:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=3, world=4
dist init r=2, world=4
FAILED [33.8616s] [ 33%]
../../../../test/distributed/fsdp/test_fsdp_hybrid_shard.py::TestFSDPHybridShard::test_hsdp_save_load_state_dict [2025-09-12 11:30:24.019] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:30:24.035] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:30:24.036] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:30:24.036] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:30:24:926677 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:30:24:926677 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:30:24:926676 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:30:24:926676 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:30:24:926675 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:30:24:926675 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:30:24:926678 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:30:24:926678 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:30:37:926677:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:37:926678:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:37:926676:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:37:926675:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:52:926995:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:52:927001:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:52:926996:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:30:52:926990:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [31.8415s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_hybrid_shard.py::TestFSDPHybridShard::test_hsdp_sync_module_state [2025-09-12 11:30:55.848] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:30:55.855] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:30:55.860] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:30:55.870] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:30:56:927008 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:30:56:927008 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:30:56:927010 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:30:56:927010 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:30:56:927011 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:30:56:927011 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:30:56:927009 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:30:56:927009 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:31:08:927011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:31:08:927010:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:31:08:927008:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:31:08:927009:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:31:09:927009:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:31:09:927011:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:31:09:927010:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-11:31:09:927008:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [16.0296s] [ 66%]
../../../../test/distributed/fsdp/test_fsdp_hybrid_shard.py::TestFSDPHybridShard::test_invalid_pg_specification_raises [2025-09-12 11:31:11.879] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:31:11.884] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:31:11.884] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:31:11.884] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:31:12:927328 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:31:12:927328 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:31:12:927325 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:31:12:927325 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:31:12:927326 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:31:12:927326 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:31:12:927327 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:31:12:927327 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [15.5278s] [ 83%]
../../../../test/distributed/fsdp/test_fsdp_hybrid_shard.py::TestFSDPHybridShard::test_raises_manual_wrap_hybrid_shard_when_none_policy [2025-09-12 11:31:27.394] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:31:27.398] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:31:27.402] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:31:27.410] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:31:27:927628 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:31:27:927628 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:31:27:927627 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:31:27:927627 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:31:27:927626 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:31:27:927626 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:31:27:927629 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:31:27:927629 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [15.7296s] [100%]

=================================== FAILURES ===================================
______________ TestFSDPHybridShard.test_fsdp_hybrid_shard_parity _______________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_hybrid_shard.py", line 341, in test_fsdp_hybrid_shard_parity
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_hybrid_shard.py", line 379, in _test_fsdp_hybrid_shard_parity
    self.assertEqual(losses[0], losses[1])
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Scalars are not close!

Expected -298.03204345703125 but got -297.7536926269531.
Absolute difference: 0.278350830078125 (up to 1e-05 allowed)
Relative difference: 0.0009339627606796456 (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_hybrid_shard.py TestFSDPHybridShard.test_fsdp_hybrid_shard_parity

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 3 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 11:29:48.271000 925661 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 926307
I0912 11:29:48.272000 925661 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 926308
I0912 11:29:48.272000 925661 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 926309
I0912 11:29:48.273000 925661 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 926310
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_hybrid_shard.py.xml -
=========================== short test summary info ============================
FAILED [33.8616s] ../../../../test/distributed/fsdp/test_fsdp_hybrid_shard.py::TestFSDPHybridShard::test_fsdp_hybrid_shard_parity - RuntimeError: Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_hybrid_shard.py", line 341, in test_fsdp_hybrid_shard_parity
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_hybrid_shard.py", line 379, in _test_fsdp_hybrid_shard_parity
    self.assertEqual(losses[0], losses[1])
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Scalars are not close!

Expected -298.03204345703125 but got -297.7536926269531.
Absolute difference: 0.278350830078125 (up to 1e-05 allowed)
Relative difference: 0.0009339627606796456 (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_hybrid_shard.py TestFSDPHybridShard.test_fsdp_hybrid_shard_parity

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
=================== 1 failed, 5 passed in 158.04s (0:02:38) ====================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 11:31:44.071] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 8 items
Running 8 items in this shard

../../../../test/distributed/fsdp/test_fsdp_ignored_modules.py::TestFSDPIgnoredModules::test_diff_ignored_modules_across_ranks [2025-09-12 11:31:46.280] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:31:46.303] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:31:46:928004 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:31:46:928004 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:31:46:928003 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:31:46:928003 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.4510s] [ 12%]
../../../../test/distributed/fsdp/test_fsdp_ignored_modules.py::TestFSDPIgnoredModules::test_ignored_modules_invalid [2025-09-12 11:32:16.474] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:32:16.510] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:32:16:928162 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:32:16:928162 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:32:16:928161 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:32:16:928161 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.8188s] [ 25%]
../../../../test/distributed/fsdp/test_fsdp_ignored_modules.py::TestFSDPIgnoredModules::test_ignored_modules_nested [2025-09-12 11:32:31.316] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:32:31.334] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:32:31:928314 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:32:31:928314 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:32:31:928313 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:32:31:928313 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.2349s] [ 37%]
../../../../test/distributed/fsdp/test_fsdp_ignored_modules.py::TestFSDPIgnoredModules::test_ignored_modules_not_under_wrapped_root_ignore_modules_False [2025-09-12 11:33:01.542] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:33:01.554] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:33:01:928473 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:33:01:928473 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:33:01:928472 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:33:01:928472 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [29.7476s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_ignored_modules.py::TestFSDPIgnoredModules::test_ignored_modules_not_under_wrapped_root_ignore_modules_True [2025-09-12 11:33:31.282] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:33:31.294] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:33:31:928631 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:33:31:928631 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:33:31:928632 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:33:31:928632 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [29.9475s] [ 62%]
../../../../test/distributed/fsdp/test_fsdp_ignored_modules.py::TestFSDPIgnoredModules::test_ignored_modules_transformer [2025-09-12 11:34:01.209] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:34:01.218] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:34:01:928792 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:34:01:928792 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:34:01:928791 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:34:01:928791 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.7491s] [ 75%]
../../../../test/distributed/fsdp/test_fsdp_ignored_modules.py::TestFSDPIgnoredModules::test_ignored_states_auto_wrap [2025-09-12 11:34:31.980] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:34:31.998] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:34:32:928952 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:34:32:928951 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:34:32:928951 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:34:32:928952 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.8251s] [ 87%]
../../../../test/distributed/fsdp/test_fsdp_ignored_modules.py::TestFSDPIgnoredModules::test_ignored_states_check [2025-09-12 11:34:46.826] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:34:46.842] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:34:47:929103 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:34:47:929102 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:34:47:929102 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:34:47:929103 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.8191s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_ignored_modules.py.xml -
======================== 8 passed in 197.60s (0:03:17) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 11:35:02.494] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/fsdp/test_fsdp_input.py::TestInputXPU::test_input_type_dict_xpu [2025-09-12 11:35:04.686] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:35:05:929327 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:35:05:929327 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.4085s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_input.py::TestInputXPU::test_input_type_list_xpu [2025-09-12 11:35:08.026] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:35:08:929405 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:35:08:929405 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.3062s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_input.py.xml -
============================== 2 passed in 8.78s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 11:35:12.226] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/fsdp/test_fsdp_memory.py::TestFSDPMemory::test_fsdp_memory_ckpt_ckpt [2025-09-12 11:35:14.379] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:35:14.398] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:35:14:929557 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:35:14:929557 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:35:14:929558 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:35:14:929558 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [36.3275s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_memory.py::TestFSDPMemory::test_fsdp_memory_ckpt_no_ckpt [2025-09-12 11:35:50.553] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:35:50.570] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:35:50:929907 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:35:50:929907 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:35:50:929908 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:35:50:929908 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [36.4596s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_memory.py.xml -
========================= 2 passed in 74.70s (0:01:14) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 11:36:28.035] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 15 items
Running 15 items in this shard

../../../../test/distributed/fsdp/test_fsdp_meta.py::TestFSDPWithMetaDevice::test_bad_arg_meta [2025-09-12 11:36:30.225] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:36:30.246] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:36:30:930332 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:36:30:930332 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:36:30:930333 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:36:30:930333 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1105s] [  6%]
../../../../test/distributed/fsdp/test_fsdp_meta.py::TestFSDPWithMetaDevice::test_bad_arg_torchdistx SKIPPED [0.0003s] [ 13%]
../../../../test/distributed/fsdp/test_fsdp_meta.py::TestFSDPWithMetaDevice::test_meta_device_with_mixed_precision [2025-09-12 11:36:45.146] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:36:45.162] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:36:45:930485 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:36:45:930485 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:36:45:930484 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:36:45:930484 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.9245s] [ 20%]
../../../../test/distributed/fsdp/test_fsdp_meta.py::TestFSDPWithMetaDevice::test_nested_model_with_meta_device_default_init_auto_wrap_False [2025-09-12 11:37:00.038] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:37:00.045] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:37:00:930634 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:37:00:930634 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:37:00:930635 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:37:00:930635 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.1469s] [ 26%]
../../../../test/distributed/fsdp/test_fsdp_meta.py::TestFSDPWithMetaDevice::test_nested_model_with_meta_device_default_init_auto_wrap_True [2025-09-12 11:37:30.147] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:37:30.162] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:37:30:930792 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:37:30:930792 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:37:30:930793 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:37:30:930793 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.2486s] [ 33%]
../../../../test/distributed/fsdp/test_fsdp_meta.py::TestFSDPWithMetaDevice::test_nested_model_with_meta_device_reset_params_auto_wrap_False [2025-09-12 11:38:00.507] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:38:00.526] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:38:00:930953 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:38:00:930953 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:38:00:930954 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:38:00:930954 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.2353s] [ 40%]
../../../../test/distributed/fsdp/test_fsdp_meta.py::TestFSDPWithMetaDevice::test_nested_model_with_meta_device_reset_params_auto_wrap_True [2025-09-12 11:38:30.638] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:38:30.670] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:38:30:931112 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:38:30:931112 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:38:30:931111 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:38:30:931111 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.2480s] [ 46%]
../../../../test/distributed/fsdp/test_fsdp_meta.py::TestFSDPWithMetaDevice::test_nested_model_with_torchdistX_default_init_auto_wrap_False SKIPPED [0.0002s] [ 53%]
../../../../test/distributed/fsdp/test_fsdp_meta.py::TestFSDPWithMetaDevice::test_nested_model_with_torchdistX_default_init_auto_wrap_True SKIPPED [0.0001s] [ 60%]
../../../../test/distributed/fsdp/test_fsdp_meta.py::TestFSDPWithMetaDevice::test_nested_model_with_torchdistX_init_fn_auto_wrap_False SKIPPED [0.0001s] [ 66%]
../../../../test/distributed/fsdp/test_fsdp_meta.py::TestFSDPWithMetaDevice::test_nested_model_with_torchdistX_init_fn_auto_wrap_True SKIPPED [0.0001s] [ 73%]
../../../../test/distributed/fsdp/test_fsdp_meta.py::TestFSDPWithMetaDevice::test_simple_model_with_meta_device_default_init [2025-09-12 11:39:01.014] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:39:01.014] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:39:01:931271 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:39:01:931271 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:39:01:931272 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:39:01:931272 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.1474s] [ 80%]
../../../../test/distributed/fsdp/test_fsdp_meta.py::TestFSDPWithMetaDevice::test_simple_model_with_meta_device_reset_params [2025-09-12 11:39:31.076] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:39:31.094] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:39:31:931432 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:39:31:931432 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:39:31:931433 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:39:31:931433 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.1481s] [ 86%]
../../../../test/distributed/fsdp/test_fsdp_meta.py::TestFSDPWithMetaDevice::test_simple_model_with_torchdistX_default_init SKIPPED [0.0002s] [ 93%]
../../../../test/distributed/fsdp/test_fsdp_meta.py::TestFSDPWithMetaDevice::test_simple_model_with_torchdistX_init_fn SKIPPED [0.0001s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_meta.py.xml -
=================== 8 passed, 7 skipped in 213.22s (0:03:33) ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 11:40:02.362] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 28 items / 1 deselected / 27 selected
Running 27 items in this shard

../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiProcess::test_cpu_init_with_sync_module_states [2025-09-12 11:40:04.696] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:40:04.710] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:40:04:931666 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:40:04:931666 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:40:04:931665 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:40:04:931665 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.3046s] [  3%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiProcess::test_fsdp_cpu_init_stays_on_cpu [2025-09-12 11:40:19.846] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:40:19.853] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:40:20:931816 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:40:20:931816 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:40:20:931817 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:40:20:931817 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.3389s] [  7%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiProcess::test_fsdp_cpu_training [2025-09-12 11:40:50.123] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:40:50.138] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:40:50:931976 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:40:50:931976 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:40:50:931977 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:40:50:931977 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1251s] [ 11%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiProcess::test_fsdp_device_id_use_index_False [2025-09-12 11:41:05.306] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:41:05.326] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:41:05:932141 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:41:05:932141 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:41:05:932140 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:41:05:932140 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.0191s] [ 14%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiProcess::test_fsdp_device_id_use_index_True [2025-09-12 11:41:20.264] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:41:20.266] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:41:20:932291 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:41:20:932291 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:41:20:932292 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:41:20:932292 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.0192s] [ 18%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiProcess::test_fsdp_module_no_compute_grad_use_second_layer_False_sharding_strategy0 [2025-09-12 11:41:35.277] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:41:35.294] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:41:35:932443 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:41:35:932443 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:41:35:932442 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:41:35:932442 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1254s] [ 22%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiProcess::test_fsdp_module_no_compute_grad_use_second_layer_False_sharding_strategy1 [2025-09-12 11:41:50.378] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:41:50.402] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:41:50:932602 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:41:50:932602 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:41:50:932601 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:41:50:932601 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.1474s] [ 25%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiProcess::test_fsdp_module_no_compute_grad_use_second_layer_True_sharding_strategy0 [2025-09-12 11:42:20.582] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:42:20.586] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:42:20:932760 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:42:20:932760 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:42:20:932761 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:42:20:932761 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1259s] [ 29%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiProcess::test_fsdp_module_no_compute_grad_use_second_layer_True_sharding_strategy1 [2025-09-12 11:42:35.695] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:42:35.714] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:42:35:932921 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:42:35:932921 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:42:35:932920 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:42:35:932920 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.0479s] [ 33%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiProcess::test_fsdp_not_all_outputs_used_in_loss [2025-09-12 11:43:05.710] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:43:05.746] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:43:05:933080 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:43:05:933080 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:43:05:933079 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:43:05:933079 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.4484s] [ 37%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiProcess::test_fsdp_optim_overlap_no_use_orig_params_error [2025-09-12 11:43:36.194] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:43:36.198] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:43:36:933239 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:43:36:933239 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:43:36:933240 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:43:36:933240 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.0254s] [ 40%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiProcess::test_fsdp_zero2_eval_with_prefetch [2025-09-12 11:43:51.209] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:43:51.210] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:43:51:933391 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:43:51:933391 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:43:51:933390 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:43:51:933390 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [66.7012s] [ 44%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiThread::test_cpu_gpu_module SKIPPED [0.0003s] [ 48%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiThread::test_device_id_auto_wrap SKIPPED [0.0001s] [ 51%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiThread::test_fsdp_device_id_cpu_offload SKIPPED [0.0002s] [ 55%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiThread::test_fsdp_device_id_no_move_ignored_params_and_bufs SKIPPED [0.0001s] [ 59%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiThread::test_fsdp_ignored_module_meta SKIPPED [0.0001s] [ 62%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiThread::test_fsdp_namedtuple SKIPPED [0.0001s] [ 66%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiThread::test_fsdp_same_model_across_ranks SKIPPED [0.0001s] [ 70%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiThread::test_fsdp_unsupported_module_cls SKIPPED [0.0001s] [ 74%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiThread::test_homogeneous_attributes SKIPPED [0.0001s] [ 77%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiThread::test_module_device_mismatches_device_id SKIPPED [0.0001s] [ 81%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiThread::test_multigpu_module SKIPPED [0.0002s] [ 85%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscMultiThread::test_no_params SKIPPED [0.0001s] [ 88%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscWorldSize1::test_training_device_mismatch_errors SKIPPED [0.0001s] [ 92%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscWorldSize1::test_unsafe_setattr SKIPPED [0.0001s] [ 96%]
../../../../test/distributed/fsdp/test_fsdp_misc.py::TestFSDPMiscWorldSize1::test_world_size_1_sharding_strategy_warning SKIPPED [0.0001s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_misc.py.xml -
=========== 12 passed, 15 skipped, 1 deselected in 295.60s (0:04:55) ===========
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 11:44:58.787] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 58 items
Running 58 items in this shard

../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_buffer_dtype_no_root_handle [2025-09-12 11:45:01.086] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:45:01.098] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:45:01:933626 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:45:01:933626 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:45:01:933627 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:45:01:933627 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.9056s] [  1%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_eval_root_cast_inputs [2025-09-12 11:45:16.747] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:45:16.750] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:45:17:933785 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:45:17:933785 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:45:17:933784 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:45:17:933784 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.4459s] [  3%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_full_precision_in_eval [2025-09-12 11:45:47.186] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:45:47.198] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:45:47:933944 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:45:47:933944 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:45:47:933945 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:45:47:933945 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.9486s] [  5%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_full_precision_in_eval_buffers [2025-09-12 11:46:18.121] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:46:18.130] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:46:18:934103 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:46:18:934103 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:46:18:934104 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:46:18:934104 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1252s] [  6%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_full_precision_in_eval_comm [2025-09-12 11:46:33.220] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:46:33.234] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:46:33:934255 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:46:33:934255 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:46:33:934254 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:46:33:934254 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.5484s] [  8%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_grads_reduced_precision [2025-09-12 11:47:03.814] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:47:03.822] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:47:04:934415 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:47:04:934414 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:47:04:934414 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:47:04:934415 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.3258s] [ 10%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_input_grads_with_param_mixed_precision [2025-09-12 11:47:19.130] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:47:19.142] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:47:19:934573 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:47:19:934574 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:47:19:934573 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:47:19:934574 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [39.0614s] [ 12%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_fp16_offload_false_fp32_enable_sharded_grad_scaler [2025-09-12 11:47:58.185] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:47:58.194] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:47:58:934733 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:47:58:934733 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:47:58:934732 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:47:58:934732 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.8265s] [ 13%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_fp16_offload_false_fp32_none [2025-09-12 11:48:14.054] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:48:14.074] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:48:14:934892 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:48:14:934892 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:48:14:934893 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:48:14:934893 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.5266s] [ 15%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_fp16_offload_false_fp64_enable_sharded_grad_scaler [2025-09-12 11:48:29.585] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:48:29.602] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:48:29:935051 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:48:29:935051 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:48:29:935050 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:48:29:935050 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.4262s] [ 17%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_fp16_offload_false_fp64_none [2025-09-12 11:48:44.991] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:48:45.010] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:48:45:935209 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:48:45:935209 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:48:45:935210 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:48:45:935210 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.4255s] [ 18%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_fp16_offload_true_fp32_enable_sharded_grad_scaler [2025-09-12 11:49:00.501] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:49:00.502] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:49:00:935368 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:49:00:935368 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:49:00:935367 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:49:00:935367 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.6254s] [ 20%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_fp16_offload_true_fp32_none [2025-09-12 11:49:16.140] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:49:16.142] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:49:16:935526 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:49:16:935526 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:49:16:935525 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:49:16:935525 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.5258s] [ 22%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_fp16_offload_true_fp64_enable_sharded_grad_scaler [2025-09-12 11:49:31.643] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:49:31.658] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:49:32:935685 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:49:32:935686 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:49:32:935685 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:49:32:935686 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.5258s] [ 24%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_fp16_offload_true_fp64_none [2025-09-12 11:49:47.118] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:49:47.118] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:49:47:935845 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:49:47:935845 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:49:47:935844 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:49:47:935844 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.4258s] [ 25%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_no_mp_offload_false_fp32_enable_sharded_grad_scaler [2025-09-12 11:50:02.524] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:50:02.534] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:50:02:936003 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:50:02:936002 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:50:02:936002 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:50:02:936003 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.3479s] [ 27%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_no_mp_offload_false_fp32_none [2025-09-12 11:50:32.870] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:50:32.873] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:50:33:936163 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:50:33:936163 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:50:33:936162 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:50:33:936162 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.3482s] [ 29%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_no_mp_offload_false_fp64_enable_sharded_grad_scaler [2025-09-12 11:51:03.270] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:51:03.298] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:51:03:936323 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:51:03:936323 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:51:03:936324 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:51:03:936324 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.3257s] [ 31%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_no_mp_offload_false_fp64_none [2025-09-12 11:51:18.622] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:51:18.630] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:51:18:936483 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:51:18:936482 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:51:18:936482 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:51:18:936483 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.4259s] [ 32%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_no_mp_offload_true_fp32_enable_sharded_grad_scaler [2025-09-12 11:51:33.959] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:51:33.978] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:51:34:936641 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:51:34:936641 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:51:34:936640 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:51:34:936640 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.2481s] [ 34%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_no_mp_offload_true_fp32_none [2025-09-12 11:52:04.274] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:52:04.290] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:52:04:936802 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:52:04:936802 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:52:04:936801 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:52:04:936801 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.3481s] [ 36%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_no_mp_offload_true_fp64_enable_sharded_grad_scaler [2025-09-12 11:52:34.574] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:52:34.579] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:52:34:936961 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:52:34:936961 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:52:34:936962 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:52:34:936962 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.3257s] [ 37%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_no_mp_offload_true_fp64_none [2025-09-12 11:52:49.970] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:52:49.978] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:52:50:937121 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:52:50:937121 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:52:50:937120 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:52:50:937120 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.3256s] [ 39%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_only_param_and_buf_offload_false_fp32_enable_sharded_grad_scaler [2025-09-12 11:53:05.290] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:53:05.306] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:53:05:937278 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:53:05:937278 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:53:05:937279 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:53:05:937279 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.7260s] [ 41%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_only_param_and_buf_offload_false_fp32_none [2025-09-12 11:53:21.034] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:53:21.049] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:53:21:937437 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:53:21:937437 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:53:21:937436 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:53:21:937436 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.7263s] [ 43%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_only_param_and_buf_offload_false_fp64_enable_sharded_grad_scaler [2025-09-12 11:53:36.722] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:53:36.732] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:53:36:937594 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:53:36:937594 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:53:36:937595 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:53:36:937595 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.5254s] [ 44%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_only_param_and_buf_offload_false_fp64_none [2025-09-12 11:53:52.291] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:53:52.298] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:53:52:937754 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:53:52:937755 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:53:52:937755 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:53:52:937754 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.5265s] [ 46%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_only_param_and_buf_offload_true_fp32_enable_sharded_grad_scaler [2025-09-12 11:54:07.742] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:54:07.746] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:54:08:937913 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:54:08:937913 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:54:08:937912 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:54:08:937912 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.4257s] [ 48%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_only_param_and_buf_offload_true_fp32_none [2025-09-12 11:54:23.174] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:54:23.186] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:54:23:938070 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:54:23:938070 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:54:23:938071 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:54:23:938071 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.6263s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_only_param_and_buf_offload_true_fp64_enable_sharded_grad_scaler [2025-09-12 11:54:38.853] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:54:38.854] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:54:39:938230 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:54:39:938230 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:54:39:938229 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:54:39:938229 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.4261s] [ 51%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_only_param_and_buf_offload_true_fp64_none [2025-09-12 11:54:54.237] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:54:54.254] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:54:54:938388 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:54:54:938388 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:54:54:938389 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:54:54:938389 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.4258s] [ 53%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_only_reduce_offload_false_fp32_enable_sharded_grad_scaler [2025-09-12 11:55:09.622] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:55:09.638] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:55:10:938547 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:55:10:938548 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:55:10:938548 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:55:10:938547 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.5250s] [ 55%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_only_reduce_offload_false_fp32_none [2025-09-12 11:55:25.188] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:55:25.206] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:55:25:938707 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:55:25:938707 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:55:25:938706 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:55:25:938706 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.5261s] [ 56%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_only_reduce_offload_false_fp64_enable_sharded_grad_scaler [2025-09-12 11:55:40.702] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:55:40.718] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:55:41:938866 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:55:41:938866 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:55:41:938867 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:55:41:938867 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.4256s] [ 58%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_only_reduce_offload_false_fp64_none [2025-09-12 11:55:56.170] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:55:56.198] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:55:56:939024 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:55:56:939024 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:55:56:939025 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:55:56:939025 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.4260s] [ 60%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_only_reduce_offload_true_fp32_enable_sharded_grad_scaler [2025-09-12 11:56:11.545] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:56:11.562] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:56:11:939184 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:56:11:939184 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:56:11:939183 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:56:11:939183 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.4258s] [ 62%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_only_reduce_offload_true_fp32_none [2025-09-12 11:56:27.026] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:56:27.047] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:56:27:939341 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:56:27:939341 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:56:27:939342 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:56:27:939342 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.6244s] [ 63%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_only_reduce_offload_true_fp64_enable_sharded_grad_scaler [2025-09-12 11:56:42.663] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:56:42.670] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:56:43:939507 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:56:43:939508 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:56:43:939507 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:56:43:939508 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.4262s] [ 65%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_e2e_full_shard_mp_only_reduce_offload_true_fp64_none [2025-09-12 11:56:58.050] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:56:58.068] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:56:58:939666 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:56:58:939666 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:56:58:939667 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:56:58:939667 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.4262s] [ 67%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_no_reshard_after_forward [2025-09-12 11:57:13.454] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:57:13.470] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:57:13:939824 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:57:13:939824 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:57:13:939825 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:57:13:939825 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.2253s] [ 68%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mixed_precision_resnet [2025-09-12 11:57:28.690] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:57:28.701] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:57:29:939982 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:57:29:939982 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:57:29:939983 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:57:29:939983 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [35.5559s] [ 70%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mp_batchnorm_convert_sync_bn_False [2025-09-12 11:58:04.275] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:58:04.304] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:58:04:940143 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:58:04:940143 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:58:04:940144 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:58:04:940144 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.2479s] [ 72%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mp_batchnorm_convert_sync_bn_True [2025-09-12 11:58:34.482] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:58:34.498] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:58:34:940301 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:58:34:940301 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:58:34:940302 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:58:34:940302 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.4483s] [ 74%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mp_embedding_default [2025-09-12 11:59:04.928] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:59:04.950] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:59:05:940460 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:59:05:940460 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:59:05:940461 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:59:05:940461 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.6251s] [ 75%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mp_embedding_only_params_and_bufs [2025-09-12 11:59:20.561] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:59:20.578] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:59:20:940619 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:59:20:940619 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:59:20:940618 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:59:20:940618 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.6262s] [ 77%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mp_embedding_params_and_reduce_diff [2025-09-12 11:59:36.214] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 11:59:36.218] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-11:59:36:940780 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:59:36:940780 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-11:59:36:940781 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-11:59:36:940781 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [26.9430s] [ 79%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionSharded::test_mp_embedding_reduce [2025-09-12 12:00:03.194] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:00:03.218] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:00:03:940939 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:00:03:940939 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:00:03:940940 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:00:03:940940 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.7261s] [ 81%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionUnsharded::test_grads_reduced_precision [2025-09-12 12:00:18.950] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:00:19:941097 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:00:19:941097 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.5071s] [ 82%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionUnsharded::test_mixed_precision_e2e_full_shard [2025-09-12 12:00:22.458] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:00:22:941176 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:00:22:941176 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.4070s] [ 84%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionUnsharded::test_mixed_precision_no_reshard_after_forward [2025-09-12 12:00:25.862] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:00:26:941254 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:00:26:941254 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.3070s] [ 86%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPMixedPrecisionIgnoredModules::test_mixed_precision_with_ignored_module [2025-09-12 12:00:29.170] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:00:29:941332 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:00:29:941332 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.2073s] [ 87%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPDifferentSubmodulePrecision::test_float16_on_one_submodule [2025-09-12 12:00:32.325] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:00:32.326] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:00:32:941406 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:00:32:941406 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:00:32:941407 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:00:32:941407 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [26.7414s] [ 89%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPDifferentSubmodulePrecision::test_float16_on_one_submodule_skip_inputs [2025-09-12 12:00:59.102] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:00:59.118] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:00:59:941565 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:00:59:941565 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:00:59:941566 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:00:59:941566 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [26.6420s] [ 91%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPDifferentSubmodulePrecision::test_float16_on_one_submodule_skip_inputs_error [2025-09-12 12:01:25.686] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:01:25.686] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:01:26:941725 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:01:26:941726 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:01:26:941726 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:01:26:941725 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1236s] [ 93%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPDifferentSubmodulePrecision::test_submodules_with_different_precisions [2025-09-12 12:01:40.824] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:01:40.846] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:01:41:941877 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:01:41:941877 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:01:41:941876 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:01:41:941876 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [26.4421s] [ 94%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPDifferentSubmodulePrecision::test_submodules_with_different_precisions_error [2025-09-12 12:02:07.222] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:02:07.234] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:02:07:942035 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:02:07:942036 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:02:07:942036 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:02:07:942035 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1251s] [ 96%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPDifferentSubmodulePrecision::test_submodules_with_external_inputs [2025-09-12 12:02:22.454] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:02:22.461] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:02:22:942188 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:02:22:942188 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:02:22:942187 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:02:22:942187 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.2254s] [ 98%]
../../../../test/distributed/fsdp/test_fsdp_mixed_precision.py::TestFSDPTrainEval::test_train_ema_eval_flow [2025-09-12 12:02:37.587] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:02:37.587] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:02:37:942345 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:02:37:942345 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:02:37:942346 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:02:37:942346 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
FullyShardedDataParallel(
  (_fsdp_wrapped_module): TransformerWithEMA(
    (module): FullyShardedDataParallel(
      (_fsdp_wrapped_module): Transformer(
        (encoder): TransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x FullyShardedDataParallel(
              (_fsdp_wrapped_module): TransformerEncoderLayer(
                (self_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
                )
                (linear1): Linear(in_features=512, out_features=2048, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (linear2): Linear(in_features=2048, out_features=512, bias=True)
                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (dropout2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (decoder): TransformerDecoder(
          (layers): ModuleList(
            (0-5): 6 x FullyShardedDataParallel(
              (_fsdp_wrapped_module): TransformerDecoderLayer(
                (self_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
                )
                (multihead_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
                )
                (linear1): Linear(in_features=512, out_features=2048, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (linear2): Linear(in_features=2048, out_features=512, bias=True)
                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (dropout2): Dropout(p=0.1, inplace=False)
                (dropout3): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (ema_module): AveragedModel(
      (module): FullyShardedDataParallel(
        (_fsdp_wrapped_module): Transformer(
          (encoder): TransformerEncoder(
            (layers): ModuleList(
              (0-5): 6 x FullyShardedDataParallel(
                (_fsdp_wrapped_module): TransformerEncoderLayer(
                  (self_attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
                  )
                  (linear1): Linear(in_features=512, out_features=2048, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                  (linear2): Linear(in_features=2048, out_features=512, bias=True)
                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                  (dropout1): Dropout(p=0.1, inplace=False)
                  (dropout2): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (decoder): TransformerDecoder(
            (layers): ModuleList(
              (0-5): 6 x FullyShardedDataParallel(
                (_fsdp_wrapped_module): TransformerDecoderLayer(
                  (self_attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
                  )
                  (multihead_attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
                  )
                  (linear1): Linear(in_features=512, out_features=2048, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                  (linear2): Linear(in_features=2048, out_features=512, bias=True)
                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                  (dropout1): Dropout(p=0.1, inplace=False)
                  (dropout2): Dropout(p=0.1, inplace=False)
                  (dropout3): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
  )
)
FullyShardedDataParallel(
  (_fsdp_wrapped_module): TransformerWithEMA(
    (module): FullyShardedDataParallel(
      (_fsdp_wrapped_module): Transformer(
        (encoder): TransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x FullyShardedDataParallel(
              (_fsdp_wrapped_module): TransformerEncoderLayer(
                (self_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
                )
                (linear1): Linear(in_features=512, out_features=2048, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (linear2): Linear(in_features=2048, out_features=512, bias=True)
                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (dropout2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (decoder): TransformerDecoder(
          (layers): ModuleList(
            (0-5): 6 x FullyShardedDataParallel(
              (_fsdp_wrapped_module): TransformerDecoderLayer(
                (self_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
                )
                (multihead_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
                )
                (linear1): Linear(in_features=512, out_features=2048, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (linear2): Linear(in_features=2048, out_features=512, bias=True)
                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (dropout2): Dropout(p=0.1, inplace=False)
                (dropout3): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (ema_module): AveragedModel(
      (module): FullyShardedDataParallel(
        (_fsdp_wrapped_module): Transformer(
          (encoder): TransformerEncoder(
            (layers): ModuleList(
              (0-5): 6 x FullyShardedDataParallel(
                (_fsdp_wrapped_module): TransformerEncoderLayer(
                  (self_attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
                  )
                  (linear1): Linear(in_features=512, out_features=2048, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                  (linear2): Linear(in_features=2048, out_features=512, bias=True)
                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                  (dropout1): Dropout(p=0.1, inplace=False)
                  (dropout2): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (decoder): TransformerDecoder(
            (layers): ModuleList(
              (0-5): 6 x FullyShardedDataParallel(
                (_fsdp_wrapped_module): TransformerDecoderLayer(
                  (self_attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
                  )
                  (multihead_attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
                  )
                  (linear1): Linear(in_features=512, out_features=2048, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                  (linear2): Linear(in_features=2048, out_features=512, bias=True)
                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                  (dropout1): Dropout(p=0.1, inplace=False)
                  (dropout2): Dropout(p=0.1, inplace=False)
                  (dropout3): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
  )
)
dist init r=1, world=2
FullyShardedDataParallel(
  (_fsdp_wrapped_module): TransformerWithEMA(
    (module): FullyShardedDataParallel(
      (_fsdp_wrapped_module): Transformer(
        (encoder): TransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x FullyShardedDataParallel(
              (_fsdp_wrapped_module): TransformerEncoderLayer(
                (self_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
                )
                (linear1): Linear(in_features=512, out_features=2048, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (linear2): Linear(in_features=2048, out_features=512, bias=True)
                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (dropout2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (decoder): TransformerDecoder(
          (layers): ModuleList(
            (0-5): 6 x FullyShardedDataParallel(
              (_fsdp_wrapped_module): TransformerDecoderLayer(
                (self_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
                )
                (multihead_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
                )
                (linear1): Linear(in_features=512, out_features=2048, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (linear2): Linear(in_features=2048, out_features=512, bias=True)
                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (dropout2): Dropout(p=0.1, inplace=False)
                (dropout3): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (ema_module): AveragedModel(
      (module): FullyShardedDataParallel(
        (_fsdp_wrapped_module): Transformer(
          (encoder): TransformerEncoder(
            (layers): ModuleList(
              (0-5): 6 x FullyShardedDataParallel(
                (_fsdp_wrapped_module): TransformerEncoderLayer(
                  (self_attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
                  )
                  (linear1): Linear(in_features=512, out_features=2048, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                  (linear2): Linear(in_features=2048, out_features=512, bias=True)
                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                  (dropout1): Dropout(p=0.1, inplace=False)
                  (dropout2): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (decoder): TransformerDecoder(
            (layers): ModuleList(
              (0-5): 6 x FullyShardedDataParallel(
                (_fsdp_wrapped_module): TransformerDecoderLayer(
                  (self_attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
                  )
                  (multihead_attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
                  )
                  (linear1): Linear(in_features=512, out_features=2048, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                  (linear2): Linear(in_features=2048, out_features=512, bias=True)
                  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                  (dropout1): Dropout(p=0.1, inplace=False)
                  (dropout2): Dropout(p=0.1, inplace=False)
                  (dropout3): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
  )
)
PASSED [17.0283s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_mixed_precision.py.xml -
======================= 58 passed in 1075.88s (0:17:55) ========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 12:02:55.643] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/fsdp/test_fsdp_multiple_forward.py::TestMultiForwardCPU::test_multi_forward_cpu [2025-09-12 12:02:57.870] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:02:57.870] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:02:57.886] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:02:57.894] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:02:58:942586 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:02:58:942586 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:02:58:942585 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:02:58:942585 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:02:58:942583 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:02:58:942583 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:02:58:942584 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:02:58:942584 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.2475s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_multiple_forward.py::TestMultiForwardXPU::test_multi_forward_xpu [2025-09-12 12:03:29.050] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:03:29.121] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:03:29.121] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:03:29.142] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:03:29:942904 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:03:29:942904 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:03:29:942901 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:03:29:942901 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:03:29:942902 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:03:29:942902 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:03:29:942903 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:03:29:942903 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.3391s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_multiple_forward.py.xml -
========================= 2 passed in 64.80s (0:01:04) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 12:04:01.346] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 1 item
Running 1 items in this shard

../../../../test/distributed/fsdp/test_fsdp_multiple_wrapping.py::TestMultipleWrappingXPU::test_multiple_wrapping_xpu [2025-09-12 12:04:03.503] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:04:03.509] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:04:03.518] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:04:03.527] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:04:03:943296 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:04:03:943296 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:04:03:943297 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:04:03:943297 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:04:03:943295 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:04:03:943295 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:04:04:943294 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:04:04:943294 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [31.3472s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_multiple_wrapping.py.xml -
============================== 1 passed in 33.50s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 12:04:35.846] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 60 items
Running 60 items in this shard

../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_compatible_with_trec [2025-09-12 12:04:38.187] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:04:38.195] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:04:38.223] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:04:38.227] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:04:38:943687 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:04:38:943687 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:04:38:943686 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:04:38:943686 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:04:38:943688 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:04:38:943688 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:04:38:943689 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:04:38:943689 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [31.8530s] [  1%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_flatten_sharded_optim_state_dict_nested [2025-09-12 12:05:09.827] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:05:09.846] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:05:09.853] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:05:09.870] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:05:10:944009 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:05:10:944009 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:05:10:944006 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:05:10:944006 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:05:10:944007 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:05:10:944007 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:05:10:944008 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:05:10:944008 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
PASSED [31.5565s] [  3%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_flatten_sharded_optim_state_dict_transformer [2025-09-12 12:05:41.374] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:05:41.414] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:05:41.426] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:05:41.428] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:05:41:944325 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:05:41:944325 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:05:41:944324 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:05:41:944324 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:05:41:944326 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:05:41:944326 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:05:41:944327 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:05:41:944327 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [32.6579s] [  5%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_full_optim_state_dict_keys [2025-09-12 12:06:14.041] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:06:14.062] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:06:14.065] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:06:14.082] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:06:14:944646 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:06:14:944646 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:06:14:944649 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:06:14:944649 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:06:14:944648 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:06:14:944648 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:06:14:944647 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:06:14:944647 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [31.0545s] [  6%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_full_optim_state_dict_nested_invalid [2025-09-12 12:06:45.090] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:06:45.138] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:06:45.160] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:06:45.178] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:06:45:944966 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:06:45:944966 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:06:45:944967 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:06:45:944967 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:06:45:944965 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:06:45:944965 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:06:45:944964 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:06:45:944964 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [31.3552s] [  8%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_interface_arguments [2025-09-12 12:07:16.499] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:07:16.564] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:07:16.630] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:07:16.633] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:07:16:945281 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:07:16:945281 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:07:16:945284 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:07:16:945284 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:07:16:945283 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:07:16:945283 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:07:16:945282 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:07:16:945282 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [31.7546s] [ 10%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_no_grad [2025-09-12 12:07:48.286] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:07:48.298] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:07:48.299] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:07:48.299] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:07:48:945602 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:07:48:945602 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:07:48:945599 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:07:48:945599 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:07:48:945601 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:07:48:945601 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:07:48:945600 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:07:48:945600 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [31.9573s] [ 11%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_optim_input_warning [2025-09-12 12:08:20.171] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:08:20.186] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:08:20.330] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:08:20.334] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:08:20:945915 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:08:20:945915 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:08:20:945918 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:08:20:945918 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:08:20:945917 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:08:20:945917 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:08:20:945916 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:08:20:945916 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.5551s] [ 13%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_optim_state_dict_nested_state_dict_type0_use_multiple_param_groups_False_rank0_only_False_use_diff_optim_inputs_False [2025-09-12 12:08:51.725] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:08:51.746] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:08:51.754] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:08:51.770] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:08:51:946236 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:08:51:946236 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:08:51:946235 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:08:51:946235 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:08:51:946233 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:08:51:946233 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:08:51:946234 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:08:51:946234 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [31.6563s] [ 15%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_optim_state_dict_nested_state_dict_type0_use_multiple_param_groups_False_rank0_only_False_use_diff_optim_inputs_True [2025-09-12 12:09:23.418] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:09:23.418] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:09:23.435] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:09:23.438] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:09:23:946551 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:09:23:946551 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:09:23:946553 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:09:23:946553 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:09:23:946552 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:09:23:946552 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:09:23:946554 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:09:23:946554 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [30.9550s] [ 16%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_optim_state_dict_nested_state_dict_type0_use_multiple_param_groups_False_rank0_only_True_use_diff_optim_inputs_False [2025-09-12 12:09:54.340] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:09:54.358] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:09:54.362] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:09:54.370] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:09:54:946870 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:09:54:946870 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:09:54:946869 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:09:54:946869 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:09:54:946871 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:09:54:946871 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:09:54:946872 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:09:54:946872 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [31.4576s] [ 18%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_optim_state_dict_nested_state_dict_type0_use_multiple_param_groups_False_rank0_only_True_use_diff_optim_inputs_True [2025-09-12 12:10:25.814] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:10:25.814] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:10:25.846] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:10:25.846] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:10:26:947190 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:10:26:947190 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:10:26:947188 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:10:26:947188 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:10:26:947187 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:10:26:947187 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:10:26:947189 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:10:26:947189 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
PASSED [31.5562s] [ 20%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_optim_state_dict_nested_state_dict_type0_use_multiple_param_groups_True_rank0_only_False_use_diff_optim_inputs_False [2025-09-12 12:10:57.359] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:10:57.372] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:10:57.382] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:10:57.384] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:10:57:947507 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:10:57:947507 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:10:57:947506 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:10:57:947506 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:10:57:947505 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:10:57:947505 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:10:57:947508 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:10:57:947508 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.1549s] [ 21%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_optim_state_dict_nested_state_dict_type0_use_multiple_param_groups_True_rank0_only_False_use_diff_optim_inputs_True [2025-09-12 12:11:28.541] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:11:28.567] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:11:28.568] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:11:28.601] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:11:28:947824 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:11:28:947824 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:11:28:947826 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:11:28:947826 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:11:28:947827 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:11:28:947827 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:11:28:947825 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:11:28:947825 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [31.6574s] [ 23%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_optim_state_dict_nested_state_dict_type0_use_multiple_param_groups_True_rank0_only_True_use_diff_optim_inputs_False [2025-09-12 12:12:00.178] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:12:00.186] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:12:00.213] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:12:00.226] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:12:00:948142 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:12:00:948142 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:12:00:948144 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:12:00:948144 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:12:00:948143 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:12:00:948143 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:12:00:948141 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:12:00:948141 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [31.7571s] [ 25%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_optim_state_dict_nested_state_dict_type0_use_multiple_param_groups_True_rank0_only_True_use_diff_optim_inputs_True [2025-09-12 12:12:31.975] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:12:31.993] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:12:31.993] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:12:31.993] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:12:32:948461 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:12:32:948461 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:12:32:948462 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:12:32:948462 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:12:32:948464 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:12:32:948464 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:12:32:948463 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:12:32:948463 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [31.5570s] [ 26%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_optim_state_dict_nested_state_dict_type1_use_multiple_param_groups_False_rank0_only_False_use_diff_optim_inputs_False [2025-09-12 12:13:03.491] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:13:03.505] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:13:03.507] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:13:03.507] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:13:03:948783 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:13:03:948783 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:13:03:948781 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:13:03:948781 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:13:03:948780 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:13:03:948780 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:13:03:948782 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:13:03:948782 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [31.5564s] [ 28%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_optim_state_dict_nested_state_dict_type1_use_multiple_param_groups_False_rank0_only_False_use_diff_optim_inputs_True [2025-09-12 12:13:35.090] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:13:35.090] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:13:35.102] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:13:35.122] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:13:35:949097 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:13:35:949097 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:13:35:949099 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:13:35:949099 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:13:35:949098 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:13:35:949098 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:13:35:949100 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:13:35:949100 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [31.4565s] [ 30%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_optim_state_dict_nested_state_dict_type1_use_multiple_param_groups_False_rank0_only_True_use_diff_optim_inputs_False [2025-09-12 12:14:06.478] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:14:06.557] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:14:06.557] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:14:06.575] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:14:06:949418 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:14:06:949418 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:14:06:949419 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:14:06:949419 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:14:06:949417 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:14:06:949417 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:14:06:949416 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:14:06:949416 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
PASSED [15.7296s] [ 31%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_optim_state_dict_nested_state_dict_type1_use_multiple_param_groups_False_rank0_only_True_use_diff_optim_inputs_True [2025-09-12 12:14:22.282] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:14:22.304] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:14:22.304] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:14:22.314] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:14:22:949720 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:14:22:949720 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:14:22:949721 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:14:22:949721 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:14:22:949719 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:14:22:949719 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:14:22:949718 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:14:22:949718 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [15.5292s] [ 33%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_optim_state_dict_nested_state_dict_type1_use_multiple_param_groups_True_rank0_only_False_use_diff_optim_inputs_False [2025-09-12 12:14:37.786] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:14:37.790] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:14:37.826] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:14:37.840] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:14:37:950019 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:14:37:950019 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:14:38:950022 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:14:38:950022 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:14:38:950021 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:14:38:950021 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:14:38:950020 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:14:38:950020 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.5558s] [ 35%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_optim_state_dict_nested_state_dict_type1_use_multiple_param_groups_True_rank0_only_False_use_diff_optim_inputs_True [2025-09-12 12:15:09.338] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:15:09.344] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:15:09.345] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:15:09.366] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:15:09:950335 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:15:09:950335 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:15:09:950337 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:15:09:950337 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:15:09:950336 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:15:09:950336 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:15:09:950338 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:15:09:950338 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.1541s] [ 36%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_optim_state_dict_nested_state_dict_type1_use_multiple_param_groups_True_rank0_only_True_use_diff_optim_inputs_False [2025-09-12 12:15:40.507] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:15:40.511] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:15:40.521] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:15:40.534] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:15:40:950655 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:15:40:950655 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:15:40:950654 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:15:40:950654 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:15:40:950657 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:15:40:950657 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:15:40:950656 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:15:40:950656 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [15.7295s] [ 38%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_optim_state_dict_nested_state_dict_type1_use_multiple_param_groups_True_rank0_only_True_use_diff_optim_inputs_True [2025-09-12 12:15:56.282] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:15:56.298] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:15:56.322] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:15:56.327] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:15:56:950957 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:15:56:950957 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:15:56:950958 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:15:56:950958 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:15:56:950955 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:15:56:950955 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:15:56:950956 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:15:56:950956 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [15.7296s] [ 40%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_optim_state_without_param_groups [2025-09-12 12:16:11.962] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:16:11.966] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:16:11.978] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:16:11.987] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:16:12:951257 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:16:12:951257 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:16:12:951258 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:16:12:951258 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:16:12:951256 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:16:12:951256 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:16:12:951259 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:16:12:951259 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [31.5565s] [ 41%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_rekey_optim_state_dict_to_ids_state_dict_type0_use_multiple_param_groups_False [2025-09-12 12:16:43.489] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:16:43.506] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:16:43.534] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:16:43.542] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:16:43:951575 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:16:43:951575 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:16:43:951576 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:16:43:951576 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:16:43:951574 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:16:43:951574 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:16:43:951577 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:16:43:951577 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [31.6566s] [ 43%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_rekey_optim_state_dict_to_ids_state_dict_type0_use_multiple_param_groups_True [2025-09-12 12:17:15.130] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:17:15.170] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:17:15.172] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:17:15.239] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:17:15:951895 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:17:15:951895 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:17:15:951896 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:17:15:951896 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:17:15:951897 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:17:15:951897 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:17:15:951894 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:17:15:951894 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [31.6563s] [ 45%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_rekey_optim_state_dict_to_ids_state_dict_type1_use_multiple_param_groups_False [2025-09-12 12:17:46.815] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:17:46.834] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:17:46.841] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:17:46.854] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:17:47:952214 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:17:47:952214 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:17:47:952212 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:17:47:952212 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:17:47:952213 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:17:47:952213 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:17:47:952215 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:17:47:952215 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [31.1563s] [ 46%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_rekey_optim_state_dict_to_ids_state_dict_type1_use_multiple_param_groups_True [2025-09-12 12:18:17.971] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:18:17.984] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:18:17.989] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:18:17.989] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:18:18:952532 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:18:18:952532 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:18:18:952533 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:18:18:952533 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:18:18:952530 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:18:18:952530 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:18:18:952531 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:18:18:952531 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [31.2561s] [ 48%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_rekey_optim_state_dict_to_names [2025-09-12 12:18:49.219] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:18:49.234] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:18:49.245] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:18:49.274] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:18:49:952848 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:18:49:952848 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:18:49:952849 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:18:49:952849 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:18:49:952851 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:18:49:952851 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:18:49:952850 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:18:49:952850 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [31.6564s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_save_load_without_0th_param_state_state_dict_type0 [2025-09-12 12:19:20.872] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:19:20.894] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:19:20.898] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:19:20.922] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:19:21:953166 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:19:21:953166 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:19:21:953165 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:19:21:953165 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:19:21:953167 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:19:21:953167 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:19:21:953164 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:19:21:953164 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [31.1548s] [ 51%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_save_load_without_0th_param_state_state_dict_type1 [2025-09-12 12:19:52.046] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:19:52.102] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:19:52.103] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:19:52.126] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:19:52:953486 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:19:52:953486 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:19:52:953487 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:19:52:953487 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:19:52:953485 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:19:52:953485 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:19:52:953484 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:19:52:953484 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [31.5555s] [ 53%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_scatter_full_optim_state_dict_nested_halve_world_size [2025-09-12 12:20:23.691] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:20:23.692] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:20:23.695] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:20:23.704] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:20:23:953803 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:20:23:953803 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:20:23:953804 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:20:23:953804 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:20:23:953802 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:20:23:953802 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:20:23:953801 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:20:23:953801 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:20:52:953803:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:20:52:953801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:20:52:953803:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:20:52:953801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:20:53:953803:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:20:53:953801:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [32.7568s] [ 55%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_scatter_full_optim_state_dict_nested_use_multiple_param_groups_False_wrap_alt_False_use_diff_optim_inputs_False [2025-09-12 12:20:56.360] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:20:56.361] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:20:56.382] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:20:56.402] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:20:56:954136 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:20:56:954136 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:20:56:954133 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:20:56:954133 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:20:56:954134 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:20:56:954134 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:20:56:954135 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:20:56:954135 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [32.0574s] [ 56%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_scatter_full_optim_state_dict_nested_use_multiple_param_groups_False_wrap_alt_False_use_diff_optim_inputs_True [2025-09-12 12:21:28.411] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:21:28.426] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:21:28.437] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:21:28.437] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:21:28:954451 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:21:28:954451 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:21:28:954453 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:21:28:954453 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:21:28:954454 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:21:28:954454 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:21:28:954452 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:21:28:954452 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [31.6564s] [ 58%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_scatter_full_optim_state_dict_nested_use_multiple_param_groups_False_wrap_alt_True_use_diff_optim_inputs_False [2025-09-12 12:22:00.126] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:22:00.134] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:22:00.140] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:22:00.154] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:22:00:954770 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:22:00:954770 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:22:00:954772 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:22:00:954772 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:22:00:954769 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:22:00:954769 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:22:00:954771 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:22:00:954771 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [31.7563s] [ 60%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_scatter_full_optim_state_dict_nested_use_multiple_param_groups_False_wrap_alt_True_use_diff_optim_inputs_True [2025-09-12 12:22:31.830] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:22:31.838] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:22:31.840] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:22:31.842] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:22:32:955089 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:22:32:955089 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:22:32:955091 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:22:32:955091 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:22:32:955092 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:22:32:955092 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:22:32:955090 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:22:32:955090 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
PASSED [31.5560s] [ 61%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_scatter_full_optim_state_dict_nested_use_multiple_param_groups_True_wrap_alt_False_use_diff_optim_inputs_False [2025-09-12 12:23:03.371] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:23:03.417] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:23:03.450] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:23:03.455] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:23:03:955410 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:23:03:955410 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:23:03:955407 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:23:03:955407 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:23:03:955408 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:23:03:955408 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:23:03:955409 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:23:03:955409 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [31.6559s] [ 63%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_scatter_full_optim_state_dict_nested_use_multiple_param_groups_True_wrap_alt_False_use_diff_optim_inputs_True [2025-09-12 12:23:35.022] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:23:35.065] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:23:35.082] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:23:35.082] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:23:35:955727 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:23:35:955727 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:23:35:955724 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:23:35:955724 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:23:35:955726 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:23:35:955726 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:23:35:955725 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:23:35:955725 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [31.9573s] [ 65%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_scatter_full_optim_state_dict_nested_use_multiple_param_groups_True_wrap_alt_True_use_diff_optim_inputs_False [2025-09-12 12:24:06.994] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:24:07.025] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:24:07.046] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:24:07.050] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:24:07:956043 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:24:07:956043 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:24:07:956046 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:24:07:956046 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:24:07:956044 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:24:07:956044 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:24:07:956045 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:24:07:956045 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [31.7563s] [ 66%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_scatter_full_optim_state_dict_nested_use_multiple_param_groups_True_wrap_alt_True_use_diff_optim_inputs_True [2025-09-12 12:24:38.750] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:24:38.810] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:24:38.826] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:24:38.838] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:24:38:956362 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:24:38:956362 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:24:39:956363 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:24:39:956363 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:24:39:956361 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:24:39:956361 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:24:39:956360 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:24:39:956360 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.8566s] [ 68%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_scatter_full_optim_state_dict_transformer [2025-09-12 12:25:10.604] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:25:10.614] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:25:10.644] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:25:10.663] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:25:10:956679 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:25:10:956679 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:25:10:956680 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:25:10:956680 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:25:10:956677 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:25:10:956677 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:25:10:956678 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:25:10:956678 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:25:39:956677:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:25:39:956679:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:25:40:956679:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:25:40:956677:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:25:40:956677:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:25:40:956679:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [33.3595s] [ 70%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_shard_full_optim_state_dict_nested_halve_world_size [2025-09-12 12:25:43.971] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:25:43.986] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:25:43.989] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:25:43.995] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:25:44:957009 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:25:44:957009 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:25:44:957010 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:25:44:957010 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:25:44:957012 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:25:44:957012 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:25:44:957011 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:25:44:957011 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:26:12:957009:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:26:12:957011:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:26:12:957009:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:26:12:957011:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:26:13:957009:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:26:13:957011:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [32.3570s] [ 71%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_shard_full_optim_state_dict_nested_use_multiple_param_groups_False_wrap_alt_False_use_diff_optim_inputs_False [2025-09-12 12:26:16.356] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:26:16.360] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:26:16.366] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:26:16.384] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:26:16:957342 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:26:16:957342 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:26:16:957339 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:26:16:957339 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:26:16:957340 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:26:16:957340 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:26:16:957341 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:26:16:957341 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.6563s] [ 73%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_shard_full_optim_state_dict_nested_use_multiple_param_groups_False_wrap_alt_False_use_diff_optim_inputs_True [2025-09-12 12:26:47.993] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:26:48.006] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:26:48.147] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:26:48:957661 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:26:48:957661 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
[2025-09-12 12:26:48.219] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:26:48:957658 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:26:48:957658 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:26:48:957660 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:26:48:957660 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:26:48:957659 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:26:48:957659 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [32.0584s] [ 75%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_shard_full_optim_state_dict_nested_use_multiple_param_groups_False_wrap_alt_True_use_diff_optim_inputs_False [2025-09-12 12:27:20.051] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:27:20.063] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:27:20.063] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:27:20.063] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:27:20:957975 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:27:20:957975 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:27:20:957976 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:27:20:957976 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:27:20:957978 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:27:20:957978 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:27:20:957977 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:27:20:957977 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [31.7569s] [ 76%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_shard_full_optim_state_dict_nested_use_multiple_param_groups_False_wrap_alt_True_use_diff_optim_inputs_True [2025-09-12 12:27:51.819] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:27:51.834] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:27:51.835] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:27:51.858] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:27:52:958296 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:27:52:958296 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:27:52:958297 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:27:52:958297 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:27:52:958295 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:27:52:958295 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:27:52:958298 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:27:52:958298 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [31.8570s] [ 78%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_shard_full_optim_state_dict_nested_use_multiple_param_groups_True_wrap_alt_False_use_diff_optim_inputs_False [2025-09-12 12:28:23.646] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:28:23.691] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:28:23.706] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:28:23.710] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:28:23:958612 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:28:23:958612 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:28:23:958613 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:28:23:958613 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:28:23:958615 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:28:23:958615 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:28:23:958614 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:28:23:958614 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [31.5557s] [ 80%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_shard_full_optim_state_dict_nested_use_multiple_param_groups_True_wrap_alt_False_use_diff_optim_inputs_True [2025-09-12 12:28:55.230] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:28:55.234] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:28:55.274] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:28:55.274] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:28:55:958936 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:28:55:958936 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:28:55:958935 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:28:55:958935 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:28:55:958934 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:28:55:958934 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:28:55:958933 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:28:55:958933 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [31.8572s] [ 81%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_shard_full_optim_state_dict_nested_use_multiple_param_groups_True_wrap_alt_True_use_diff_optim_inputs_False [2025-09-12 12:29:27.124] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:29:27.127] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:29:27.134] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:29:27.142] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:29:27:959255 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:29:27:959255 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:29:27:959253 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:29:27:959253 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:29:27:959254 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:29:27:959254 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:29:27:959256 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:29:27:959256 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [31.2525s] [ 83%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_shard_full_optim_state_dict_nested_use_multiple_param_groups_True_wrap_alt_True_use_diff_optim_inputs_True [2025-09-12 12:29:58.347] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:29:58.368] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:29:58.370] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:29:58.377] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:29:58:959573 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:29:58:959573 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:29:58:959571 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:29:58:959571 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:29:58:959572 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:29:58:959572 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:29:58:959574 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:29:58:959574 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [31.7566s] [ 85%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_shard_full_optim_state_dict_transformer [2025-09-12 12:30:30.117] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:30:30.134] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:30:30.147] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:30:30.147] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:30:30:959891 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:30:30:959891 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:30:30:959892 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:30:30:959892 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:30:30:959890 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:30:30:959890 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:30:30:959889 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:30:30:959889 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:30:58:959889:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:30:58:959891:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:30:59:959889:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:30:59:959891:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:31:00:959889:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:31:00:959891:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [33.0573s] [ 86%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_shard_full_optim_state_dict_unmanaged_params_state_dict_type0_add_to_fsdp_module_False [2025-09-12 12:31:03.150] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:31:03.183] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:31:03.202] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:31:03.206] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:31:03:960219 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:31:03:960219 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:31:03:960220 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:31:03:960220 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:31:03:960222 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:31:03:960222 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:31:03:960221 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:31:03:960221 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [31.4386s] [ 88%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_shard_full_optim_state_dict_unmanaged_params_state_dict_type0_add_to_fsdp_module_True [2025-09-12 12:31:34.583] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:31:34.587] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:31:34.617] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:31:34.631] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:31:34:960537 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:31:34:960537 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:31:34:960539 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:31:34:960539 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:31:34:960538 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:31:34:960538 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:31:34:960540 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:31:34:960540 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [31.4565s] [ 90%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_shard_full_optim_state_dict_unmanaged_params_state_dict_type1_add_to_fsdp_module_False [2025-09-12 12:32:06.046] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:32:06.072] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:32:06.072] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:32:06.075] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:32:06:960856 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:32:06:960856 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:32:06:960858 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:32:06:960858 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:32:06:960857 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:32:06:960857 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:32:06:960855 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:32:06:960855 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.5569s] [ 91%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_shard_full_optim_state_dict_unmanaged_params_state_dict_type1_add_to_fsdp_module_True [2025-09-12 12:32:37.592] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:32:37.592] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:32:37.602] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:32:37.638] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:32:37:961174 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:32:37:961174 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:32:37:961173 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:32:37:961173 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:32:37:961176 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:32:37:961176 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:32:37:961175 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:32:37:961175 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [31.2570s] [ 93%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_state_dict_with_none_tensor_state [2025-09-12 12:33:08.882] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:33:08.908] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:33:08.908] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:33:08.930] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:33:09:961491 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:33:09:961491 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:33:09:961492 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:33:09:961492 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:33:09:961493 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:33:09:961493 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:33:09:961490 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:33:09:961490 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.4562s] [ 95%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_use_orig_params [2025-09-12 12:33:40.336] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:33:40.346] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:33:40.350] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:33:40.382] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:33:40:961809 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:33:40:961809 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:33:40:961810 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:33:40:961810 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:33:40:961807 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:33:40:961807 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:33:40:961808 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:33:40:961808 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:34:09:961807:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:34:09:961809:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:34:09:961807:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:34:09:961809:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:34:10:961807:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:34:10:961809:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:34:11:961809:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-12:34:11:961807:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [34.3612s] [ 96%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_with_empty_optimizer_state [2025-09-12 12:34:14.692] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:34:14.692] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:34:14.697] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:34:14.702] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:34:14:962144 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:34:14:962144 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:34:14:962143 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:34:14:962143 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:34:14:962142 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:34:14:962142 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:34:14:962145 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:34:14:962145 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [15.8302s] [ 98%]
../../../../test/distributed/fsdp/test_fsdp_optim_state.py::TestFSDPOptimState::test_with_no_shard [2025-09-12 12:34:30.527] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:34:30.529] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:34:30.544] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:34:30.556] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:34:30:962443 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:34:30:962443 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:34:30:962442 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:34:30:962442 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:34:30:962445 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:34:30:962445 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:34:30:962444 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:34:30:962444 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [16.3309s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_optim_state.py.xml -
======================= 60 passed in 1810.93s (0:30:10) ========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 12:34:47.594] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/fsdp/test_fsdp_pure_fp16.py::TestPureFP16XPU::test_fp16_dtypes_xpu [2025-09-12 12:34:49.842] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:34:49.855] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:34:49.862] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:34:49.862] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:34:50:962832 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:34:50:962832 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:34:50:962834 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:34:50:962834 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:34:50:962835 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:34:50:962835 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:34:50:962833 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:34:50:962833 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [31.5570s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_pure_fp16.py::TestPureFP16XPU::test_pure_fp16_training_xpu [2025-09-12 12:35:21.302] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:35:21.342] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:35:21.342] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:35:21.358] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:35:21:963149 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:35:21:963149 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:35:21:963152 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:35:21:963152 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:35:21:963151 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:35:21:963151 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:35:21:963150 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:35:21:963150 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
PASSED [16.3260s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_pure_fp16.py.xml -
============================== 2 passed in 49.97s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 12:35:38.615] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 20 items
Running 20 items in this shard

../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardGradScaler::test_grad_scaling PASSED [0.2104s] [  5%]
../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardGradScaler::test_inf_gradients_skip_optim_step PASSED [0.0020s] [ 10%]
../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardGradScaler::test_scaling_unscaling_sparse PASSED [0.0049s] [ 15%]
../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardedGradScalerParityWithDDP::test_fsdp_ddp_parity_with_grad_scaler_offload_false_none_mixed_precision_none [2025-09-12 12:35:40.779] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:35:40.827] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:35:40.827] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:35:40.836] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:35:40:963636 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:35:40:963636 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:35:41:963634 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:35:41:963634 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:35:41:963635 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:35:41:963635 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:35:41:963637 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:35:41:963637 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [16.0301s] [ 20%]
../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardedGradScalerParityWithDDP::test_fsdp_ddp_parity_with_grad_scaler_offload_false_none_mixed_precision_use_orig_params [2025-09-12 12:35:56.854] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:35:56.868] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:35:56.874] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:35:56.886] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:35:57:963954 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:35:57:963954 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:35:57:963955 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:35:57:963955 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:35:57:963953 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:35:57:963953 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:35:57:963956 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:35:57:963956 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [16.0265s] [ 25%]
../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardedGradScalerParityWithDDP::test_fsdp_ddp_parity_with_grad_scaler_offload_false_none_none_none [2025-09-12 12:36:12.862] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:36:12.886] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:36:12.888] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:36:12.889] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:36:13:964273 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:36:13:964273 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:36:13:964270 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:36:13:964270 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:36:13:964272 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:36:13:964272 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:36:13:964271 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:36:13:964271 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
FAILED [31.5476s] [ 30%]
../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardedGradScalerParityWithDDP::test_fsdp_ddp_parity_with_grad_scaler_offload_false_none_none_use_orig_params [2025-09-12 12:36:44.435] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:36:44.437] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:36:44.439] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:36:44.442] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:36:44:964590 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:36:44:964590 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:36:44:964588 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:36:44:964588 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:36:44:964591 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:36:44:964591 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:36:44:964589 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:36:44:964589 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [31.3469s] [ 35%]
../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardedGradScalerParityWithDDP::test_fsdp_ddp_parity_with_grad_scaler_offload_false_shard_grad_op_mixed_precision_none [2025-09-12 12:37:15.771] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:37:15.779] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:37:15.779] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:37:15.780] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:37:15:964906 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:37:15:964906 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:37:15:964907 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:37:15:964907 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:37:15:964909 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:37:16:964909 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:37:16:964908 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:37:16:964908 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [15.9271s] [ 40%]
../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardedGradScalerParityWithDDP::test_fsdp_ddp_parity_with_grad_scaler_offload_false_shard_grad_op_mixed_precision_use_orig_params [2025-09-12 12:37:31.762] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:37:31.762] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:37:31.763] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:37:31.786] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:37:31:965225 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:37:31:965225 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:37:31:965226 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:37:31:965226 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:37:31:965227 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:37:31:965227 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:37:32:965224 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:37:32:965224 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [16.0264s] [ 45%]
../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardedGradScalerParityWithDDP::test_fsdp_ddp_parity_with_grad_scaler_offload_false_shard_grad_op_none_none [2025-09-12 12:37:47.723] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:37:47.729] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:37:47.730] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:37:47.731] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:37:47:965542 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:37:47:965541 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:37:47:965542 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:37:47:965541 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:37:47:965544 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:37:47:965544 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:37:48:965543 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:37:48:965543 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.3496s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardedGradScalerParityWithDDP::test_fsdp_ddp_parity_with_grad_scaler_offload_false_shard_grad_op_none_use_orig_params [2025-09-12 12:38:19.068] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:38:19.086] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:38:19.098] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:38:19.106] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:38:19:965858 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:38:19:965858 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:38:19:965859 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:38:19:965859 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:38:19:965860 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:38:19:965860 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:38:19:965857 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:38:19:965857 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [31.5480s] [ 55%]
../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardedGradScalerParityWithDDP::test_fsdp_ddp_parity_with_grad_scaler_offload_true_none_mixed_precision_none [2025-09-12 12:38:50.619] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:38:50.637] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:38:50.637] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:38:50.658] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:38:50:966177 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:38:50:966177 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:38:50:966178 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:38:50:966178 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:38:50:966176 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:38:50:966176 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:38:50:966175 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:38:50:966175 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
PASSED [16.1220s] [ 60%]
../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardedGradScalerParityWithDDP::test_fsdp_ddp_parity_with_grad_scaler_offload_true_none_mixed_precision_use_orig_params [2025-09-12 12:39:06.703] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:39:06.766] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:39:06.766] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:39:06.783] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:39:06:966494 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:39:06:966494 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:39:06:966495 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:39:06:966495 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:39:06:966493 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:39:06:966493 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:39:06:966492 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:39:06:966492 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [16.0246s] [ 65%]
../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardedGradScalerParityWithDDP::test_fsdp_ddp_parity_with_grad_scaler_offload_true_none_none_none [2025-09-12 12:39:22.782] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:39:22.782] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:39:22.784] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:39:22.794] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:39:22:966811 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:39:22:966811 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:39:22:966812 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:39:22:966812 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:39:23:966809 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:39:23:966809 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:39:23:966810 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:39:23:966810 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
FAILED [31.1492s] [ 70%]
../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardedGradScalerParityWithDDP::test_fsdp_ddp_parity_with_grad_scaler_offload_true_none_none_use_orig_params [2025-09-12 12:39:53.958] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:39:53.966] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:39:53.966] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:39:53.972] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:39:54:967126 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:39:54:967126 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:39:54:967127 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:39:54:967127 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:39:54:967129 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:39:54:967129 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:39:54:967128 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:39:54:967128 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [31.4483s] [ 75%]
../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardedGradScalerParityWithDDP::test_fsdp_ddp_parity_with_grad_scaler_offload_true_shard_grad_op_mixed_precision_none [2025-09-12 12:40:25.406] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:40:25.426] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:40:25.441] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:40:25.454] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:40:25:967447 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:40:25:967447 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:40:25:967444 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:40:25:967444 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:40:25:967446 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:40:25:967446 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:40:25:967445 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:40:25:967445 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [16.0262s] [ 80%]
../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardedGradScalerParityWithDDP::test_fsdp_ddp_parity_with_grad_scaler_offload_true_shard_grad_op_mixed_precision_use_orig_params [2025-09-12 12:40:41.438] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:40:41.445] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:40:41.466] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:40:41.478] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:40:41:967761 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:40:41:967761 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:40:41:967763 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:40:41:967763 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:40:41:967764 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:40:41:967764 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:40:41:967762 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:40:41:967762 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [16.2271s] [ 85%]
../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardedGradScalerParityWithDDP::test_fsdp_ddp_parity_with_grad_scaler_offload_true_shard_grad_op_none_none [2025-09-12 12:40:57.642] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:40:57.646] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:40:57.655] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:40:57.668] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:40:57:968079 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:40:57:968079 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:40:57:968080 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:40:57:968080 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:40:57:968081 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:40:57:968081 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:40:57:968078 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:40:57:968078 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [31.5485s] [ 90%]
../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardedGradScalerParityWithDDP::test_fsdp_ddp_parity_with_grad_scaler_offload_true_shard_grad_op_none_use_orig_params [2025-09-12 12:41:29.163] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:41:29.174] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:41:29.178] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:41:29.190] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:41:29:968399 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:41:29:968399 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:41:29:968400 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:41:29:968400 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:41:29:968398 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:41:29:968398 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:41:29:968397 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:41:29:968397 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.5483s] [ 95%]
../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardedGradScalerParityWithDDP::test_sharded_grad_scaler_found_inf [2025-09-12 12:42:00.731] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:42:00.740] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:42:00.740] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:42:00.760] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:42:00:968715 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:42:00:968715 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:42:00:968716 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:42:00:968716 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:42:00:968717 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:42:00:968717 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:42:00:968714 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:42:00:968714 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [50.9760s] [100%]

=================================== FAILURES ===================================
_ TestShardedGradScalerParityWithDDP.test_fsdp_ddp_parity_with_grad_scaler_offload_false_none_none_none _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py", line 205, in test_fsdp_ddp_parity_with_grad_scaler
    self._test_fsdp_parity(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py TestShardedGradScalerParityWithDDP.test_fsdp_ddp_parity_with_grad_scaler_offload_false_none_none_none

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py", line 205, in test_fsdp_ddp_parity_with_grad_scaler
    self._test_fsdp_parity(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py TestShardedGradScalerParityWithDDP.test_fsdp_ddp_parity_with_grad_scaler_offload_false_none_none_none

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 2 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 12:36:11.021000 963467 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 964270
I0912 12:36:11.022000 963467 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 964271
I0912 12:36:11.022000 963467 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 964272
I0912 12:36:11.023000 963467 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 964273
_ TestShardedGradScalerParityWithDDP.test_fsdp_ddp_parity_with_grad_scaler_offload_true_none_none_none _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py", line 205, in test_fsdp_ddp_parity_with_grad_scaler
    self._test_fsdp_parity(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py TestShardedGradScalerParityWithDDP.test_fsdp_ddp_parity_with_grad_scaler_offload_true_none_none_none

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py", line 205, in test_fsdp_ddp_parity_with_grad_scaler
    self._test_fsdp_parity(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py TestShardedGradScalerParityWithDDP.test_fsdp_ddp_parity_with_grad_scaler_offload_true_none_none_none

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 1 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 12:39:20.924000 963467 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 966809
I0912 12:39:20.925000 963467 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 966810
I0912 12:39:20.925000 963467 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 966811
I0912 12:39:20.926000 963467 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 966812
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_sharded_grad_scaler.py.xml -
=========================== short test summary info ============================
FAILED [31.5476s] ../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardedGradScalerParityWithDDP::test_fsdp_ddp_parity_with_grad_scaler_offload_false_none_none_none - RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py", line 205, in test_fsdp_ddp_parity_with_grad_scaler
    self._test_fsdp_parity(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py TestShardedGradScalerParityWithDDP.test_fsdp_ddp_parity_with_grad_scaler_offload_false_none_none_none

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py", line 205, in test_fsdp_ddp_parity_with_grad_scaler
    self._test_fsdp_parity(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py TestShardedGradScalerParityWithDDP.test_fsdp_ddp_parity_with_grad_scaler_offload_false_none_none_none

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [31.1492s] ../../../../test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py::TestShardedGradScalerParityWithDDP::test_fsdp_ddp_parity_with_grad_scaler_offload_true_none_none_none - RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py", line 205, in test_fsdp_ddp_parity_with_grad_scaler
    self._test_fsdp_parity(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py TestShardedGradScalerParityWithDDP.test_fsdp_ddp_parity_with_grad_scaler_offload_true_none_none_none

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py", line 205, in test_fsdp_ddp_parity_with_grad_scaler
    self._test_fsdp_parity(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1493, in _test_fsdp_parity
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 32 / 32 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 1e-05 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

The failure occurred for item [0]
FSDP did not match DDP

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py TestShardedGradScalerParityWithDDP.test_fsdp_ddp_parity_with_grad_scaler_offload_true_none_none_none

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
=================== 2 failed, 18 passed in 433.11s (0:07:13) ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 12:42:52.695] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 179 items
Running 179 items in this shard

../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload0_fp16_False_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 12:42:54.933] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:42:54.950] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:42:55:969111 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:42:55:969111 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:42:55:969112 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:42:55:969112 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.5303s] [  0%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload0_fp16_False_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 12:43:25.173] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:43:25.178] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:43:25:969270 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:43:25:969270 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:43:25:969269 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:43:25:969269 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.7194s] [  1%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload0_fp16_False_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 12:43:39.938] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:43:39.944] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:43:40:969420 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:43:40:969420 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:43:40:969421 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:43:40:969421 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.7186s] [  1%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload0_fp16_False_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 12:43:54.646] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:43:54.654] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:43:54:969571 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:43:54:969571 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:43:54:969572 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:43:54:969572 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.8249s] [  2%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload0_fp16_True_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 12:44:09.464] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:44:09.470] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:44:09:969721 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:44:09:969721 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:44:09:969722 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:44:09:969722 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.5260s] [  2%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload0_fp16_True_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 12:44:25.086] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:44:25.092] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:44:25:969880 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:44:25:969880 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:44:25:969879 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:44:25:969879 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.8246s] [  3%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload0_fp16_True_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 12:44:39.826] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:44:39.834] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:44:40:970030 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:44:40:970030 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:44:40:970031 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:44:40:970031 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.8253s] [  3%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload0_fp16_True_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 12:44:54.648] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:44:54.662] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:44:54:970181 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:44:54:970181 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:44:54:970180 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:44:54:970180 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.7248s] [  4%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload1_fp16_False_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 12:45:09.339] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:45:09.381] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:45:09:970330 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:45:09:970330 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:45:09:970331 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:45:09:970331 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.1473s] [  5%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload1_fp16_False_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 12:45:39.534] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:45:39.542] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:45:39:970490 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:45:39:970490 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:45:39:970489 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:45:39:970489 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.9249s] [  5%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload1_fp16_False_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 12:45:54.462] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:45:54.478] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:45:54:970640 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:45:54:970640 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:45:54:970641 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:45:54:970641 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.8247s] [  6%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload1_fp16_False_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 12:46:09.250] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:46:09.286] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:46:09:970790 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:46:09:970790 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:46:09:970791 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:46:09:970791 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.7248s] [  6%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload1_fp16_True_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 12:46:24.014] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:46:24.014] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:46:24:970941 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:46:24:970941 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:46:24:970942 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:46:24:970942 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.4261s] [  7%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload1_fp16_True_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 12:46:39.436] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:46:39.438] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:46:39:971099 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:46:39:971099 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:46:39:971100 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:46:39:971100 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.7249s] [  7%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload1_fp16_True_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 12:46:54.134] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:46:54.150] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:46:54:971251 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:46:54:971251 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:46:54:971250 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:46:54:971250 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.9248s] [  8%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload1_fp16_True_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 12:47:09.082] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:47:09.082] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:47:09:971402 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:47:09:971401 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:47:09:971402 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:47:09:971401 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.7248s] [  8%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload0_fp16_False_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 12:47:23.806] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:47:23.814] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:47:24:971552 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:47:24:971552 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:47:24:971551 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:47:24:971551 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.2486s] [  9%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload0_fp16_False_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 12:47:54.059] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:47:54.066] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:47:54:971710 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:47:54:971710 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:47:54:971711 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:47:54:971711 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.1479s] [ 10%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload0_fp16_False_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 12:48:24.207] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:48:24.210] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:48:24:971868 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:48:24:971868 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:48:24:971869 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:48:24:971869 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.6241s] [ 10%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload0_fp16_False_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 12:48:38.814] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:48:38.838] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:48:39:972020 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:48:39:972020 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:48:39:972019 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:48:39:972019 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.7241s] [ 11%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload0_fp16_True_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 12:48:53.552] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:48:53.562] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:48:53:972170 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:48:53:972170 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:48:53:972171 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:48:53:972171 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.2259s] [ 11%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload0_fp16_True_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 12:49:08.866] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:49:08.898] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:49:09:972329 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:49:09:972328 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:49:09:972328 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:49:09:972329 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.4260s] [ 12%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload0_fp16_True_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 12:49:24.212] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:49:24.230] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:49:24:972487 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:49:24:972487 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:49:24:972486 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:49:24:972486 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.8249s] [ 12%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload0_fp16_True_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 12:49:39.038] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:49:39.041] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:49:39:972637 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:49:39:972637 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:49:39:972638 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:49:39:972638 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.7249s] [ 13%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload1_fp16_False_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 12:49:53.774] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:49:53.794] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:49:53:972787 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:49:53:972787 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:49:53:972788 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:49:53:972788 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.1482s] [ 13%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload1_fp16_False_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 12:50:23.886] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:50:23.922] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:50:24:972945 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:50:24:972945 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:50:24:972946 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:50:24:972946 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.2353s] [ 14%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload1_fp16_False_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 12:50:54.170] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:50:54.171] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:50:54:973105 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:50:54:973106 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:50:54:973105 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:50:54:973106 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.7192s] [ 15%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload1_fp16_False_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 12:51:08.866] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:51:08.890] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:51:09:973257 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:51:09:973257 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:51:09:973256 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:51:09:973256 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.8250s] [ 15%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload1_fp16_True_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 12:51:23.710] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:51:23.714] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:51:23:973408 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:51:23:973408 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:51:23:973409 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:51:23:973409 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.2260s] [ 16%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload1_fp16_True_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 12:51:38.902] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:51:38.922] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:51:39:973567 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:51:39:973567 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:51:39:973568 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:51:39:973568 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.3257s] [ 16%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload1_fp16_True_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 12:51:54.327] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:51:54.346] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:51:54:973726 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:51:54:973726 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:51:54:973727 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:51:54:973727 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.9253s] [ 17%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload1_fp16_True_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 12:52:09.234] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:52:09.237] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:52:09:973879 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:52:09:973879 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:52:09:973878 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:52:09:973878 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.9251s] [ 17%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload0_fp16_False_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 12:52:24.158] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:52:24.160] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:52:24:974029 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:52:24:974029 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:52:24:974030 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:52:24:974030 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.3354s] [ 18%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload0_fp16_False_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 12:52:54.442] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:52:54.458] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:52:54:974188 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:52:54:974188 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:52:54:974189 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:52:54:974189 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.1480s] [ 18%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload0_fp16_False_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 12:53:24.596] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:53:24.602] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:53:24:974348 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:53:24:974348 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:53:24:974347 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:53:24:974347 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.0387s] [ 19%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload0_fp16_False_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 12:53:54.670] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:53:54.678] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:53:54:974507 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:53:54:974507 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:53:54:974508 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:53:54:974508 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.3475s] [ 20%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload0_fp16_True_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 12:54:24.962] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:54:24.974] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:54:25:974666 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:54:25:974666 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:54:25:974665 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:54:25:974665 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.3248s] [ 20%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload0_fp16_True_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 12:54:40.266] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:54:40.282] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:54:40:974826 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:54:40:974826 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:54:40:974825 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:54:40:974825 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.2256s] [ 21%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload0_fp16_True_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 12:54:55.529] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:54:55.538] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:54:55:974983 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:54:55:974983 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:54:55:974984 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:54:55:974984 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.3257s] [ 21%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload0_fp16_True_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 12:55:10.850] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:55:10.863] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:55:11:975142 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:55:11:975142 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:55:11:975143 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:55:11:975143 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.3259s] [ 22%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload1_fp16_False_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 12:55:26.191] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:55:26.194] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:55:26:975301 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:55:26:975301 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:55:26:975300 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:55:26:975300 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [29.9475s] [ 22%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload1_fp16_False_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 12:55:56.132] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:55:56.146] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:55:56:975461 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:55:56:975461 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:55:56:975460 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:55:56:975460 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.2470s] [ 23%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload1_fp16_False_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 12:56:26.358] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:56:26.370] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:56:26:975620 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:56:26:975620 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:56:26:975621 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:56:26:975621 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.2482s] [ 24%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload1_fp16_False_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 12:56:56.666] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:56:56.699] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:56:56:975781 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:56:56:975781 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:56:56:975780 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:56:56:975780 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.2483s] [ 24%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload1_fp16_True_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 12:57:26.869] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:57:26.886] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:57:27:975941 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:57:27:975941 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:57:27:975942 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:57:27:975942 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.2260s] [ 25%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload1_fp16_True_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 12:57:42.078] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:57:42.094] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:57:42:976100 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:57:42:976100 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:57:42:976099 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:57:42:976099 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1254s] [ 25%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload1_fp16_True_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 12:57:57.190] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:57:57.202] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:57:57:976258 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:57:57:976258 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:57:57:976259 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:57:57:976259 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.2260s] [ 26%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_basic_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload1_fp16_True_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 12:58:12.475] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:58:12.482] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:58:12:976417 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:58:12:976417 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:58:12:976418 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:58:12:976418 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.3244s] [ 26%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload0_mixed_precision_False_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 12:58:27.802] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:58:27.810] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:58:28:976576 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:58:28:976576 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:58:28:976575 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:58:28:976575 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.2258s] [ 27%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload0_mixed_precision_False_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 12:58:43.099] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:58:43.106] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:58:43:976726 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:58:43:976726 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:58:43:976725 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:58:43:976725 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.7250s] [ 27%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload0_mixed_precision_False_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 12:58:57.710] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:58:57.713] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:58:57:976876 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:58:57:976877 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:58:57:976877 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:58:57:976876 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.9250s] [ 28%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload0_mixed_precision_False_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 12:59:12.690] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:59:12.698] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:59:12:977026 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:59:12:977026 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:59:12:977027 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:59:12:977027 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.9251s] [ 29%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload0_mixed_precision_True_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 12:59:27.555] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:59:27.566] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:59:27:977176 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:59:27:977176 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:59:27:977177 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:59:27:977177 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1200s] [ 29%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload0_mixed_precision_True_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 12:59:42.695] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:59:42.698] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:59:42:977327 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:59:42:977327 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:59:42:977328 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:59:42:977328 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.8247s] [ 30%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload0_mixed_precision_True_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 12:59:57.540] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 12:59:57.542] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-12:59:57:977477 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:59:57:977477 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-12:59:57:977478 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-12:59:57:977478 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.9250s] [ 30%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload0_mixed_precision_True_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 13:00:12.518] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:00:12.554] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:00:12:977627 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:00:12:977627 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:00:12:977628 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:00:12:977628 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.8249s] [ 31%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload1_mixed_precision_False_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 13:00:27.300] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:00:27.314] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:00:27:977779 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:00:27:977778 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:00:27:977779 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:00:27:977778 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.3252s] [ 31%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload1_mixed_precision_False_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 13:00:42.602] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:00:42.642] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:00:42:977930 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:00:42:977930 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:00:42:977929 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:00:42:977929 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.9196s] [ 32%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload1_mixed_precision_False_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 13:00:57.526] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:00:57.529] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:00:57:978081 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:00:57:978081 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:00:57:978080 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:00:57:978080 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.9256s] [ 32%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload1_mixed_precision_False_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 13:01:12.476] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:01:12.482] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:01:12:978230 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:01:12:978230 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:01:12:978231 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:01:12:978231 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.8252s] [ 33%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload1_mixed_precision_True_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 13:01:27.299] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:01:27.299] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:01:27:978381 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:01:27:978381 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:01:27:978382 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:01:27:978382 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.5259s] [ 34%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload1_mixed_precision_True_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 13:01:42.794] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:01:42.815] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:01:43:978532 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:01:43:978532 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:01:43:978533 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:01:43:978533 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.8252s] [ 34%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload1_mixed_precision_True_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 13:01:57.650] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:01:57.694] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:01:57:978684 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:01:57:978684 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:01:57:978683 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:01:57:978683 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.9251s] [ 35%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_local_state_dict_cpu_offload1_mixed_precision_True_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 13:02:12.542] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:02:12.546] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:02:12:978835 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:02:12:978835 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:02:12:978834 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:02:12:978834 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.9245s] [ 35%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload0_mixed_precision_False_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 13:02:27.586] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:02:27.587] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:02:27:978986 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:02:27:978986 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:02:27:978987 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:02:27:978987 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1259s] [ 36%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload0_mixed_precision_False_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 13:02:42.609] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:02:42.630] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:02:42:979136 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:02:42:979136 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:02:42:979137 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:02:42:979137 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.2235s] [ 36%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload0_mixed_precision_False_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 13:02:57.826] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:02:57.834] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:02:58:979287 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:02:58:979287 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:02:58:979288 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:02:58:979288 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.9190s] [ 37%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload0_mixed_precision_False_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 13:03:12.774] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:03:12.786] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:03:12:979437 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:03:12:979437 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:03:13:979438 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:03:13:979438 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.8252s] [ 37%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload0_mixed_precision_True_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 13:03:27.574] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:03:27.595] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:03:27:979588 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:03:27:979588 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:03:27:979587 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:03:27:979587 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1255s] [ 38%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload0_mixed_precision_True_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 13:03:42.698] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:03:42.701] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:03:42:979738 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:03:42:979738 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:03:42:979737 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:03:42:979737 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.0251s] [ 39%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload0_mixed_precision_True_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 13:03:57.798] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:03:57.830] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:03:58:979888 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:03:58:979888 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:03:58:979889 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:03:58:979889 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.8248s] [ 39%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload0_mixed_precision_True_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 13:04:12.643] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:04:12.654] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:04:12:980039 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:04:12:980039 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:04:12:980038 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:04:12:980038 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.8249s] [ 40%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload1_mixed_precision_False_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 13:04:27.362] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:04:27.402] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:04:27:980189 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:04:27:980189 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:04:27:980188 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:04:27:980188 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1252s] [ 40%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload1_mixed_precision_False_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 13:04:42.606] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:04:42.606] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:04:42:980339 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:04:42:980339 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:04:42:980340 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:04:42:980340 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1258s] [ 41%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload1_mixed_precision_False_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 13:04:57.710] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:04:57.722] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:04:57:980490 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:04:57:980490 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:04:57:980489 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:04:57:980489 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.9251s] [ 41%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload1_mixed_precision_False_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 13:05:12.572] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:05:12.594] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:05:12:980639 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:05:12:980639 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:05:12:980640 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:05:12:980640 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.7248s] [ 42%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload1_mixed_precision_True_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 13:05:27.301] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:05:27.314] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:05:27:980790 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:05:27:980790 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:05:27:980791 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:05:27:980791 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1254s] [ 43%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload1_mixed_precision_True_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 13:05:42.507] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:05:42.510] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:05:42:980942 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:05:42:980942 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:05:42:980941 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:05:42:980941 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.2258s] [ 43%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload1_mixed_precision_True_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 13:05:57.682] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:05:57.698] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:05:57:981091 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:05:57:981091 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:05:57:981092 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:05:57:981092 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.7249s] [ 44%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_sharded_state_dict_cpu_offload1_mixed_precision_True_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 13:06:12.367] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:06:12.382] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:06:12:981242 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:06:12:981242 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:06:12:981241 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:06:12:981241 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.8250s] [ 44%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload0_mixed_precision_False_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 13:06:27.282] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:06:27.286] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:06:27:981393 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:06:27:981392 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:06:27:981392 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:06:27:981393 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.2258s] [ 45%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload0_mixed_precision_False_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 13:06:42.434] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:06:42.450] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:06:42:981542 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:06:42:981542 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:06:42:981543 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:06:42:981543 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1257s] [ 45%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload0_mixed_precision_False_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 13:06:57.561] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:06:57.574] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:06:57:981694 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:06:57:981694 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:06:57:981693 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:06:57:981693 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.0254s] [ 46%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload0_mixed_precision_False_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 13:07:12.566] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:07:12.606] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:07:12:981845 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:07:12:981845 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:07:12:981844 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:07:12:981844 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.0253s] [ 46%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload0_mixed_precision_True_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 13:07:27.602] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:07:27.634] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:07:27:981994 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:07:27:981994 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:07:27:981995 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:07:27:981995 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.2254s] [ 47%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload0_mixed_precision_True_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 13:07:42.822] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:07:42.834] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:07:43:982144 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:07:43:982145 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:07:43:982144 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:07:43:982145 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.2258s] [ 48%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload0_mixed_precision_True_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 13:07:58.047] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:07:58.080] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:07:58:982296 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:07:58:982296 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:07:58:982295 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:07:58:982295 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1253s] [ 48%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload0_mixed_precision_True_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 13:08:13.214] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:08:13.215] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:08:13:982445 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:08:13:982445 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:08:13:982446 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:08:13:982446 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1193s] [ 49%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload1_mixed_precision_False_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 13:08:28.414] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:08:28.450] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:08:28:982595 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:08:28:982595 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:08:28:982596 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:08:28:982596 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.4234s] [ 49%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload1_mixed_precision_False_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 13:08:43.732] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:08:43.738] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:08:43:982745 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:08:43:982746 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:08:43:982745 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:08:43:982746 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.2258s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload1_mixed_precision_False_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 13:08:58.962] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:08:58.964] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:08:59:982896 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:08:59:982896 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:08:59:982897 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:08:59:982897 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1246s] [ 50%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload1_mixed_precision_False_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 13:09:14.130] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:09:14.158] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:09:14:983046 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:09:14:983046 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:09:14:983047 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:09:14:983047 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1261s] [ 51%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload1_mixed_precision_True_state_dict_rank0_and_offload_False_use_orig_params_False [2025-09-12 13:09:29.212] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:09:29.226] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:09:29:983197 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:09:29:983197 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:09:29:983196 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:09:29:983196 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1258s] [ 51%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload1_mixed_precision_True_state_dict_rank0_and_offload_False_use_orig_params_True [2025-09-12 13:09:44.354] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:09:44.380] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:09:44:983347 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:09:44:983347 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:09:44:983348 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:09:44:983348 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.2257s] [ 52%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload1_mixed_precision_True_state_dict_rank0_and_offload_True_use_orig_params_False [2025-09-12 13:09:59.567] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:09:59.582] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:09:59:983497 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:09:59:983497 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:09:59:983498 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:09:59:983498 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1255s] [ 53%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_buffers_save_and_load_state_dict_state_dict_type_state_dict_cpu_offload1_mixed_precision_True_state_dict_rank0_and_offload_True_use_orig_params_True [2025-09-12 13:10:14.702] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:10:14.708] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:10:14:983649 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:10:14:983648 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:10:14:983648 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:10:14:983649 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1256s] [ 53%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_keys_state_dict_type_local_state_dict [2025-09-12 13:10:29.826] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:10:29.840] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:10:30:983800 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:10:30:983800 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:10:30:983801 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:10:30:983801 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1257s] [ 54%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_keys_state_dict_type_sharded_state_dict [2025-09-12 13:10:44.918] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:10:44.946] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:10:45:983951 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:10:45:983951 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:10:45:983950 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:10:45:983950 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.9190s] [ 54%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_keys_state_dict_type_state_dict [2025-09-12 13:10:59.969] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:10:59.986] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:11:00:984101 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:11:00:984100 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:11:00:984100 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:11:00:984101 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.0188s] [ 55%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_sharded_state_dict_checkpoint_wrap_both_after_wrap_rank0_only_and_offload_False [2025-09-12 13:11:14.938] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:11:14.942] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:11:15:984250 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:11:15:984250 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:11:15:984251 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:11:15:984251 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1197s] [ 55%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_sharded_state_dict_checkpoint_wrap_both_after_wrap_rank0_only_and_offload_True [2025-09-12 13:11:30.014] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:11:30.026] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:11:30:984401 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:11:30:984401 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:11:30:984402 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:11:30:984402 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.0253s] [ 56%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_sharded_state_dict_checkpoint_wrap_both_rank0_only_and_offload_False [2025-09-12 13:11:45.046] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:11:45.050] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:11:45:984553 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:11:45:984553 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:11:45:984552 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:11:45:984552 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.2250s] [ 56%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_sharded_state_dict_checkpoint_wrap_both_rank0_only_and_offload_True [2025-09-12 13:12:00.280] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:12:00.286] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:12:00:984704 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:12:00:984704 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:12:00:984703 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:12:00:984703 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1246s] [ 57%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_sharded_state_dict_checkpoint_wrap_dest_rank0_only_and_offload_False [2025-09-12 13:12:15.424] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:12:15.442] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:12:15:984855 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:12:15:984855 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:12:15:984854 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:12:15:984854 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.2257s] [ 58%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_sharded_state_dict_checkpoint_wrap_dest_rank0_only_and_offload_True [2025-09-12 13:12:30.622] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:12:30.650] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:12:30:985005 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:12:30:985005 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:12:30:985006 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:12:30:985006 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.2254s] [ 58%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_sharded_state_dict_checkpoint_wrap_source_after_wrap_rank0_only_and_offload_False [2025-09-12 13:12:45.846] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:12:45.852] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:12:46:985156 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:12:46:985155 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:12:46:985155 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:12:46:985156 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1192s] [ 59%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_sharded_state_dict_checkpoint_wrap_source_after_wrap_rank0_only_and_offload_True [2025-09-12 13:13:00.948] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:13:00.966] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:13:01:985307 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:13:01:985307 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:13:01:985306 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:13:01:985306 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.2252s] [ 59%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_sharded_state_dict_checkpoint_wrap_source_rank0_only_and_offload_False [2025-09-12 13:13:16.156] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:13:16.162] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:13:16:985457 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:13:16:985457 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:13:16:985456 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:13:16:985456 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.2252s] [ 60%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_sharded_state_dict_checkpoint_wrap_source_rank0_only_and_offload_True [2025-09-12 13:13:31.427] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:13:31.434] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:13:31:985607 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:13:31:985607 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:13:31:985608 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:13:31:985608 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.2257s] [ 60%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_state_dict_checkpoint_wrap_both_after_wrap_rank0_only_and_offload_False [2025-09-12 13:13:46.622] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:13:46.642] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:13:46:985757 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:13:46:985757 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:13:46:985758 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:13:46:985758 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1253s] [ 61%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_state_dict_checkpoint_wrap_both_after_wrap_rank0_only_and_offload_True [2025-09-12 13:14:01.774] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:14:01.794] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:14:01:985910 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:14:01:985910 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:14:01:985909 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:14:01:985909 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1255s] [ 62%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_state_dict_checkpoint_wrap_both_rank0_only_and_offload_False [2025-09-12 13:14:16.904] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:14:16.906] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:14:17:986060 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:14:17:986060 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:14:17:986059 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:14:17:986059 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1257s] [ 62%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_state_dict_checkpoint_wrap_both_rank0_only_and_offload_True [2025-09-12 13:14:32.030] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:14:32.038] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:14:32:986210 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:14:32:986210 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:14:32:986209 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:14:32:986209 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1258s] [ 63%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_state_dict_checkpoint_wrap_dest_rank0_only_and_offload_False [2025-09-12 13:14:47.164] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:14:47.166] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:14:47:986361 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:14:47:986361 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:14:47:986360 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:14:47:986360 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.3249s] [ 63%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_state_dict_checkpoint_wrap_dest_rank0_only_and_offload_True [2025-09-12 13:15:02.462] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:15:02.494] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:15:02:986510 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:15:02:986510 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:15:02:986511 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:15:02:986511 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.2256s] [ 64%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_state_dict_checkpoint_wrap_source_after_wrap_rank0_only_and_offload_False [2025-09-12 13:15:17.695] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:15:17.706] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:15:17:986661 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:15:17:986661 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:15:17:986660 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:15:17:986660 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.0244s] [ 64%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_state_dict_checkpoint_wrap_source_after_wrap_rank0_only_and_offload_True [2025-09-12 13:15:32.710] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:15:32.742] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:15:32:986813 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:15:32:986813 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:15:32:986812 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:15:32:986812 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1253s] [ 65%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_state_dict_checkpoint_wrap_source_rank0_only_and_offload_False [2025-09-12 13:15:47.855] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:15:47.874] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:15:48:986962 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:15:48:986962 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:15:48:986963 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:15:48:986963 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.0247s] [ 65%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_fsdp_state_dict_with_activation_checkpoint_state_dict_type_state_dict_checkpoint_wrap_source_rank0_only_and_offload_True [2025-09-12 13:16:02.982] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:16:02.982] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:16:03:987113 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:16:03:987113 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:16:03:987112 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:16:03:987112 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.2258s] [ 66%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_full_state_dict_missing_unexpected_keys_cleaned [2025-09-12 13:16:18.078] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:16:18.106] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:16:18:987263 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:16:18:987263 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:16:18:987262 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:16:18:987262 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.9251s] [ 67%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_local_state_dict_with_empty_ranks [2025-09-12 13:16:33.029] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:16:33.034] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:16:33:987415 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:16:33:987415 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:16:33:987414 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:16:33:987414 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [29.9481s] [ 67%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_save_and_load_after_forward_state_dict_state_dict_type_local_state_dict_mixed_precision_False_state_dict_rank0_and_offload_False [2025-09-12 13:17:02.994] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:17:02.998] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:17:03:987573 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:17:03:987573 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:17:03:987574 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:17:03:987574 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.2479s] [ 68%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_save_and_load_after_forward_state_dict_state_dict_type_local_state_dict_mixed_precision_False_state_dict_rank0_and_offload_True [2025-09-12 13:17:33.210] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:17:33.242] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:17:33:987737 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:17:33:987737 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:17:33:987736 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:17:33:987736 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.6246s] [ 68%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_save_and_load_after_forward_state_dict_state_dict_type_local_state_dict_mixed_precision_True_state_dict_rank0_and_offload_False [2025-09-12 13:17:47.861] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:17:47.862] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:17:48:987888 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:17:48:987888 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:17:48:987887 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:17:48:987887 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.3268s] [ 69%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_save_and_load_after_forward_state_dict_state_dict_type_local_state_dict_mixed_precision_True_state_dict_rank0_and_offload_True [2025-09-12 13:18:03.197] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:18:03.202] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:18:03:988046 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:18:03:988046 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:18:03:988045 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:18:03:988045 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.7250s] [ 69%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_save_and_load_after_forward_state_dict_state_dict_type_sharded_state_dict_mixed_precision_False_state_dict_rank0_and_offload_False [2025-09-12 13:18:17.918] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:18:17.919] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:18:18:988196 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:18:18:988196 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:18:18:988195 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:18:18:988195 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.0482s] [ 70%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_save_and_load_after_forward_state_dict_state_dict_type_sharded_state_dict_mixed_precision_False_state_dict_rank0_and_offload_True [2025-09-12 13:18:47.951] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:18:47.974] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:18:48:988356 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:18:48:988356 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:18:48:988355 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:18:48:988355 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.7251s] [ 70%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_save_and_load_after_forward_state_dict_state_dict_type_sharded_state_dict_mixed_precision_True_state_dict_rank0_and_offload_False [2025-09-12 13:19:02.648] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:19:02.666] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:19:02:988505 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:19:02:988505 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:19:02:988506 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:19:02:988506 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.3250s] [ 71%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_save_and_load_after_forward_state_dict_state_dict_type_sharded_state_dict_mixed_precision_True_state_dict_rank0_and_offload_True [2025-09-12 13:19:18.098] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:19:18.118] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:19:18:988663 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:19:18:988663 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:19:18:988664 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:19:18:988664 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.9184s] [ 72%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_save_and_load_after_forward_state_dict_state_dict_type_state_dict_mixed_precision_False_state_dict_rank0_and_offload_False [2025-09-12 13:19:33.014] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:19:33.046] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:19:33:988814 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:19:33:988814 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:19:33:988813 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:19:33:988813 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.1474s] [ 72%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_save_and_load_after_forward_state_dict_state_dict_type_state_dict_mixed_precision_False_state_dict_rank0_and_offload_True [2025-09-12 13:20:03.058] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:20:03.090] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:20:03:988973 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:20:03:988973 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:20:03:988972 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:20:03:988972 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.1346s] [ 73%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_save_and_load_after_forward_state_dict_state_dict_type_state_dict_mixed_precision_True_state_dict_rank0_and_offload_False [2025-09-12 13:20:33.307] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:20:33.330] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:20:33:989133 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:20:33:989134 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:20:33:989133 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:20:33:989134 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.3258s] [ 73%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_save_and_load_after_forward_state_dict_state_dict_type_state_dict_mixed_precision_True_state_dict_rank0_and_offload_True [2025-09-12 13:20:48.553] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:20:48.566] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:20:48:989292 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:20:48:989292 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:20:48:989293 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:20:48:989293 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1195s] [ 74%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_sharded_load_multi_backend_pg [2025-09-12 13:21:03.669] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:21:03.670] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:21:03:989450 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:21:03:989450 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:21:03:989451 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:21:03:989451 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2025:09:12-13:21:16:989450:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:21:16:989451:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2025:09:12-13:21:16:989450:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:21:16:989451:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.9267s] [ 74%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_shared_module_and_shared_parameter [2025-09-12 13:21:19.597] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:21:19.602] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:21:19:989622 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:21:19:989622 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:21:19:989623 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:21:19:989623 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.9248s] [ 75%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_load_into_local_module_state_dict_type_sharded_state_dict_state_dict_rank0_and_offload_False_fsdp_root_False [2025-09-12 13:21:34.519] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:21:34.522] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:21:34:989774 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:21:34:989773 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:21:34:989774 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:21:34:989773 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.1473s] [ 75%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_load_into_local_module_state_dict_type_sharded_state_dict_state_dict_rank0_and_offload_False_fsdp_root_True [2025-09-12 13:22:04.718] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:22:04.718] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:22:04:989935 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:22:04:989935 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:22:04:989934 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:22:04:989934 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.2420s] [ 76%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_load_into_local_module_state_dict_type_sharded_state_dict_state_dict_rank0_and_offload_True_fsdp_root_False [2025-09-12 13:22:34.874] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:22:34.914] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:22:35:990096 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:22:35:990096 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:22:35:990095 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:22:35:990095 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.6247s] [ 77%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_load_into_local_module_state_dict_type_sharded_state_dict_state_dict_rank0_and_offload_True_fsdp_root_True [2025-09-12 13:22:49.548] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:22:49.550] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:22:49:990247 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:22:49:990247 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:22:49:990248 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:22:49:990248 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.8253s] [ 77%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_load_into_local_module_state_dict_type_state_dict_state_dict_rank0_and_offload_False_fsdp_root_False [2025-09-12 13:23:04.382] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:23:04.394] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:23:04:990397 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:23:04:990397 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:23:04:990398 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:23:04:990398 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [29.9477s] [ 78%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_load_into_local_module_state_dict_type_state_dict_state_dict_rank0_and_offload_False_fsdp_root_True [2025-09-12 13:23:34.310] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:23:34.318] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:23:34:990555 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:23:34:990555 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:23:34:990556 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:23:34:990556 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.0479s] [ 78%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_load_into_local_module_state_dict_type_state_dict_state_dict_rank0_and_offload_True_fsdp_root_False [2025-09-12 13:24:04.346] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:24:04.354] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:24:04:990717 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:24:04:990717 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:24:04:990716 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:24:04:990716 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [29.9476s] [ 79%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_load_into_local_module_state_dict_type_state_dict_state_dict_rank0_and_offload_True_fsdp_root_True [2025-09-12 13:24:34.306] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:24:34.319] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:24:34:990876 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:24:34:990876 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:24:34:990875 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:24:34:990875 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.1421s] [ 79%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_rank0_offload_save_load_flow_use_orig_params_False [2025-09-12 13:25:04.460] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:25:04.462] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:25:04:991035 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:25:04:991035 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:25:04:991034 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:25:04:991034 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.2254s] [ 80%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_rank0_offload_save_load_flow_use_orig_params_True [2025-09-12 13:25:19.675] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:25:19.694] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:25:19:991185 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:25:19:991185 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:25:19:991186 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:25:19:991186 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1254s] [ 81%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_save_load_flow_state_dict_type_local_state_dict [2025-09-12 13:25:34.814] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:25:34.818] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:25:35:991336 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:25:35:991337 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:25:35:991337 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:25:35:991336 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.2482s] [ 81%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_save_load_flow_state_dict_type_sharded_state_dict [2025-09-12 13:26:05.158] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:26:05.158] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:26:05:991496 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:26:05:991496 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:26:05:991495 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:26:05:991495 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.2477s] [ 82%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_save_load_flow_state_dict_type_state_dict [2025-09-12 13:26:35.294] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:26:35.307] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:26:35:991656 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:26:35:991656 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:26:35:991657 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:26:35:991657 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.3483s] [ 82%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_skip_module_state_dict_type_local_state_dict_double_nest_True [2025-09-12 13:27:05.622] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:27:05.658] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:27:05:991816 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:27:05:991816 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:27:05:991815 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:27:05:991815 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.3484s] [ 83%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_skip_module_state_dict_type_sharded_state_dict_double_nest_True [2025-09-12 13:27:35.986] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:27:36.010] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:27:36:991977 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:27:36:991977 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:27:36:991976 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:27:36:991976 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.1478s] [ 83%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_skip_module_state_dict_type_state_dict_double_nest_True [2025-09-12 13:28:06.135] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:28:06.150] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:28:06:992136 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:28:06:992136 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:28:06:992137 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:28:06:992137 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.0482s] [ 84%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_type [2025-09-12 13:28:36.250] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:28:36.274] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:28:36:992297 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:28:36:992297 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:28:36:992296 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:28:36:992296 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.9197s] [ 84%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_ignored_modules_state_dict_type_sharded_state_dict_prefix_False_ignore_inner_False_mixed_precision_False [2025-09-12 13:28:51.114] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:28:51.130] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:28:51:992448 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:28:51:992448 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:28:51:992447 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:28:51:992447 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.0256s] [ 85%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_ignored_modules_state_dict_type_sharded_state_dict_prefix_False_ignore_inner_False_mixed_precision_True [2025-09-12 13:29:06.118] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:29:06.139] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:29:06:992599 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:29:06:992599 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:29:06:992598 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:29:06:992598 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.9218s] [ 86%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_ignored_modules_state_dict_type_sharded_state_dict_prefix_False_ignore_inner_True_mixed_precision_False [2025-09-12 13:29:21.066] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:29:21.086] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:29:21:992748 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:29:21:992748 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:29:21:992749 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:29:21:992749 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.8249s] [ 86%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_ignored_modules_state_dict_type_sharded_state_dict_prefix_False_ignore_inner_True_mixed_precision_True [2025-09-12 13:29:35.986] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:29:35.996] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:29:36:992899 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:29:36:992898 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:29:36:992898 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:29:36:992899 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.0252s] [ 87%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_ignored_modules_state_dict_type_sharded_state_dict_prefix_True_ignore_inner_False_mixed_precision_False [2025-09-12 13:29:51.072] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:29:51.090] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:29:51:993050 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:29:51:993051 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:29:51:993051 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:29:51:993050 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.2250s] [ 87%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_ignored_modules_state_dict_type_sharded_state_dict_prefix_True_ignore_inner_False_mixed_precision_True [2025-09-12 13:30:06.158] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:30:06.176] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:30:06:993201 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:30:06:993201 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:30:06:993200 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:30:06:993200 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.8259s] [ 88%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_ignored_modules_state_dict_type_sharded_state_dict_prefix_True_ignore_inner_True_mixed_precision_False [2025-09-12 13:30:20.962] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:30:20.970] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:30:21:993352 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:30:21:993351 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:30:21:993351 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:30:21:993352 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.9251s] [ 88%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_ignored_modules_state_dict_type_sharded_state_dict_prefix_True_ignore_inner_True_mixed_precision_True [2025-09-12 13:30:35.935] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:30:35.954] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:30:36:993504 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:30:36:993504 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:30:36:993503 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:30:36:993503 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.9250s] [ 89%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_ignored_modules_state_dict_type_state_dict_prefix_False_ignore_inner_False_mixed_precision_False [2025-09-12 13:30:50.866] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:30:50.886] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:30:51:993656 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:30:51:993656 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:30:51:993655 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:30:51:993655 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1253s] [ 89%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_ignored_modules_state_dict_type_state_dict_prefix_False_ignore_inner_False_mixed_precision_True [2025-09-12 13:31:05.942] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:31:05.958] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:31:06:993806 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:31:06:993806 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:31:06:993807 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:31:06:993807 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.0254s] [ 90%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_ignored_modules_state_dict_type_state_dict_prefix_False_ignore_inner_True_mixed_precision_False [2025-09-12 13:31:20.950] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:31:20.986] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:31:21:993956 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:31:21:993956 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:31:21:993957 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:31:21:993957 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.0251s] [ 91%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_ignored_modules_state_dict_type_state_dict_prefix_False_ignore_inner_True_mixed_precision_True [2025-09-12 13:31:36.088] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:31:36.106] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:31:36:994108 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:31:36:994108 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:31:36:994107 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:31:36:994107 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.0255s] [ 91%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_ignored_modules_state_dict_type_state_dict_prefix_True_ignore_inner_False_mixed_precision_False [2025-09-12 13:31:51.086] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:31:51.114] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:31:51:994258 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:31:51:994258 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:31:51:994259 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:31:51:994259 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1254s] [ 92%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_ignored_modules_state_dict_type_state_dict_prefix_True_ignore_inner_False_mixed_precision_True [2025-09-12 13:32:06.162] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:32:06.165] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:32:06:994410 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:32:06:994410 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:32:06:994409 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:32:06:994409 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.0240s] [ 92%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_ignored_modules_state_dict_type_state_dict_prefix_True_ignore_inner_True_mixed_precision_False [2025-09-12 13:32:21.182] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:32:21.196] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:32:21:994563 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:32:21:994562 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:32:21:994563 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:32:21:994562 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.0255s] [ 93%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_ignored_modules_state_dict_type_state_dict_prefix_True_ignore_inner_True_mixed_precision_True [2025-09-12 13:32:36.190] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:32:36.195] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:32:36:994712 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:32:36:994712 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:32:36:994713 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:32:36:994713 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.0245s] [ 93%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_manual_ac_wrapper_state_dict_type_sharded_state_dict_rank0_only_and_offload_False [2025-09-12 13:32:51.236] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:32:51.246] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:32:51:994864 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:32:51:994864 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:32:51:994863 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:32:51:994863 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1191s] [ 94%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_manual_ac_wrapper_state_dict_type_sharded_state_dict_rank0_only_and_offload_True [2025-09-12 13:33:06.352] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:33:06.362] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:33:06:995014 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:33:06:995014 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:33:06:995013 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:33:06:995013 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.7189s] [ 94%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_manual_ac_wrapper_state_dict_type_state_dict_rank0_only_and_offload_False [2025-09-12 13:33:21.044] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:33:21.058] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:33:21:995164 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:33:21:995164 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:33:21:995163 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:33:21:995163 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1251s] [ 95%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_manual_ac_wrapper_state_dict_type_state_dict_rank0_only_and_offload_True [2025-09-12 13:33:36.326] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:33:36.342] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:33:36:995313 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:33:36:995313 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:33:36:995314 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:33:36:995314 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.2256s] [ 96%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_shared_parameters_state_dict_type_local_state_dict [2025-09-12 13:33:51.421] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:33:51.430] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:33:51:995464 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:33:51:995464 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:33:51:995465 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:33:51:995465 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.0254s] [ 96%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_shared_parameters_state_dict_type_sharded_state_dict [2025-09-12 13:34:06.454] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:34:06.462] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:34:06:995614 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:34:06:995614 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:34:06:995615 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:34:06:995615 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.0255s] [ 97%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_state_dict_with_shared_parameters_state_dict_type_state_dict [2025-09-12 13:34:21.484] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:34:21.490] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:34:21:995764 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:34:21:995764 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:34:21:995765 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:34:21:995765 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.0252s] [ 97%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_torch_save_load [2025-09-12 13:34:36.510] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:34:36.519] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:34:36:995915 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:34:36:995915 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:34:36:995916 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:34:36:995916 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.0259s] [ 98%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_world_size_one [2025-09-12 13:34:51.518] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:34:51.522] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:34:51:996066 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:34:51:996067 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:34:51:996066 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:34:51:996067 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.9255s] [ 98%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict::test_wrong_state_dict_config [2025-09-12 13:35:06.460] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:35:06.478] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:35:06:996218 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:35:06:996218 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:35:06:996219 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:35:06:996219 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.8251s] [ 99%]
../../../../test/distributed/fsdp/test_fsdp_state_dict.py::TestFSDPStateDict4GPUs::test_local_state_dict_reshard [2025-09-12 13:35:21.330] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:35:21.330] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:35:21.334] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:35:21.348] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:35:21:996368 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:35:21:996368 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:35:21:996370 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:35:21:996370 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:35:21:996369 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:35:21:996369 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:35:21:996371 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:35:21:996371 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:35:50:996368:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:35:50:996369:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [31.8571s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_state_dict.py.xml -
======================= 179 passed in 3180.49s (0:53:00) =======================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 13:35:54.195] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 3 items
Running 3 items in this shard

../../../../test/distributed/fsdp/test_fsdp_tp_integration.py::TestTPFSDPIntegration::test_fsdp_tp_extension_grad [2025-09-12 13:35:56.486] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:35:56.489] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:35:56.533] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:35:56.535] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:35:56:996765 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:35:56:996765 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:35:56:996767 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:35:56:996767 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:35:56:996766 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:35:56:996766 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:35:56:996764 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:35:56:996764 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:36:09:996765:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:09:996764:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:09:996767:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:09:996766:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:09:996765:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:09:996767:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:09:996764:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:09:996766:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [32.2560s] [ 33%]
../../../../test/distributed/fsdp/test_fsdp_tp_integration.py::TestTPFSDPIntegration::test_fsdp_tp_integration [2025-09-12 13:36:28.442] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:36:28.482] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:36:28.502] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:36:28.514] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:36:28:997101 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:36:28:997101 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:36:28:997098 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:36:28:997098 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:36:28:997099 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:36:28:997099 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:36:28:997100 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:36:28:997100 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:36:41:997098:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:41:997099:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:41:997100:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:41:997101:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:42:997098:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:42:997101:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:42:997099:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:42:997100:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:58:997098:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:58:997100:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:58:997099:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:58:997101:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:58:997099:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:58:997101:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:58:997100:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:58:997098:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:58:997100:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:58:997101:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:58:997098:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:58:997099:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:59:997099:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:59:997101:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:59:997098:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:59:997100:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:59:997098:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:59:997100:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:59:997099:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:59:997101:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:59:997099:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:59:997098:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:59:997101:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:36:59:997100:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:00:997101:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:00:997100:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:00:997098:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:00:997099:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:00:997098:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:00:997100:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:00:997101:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:00:997099:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:00:997101:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:00:997100:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:00:997098:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:00:997099:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:01:997098:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:01:997100:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:01:997101:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:01:997099:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:01:997100:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:01:997098:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:01:997099:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:01:997101:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:01:997099:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:01:997098:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:01:997100:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:01:997101:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:02:997098:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:02:997099:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:02:997100:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:02:997101:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:02:997099:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:02:997098:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:02:997101:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:02:997100:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=1, world=4
skip_if_not_powerof2_worldsize_xpu x: 4
dist init r=3, world=4
skip_if_not_powerof2_worldsize_xpu x: 4
dist init r=2, world=4
skip_if_not_powerof2_worldsize_xpu x: 4
dist init r=0, world=4
skip_if_not_powerof2_worldsize_xpu x: 4
PASSED [36.9645s] [ 66%]
../../../../test/distributed/fsdp/test_fsdp_tp_integration.py::TestTPFSDPIntegration::test_fsdp_tp_sync_module_state [2025-09-12 13:37:05.424] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:37:05.426] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:37:05.434] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:37:05.454] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:37:05:997544 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:37:05:997544 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:37:05:997547 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:37:05:997547 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:37:05:997545 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:37:05:997545 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:37:05:997546 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:37:05:997546 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:37:18:997544:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:18:997546:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:18:997545:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-13:37:18:997547:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [16.1304s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_tp_integration.py.xml -
========================= 3 passed in 87.36s (0:01:27) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 13:37:22.366] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 1 item
Running 1 items in this shard

../../../../test/distributed/fsdp/test_fsdp_traversal.py::TestTraversalXPU::test_fsdp_modules_xpu [2025-09-12 13:37:24.494] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:37:24.502] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:37:24:997930 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:37:24:997930 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:37:25:997931 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:37:25:997931 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.2248s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_traversal.py.xml -
============================== 1 passed in 17.28s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 13:37:40.679] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 1 item
Running 1 items in this shard

../../../../test/distributed/fsdp/test_fsdp_uneven.py::TestUnevenParamShardXPU::test_one_iteration_xpu [2025-09-12 13:37:42.942] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:37:42.942] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:37:42.951] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:37:42.974] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:37:43:998156 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:37:43:998156 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:37:43:998155 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:37:43:998155 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:37:43:998154 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:37:43:998154 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:37:43:998157 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:37:43:998157 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [31.3416s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_uneven.py.xml -
============================== 1 passed in 33.53s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 13:38:15.131] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 15 items
Running 15 items in this shard

../../../../test/distributed/fsdp/test_fsdp_unshard_params.py::TestUnshardParams::test_named_parameters_and_buffers [2025-09-12 13:38:17.280] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:38:17.298] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:38:17:998546 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:38:17:998546 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:38:17:998547 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:38:17:998547 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1114s] [  6%]
../../../../test/distributed/fsdp/test_fsdp_unshard_params.py::TestUnshardParams::test_unshard_params_param_data [2025-09-12 13:38:32.210] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:38:32.222] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:38:32:998696 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:38:32:998696 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:38:32:998697 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:38:32:998697 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.3264s] [ 13%]
../../../../test/distributed/fsdp/test_fsdp_unshard_params.py::TestUnshardParams::test_unshard_params_recurse [2025-09-12 13:38:47.522] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:38:47.530] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:38:47:998847 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:38:47:998847 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:38:47:998846 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:38:47:998846 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.0250s] [ 20%]
../../../../test/distributed/fsdp/test_fsdp_unshard_params.py::TestUnshardParams::test_unshard_params_respects_reshard [2025-09-12 13:39:02.570] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:39:02.605] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:39:02:998997 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:39:02:998997 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:39:02:998998 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:39:02:998998 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [30.4479s] [ 26%]
../../../../test/distributed/fsdp/test_fsdp_unshard_params.py::TestUnshardParams::test_unshard_params_writeback [2025-09-12 13:39:32.994] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:39:33.000] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:39:33:999156 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:39:33:999156 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:39:33:999157 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:39:33:999157 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.0253s] [ 33%]
../../../../test/distributed/fsdp/test_fsdp_unshard_params.py::TestUnshardParams::test_unshard_singleton_param_writeback [2025-09-12 13:39:48.038] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:39:48.078] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:39:48:999308 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:39:48:999308 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:39:48:999307 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:39:48:999307 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.9250s] [ 40%]
../../../../test/distributed/fsdp/test_fsdp_unshard_params.py::TestUnshardParams::test_unshard_submodule [2025-09-12 13:40:02.966] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:40:02.997] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:40:03:999458 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:40:03:999458 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:40:03:999457 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:40:03:999457 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.8250s] [ 46%]
../../../../test/distributed/fsdp/test_fsdp_unshard_params.py::TestUnshardParams::test_with_grads_core [2025-09-12 13:40:17.802] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:40:17.830] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:40:18:999608 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:40:18:999608 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:40:18:999607 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:40:18:999607 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [43.6670s] [ 53%]
../../../../test/distributed/fsdp/test_fsdp_unshard_params.py::TestUnshardParams::test_with_grads_none_grads [2025-09-12 13:41:01.544] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:41:01.550] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:41:01:999766 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:41:01:999766 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:41:01:999767 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:41:01:999767 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [15.1252s] [ 60%]
../../../../test/distributed/fsdp/test_fsdp_unshard_params.py::TestUnshardParamsNoShard::test_unshard_params_param_data_no_shard [2025-09-12 13:41:16.650] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:41:16:999917 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:41:16:999917 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.3069s] [ 66%]
../../../../test/distributed/fsdp/test_fsdp_unshard_params.py::TestUnshardParamsNoShard::test_unshard_params_writeback_no_shard [2025-09-12 13:41:19.970] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:41:20:999991 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:41:20:999991 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.2068s] [ 73%]
../../../../test/distributed/fsdp/test_fsdp_unshard_params.py::TestUnshardParamsErrors::test_offload_to_cpu_no_shard_raises [2025-09-12 13:41:23.098] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:41:23.105] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:41:23:1000067 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:41:23:1000067 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:41:23:1000068 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:41:23:1000068 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.8250s] [ 80%]
../../../../test/distributed/fsdp/test_fsdp_unshard_params.py::TestUnshardParamsErrors::test_rank0_only_with_writeback_raises [2025-09-12 13:41:37.920] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:41:37.938] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:41:38:1000218 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:41:38:1000218 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:41:38:1000219 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:41:38:1000219 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.7237s] [ 86%]
../../../../test/distributed/fsdp/test_fsdp_unshard_params.py::TestUnshardParamsErrors::test_unshard_params_from_backward_raises [2025-09-12 13:41:52.630] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:41:52.642] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:41:52:1000369 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:41:52:1000369 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:41:52:1000370 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:41:52:1000370 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [14.8252s] [ 93%]
../../../../test/distributed/fsdp/test_fsdp_unshard_params.py::TestUnshardParamsErrors::test_unshard_params_from_forward_raises [2025-09-12 13:42:07.486] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:42:07.506] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:42:07:1000528 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:42:07:1000528 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:42:07:1000527 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:42:07:1000527 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [14.9253s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_unshard_params.py.xml -
======================== 15 passed in 247.29s (0:04:07) ========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 13:42:22.887] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 25 items
Running 25 items in this shard

../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsMultipleParamGroups::test_diff_hyperparams_cpu_offload_sharding_strategy_str_full_shard [2025-09-12 13:42:34.059] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:42:34.082] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:42:44:1001141 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:42:44:1001141 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:42:45:1001142 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:42:45:1001142 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [54.3845s] [  4%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsMultipleParamGroups::test_diff_hyperparams_cpu_offload_sharding_strategy_str_no_shard [2025-09-12 13:43:28.374] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:43:28.390] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:43:38:1002079 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:43:38:1002079 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:43:39:1002078 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:43:39:1002078 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [39.4627s] [  8%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsMultipleParamGroups::test_diff_hyperparams_cpu_offload_sharding_strategy_str_shard_grad_op [2025-09-12 13:44:07.821] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:44:07.838] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:44:17:1003015 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:44:17:1003015 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:44:19:1003014 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:44:19:1003014 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [54.0845s] [ 12%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsMultipleParamGroups::test_diff_hyperparams_sharding_strategy_str_full_shard [2025-09-12 13:45:01.914] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:45:01.917] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:45:11:1003952 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:45:11:1003952 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:45:13:1003951 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:45:13:1003951 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
FAILED [55.1862s] [ 16%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsMultipleParamGroups::test_diff_hyperparams_sharding_strategy_str_no_shard [2025-09-12 13:45:57.090] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:45:57.114] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:46:07:1004887 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:46:07:1004887 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:46:08:1004886 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:46:08:1004886 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [79.9183s] [ 20%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsMultipleParamGroups::test_diff_hyperparams_sharding_strategy_str_shard_grad_op [2025-09-12 13:47:17.016] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:47:17.026] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:47:26:1005822 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:47:26:1005822 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:47:28:1005821 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:47:28:1005821 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
FAILED [300.0615s] [ 24%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsMultipleParamGroups::test_diff_trainability [2025-09-12 13:52:17.107] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:52:17.125] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:52:27:1006762 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:52:27:1006762 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:52:28:1006763 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:52:28:1006763 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [56.3882s] [ 28%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsMultipleParamGroups::test_fsdp_compile [2025-09-12 13:53:13.442] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:53:13.458] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:53:23:1007699 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:53:23:1007699 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:53:24:1007698 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:53:24:1007698 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [73.9157s] [ 32%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsMultipleParamGroups::test_multiple_optimizers [2025-09-12 13:54:27.378] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:54:27.390] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:54:37:1009285 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:54:37:1009285 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:54:38:1009284 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:54:38:1009284 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [53.4829s] [ 36%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsUnshardReshard::test_multiple_forward_offload_params_False [2025-09-12 13:55:20.850] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:55:20.867] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:55:30:1010221 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:55:30:1010221 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:55:32:1010220 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:55:32:1010220 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [42.0669s] [ 40%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsUnshardReshard::test_multiple_forward_offload_params_True [2025-09-12 13:56:02.999] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:56:03.009] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:56:13:1011154 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:56:13:1011154 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:56:14:1011155 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:56:14:1011155 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [42.3651s] [ 44%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsUnshardReshard::test_summon_between_two_forwards_offload_params_False [2025-09-12 13:56:45.295] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:56:45.310] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:56:55:1012281 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:56:55:1012281 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:56:56:1012280 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:56:56:1012280 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [41.9658s] [ 48%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsUnshardReshard::test_summon_between_two_forwards_offload_params_True [2025-09-12 13:57:27.254] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:57:27.273] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:57:37:1013215 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:57:37:1013215 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:57:38:1013216 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:57:38:1013216 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [42.1675s] [ 52%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsParamAccess::test_access_params_after_forward [2025-09-12 13:58:09.417] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:58:09.434] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:58:19:1014339 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:58:19:1014339 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:58:20:1014340 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:58:20:1014340 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [41.0650s] [ 56%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsWriteback::test_grad_writeback [2025-09-12 13:58:50.506] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:58:50.518] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:59:00:1015273 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:59:00:1015273 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:59:01:1015272 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:59:01:1015272 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [41.0652s] [ 60%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsWriteback::test_no_reshard_and_mixed_precision [2025-09-12 13:59:31.642] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 13:59:31.655] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-13:59:41:1016206 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:59:41:1016206 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-13:59:42:1016207 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-13:59:42:1016207 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [41.2665s] [ 64%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsWriteback::test_param_writeback [2025-09-12 14:00:12.859] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:00:12.862] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:00:23:1017141 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:00:23:1017141 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:00:24:1017140 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:00:24:1017140 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [26.2430s] [ 68%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsWriteback::test_writeback_between_fwd_and_bwd_for_no_reshard_raises [2025-09-12 14:00:39.134] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:00:39.158] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:00:49:1018067 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:00:49:1018067 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:00:50:1018066 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:00:50:1018066 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [25.9418s] [ 72%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsWriteback::test_writeback_shape_mismatch [2025-09-12 14:01:05.003] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:01:05.003] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:01:15:1018999 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:01:15:1018999 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:01:16:1019000 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:01:16:1019000 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [25.8424s] [ 76%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsFQNs::test_named_parameters_in_forward [2025-09-12 14:01:30.863] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:01:30.865] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:01:30.882] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:01:30.893] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:01:40:1019926 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:01:40:1019926 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:01:42:1019924 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:01:42:1019924 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:01:43:1019927 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:01:43:1019927 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:01:44:1019925 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:01:44:1019925 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [29.2517s] [ 80%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsNoSync::test_no_sync_correctness [2025-09-12 14:02:00.107] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:02:00.125] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:02:10:1021775 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:02:10:1021775 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:02:11:1021774 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:02:11:1021774 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [40.8648s] [ 84%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsNoSync::test_no_sync_mixed_precision [2025-09-12 14:02:41.023] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:02:41.034] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:02:51:1022709 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:02:51:1022709 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:02:52:1022710 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:02:52:1022710 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [40.8641s] [ 88%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsInit::test_non_uniform_requires_grad [2025-09-12 14:03:21.906] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:03:21.908] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:03:22.019] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:03:22.019] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:03:32:1023646 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:03:32:1023646 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:03:33:1023645 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:03:33:1023645 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:03:34:1023643 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:03:34:1023643 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:03:36:1023644 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:03:36:1023644 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [29.2518s] [ 92%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestMultiTensorApply::test_multi_tensor_apply_size0_tensors_cpu PASSED [0.0040s] [ 96%]
../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestMultiTensorApply::test_multi_tensor_apply_size0_tensors_cuda PASSED [0.0171s] [100%]

=================================== FAILURES ===================================
_ TestFSDPUseOrigParamsMultipleParamGroups.test_diff_hyperparams_sharding_strategy_str_full_shard _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_use_orig_params.py", line 287, in test_diff_hyperparams
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_use_orig_params.py", line 374, in _test_diff_hyperparams
    self._check_train_parity(
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_use_orig_params.py", line 197, in _check_train_parity
    torch.testing.assert_close(iter_losses[0], iter_losses[1])
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Scalars are not close!

Expected 0.5508145093917847 but got 0.4790288209915161.
Absolute difference: 0.07178568840026855 (up to 1e-05 allowed)
Relative difference: 0.13032642963515084 (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_use_orig_params.py TestFSDPUseOrigParamsMultipleParamGroups.test_diff_hyperparams_sharding_strategy_str_full_shard

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 0 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 13:45:00.566000 1000681 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1003951
I0912 13:45:00.566000 1000681 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1003952
_ TestFSDPUseOrigParamsMultipleParamGroups.test_diff_hyperparams_sharding_strategy_str_shard_grad_op _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1025, in _check_return_codes
    raise RuntimeError(
RuntimeError: Process 0 terminated or timed out after 300.0586745738983 seconds
----------------------------- Captured stdout call -----------------------------
Timing out after 300 seconds and killing subprocesses.
----------------------------- Captured stderr call -----------------------------
I0912 13:47:15.675000 1000681 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1005821
I0912 13:47:15.675000 1000681 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1005822
E0912 13:52:15.730000 1000681 site-packages/torch/testing/_internal/common_distributed.py:909] Encountered error while trying to get traceback for process 0: [Errno 32] Broken pipe
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928] Process 1 timed out with traceback: 
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928] Thread 0x00007ff070ffd640 (most recent call first):
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   <no Python frame>
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928] Thread 0x00007ff06bfff640 (most recent call first):
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   <no Python frame>
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928] Thread 0x00007ff0717fe640 (most recent call first):
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   <no Python frame>
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928] Thread 0x00007ff071fff640 (most recent call first):
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   <no Python frame>
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928] Current thread 0x00007ff08089f640 (most recent call first):
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 825 in _event_listener
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 953 in run
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 1016 in _bootstrap_inner
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 973 in _bootstrap
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928] Thread 0x00007ff1bc0e5e00 (most recent call first):
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/autograd/graph.py", line 841 in _engine_run_backward
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/autograd/__init__.py", line 354 in backward
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_tensor.py", line 625 in backward
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 324 in run_backward
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_use_orig_params.py", line 190 in _check_train_parity
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_use_orig_params.py", line 374 in _test_diff_hyperparams
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147 in run_subtests
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188 in run_subtests
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_use_orig_params.py", line 287 in test_diff_hyperparams
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221 in wrapper
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552 in instantiated_test
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225 in wrapper
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718 in wrapper
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864 in run_test
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1237 in _run
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/process.py", line 108 in run
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/process.py", line 314 in _bootstrap
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/spawn.py", line 129 in _main
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/spawn.py", line 116 in spawn_main
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928]   File "<string>", line 1 in <module>
E0912 13:52:15.733000 1000681 site-packages/torch/testing/_internal/common_distributed.py:928] 
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_fsdp_use_orig_params.py.xml -
=========================== short test summary info ============================
FAILED [55.1862s] ../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsMultipleParamGroups::test_diff_hyperparams_sharding_strategy_str_full_shard - RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_use_orig_params.py", line 287, in test_diff_hyperparams
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_use_orig_params.py", line 374, in _test_diff_hyperparams
    self._check_train_parity(
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/fsdp/test_fsdp_use_orig_params.py", line 197, in _check_train_parity
    torch.testing.assert_close(iter_losses[0], iter_losses[1])
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Scalars are not close!

Expected 0.5508145093917847 but got 0.4790288209915161.
Absolute difference: 0.07178568840026855 (up to 1e-05 allowed)
Relative difference: 0.13032642963515084 (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/fsdp/test_fsdp_use_orig_params.py TestFSDPUseOrigParamsMultipleParamGroups.test_diff_hyperparams_sharding_strategy_str_full_shard

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [300.0615s] ../../../../test/distributed/fsdp/test_fsdp_use_orig_params.py::TestFSDPUseOrigParamsMultipleParamGroups::test_diff_hyperparams_sharding_strategy_str_shard_grad_op - RuntimeError: Process 0 terminated or timed out after 300.0586745738983 seconds
================== 2 failed, 23 passed in 1288.28s (0:21:28) ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:03:52.810] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 8 items
Running 8 items in this shard

../../../../test/distributed/fsdp/test_hsdp_dtensor_state_dict.py::TestHSDPWithDeviceMeshAndDTensorXPU::test_dtensor_sharded_model_load_state_dict_offload_to_cpu_False_xpu [2025-09-12 14:03:55.001] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:03:55.006] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:03:55.183] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:03:55.199] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:03:55:1025569 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:03:55:1025569 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:03:55:1025572 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:03:55:1025572 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:03:55:1025570 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:03:55:1025570 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:03:55:1025571 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:03:55:1025571 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:04:12:1025878:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:04:12:1025892:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:04:12:1025881:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:04:12:1025887:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:04:24:1025569:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:04:24:1025571:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:04:24:1025572:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:04:24:1025570:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [32.3542s] [ 12%]
../../../../test/distributed/fsdp/test_hsdp_dtensor_state_dict.py::TestHSDPWithDeviceMeshAndDTensorXPU::test_dtensor_sharded_model_load_state_dict_offload_to_cpu_True_xpu [2025-09-12 14:04:27.362] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:04:27.365] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:04:27.368] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:04:27.383] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:04:27:1025905 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:04:27:1025905 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:04:27:1025903 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:04:27:1025903 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:04:27:1025902 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:04:27:1025902 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:04:27:1025904 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:04:27:1025904 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:04:44:1026215:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:04:44:1026221:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:04:44:1026224:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:04:44:1026210:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:04:56:1025903:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:04:56:1025902:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:04:56:1025904:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:04:56:1025905:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [32.3479s] [ 25%]
../../../../test/distributed/fsdp/test_hsdp_dtensor_state_dict.py::TestHSDPWithDeviceMeshAndDTensorXPU::test_dtensor_sharded_optim_load_state_dict_offload_to_cpu_False_xpu [2025-09-12 14:04:59.687] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:04:59.700] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:04:59.706] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:04:59.706] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:05:00:1026238 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:05:00:1026238 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:05:00:1026236 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:05:00:1026236 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:05:00:1026237 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:05:00:1026237 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:05:00:1026235 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:05:00:1026235 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:05:16:1026551:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:05:16:1026549:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:05:16:1026546:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:05:16:1026556:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:05:28:1026235:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:05:28:1026238:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:05:28:1026237:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:05:28:1026236:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [32.4405s] [ 37%]
../../../../test/distributed/fsdp/test_hsdp_dtensor_state_dict.py::TestHSDPWithDeviceMeshAndDTensorXPU::test_dtensor_sharded_optim_load_state_dict_offload_to_cpu_True_xpu [2025-09-12 14:05:32.134] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:05:32.162] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:05:32.186] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:05:32.206] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:05:32:1026568 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:05:32:1026568 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:05:32:1026569 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:05:32:1026569 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:05:32:1026570 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:05:32:1026570 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:05:32:1026567 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:05:32:1026567 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:05:49:1026890:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:05:49:1026880:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:05:49:1026887:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:05:49:1026885:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:01:1026570:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:01:1026567:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:01:1026568:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:01:1026569:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [32.4512s] [ 50%]
../../../../test/distributed/fsdp/test_hsdp_dtensor_state_dict.py::TestHSDPWithDeviceMeshAndDTensorXPU::test_dtensor_sharded_tensor_state_dict_identical_offload_to_cpu_False_xpu [2025-09-12 14:06:04.598] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:06:04.606] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:06:04.614] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:06:04.626] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:06:05:1026902 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:06:05:1026902 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:06:05:1026904 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:06:05:1026904 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:06:05:1026905 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:06:05:1026905 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:06:05:1026903 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:06:05:1026903 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:06:21:1027215:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:21:1027213:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:21:1027220:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:21:1027222:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:33:1026904:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:33:1026903:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:33:1026905:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:33:1026902:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:34:1026903:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:34:1026902:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:34:1026904:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:34:1026905:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:34:1027215:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:34:1027213:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:34:1027222:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:34:1027220:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [33.1511s] [ 62%]
../../../../test/distributed/fsdp/test_hsdp_dtensor_state_dict.py::TestHSDPWithDeviceMeshAndDTensorXPU::test_dtensor_sharded_tensor_state_dict_identical_offload_to_cpu_True_xpu [2025-09-12 14:06:37.750] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:06:37.751] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:06:37.764] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:06:37.790] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:06:38:1027253 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:06:38:1027253 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:06:38:1027251 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:06:38:1027251 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:06:38:1027252 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:06:38:1027252 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:06:38:1027254 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:06:38:1027254 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:06:54:1027562:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:54:1027574:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:54:1027569:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:06:54:1027559:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:06:1027253:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:06:1027252:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:06:1027251:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:06:1027254:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:07:1027254:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:07:1027253:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:07:1027252:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:07:1027251:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:07:1027574:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:07:1027562:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:07:1027559:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:07:1027569:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [32.9508s] [ 75%]
../../../../test/distributed/fsdp/test_hsdp_dtensor_state_dict.py::TestHSDPWithDeviceMeshAndDTensorXPU::test_hsdp_init_with_device_mesh_xpu [2025-09-12 14:07:10.687] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:07:10.703] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:07:10.834] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:07:10.850] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:07:11:1027600 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:07:11:1027600 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:07:11:1027602 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:07:11:1027602 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:07:11:1027601 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:07:11:1027601 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:07:11:1027603 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:07:11:1027603 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:07:27:1027918:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:27:1027923:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:27:1027913:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:27:1027908:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:39:1027600:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:39:1027601:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:39:1027603:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:39:1027602:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [31.9481s] [ 87%]
../../../../test/distributed/fsdp/test_hsdp_dtensor_state_dict.py::TestHSDPWithDeviceMeshAndDTensorXPU::test_root_module_is_not_FSDP_xpu [2025-09-12 14:07:42.627] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:07:42.631] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:07:42.642] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:07:42.642] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:07:43:1027934 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:07:43:1027934 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:07:43:1027935 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:07:43:1027935 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:07:43:1027936 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:07:43:1027936 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:07:43:1027933 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:07:43:1027933 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:07:55:1027936:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:55:1027935:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:55:1027933:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:07:55:1027934:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:08:11:1028254:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:08:11:1028252:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:08:11:1028259:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:08:11:1028249:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [32.3491s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_hsdp_dtensor_state_dict.py.xml -
======================== 8 passed in 262.09s (0:04:22) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:08:15.999] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/fsdp/test_shard_utils.py::TestShardUtilsDistributed::test_create_chunk_sharded_tensor [2025-09-12 14:08:18.158] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:08:18.162] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:08:18:1028340 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:08:18:1028340 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:08:18:1028341 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:08:18:1028341 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [15.1119s] [ 50%]
../../../../test/distributed/fsdp/test_shard_utils.py::TestShardUtilsDistributedDTensor::test_create_chunk_dtensor [2025-09-12 14:08:33.074] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:08:33.090] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:08:33:1028490 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:08:33:1028491 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:08:33:1028490 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:08:33:1028491 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.1202s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_shard_utils.py.xml -
============================== 2 passed in 32.22s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:08:49.211] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 5 items
Running 5 items in this shard

../../../../test/distributed/fsdp/test_utils.py::TestUtilsXPU::test_apply_to_tensors_cpu_xpu_xpu PASSED [0.0050s] [ 20%]
../../../../test/distributed/fsdp/test_utils.py::TestUtilsXPU::test_apply_to_tensors_device_list0_xpu PASSED [0.0016s] [ 40%]
../../../../test/distributed/fsdp/test_utils.py::TestUtilsXPU::test_apply_to_tensors_device_list1_xpu PASSED [0.0017s] [ 60%]
../../../../test/distributed/fsdp/test_utils.py::TestUtilsXPU::test_packed_sequence_xpu PASSED [0.0019s] [ 80%]
../../../../test/distributed/fsdp/test_utils.py::TestUtilsXPU::test_replace_by_prefix_xpu PASSED [0.0005s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_utils.py.xml -
============================== 5 passed in 2.20s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:08:51.864] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 52 items
Running 52 items in this shard

../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_bn_always_wrapped_individually [2025-09-12 14:08:53.999] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:08:54.005] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:08:54.014] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:08:54.035] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:08:54:1028790 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:08:54:1028790 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:08:54:1028789 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:08:54:1028789 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:08:54:1028788 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:08:54:1028788 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:08:54:1028787 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:08:54:1028787 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [15.9333s] [  1%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_error_already_wrapped_nested_False_device_init_mode0 [2025-09-12 14:09:09.817] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:09:09.839] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:09:09.841] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:09:09.877] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:09:10:1029088 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:09:10:1029088 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:09:10:1029087 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:09:10:1029087 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:09:10:1029089 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:09:10:1029089 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:09:10:1029090 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:09:10:1029090 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [15.7220s] [  3%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_error_already_wrapped_nested_False_device_init_mode1 [2025-09-12 14:09:25.573] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:09:25.586] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:09:25.668] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:09:25.681] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:09:26:1029389 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:09:26:1029389 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:09:26:1029390 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:09:26:1029390 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:09:26:1029387 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:09:26:1029387 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:09:26:1029388 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:09:26:1029388 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [15.7299s] [  5%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_error_already_wrapped_nested_True_device_init_mode0 [2025-09-12 14:09:41.298] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:09:41.301] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:09:41.304] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:09:41.314] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:09:42:1029688 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:09:42:1029688 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:09:42:1029687 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:09:42:1029687 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:09:42:1029690 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:09:42:1029690 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:09:42:1029689 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:09:42:1029689 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
PASSED [15.5291s] [  7%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_error_already_wrapped_nested_True_device_init_mode1 [2025-09-12 14:09:56.826] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:09:56.826] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:09:56.837] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:09:56.840] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:09:57:1029990 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:09:57:1029990 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:09:57:1029991 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:09:57:1029991 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:09:57:1029988 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:09:57:1029988 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:09:57:1029989 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:09:57:1029989 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [15.6289s] [  9%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_main_wrap_api_cpu_offload0_backward_prefetch0_forward_prefetch_False_device_init_mode0 [2025-09-12 14:10:12.498] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:10:12.509] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:10:12.515] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:10:12.534] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:10:13:1030290 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:10:13:1030290 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:10:13:1030289 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:10:13:1030289 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:10:13:1030291 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:10:13:1030291 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:10:13:1030292 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:10:13:1030292 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [31.1551s] [ 11%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_main_wrap_api_cpu_offload0_backward_prefetch0_forward_prefetch_False_device_init_mode1 [2025-09-12 14:10:43.603] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:10:43.611] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:10:43.614] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:10:43.630] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:10:44:1030609 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:10:44:1030609 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:10:44:1030608 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:10:44:1030608 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:10:44:1030607 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:10:44:1030607 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:10:44:1030610 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:10:44:1030610 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [31.1550s] [ 13%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_main_wrap_api_cpu_offload0_backward_prefetch0_forward_prefetch_True_device_init_mode0 [2025-09-12 14:11:14.772] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:11:14.774] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:11:14.786] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:11:14.787] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:11:15:1030925 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:11:15:1030925 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:11:15:1030927 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:11:15:1030927 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:11:15:1030926 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:11:15:1030926 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:11:15:1030928 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:11:15:1030928 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [31.1548s] [ 15%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_main_wrap_api_cpu_offload0_backward_prefetch0_forward_prefetch_True_device_init_mode1 [2025-09-12 14:11:45.947] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:11:45.958] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:11:45.962] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:11:45.970] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:11:46:1031246 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:11:46:1031246 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:11:46:1031243 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:11:46:1031243 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:11:46:1031244 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:11:46:1031244 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:11:46:1031245 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:11:46:1031245 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [31.2494s] [ 17%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_main_wrap_api_cpu_offload0_backward_prefetch1_forward_prefetch_False_device_init_mode0 [2025-09-12 14:12:17.160] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:12:17.166] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:12:17.168] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:12:17.168] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:12:17:1031564 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:12:17:1031564 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:12:17:1031562 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:12:17:1031562 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:12:18:1031563 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:12:18:1031563 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:12:18:1031565 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:12:18:1031565 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
PASSED [31.0547s] [ 19%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_main_wrap_api_cpu_offload0_backward_prefetch1_forward_prefetch_False_device_init_mode1 [2025-09-12 14:12:48.230] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:12:48.241] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:12:48.246] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:12:48.256] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:12:49:1031882 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:12:49:1031882 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:12:49:1031883 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:12:49:1031883 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:12:49:1031881 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:12:49:1031881 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:12:49:1031884 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:12:49:1031884 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
PASSED [31.0546s] [ 21%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_main_wrap_api_cpu_offload0_backward_prefetch1_forward_prefetch_True_device_init_mode0 [2025-09-12 14:13:19.290] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:13:19.295] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:13:19.305] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:13:19.305] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:13:20:1032202 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:13:20:1032202 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:13:20:1032199 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:13:20:1032199 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:13:20:1032201 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:13:20:1032201 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:13:20:1032200 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:13:20:1032200 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [31.0548s] [ 23%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_main_wrap_api_cpu_offload0_backward_prefetch1_forward_prefetch_True_device_init_mode1 [2025-09-12 14:13:50.358] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:13:50.368] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:13:50.371] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:13:50.390] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:13:51:1032517 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:13:51:1032517 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:13:51:1032518 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:13:51:1032518 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:13:51:1032516 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:13:51:1032516 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:13:51:1032519 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:13:51:1032519 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [31.0549s] [ 25%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_main_wrap_api_cpu_offload1_backward_prefetch0_forward_prefetch_False_device_init_mode0 [2025-09-12 14:14:21.457] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:14:21.470] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:14:21.470] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:14:21.478] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:14:22:1032834 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:14:22:1032834 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:14:22:1032837 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:14:22:1032837 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:14:22:1032835 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:14:22:1032835 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:14:22:1032836 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:14:22:1032836 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [15.7296s] [ 26%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_main_wrap_api_cpu_offload1_backward_prefetch0_forward_prefetch_False_device_init_mode1 [2025-09-12 14:14:37.136] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:14:37.139] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:14:37.142] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:14:37.158] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:14:37:1033137 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:14:37:1033137 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:14:37:1033134 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:14:37:1033134 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:14:38:1033136 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:14:38:1033136 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:14:38:1033135 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:14:38:1033135 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.3561s] [ 28%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_main_wrap_api_cpu_offload1_backward_prefetch0_forward_prefetch_True_device_init_mode0 [2025-09-12 14:15:08.478] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:15:08.494] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:15:08.494] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:15:08.501] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:15:09:1033455 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:15:09:1033455 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:15:09:1033454 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:15:09:1033454 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:15:09:1033453 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:15:09:1033453 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:15:09:1033456 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:15:09:1033456 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [15.8222s] [ 30%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_main_wrap_api_cpu_offload1_backward_prefetch0_forward_prefetch_True_device_init_mode1 [2025-09-12 14:15:24.321] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:15:24.338] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:15:24.348] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:15:24.355] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:15:25:1033754 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:15:25:1033754 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:15:25:1033757 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:15:25:1033757 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:15:25:1033755 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:15:25:1033755 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:15:25:1033756 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:15:25:1033756 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
PASSED [30.9548s] [ 32%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_main_wrap_api_cpu_offload1_backward_prefetch1_forward_prefetch_False_device_init_mode0 [2025-09-12 14:15:55.274] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:15:55.274] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:15:55.287] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:15:55.300] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:15:56:1034073 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:15:56:1034073 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:15:56:1034075 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:15:56:1034075 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:15:56:1034074 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:15:56:1034074 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:15:56:1034076 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:15:56:1034076 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [15.6292s] [ 34%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_main_wrap_api_cpu_offload1_backward_prefetch1_forward_prefetch_False_device_init_mode1 [2025-09-12 14:16:10.887] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:16:10.906] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:16:10.912] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:16:10.922] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:16:11:1034377 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:16:11:1034377 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:16:11:1034378 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:16:11:1034378 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:16:11:1034376 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:16:11:1034376 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:16:11:1034375 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:16:11:1034375 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [31.0547s] [ 36%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_main_wrap_api_cpu_offload1_backward_prefetch1_forward_prefetch_True_device_init_mode0 [2025-09-12 14:16:41.931] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:16:41.947] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:16:41.966] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:16:41.994] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:16:42:1034696 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:16:42:1034696 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:16:42:1034695 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:16:42:1034695 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:16:42:1034694 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:16:42:1034694 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:16:42:1034697 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:16:42:1034697 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [15.8307s] [ 38%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_main_wrap_api_cpu_offload1_backward_prefetch1_forward_prefetch_True_device_init_mode1 [2025-09-12 14:16:57.774] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:16:57.778] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:16:57.790] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:16:57.795] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:16:58:1034998 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:16:58:1034998 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:16:58:1034997 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:16:58:1034997 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:16:58:1034999 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:16:58:1034999 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:16:58:1035000 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:16:58:1035000 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [31.0555s] [ 40%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_wrap_batchnorm_individually_use_or_policy_False [2025-09-12 14:17:28.864] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:17:28.882] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:17:28.890] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:17:28.893] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:17:29:1035322 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:17:29:1035322 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:17:29:1035323 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:17:29:1035323 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:17:29:1035320 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:17:29:1035320 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:17:29:1035321 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:17:29:1035321 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [15.7298s] [ 42%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_wrap_batchnorm_individually_use_or_policy_True [2025-09-12 14:17:44.585] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:17:44.586] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:17:44.586] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:17:44.594] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:17:45:1035622 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:17:45:1035622 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:17:45:1035623 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:17:45:1035623 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:17:45:1035621 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:17:45:1035621 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:17:45:1035620 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:17:45:1035620 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [15.7298s] [ 44%]
../../../../test/distributed/fsdp/test_wrap.py::TestFSDPWrap::test_zero_argument [2025-09-12 14:18:00.327] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:18:00.329] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:18:00.343] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:18:00.350] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:18:01:1035923 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:18:01:1035923 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:18:01:1035925 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:18:01:1035925 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:18:01:1035926 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:18:01:1035926 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:18:01:1035924 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:18:01:1035924 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [15.7294s] [ 46%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_always_wrap PASSED [0.0316s] [ 48%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_always_wrap_with_ignored_modules_wrap_method0 SKIPPED [0.0002s] [ 50%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_always_wrap_with_ignored_modules_wrap_method1 SKIPPED [0.0001s] [ 51%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_auto_wrap_api SKIPPED [0.0001s] [ 53%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_auto_wrap_preset_exclude_wrap SKIPPED [0.0001s] [ 55%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_auto_wrap_preset_exclude_wrap_include_children SKIPPED [0.0001s] [ 57%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_auto_wrap_preset_force_leaf SKIPPED [0.0001s] [ 59%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_auto_wrap_preset_force_leaf_custom SKIPPED [0.0001s] [ 61%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_auto_wrap_smoke_test_device_init_mode0_cpu_offload0_use_device_id_False 2025:09:12-14:18:14:1036225 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:18:14:1036225 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [0.6311s] [ 63%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_auto_wrap_smoke_test_device_init_mode0_cpu_offload0_use_device_id_True PASSED [0.4116s] [ 65%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_auto_wrap_smoke_test_device_init_mode0_cpu_offload1_use_device_id_False 2025:09:12-14:18:15:1036225:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [0.2792s] [ 67%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_auto_wrap_smoke_test_device_init_mode0_cpu_offload1_use_device_id_True 2025:09:12-14:18:16:1036225:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [0.2711s] [ 69%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_auto_wrap_smoke_test_device_init_mode1_cpu_offload0_use_device_id_False 2025:09:12-14:18:16:1036225:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [0.2711s] [ 71%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_auto_wrap_smoke_test_device_init_mode1_cpu_offload0_use_device_id_True 2025:09:12-14:18:16:1036225:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [0.2708s] [ 73%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_auto_wrap_smoke_test_device_init_mode1_cpu_offload1_use_device_id_False PASSED [0.0004s] [ 75%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_auto_wrap_smoke_test_device_init_mode1_cpu_offload1_use_device_id_True PASSED [0.0003s] [ 76%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_auto_wrap_with_ignored_modules_wrap_method0 SKIPPED [0.0001s] [ 78%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_auto_wrap_with_ignored_modules_wrap_method1 SKIPPED [0.0001s] [ 80%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_custom_policy SKIPPED [0.0001s] [ 82%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_frozen_params SKIPPED [0.0001s] [ 84%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_module_wrap_policy SKIPPED [0.0001s] [ 86%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_module_wrap_policy_callable SKIPPED [0.0001s] [ 88%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_transformer_auto_wrap_policy SKIPPED [0.0001s] [ 90%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_wrap_disabled_outside_context SKIPPED [0.0001s] [ 92%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_wrap_override_defaults SKIPPED [0.0001s] [ 94%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_wrap_wrap_method0 SKIPPED [0.0001s] [ 96%]
../../../../test/distributed/fsdp/test_wrap.py::TestAutoWrap::test_wrap_wrap_method1 SKIPPED [0.0001s] [ 98%]
../../../../test/distributed/fsdp/test_wrap.py::TestWrapUtils::test_validate_frozen_params PASSED [0.0092s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_fsdp_test_wrap.py.xml -
================== 34 passed, 18 skipped in 566.41s (0:09:26) ==================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:18:19.586] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 4 items
Running 4 items in this shard

../../../../test/distributed/test_backends.py::TestMiscCollectiveUtilsCPU::test_create_pg_cpu [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
PASSED [0.0127s] [ 25%]
../../../../test/distributed/test_backends.py::TestMiscCollectiveUtilsCPU::test_device_to_backend_mapping_cpu PASSED [0.0004s] [ 50%]
../../../../test/distributed/test_backends.py::TestMiscCollectiveUtilsXPU::test_create_pg_xpu PASSED [0.0013s] [ 75%]
../../../../test/distributed/test_backends.py::TestMiscCollectiveUtilsXPU::test_device_to_backend_mapping_xpu PASSED [0.0004s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_test_backends.py.xml -
============================== 4 passed in 2.09s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:18:22.086] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 27 items
Running 27 items in this shard

../../../../test/distributed/test_c10d_common.py::TimeoutTest::test_store_based_barrier PASSED [31.1979s] [  3%]
../../../../test/distributed/test_c10d_common.py::ComputeBucketAssignmentTest::test_multi_limit_multi_dtype PASSED [0.0009s] [  7%]
../../../../test/distributed/test_c10d_common.py::ComputeBucketAssignmentTest::test_multi_limit_single_dtype PASSED [0.0006s] [ 11%]
../../../../test/distributed/test_c10d_common.py::ComputeBucketAssignmentTest::test_single_limit_multi_dtype PASSED [0.0006s] [ 14%]
../../../../test/distributed/test_c10d_common.py::ComputeBucketAssignmentTest::test_single_limit_single_dtype PASSED [0.0006s] [ 18%]
../../../../test/distributed/test_c10d_common.py::CommTest::test_debug_level [2025-09-12 14:18:55.305] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:18:55.341] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.7069s] [ 22%]
../../../../test/distributed/test_c10d_common.py::PythonProcessGroupExtensionTest::test_abort [2025-09-12 14:18:57.932] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:18:57.946] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:18:57.992] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:18:58.006] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [3.4095s] [ 25%]
../../../../test/distributed/test_c10d_common.py::PythonProcessGroupExtensionTest::test_backend_class_attr [2025-09-12 14:19:01.366] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:01.390] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:01.390] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:01.410] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.8089s] [ 29%]
../../../../test/distributed/test_c10d_common.py::PythonProcessGroupExtensionTest::test_backend_config [2025-09-12 14:19:04.172] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:04.175] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:04.195] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:04.206] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
FAILED [2.6092s] [ 33%]
../../../../test/distributed/test_c10d_common.py::PythonProcessGroupExtensionTest::test_canonicalize_helper [2025-09-12 14:19:06.819] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:06.820] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:06.824] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:06.854] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [3.2092s] [ 37%]
../../../../test/distributed/test_c10d_common.py::PythonProcessGroupExtensionTest::test_collectives [2025-09-12 14:19:10.066] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:10.066] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:10.082] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:10.092] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [3.2095s] [ 40%]
../../../../test/distributed/test_c10d_common.py::PythonProcessGroupExtensionTest::test_get_backend_name [2025-09-12 14:19:13.190] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:13.202] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:13.210] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:13.216] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.9087s] [ 44%]
../../../../test/distributed/test_c10d_common.py::PythonProcessGroupExtensionTest::test_init_process_group_with_multiple_backends [2025-09-12 14:19:16.187] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:16.208] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:16.208] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:16.210] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.9087s] [ 48%]
../../../../test/distributed/test_c10d_common.py::PythonProcessGroupExtensionTest::test_is_backend_available [2025-09-12 14:19:19.025] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:19.034] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:19.034] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:19.035] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.9089s] [ 51%]
../../../../test/distributed/test_c10d_common.py::PythonProcessGroupExtensionTest::test_send_recv [2025-09-12 14:19:22.002] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:22.020] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:22.036] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:22.043] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [3.3096s] [ 55%]
../../../../test/distributed/test_c10d_common.py::PythonProcessGroupExtensionTest::test_shutdown [2025-09-12 14:19:25.239] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:25.250] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:25.252] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:25.258] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [3.4094s] [ 59%]
../../../../test/distributed/test_c10d_common.py::ProcessGroupWithDispatchedCollectivesTests::test_default_process_group [2025-09-12 14:19:28.627] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [4.0079s] [ 62%]
../../../../test/distributed/test_c10d_common.py::ProcessGroupWithDispatchedCollectivesTests::test_init_process_group_for_all_backends [2025-09-12 14:19:32.731] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
PASSED [2.9062s] [ 66%]
../../../../test/distributed/test_c10d_common.py::ProcessGroupWithDispatchedCollectivesTests::test_init_process_group_optional_backend [2025-09-12 14:19:35.632] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.6058s] [ 70%]
../../../../test/distributed/test_c10d_common.py::ReduceOpTest::test_op_isinstance_of_reduceop PASSED [0.0009s] [ 74%]
../../../../test/distributed/test_c10d_common.py::ReduceOpTest::test_reduceop_copyable PASSED [0.0021s] [ 77%]
../../../../test/distributed/test_c10d_common.py::ReduceOpTest::test_reduceop_equal PASSED [0.0022s] [ 81%]
../../../../test/distributed/test_c10d_common.py::ReduceOpTest::test_reduceop_pickle PASSED [0.0026s] [ 85%]
../../../../test/distributed/test_c10d_common.py::LocalRankTest::testNodeLocalRank [2025-09-12 14:19:38.275] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:38.288] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:38.290] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:38.314] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [3.0092s] [ 88%]
../../../../test/distributed/test_c10d_common.py::LocalRankTest::testNodeLocalRankOverridesFallback [2025-09-12 14:19:41.199] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:41.205] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:41.219] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:41.234] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.8088s] [ 92%]
../../../../test/distributed/test_c10d_common.py::LocalRankTest::testWithoutEnv [2025-09-12 14:19:44.042] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:44.050] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:44.057] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:44.062] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.9077s] [ 96%]
../../../../test/distributed/test_c10d_common.py::LocalRankTest::testWithoutEnvWithFallback [2025-09-12 14:19:46.972] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:46.985] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:46.986] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:47.000] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.9081s] [100%]

=================================== FAILURES ===================================
_____________ PythonProcessGroupExtensionTest.test_backend_config ______________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_c10d_common.py", line 1802, in test_backend_config
    self.assertEqual(str(config), expected_value)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: String comparison failed: 'cpu:dummy,cuda:dummy' != 'cpu:dummy,cuda:dummy,xpu:dummy'
- cpu:dummy,cuda:dummy
+ cpu:dummy,cuda:dummy,xpu:dummy
?                     ++++++++++


To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_c10d_common.py PythonProcessGroupExtensionTest.test_backend_config

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_c10d_common.py", line 1802, in test_backend_config
    self.assertEqual(str(config), expected_value)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: String comparison failed: 'cpu:dummy,cuda:dummy' != 'cpu:dummy,cuda:dummy,xpu:dummy'
- cpu:dummy,cuda:dummy
+ cpu:dummy,cuda:dummy,xpu:dummy
?                     ++++++++++


To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_c10d_common.py PythonProcessGroupExtensionTest.test_backend_config

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 0 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 14:19:02.873000 1036321 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1037120
I0912 14:19:02.873000 1036321 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1037121
I0912 14:19:02.874000 1036321 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1037122
I0912 14:19:02.874000 1036321 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1037123
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_test_c10d_common.py.xml -
=========================== short test summary info ============================
FAILED [2.6092s] ../../../../test/distributed/test_c10d_common.py::PythonProcessGroupExtensionTest::test_backend_config - RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_c10d_common.py", line 1802, in test_backend_config
    self.assertEqual(str(config), expected_value)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: String comparison failed: 'cpu:dummy,cuda:dummy' != 'cpu:dummy,cuda:dummy,xpu:dummy'
- cpu:dummy,cuda:dummy
+ cpu:dummy,cuda:dummy,xpu:dummy
?                     ++++++++++


To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_c10d_common.py PythonProcessGroupExtensionTest.test_backend_config

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_c10d_common.py", line 1802, in test_backend_config
    self.assertEqual(str(config), expected_value)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: String comparison failed: 'cpu:dummy,cuda:dummy' != 'cpu:dummy,cuda:dummy,xpu:dummy'
- cpu:dummy,cuda:dummy
+ cpu:dummy,cuda:dummy,xpu:dummy
?                     ++++++++++


To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_c10d_common.py PythonProcessGroupExtensionTest.test_backend_config

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
=================== 1 failed, 26 passed in 87.69s (0:01:27) ====================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:19:51.258] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/test_c10d_logger.py::C10dErrorLoggerTest::test_exception_logger [2025-09-12 14:19:53.418] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:53.427] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:53.438] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:19:53.486] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:19:53:1040902 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:19:53:1040902 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:19:53:1040903 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:19:53:1040903 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:19:53:1040905 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:19:53:1040905 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:19:53:1040904 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:19:53:1040904 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6258s] [ 50%]
../../../../test/distributed/test_c10d_logger.py::C10dErrorLoggerTest::test_get_or_create_logger [2025-09-12 14:20:08.823] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:08.911] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:08.994] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:09.013] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.8086s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_test_c10d_logger.py.xml -
============================== 2 passed in 20.32s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:20:12.550] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 18 items
Running 18 items in this shard

../../../../test/distributed/test_c10d_object_collectives.py::TestObjectCollectivesCPU::test_all_gather_object_cpu [2025-09-12 14:20:14.699] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:14.714] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:14.721] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:14.726] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:20:15:1041563 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:15:1041563 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:15:1041564 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:15:1041564 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:15:1041562 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:15:1041562 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:15:1041561 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:15:1041561 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [4.3113s] [  5%]
../../../../test/distributed/test_c10d_object_collectives.py::TestObjectCollectivesCPU::test_broadcast_object_list_cpu [2025-09-12 14:20:18.987] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:19.064] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:19.095] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:19.095] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:20:19:1041861 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:19:1041861 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:19:1041864 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:19:1041864 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:19:1041862 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:19:1041862 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:19:1041863 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:19:1041863 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [4.1096s] [ 11%]
../../../../test/distributed/test_c10d_object_collectives.py::TestObjectCollectivesCPU::test_gather_object_cpu [2025-09-12 14:20:23.153] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:23.154] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:23.154] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:23.166] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:20:23:1042161 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:23:1042161 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:23:1042164 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:23:1042164 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:23:1042163 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:23:1042163 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:23:1042162 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:23:1042162 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [4.2106s] [ 16%]
../../../../test/distributed/test_c10d_object_collectives.py::TestObjectCollectivesCPU::test_scatter_object_list_cpu [2025-09-12 14:20:27.315] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:27.333] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:27.436] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:27.446] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:20:27:1042462 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:27:1042462 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:27:1042464 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:27:1042464 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:27:1042463 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:27:1042463 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:27:1042461 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:27:1042461 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [4.1094s] [ 22%]
../../../../test/distributed/test_c10d_object_collectives.py::TestObjectCollectivesCPU::test_send_recv_object_list_cpu [2025-09-12 14:20:31.432] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:31.446] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:31.474] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:31.478] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:20:31:1042764 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:31:1042764 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:31:1042763 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:31:1042763 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [3.8096s] [ 27%]
../../../../test/distributed/test_c10d_object_collectives.py::TestObjectCollectivesCPU::test_subpg_all_gather_object_cpu [2025-09-12 14:20:35.264] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:35.264] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:35.284] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:35.304] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:20:35:1043059 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:35:1043059 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:35:1043058 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:35:1043058 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:35:1043061 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:35:1043061 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:35:1043060 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:35:1043060 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [4.3099s] [ 33%]
../../../../test/distributed/test_c10d_object_collectives.py::TestObjectCollectivesCPU::test_subpg_broadcast_object_cpu [2025-09-12 14:20:39.543] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:39.555] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:39.557] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:39.598] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:20:39:1043365 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:39:1043365 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:40:1043367 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:40:1043367 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:40:1043366 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:40:1043366 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:40:1043364 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:40:1043364 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [4.0105s] [ 38%]
../../../../test/distributed/test_c10d_object_collectives.py::TestObjectCollectivesCPU::test_subpg_gather_object_cpu [2025-09-12 14:20:43.577] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:43.590] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:43.595] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:43.618] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:20:44:1043671 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:44:1043671 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:44:1043669 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:44:1043669 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:44:1043668 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:44:1043668 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:44:1043670 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:44:1043670 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [4.1126s] [ 44%]
../../../../test/distributed/test_c10d_object_collectives.py::TestObjectCollectivesCPU::test_subpg_scatter_object_cpu [2025-09-12 14:20:47.683] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:47.702] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:47.708] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:47.724] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:20:48:1043975 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:48:1043975 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:48:1043972 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:48:1043972 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:48:1043973 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:48:1043973 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:48:1043974 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:48:1043974 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [3.9111s] [ 50%]
../../../../test/distributed/test_c10d_object_collectives.py::TestObjectCollectivesXPU::test_all_gather_object_xpu [2025-09-12 14:20:51.613] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:51.615] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:51.621] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:51.630] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:20:52:1044276 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:52:1044276 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:52:1044278 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:52:1044278 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:52:1044279 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:52:1044279 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:52:1044277 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:52:1044277 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [4.3114s] [ 55%]
../../../../test/distributed/test_c10d_object_collectives.py::TestObjectCollectivesXPU::test_broadcast_object_list_xpu [2025-09-12 14:20:55.945] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:55.945] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:55.950] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:20:55.953] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:20:56:1044579 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:56:1044579 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:56:1044577 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:56:1044577 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:56:1044578 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:56:1044578 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:20:56:1044580 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:20:56:1044580 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [4.2110s] [ 61%]
../../../../test/distributed/test_c10d_object_collectives.py::TestObjectCollectivesXPU::test_gather_object_xpu [2025-09-12 14:21:00.139] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:00.145] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:00.158] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:00.166] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:21:00:1044877 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:00:1044877 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:00:1044879 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:00:1044879 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:00:1044878 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:00:1044878 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:00:1044880 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:00:1044880 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [4.2113s] [ 66%]
../../../../test/distributed/test_c10d_object_collectives.py::TestObjectCollectivesXPU::test_scatter_object_list_xpu [2025-09-12 14:21:04.330] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:04.346] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:04.353] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:04.374] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:21:04:1045178 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:04:1045178 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:04:1045180 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:04:1045180 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:04:1045177 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:04:1045177 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:04:1045179 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:04:1045179 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [4.0112s] [ 72%]
../../../../test/distributed/test_c10d_object_collectives.py::TestObjectCollectivesXPU::test_send_recv_object_list_xpu [2025-09-12 14:21:08.322] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:08.414] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:08.414] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:08.418] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:21:08:1045478 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:08:1045478 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:08:1045477 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:08:1045477 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [3.8105s] [ 77%]
../../../../test/distributed/test_c10d_object_collectives.py::TestObjectCollectivesXPU::test_subpg_all_gather_object_xpu [2025-09-12 14:21:12.146] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:12.214] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:12.214] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:12.234] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:21:12:1045775 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:12:1045775 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:12:1045772 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:12:1045773 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:12:1045772 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:12:1045773 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:12:1045774 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:12:1045774 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [4.2117s] [ 83%]
../../../../test/distributed/test_c10d_object_collectives.py::TestObjectCollectivesXPU::test_subpg_broadcast_object_xpu [2025-09-12 14:21:16.364] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:16.367] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:16.386] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:16.392] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:21:16:1046080 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:16:1046080 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:16:1046077 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:16:1046077 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:16:1046079 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:16:1046079 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:16:1046078 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:16:1046078 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [4.0113s] [ 88%]
../../../../test/distributed/test_c10d_object_collectives.py::TestObjectCollectivesXPU::test_subpg_gather_object_xpu [2025-09-12 14:21:20.378] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:20.431] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:20.431] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:20.451] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:21:20:1046382 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:20:1046382 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:20:1046385 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:20:1046385 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:20:1046383 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:20:1046383 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:20:1046384 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:20:1046384 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [4.0111s] [ 94%]
../../../../test/distributed/test_c10d_object_collectives.py::TestObjectCollectivesXPU::test_subpg_scatter_object_xpu [2025-09-12 14:21:24.412] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:24.413] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:24.414] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:24.440] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:21:24:1046687 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:24:1046687 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:24:1046686 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:24:1046686 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:24:1046689 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:24:1046689 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:24:1046688 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:24:1046688 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [4.0114s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_test_c10d_object_collectives.py.xml -
======================== 18 passed in 75.77s (0:01:15) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:21:29.262] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 8 items
Running 8 items in this shard

../../../../test/distributed/test_compute_comm_reordering.py::TestComputeCommReorderingMultiProc::test_grouped_scheduler_node [2025-09-12 14:21:40.454] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:21:40.466] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:21:54:1047452 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:54:1047452 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:21:54:1047453 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:21:54:1047453 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [29.1519s] [ 12%]
../../../../test/distributed/test_compute_comm_reordering.py::TestComputeCommReorderingMultiProc::test_inductor_default_comms_ordering [2025-09-12 14:22:09.530] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:22:09.558] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
FAILED [18.5325s] [ 25%]
../../../../test/distributed/test_compute_comm_reordering.py::TestComputeCommReorderingMultiProc::test_nccl_heuristics [2025-09-12 14:22:28.092] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:22:28.110] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [13.4237s] [ 37%]
../../../../test/distributed/test_compute_comm_reordering.py::TestComputeCommReorderingMultiProc::test_raise_comms [2025-09-12 14:22:41.482] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:22:41.495] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:22:55:1050641 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:22:55:1050641 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:22:55:1050642 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:22:55:1050642 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
final peak_memory=128
final peak_memory=128
PASSED [28.8473s] [ 50%]
../../../../test/distributed/test_compute_comm_reordering.py::TestComputeCommReorderingMultiProc::test_reorder_compute_for_overlap [2025-09-12 14:23:10.416] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:23:10.434] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:23:24:1051593 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:23:24:1051593 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:23:24:1051594 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:23:24:1051594 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
final peak_memory=192
final peak_memory=192
PASSED [29.6485s] [ 62%]
../../../../test/distributed/test_compute_comm_reordering.py::TestComputeCommReorderingMultiProc::test_reorder_compute_for_overlap_custom_runtime_estimation [2025-09-12 14:23:39.973] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:23:39.990] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:23:52:1052602 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:23:52:1052602 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:23:52:1052601 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:23:52:1052601 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
final peak_memory=192
final peak_memory=192
PASSED [28.1458s] [ 75%]
../../../../test/distributed/test_compute_comm_reordering.py::TestComputeCommReorderingMultiProc::test_sink_waits [2025-09-12 14:24:08.090] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:24:08.102] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:24:20:1053534 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:24:20:1053534 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:24:20:1053535 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:24:20:1053535 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
final peak_memory=128
final peak_memory=128
PASSED [27.2442s] [ 87%]
../../../../test/distributed/test_compute_comm_reordering.py::TestComputeCommReorderingMultiProc::test_sink_waits_raise_comms [2025-09-12 14:24:35.371] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:24:35.386] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:24:49:1054468 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:24:49:1054468 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:24:49:1054467 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:24:49:1054467 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
final peak_memory=128
final peak_memory=128
final peak_memory=128
final peak_memory=128
PASSED [28.8472s] [100%]

=================================== FAILURES ===================================
___ TestComputeCommReorderingMultiProc.test_inductor_default_comms_ordering ____
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_compute_comm_reordering.py", line 463, in test_inductor_default_comms_ordering
    fn(g1, g2, g3)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_compute_comm_reordering.py", line 442, in fn
    @torch.compile
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/torchinductor_jenkins/tmpoo9s8u0v/el/celr5t3wzpcllmzwmg6dwknn6g7blqnyqtj5s5k3imn5t2vvzigk.py", line 173, in call
    torch.ops._c10d_functional.all_reduce_.default(buf0, 'avg', '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_compute_comm_reordering.py TestComputeCommReorderingMultiProc.test_inductor_default_comms_ordering

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 0 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 14:22:07.695000 1046992 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1048427
I0912 14:22:07.696000 1046992 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1048428
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_test_compute_comm_reordering.py.xml -
=========================== short test summary info ============================
FAILED [18.5325s] ../../../../test/distributed/test_compute_comm_reordering.py::TestComputeCommReorderingMultiProc::test_inductor_default_comms_ordering - RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_compute_comm_reordering.py", line 463, in test_inductor_default_comms_ordering
    fn(g1, g2, g3)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_compute_comm_reordering.py", line 442, in fn
    @torch.compile
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/torchinductor_jenkins/tmpoo9s8u0v/el/celr5t3wzpcllmzwmg6dwknn6g7blqnyqtj5s5k3imn5t2vvzigk.py", line 173, in call
    torch.ops._c10d_functional.all_reduce_.default(buf0, 'avg', '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_compute_comm_reordering.py TestComputeCommReorderingMultiProc.test_inductor_default_comms_ordering

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
=================== 1 failed, 7 passed in 214.88s (0:03:34) ====================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:25:05.012] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 13 items
Running 13 items in this shard

../../../../test/distributed/test_control_collectives.py::TestCollectives::test_all_gather_timeout PASSED [0.1658s] [  7%]
../../../../test/distributed/test_control_collectives.py::TestCollectives::test_all_sum PASSED [0.0054s] [ 15%]
../../../../test/distributed/test_control_collectives.py::TestCollectives::test_all_sum_timeout PASSED [0.0051s] [ 23%]
../../../../test/distributed/test_control_collectives.py::TestCollectives::test_barrier PASSED [0.0015s] [ 30%]
../../../../test/distributed/test_control_collectives.py::TestCollectives::test_barrier_timeout PASSED [0.0044s] [ 38%]
../../../../test/distributed/test_control_collectives.py::TestCollectives::test_broadcast PASSED [0.0023s] [ 46%]
../../../../test/distributed/test_control_collectives.py::TestCollectives::test_broadcast_timeout PASSED [0.0018s] [ 53%]
../../../../test/distributed/test_control_collectives.py::TestCollectives::test_gather PASSED [0.0022s] [ 61%]
../../../../test/distributed/test_control_collectives.py::TestCollectives::test_gather_timeout PASSED [0.0039s] [ 69%]
../../../../test/distributed/test_control_collectives.py::TestCollectives::test_scatter PASSED [0.0025s] [ 76%]
../../../../test/distributed/test_control_collectives.py::TestCollectives::test_scatter_timeout PASSED [0.0017s] [ 84%]
../../../../test/distributed/test_control_collectives.py::TestCollectives::test_simple_user_func PASSED [0.0020s] [ 92%]
../../../../test/distributed/test_control_collectives.py::TestCollectives::test_unique PASSED [0.0009s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_test_control_collectives.py.xml -
============================== 13 passed in 2.19s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:25:08.550] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 56 items
Running 56 items in this shard

../../../../test/distributed/test_device_mesh.py::DeviceMeshTestGlooBackend::test_device_mesh_reuse_default_group [2025-09-12 14:25:10.742] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:10.745] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:10.751] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:10.755] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
FAILED [2.9032s] [  1%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshSetDeviceTest::test_auto_set_device_from_heuristic [2025-09-12 14:25:13.475] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:13.482] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:13.489] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:13.491] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
FAILED [2.7085s] [  3%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshSetDeviceTest::test_auto_set_device_from_local_rank [2025-09-12 14:25:16.186] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:16.190] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:16.206] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:16.206] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
FAILED [2.8093s] [  5%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshSetDeviceTest::test_manual_set_device [2025-09-12 14:25:18.974] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:19.014] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:19.037] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:19.054] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
FAILED [2.7119s] [  7%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTest::test_2d_mesh_eager_init_subgroup [2025-09-12 14:25:21.678] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:21.745] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:21.745] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:21.762] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:25:21:1056793 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:25:21:1056793 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:25:21:1056795 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:25:21:1056795 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:25:21:1056794 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:25:21:1056794 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:25:21:1056792 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:25:21:1056792 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6315s] [  8%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTest::test_2d_mesh_non_eager_init_subgroup [2025-09-12 14:25:37.326] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:37.330] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:37.330] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:37.358] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:25:37:1057103 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:25:37:1057103 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:25:37:1057101 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:25:37:1057101 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:25:37:1057100 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:25:37:1057100 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:25:37:1057102 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:25:37:1057102 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5291s] [ 10%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTest::test_assert_invalid_mesh_tensor [2025-09-12 14:25:52.843] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:52.848] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:52.849] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:25:52.861] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:25:53:1057410 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:25:53:1057410 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:25:53:1057409 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:25:53:1057409 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:25:53:1057412 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:25:53:1057412 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:25:53:1057411 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:25:53:1057411 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.4288s] [ 12%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTest::test_device_mesh_2d [2025-09-12 14:26:08.282] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:26:08.295] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:26:08.318] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:26:08.319] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:26:08:1057714 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:26:08:1057714 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:26:08:1057713 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:26:08:1057713 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:26:08:1057712 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:26:08:1057712 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:26:08:1057711 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:26:08:1057711 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7272s] [ 14%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTest::test_device_mesh_init_backend [2025-09-12 14:26:23.985] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:26:23.994] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:26:24.006] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:26:24.015] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:26:24:1058020 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:26:24:1058020 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:26:24:1058021 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:26:24:1058021 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:26:24:1058022 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:26:24:1058022 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:26:24:1058019 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:26:24:1058019 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6260s] [ 16%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTest::test_fake_pg_device_mesh [2025-09-12 14:26:39.601] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:26:39.614] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:26:39.618] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:26:39.626] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.8082s] [ 17%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTest::test_from_group_with_global_pg [2025-09-12 14:26:42.429] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:26:42.446] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:26:42.466] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:26:42.474] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:26:42:1058607 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:26:42:1058607 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:26:42:1058605 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:26:42:1058605 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:26:42:1058608 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:26:42:1058608 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:26:42:1058606 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:26:42:1058606 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.4283s] [ 19%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTest::test_from_group_with_invalid_mesh [2025-09-12 14:26:57.866] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:26:57.877] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:26:57.886] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:26:57.898] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:26:58:1058906 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:26:58:1058906 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:26:58:1058908 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:26:58:1058908 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:26:58:1058909 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:26:58:1058909 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:26:58:1058907 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:26:58:1058907 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.4261s] [ 21%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTest::test_get_group_and_get_all_groups [2025-09-12 14:27:13.276] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:27:13.286] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:27:13.318] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:27:13.334] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:27:13:1059214 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:27:13:1059214 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:27:13:1059217 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:27:13:1059217 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:27:13:1059216 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:27:13:1059216 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:27:13:1059215 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:27:13:1059215 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6291s] [ 23%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTest::test_get_local_rank [2025-09-12 14:27:28.895] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:27:28.920] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:27:28.951] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:27:28.962] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:27:29:1059523 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:27:29:1059523 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:27:29:1059525 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:27:29:1059525 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:27:29:1059524 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:27:29:1059524 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:27:29:1059526 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:27:29:1059526 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5282s] [ 25%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTest::test_get_local_rank_raises_exception [2025-09-12 14:27:44.439] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:27:44.451] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:27:44.458] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:27:44.458] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:27:44:1059834 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:27:44:1059833 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:27:44:1059834 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:27:44:1059833 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:27:44:1059835 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:27:44:1059835 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:27:44:1059832 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:27:44:1059832 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6296s] [ 26%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTest::test_init_process_group [2025-09-12 14:28:00.076] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:28:00.098] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:28:00.110] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:28:00.123] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:28:00:1060144 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:28:00:1060144 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:28:00:1060145 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:28:00:1060145 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:28:01:1060143 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:28:01:1060143 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:28:01:1060142 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:28:01:1060142 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.1300s] [ 28%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTest::test_raises_invalid_device_type [2025-09-12 14:28:16.198] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:28:16.218] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:28:16.220] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:28:16.242] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.8083s] [ 30%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTest::test_set_mesh_dim_group_options [2025-09-12 14:28:19.092] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:28:19.114] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:28:19.124] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:28:19.146] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:28:19:1060738 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:28:19:1060738 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:28:19:1060735 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:28:19:1060735 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:28:19:1060736 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:28:19:1060736 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:28:19:1060737 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:28:19:1060737 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5281s] [ 32%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTestNDim::test_device_mesh_hash [2025-09-12 14:28:34.606] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:28:34.679] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:28:34.679] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:28:34.686] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:28:34:1061040 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:28:34:1061040 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:28:34:1061041 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:28:34:1061041 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:28:34:1061039 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:28:34:1061039 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:28:34:1061042 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:28:34:1061042 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7294s] [ 33%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTestNDim::test_device_mesh_nd [2025-09-12 14:28:50.318] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:28:50.326] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:28:50.331] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:28:50.334] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [2.7084s] [ 35%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTestNDim::test_device_mesh_parent_child_hash [2025-09-12 14:28:52.970] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:28:53.014] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:28:53.032] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:28:53.050] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:28:53:1061655 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:28:53:1061655 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:28:53:1061658 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:28:53:1061658 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:28:53:1061657 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:28:53:1061657 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:28:53:1061656 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:28:53:1061656 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.4287s] [ 37%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTestNDim::test_from_group_with_mesh_shape_2d [2025-09-12 14:29:08.390] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:08.470] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:08.574] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:29:08:1061974 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:29:08:1061974 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
[2025-09-12 14:29:08.603] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:29:08:1061975 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:29:08:1061975 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:29:08:1061973 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:29:08:1061973 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:29:08:1061976 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:29:08:1061976 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7214s] [ 39%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTestNDim::test_from_group_with_mesh_shape_3d [2025-09-12 14:29:24.146] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:24.154] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:24.158] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:24.190] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:29:24:1062291 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:29:24:1062291 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:29:24:1062289 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:29:24:1062289 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:29:24:1062292 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:29:24:1062292 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:29:24:1062290 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:29:24:1062290 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5290s] [ 41%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshTestNDim::test_get_local_rank_3d [2025-09-12 14:29:39.678] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:39.682] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:39.687] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:39.702] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [2.8074s] [ 42%]
../../../../test/distributed/test_device_mesh.py::InitDeviceMeshTest::test_backend_override_argument_dict_with_idx_and_backend_eager [2025-09-12 14:29:42.481] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:42.494] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:42.496] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:42.518] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
FAILED [2.6084s] [ 44%]
../../../../test/distributed/test_device_mesh.py::InitDeviceMeshTest::test_backend_override_argument_dict_with_idx_and_backend_lazy [2025-09-12 14:29:45.098] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:45.150] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:45.158] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:45.178] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
FAILED [2.6094s] [ 46%]
../../../../test/distributed/test_device_mesh.py::InitDeviceMeshTest::test_backend_override_argument_dict_with_name_and_options [2025-09-12 14:29:47.727] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:47.728] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:47.729] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:47.749] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
FAILED [2.6098s] [ 48%]
../../../../test/distributed/test_device_mesh.py::InitDeviceMeshTest::test_backend_override_argument_errors [2025-09-12 14:29:50.315] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:50.342] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:50.367] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:29:50.369] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:29:50:1063756 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:29:50:1063756 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:29:50:1063754 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:29:50:1063754 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:29:50:1063755 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:29:50:1063755 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:29:50:1063757 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:29:50:1063757 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5295s] [ 50%]
../../../../test/distributed/test_device_mesh.py::InitDeviceMeshTest::test_init_device_mesh [2025-09-12 14:30:05.851] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:30:05.861] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:30:05.861] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:30:05.864] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:30:06:1064059 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:30:06:1064058 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:30:06:1064059 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:30:06:1064058 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:30:06:1064056 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:30:06:1064056 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:30:06:1064057 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:30:06:1064057 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5295s] [ 51%]
../../../../test/distributed/test_device_mesh.py::InitDeviceMeshTest::test_raises_duplicate_mesh_dim_names [2025-09-12 14:30:21.401] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:30:21.405] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:30:21.406] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:30:21.415] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:30:21:1064372 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:30:21:1064372 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:30:21:1064375 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:30:21:1064375 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:30:21:1064374 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:30:21:1064374 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:30:21:1064373 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:30:21:1064373 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.4296s] [ 53%]
../../../../test/distributed/test_device_mesh.py::InitDeviceMeshTest::test_raises_mesh_shape_mesh_dim_names_mismatch [2025-09-12 14:30:36.810] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:30:36.810] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:30:36.838] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:30:36.846] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:30:37:1064676 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:30:37:1064676 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:30:37:1064675 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:30:37:1064675 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:30:37:1064673 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:30:37:1064673 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:30:37:1064674 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:30:37:1064674 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5295s] [ 55%]
../../../../test/distributed/test_device_mesh.py::TestDeviceMeshGetItem::test_cache_and_reuse_submesh_slice_result [2025-09-12 14:30:52.310] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:30:52.373] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:30:52.373] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:30:52.374] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:30:52:1064974 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:30:52:1064974 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:30:52:1064977 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:30:52:1064977 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:30:52:1064975 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:30:52:1064976 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:30:52:1064975 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:30:52:1064976 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5293s] [ 57%]
../../../../test/distributed/test_device_mesh.py::TestDeviceMeshGetItem::test_flatten_mesh_1d [2025-09-12 14:31:07.884] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:31:07.886] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:31:07.888] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:31:07.926] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:31:08:1065283 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:31:08:1065283 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:31:08:1065285 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:31:08:1065285 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:31:08:1065286 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:31:08:1065286 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:31:08:1065284 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:31:08:1065284 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6298s] [ 58%]
../../../../test/distributed/test_device_mesh.py::TestDeviceMeshGetItem::test_flatten_mesh_3d [2025-09-12 14:31:23.466] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:31:23.543] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:31:23.543] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:31:23.562] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:31:23:1065584 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:31:23:1065584 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:31:23:1065583 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:31:23:1065583 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:31:23:1065585 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:31:23:1065585 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:31:23:1065586 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:31:23:1065586 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6279s] [ 60%]
../../../../test/distributed/test_device_mesh.py::TestDeviceMeshGetItem::test_flatten_mesh_4d [2025-09-12 14:31:39.109] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:31:39.126] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:31:39.137] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:31:39.158] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [2.8079s] [ 62%]
../../../../test/distributed/test_device_mesh.py::TestDeviceMeshGetItem::test_get_item_1d [2025-09-12 14:31:41.918] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:31:41.938] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:31:41.954] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:31:41.970] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:31:42:1066195 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:31:42:1066195 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:31:42:1066196 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:31:42:1066196 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:31:42:1066194 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:31:42:1066194 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:31:42:1066193 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:31:42:1066193 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5292s] [ 64%]
../../../../test/distributed/test_device_mesh.py::TestDeviceMeshGetItem::test_get_item_2d [2025-09-12 14:31:57.470] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:31:57.474] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:31:57.498] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:31:57.498] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:31:57:1066495 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:31:57:1066495 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:31:57:1066496 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:31:57:1066496 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:31:57:1066494 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:31:57:1066494 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:31:57:1066497 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:31:57:1066497 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6295s] [ 66%]
../../../../test/distributed/test_device_mesh.py::TestDeviceMeshGetItem::test_get_item_3d [2025-09-12 14:32:13.081] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:32:13.094] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:32:13.098] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:32:13.115] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [2.9080s] [ 67%]
../../../../test/distributed/test_device_mesh.py::TestDeviceMeshGetItem::test_get_item_3d_noncontiguous_slicing [2025-09-12 14:32:15.988] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:32:16.006] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:32:16.014] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:32:16.038] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [2.9083s] [ 69%]
../../../../test/distributed/test_device_mesh.py::TestDeviceMeshGetItem::test_raises_invalid_mesh_dim_name [2025-09-12 14:32:18.895] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:32:18.910] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:32:18.924] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:32:18.946] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:32:19:1067379 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:32:19:1067379 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:32:19:1067381 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:32:19:1067381 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:32:19:1067378 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:32:19:1067378 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:32:19:1067380 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:32:19:1067380 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.3285s] [ 71%]
../../../../test/distributed/test_device_mesh.py::TestDeviceMeshGetItem::test_raises_no_mesh_dim_found [2025-09-12 14:32:34.226] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:32:34.266] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:32:34.282] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:32:34.298] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:32:34:1067690 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:32:34:1067690 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:32:34:1067691 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:32:34:1067691 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:32:34:1067689 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:32:34:1067689 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:32:34:1067692 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:32:34:1067692 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.4286s] [ 73%]
../../../../test/distributed/test_device_mesh.py::TestDeviceMeshGetItem::test_reconstruct_mesh_with_flatten_dim [2025-09-12 14:32:49.674] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:32:49.685] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:32:49.689] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:32:49.718] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [2.8082s] [ 75%]
../../../../test/distributed/test_device_mesh.py::TestMeshEnv::test_get_all_submeshes [2025-09-12 14:32:52.463] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:32:52.497] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:32:52.541] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:32:52.542] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:32:52:1068285 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:32:52:1068285 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:32:52:1068286 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:32:52:1068286 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:32:52:1068287 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:32:52:1068287 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:32:52:1068288 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:32:52:1068288 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5297s] [ 76%]
../../../../test/distributed/test_device_mesh.py::TestMeshEnv::test_get_mesh_dim_by_name [2025-09-12 14:33:07.982] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:33:08.058] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:33:08.078] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:33:08.082] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:33:08:1068597 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:33:08:1068597 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:33:08:1068596 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:33:08:1068596 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:33:08:1068598 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:33:08:1068598 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:33:08:1068599 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:33:08:1068599 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6295s] [ 78%]
../../../../test/distributed/test_device_mesh.py::TestMeshEnv::test_get_root_mesh [2025-09-12 14:33:23.637] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:33:23.646] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:33:23.653] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:33:23.674] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:33:23:1068906 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:33:23:1068906 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:33:23:1068904 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:33:23:1068904 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:33:23:1068905 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:33:23:1068905 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:33:23:1068907 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:33:23:1068907 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5297s] [ 80%]
../../../../test/distributed/test_device_mesh.py::TestMeshEnv::test_get_root_mesh_dim_exist [2025-09-12 14:33:39.175] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:33:39.176] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:33:39.176] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:33:39.176] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:33:39:1069218 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:33:39:1069218 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:33:39:1069216 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:33:39:1069216 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:33:39:1069217 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:33:39:1069217 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:33:39:1069219 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:33:39:1069219 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.4293s] [ 82%]
../../../../test/distributed/test_device_mesh.py::TestMeshEnv::test_get_root_mesh_dim_not_exist [2025-09-12 14:33:54.586] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:33:54.607] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:33:54.638] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:33:54.638] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:33:54:1069526 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:33:54:1069526 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:33:54:1069527 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:33:54:1069527 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:33:54:1069525 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:33:54:1069525 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:33:54:1069528 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:33:54:1069528 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6296s] [ 83%]
../../../../test/distributed/test_device_mesh.py::TestMeshEnv::test_mesh_slice_fake_tensor_mode [2025-09-12 14:34:10.216] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:34:10.238] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:34:10.251] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:34:10.271] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:34:10:1069826 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:34:10:1069826 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:34:10:1069828 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:34:10:1069828 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:34:10:1069827 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:34:10:1069827 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:34:10:1069825 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:34:10:1069825 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6293s] [ 85%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshCollectiveTest::test_all_gather_uneven [2025-09-12 14:34:25.851] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:34:25.866] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:34:25.877] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:34:25.877] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:34:26:1070135 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:34:26:1070135 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:34:26:1070136 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:34:26:1070136 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:34:26:1070134 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:34:26:1070134 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:34:26:1070133 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:34:26:1070133 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8298s] [ 87%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshCollectiveTest::test_broadcast_1d [2025-09-12 14:34:41.687] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:34:41.696] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:34:41.696] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:34:41.697] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:34:41:1070434 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:34:41:1070434 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:34:41:1070436 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:34:41:1070436 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:34:41:1070435 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:34:41:1070435 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:34:42:1070433 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:34:42:1070433 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5294s] [ 89%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshCollectiveTest::test_broadcast_nd [2025-09-12 14:34:57.306] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:34:57.310] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:34:57.318] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:34:57.326] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:34:57:1070735 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:34:57:1070735 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:34:57:1070738 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:34:57:1070738 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:34:57:1070736 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:34:57:1070736 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:34:57:1070737 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:34:57:1070737 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:34:58:1070735:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:34:58:1070736:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:34:58:1070737:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:34:58:1070738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:34:58:1070736:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:34:58:1070735:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:34:58:1070737:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:34:58:1070738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:34:59:1070735:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:34:59:1070736:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:34:59:1070738:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:34:59:1070737:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [16.5312s] [ 91%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshCollectiveTest::test_reduce_scatter_contiguous [2025-09-12 14:35:13.746] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:35:13.760] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:35:13.771] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:35:13.780] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:35:14:1071061 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:35:14:1071061 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:35:14:1071060 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:35:14:1071060 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:35:14:1071062 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:35:14:1071062 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:35:14:1071059 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:35:14:1071059 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [30.7545s] [ 92%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshCollectiveTest::test_reduce_scatter_uneven [2025-09-12 14:35:44.579] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:35:44.598] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:35:44.600] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:35:44.630] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:35:44:1071364 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:35:44:1071364 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:35:44:1071361 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:35:44:1071361 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:35:44:1071363 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:35:44:1071363 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:35:44:1071362 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:35:44:1071362 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [30.8547s] [ 94%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshCollectiveTest::test_scatter_1d [2025-09-12 14:36:15.366] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:36:15.381] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:36:15.392] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:36:15.402] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:36:15:1071663 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:36:15:1071663 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:36:15:1071665 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:36:15:1071665 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:36:15:1071662 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:36:15:1071662 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:36:15:1071664 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:36:15:1071664 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7299s] [ 96%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshCollectiveTest::test_scatter_nd [2025-09-12 14:36:31.086] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:36:31.150] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:36:31.195] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:36:31.195] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:36:31:1071966 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:36:31:1071966 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:36:31:1071965 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:36:31:1071965 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:36:31:1071967 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:36:31:1071967 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:36:31:1071964 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:36:31:1071964 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:36:32:1071964:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:36:32:1071965:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:36:32:1071966:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:36:32:1071967:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:36:32:1071964:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:36:32:1071965:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:36:32:1071967:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:36:32:1071966:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:36:32:1071964:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:36:32:1071966:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:36:32:1071965:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:36:32:1071967:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [16.5304s] [ 98%]
../../../../test/distributed/test_device_mesh.py::DeviceMeshCollectiveTest::test_scatter_uneven [2025-09-12 14:36:47.635] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:36:47.641] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:36:47.641] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:36:47.675] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:36:47:1072292 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:36:47:1072292 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:36:47:1072291 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:36:47:1072291 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:36:47:1072290 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:36:47:1072290 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:36:47:1072289 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:36:47:1072289 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6293s] [100%]

=================================== FAILURES ===================================
________ DeviceMeshTestGlooBackend.test_device_mesh_reuse_default_group ________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 507, in wrapper
    self.destroy_pg()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 437, in destroy_pg
    dist.barrier(device_ids=[device_id])
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4881, in barrier
    work = group.barrier(opts=opts)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py DeviceMeshTestGlooBackend.test_device_mesh_reuse_default_group

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 507, in wrapper
    self.destroy_pg()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 437, in destroy_pg
    dist.barrier(device_ids=[device_id])
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4881, in barrier
    work = group.barrier(opts=opts)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py DeviceMeshTestGlooBackend.test_device_mesh_reuse_default_group

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 0 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 14:25:08.877000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1055617
I0912 14:25:08.877000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1055618
I0912 14:25:08.878000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1055619
I0912 14:25:08.878000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1055620
_________ DeviceMeshSetDeviceTest.test_auto_set_device_from_heuristic __________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 125, in test_auto_set_device_from_heuristic
    self.assertEqual(torch.cuda.current_device(), self.rank)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 1069, in current_device
    _lazy_init()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py DeviceMeshSetDeviceTest.test_auto_set_device_from_heuristic

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 125, in test_auto_set_device_from_heuristic
    self.assertEqual(torch.cuda.current_device(), self.rank)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 1069, in current_device
    _lazy_init()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py DeviceMeshSetDeviceTest.test_auto_set_device_from_heuristic

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 125, in test_auto_set_device_from_heuristic
    self.assertEqual(torch.cuda.current_device(), self.rank)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 1069, in current_device
    _lazy_init()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py DeviceMeshSetDeviceTest.test_auto_set_device_from_heuristic

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 1 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 14:25:11.592000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1055914
I0912 14:25:11.593000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1055915
I0912 14:25:11.593000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1055916
I0912 14:25:11.594000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1055917
_________ DeviceMeshSetDeviceTest.test_auto_set_device_from_local_rank _________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 106, in test_auto_set_device_from_local_rank
    self.assertEqual(torch.cuda.current_device(), local_rank)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 1069, in current_device
    _lazy_init()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py DeviceMeshSetDeviceTest.test_auto_set_device_from_local_rank

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 106, in test_auto_set_device_from_local_rank
    self.assertEqual(torch.cuda.current_device(), local_rank)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 1069, in current_device
    _lazy_init()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py DeviceMeshSetDeviceTest.test_auto_set_device_from_local_rank

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 1 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 14:25:14.302000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1056211
I0912 14:25:14.302000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1056212
I0912 14:25:14.303000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1056213
I0912 14:25:14.303000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1056214
________________ DeviceMeshSetDeviceTest.test_manual_set_device ________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 78, in test_manual_set_device
    torch.cuda.set_device((self.rank + 2) % self.world_size)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 567, in set_device
    torch._C._cuda_setDevice(device)
AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py DeviceMeshSetDeviceTest.test_manual_set_device

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 3 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 14:25:17.112000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1056508
I0912 14:25:17.113000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1056509
I0912 14:25:17.114000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1056510
I0912 14:25:17.116000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1056511
_ InitDeviceMeshTest.test_backend_override_argument_dict_with_idx_and_backend_eager _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 505, in wrapper
    raise e
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 502, in wrapper
    func(self, *args, **kwargs)  # type: ignore[misc]
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 632, in test_backend_override_argument_dict_with_idx_and_backend_eager
    self._test_backend_override_argument_dict_with_idx_and_backend()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 593, in _test_backend_override_argument_dict_with_idx_and_backend
    mesh = init_device_mesh(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/device_mesh.py", line 1170, in init_device_mesh
    device_mesh = DeviceMesh(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/device_mesh.py", line 484, in __init__
    self._init_process_groups(backend_override)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/device_mesh.py", line 659, in _init_process_groups
    dim_group = new_group(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 95, in wrapper
    func_return = func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 5280, in new_group
    return _new_group_with_tag(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 5370, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 2132, in _new_process_group_helper
    if device_id and pg._get_backend(device_id).supports_splitting:
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py InitDeviceMeshTest.test_backend_override_argument_dict_with_idx_and_backend_eager

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 505, in wrapper
    raise e
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 502, in wrapper
    func(self, *args, **kwargs)  # type: ignore[misc]
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 632, in test_backend_override_argument_dict_with_idx_and_backend_eager
    self._test_backend_override_argument_dict_with_idx_and_backend()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 593, in _test_backend_override_argument_dict_with_idx_and_backend
    mesh = init_device_mesh(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/device_mesh.py", line 1170, in init_device_mesh
    device_mesh = DeviceMesh(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/device_mesh.py", line 484, in __init__
    self._init_process_groups(backend_override)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/device_mesh.py", line 659, in _init_process_groups
    dim_group = new_group(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 95, in wrapper
    func_return = func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 5280, in new_group
    return _new_group_with_tag(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 5370, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 2132, in _new_process_group_helper
    if device_id and pg._get_backend(device_id).supports_splitting:
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py InitDeviceMeshTest.test_backend_override_argument_dict_with_idx_and_backend_eager

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 1 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 14:29:40.631000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1062889
I0912 14:29:40.632000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1062890
I0912 14:29:40.632000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1062891
I0912 14:29:40.633000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1062892
_ InitDeviceMeshTest.test_backend_override_argument_dict_with_idx_and_backend_lazy _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 505, in wrapper
    raise e
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 502, in wrapper
    func(self, *args, **kwargs)  # type: ignore[misc]
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 628, in test_backend_override_argument_dict_with_idx_and_backend_lazy
    self._test_backend_override_argument_dict_with_idx_and_backend()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 612, in _test_backend_override_argument_dict_with_idx_and_backend
    self.assertIsNone(get_opts(mesh, 0))
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 603, in get_opts
    ._get_backend(torch.device(f"{self.device_type}:{self.rank}"))
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py InitDeviceMeshTest.test_backend_override_argument_dict_with_idx_and_backend_lazy

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 2 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 14:29:43.241000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1063177
I0912 14:29:43.241000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1063178
I0912 14:29:43.242000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1063179
I0912 14:29:43.243000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1063180
_ InitDeviceMeshTest.test_backend_override_argument_dict_with_name_and_options _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 505, in wrapper
    raise e
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 502, in wrapper
    func(self, *args, **kwargs)  # type: ignore[misc]
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 653, in test_backend_override_argument_dict_with_name_and_options
    self.assertIsNone(get_opts(mesh, 0))
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 649, in get_opts
    ._get_backend(torch.device(f"{self.device_type}:{self.rank}"))
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py InitDeviceMeshTest.test_backend_override_argument_dict_with_name_and_options

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 2 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 14:29:45.852000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1063469
I0912 14:29:45.852000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1063470
I0912 14:29:45.853000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1063471
I0912 14:29:45.854000 1055544 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1063472
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_test_device_mesh.py.xml -
=========================== short test summary info ============================
FAILED [2.9032s] ../../../../test/distributed/test_device_mesh.py::DeviceMeshTestGlooBackend::test_device_mesh_reuse_default_group - RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 507, in wrapper
    self.destroy_pg()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 437, in destroy_pg
    dist.barrier(device_ids=[device_id])
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4881, in barrier
    work = group.barrier(opts=opts)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py DeviceMeshTestGlooBackend.test_device_mesh_reuse_default_group

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 507, in wrapper
    self.destroy_pg()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 437, in destroy_pg
    dist.barrier(device_ids=[device_id])
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4881, in barrier
    work = group.barrier(opts=opts)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py DeviceMeshTestGlooBackend.test_device_mesh_reuse_default_group

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [2.7085s] ../../../../test/distributed/test_device_mesh.py::DeviceMeshSetDeviceTest::test_auto_set_device_from_heuristic - RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 125, in test_auto_set_device_from_heuristic
    self.assertEqual(torch.cuda.current_device(), self.rank)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 1069, in current_device
    _lazy_init()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py DeviceMeshSetDeviceTest.test_auto_set_device_from_heuristic

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 125, in test_auto_set_device_from_heuristic
    self.assertEqual(torch.cuda.current_device(), self.rank)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 1069, in current_device
    _lazy_init()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py DeviceMeshSetDeviceTest.test_auto_set_device_from_heuristic

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 125, in test_auto_set_device_from_heuristic
    self.assertEqual(torch.cuda.current_device(), self.rank)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 1069, in current_device
    _lazy_init()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py DeviceMeshSetDeviceTest.test_auto_set_device_from_heuristic

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [2.8093s] ../../../../test/distributed/test_device_mesh.py::DeviceMeshSetDeviceTest::test_auto_set_device_from_local_rank - RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 106, in test_auto_set_device_from_local_rank
    self.assertEqual(torch.cuda.current_device(), local_rank)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 1069, in current_device
    _lazy_init()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py DeviceMeshSetDeviceTest.test_auto_set_device_from_local_rank

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 106, in test_auto_set_device_from_local_rank
    self.assertEqual(torch.cuda.current_device(), local_rank)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 1069, in current_device
    _lazy_init()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py DeviceMeshSetDeviceTest.test_auto_set_device_from_local_rank

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [2.7119s] ../../../../test/distributed/test_device_mesh.py::DeviceMeshSetDeviceTest::test_manual_set_device - RuntimeError: Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 78, in test_manual_set_device
    torch.cuda.set_device((self.rank + 2) % self.world_size)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 567, in set_device
    torch._C._cuda_setDevice(device)
AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py DeviceMeshSetDeviceTest.test_manual_set_device

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [2.6084s] ../../../../test/distributed/test_device_mesh.py::InitDeviceMeshTest::test_backend_override_argument_dict_with_idx_and_backend_eager - RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 505, in wrapper
    raise e
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 502, in wrapper
    func(self, *args, **kwargs)  # type: ignore[misc]
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 632, in test_backend_override_argument_dict_with_idx_and_backend_eager
    self._test_backend_override_argument_dict_with_idx_and_backend()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 593, in _test_backend_override_argument_dict_with_idx_and_backend
    mesh = init_device_mesh(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/device_mesh.py", line 1170, in init_device_mesh
    device_mesh = DeviceMesh(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/device_mesh.py", line 484, in __init__
    self._init_process_groups(backend_override)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/device_mesh.py", line 659, in _init_process_groups
    dim_group = new_group(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 95, in wrapper
    func_return = func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 5280, in new_group
    return _new_group_with_tag(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 5370, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 2132, in _new_process_group_helper
    if device_id and pg._get_backend(device_id).supports_splitting:
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py InitDeviceMeshTest.test_backend_override_argument_dict_with_idx_and_backend_eager

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 505, in wrapper
    raise e
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 502, in wrapper
    func(self, *args, **kwargs)  # type: ignore[misc]
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 632, in test_backend_override_argument_dict_with_idx_and_backend_eager
    self._test_backend_override_argument_dict_with_idx_and_backend()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 593, in _test_backend_override_argument_dict_with_idx_and_backend
    mesh = init_device_mesh(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/device_mesh.py", line 1170, in init_device_mesh
    device_mesh = DeviceMesh(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/device_mesh.py", line 484, in __init__
    self._init_process_groups(backend_override)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/device_mesh.py", line 659, in _init_process_groups
    dim_group = new_group(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 95, in wrapper
    func_return = func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 5280, in new_group
    return _new_group_with_tag(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 5370, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 2132, in _new_process_group_helper
    if device_id and pg._get_backend(device_id).supports_splitting:
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py InitDeviceMeshTest.test_backend_override_argument_dict_with_idx_and_backend_eager

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [2.6094s] ../../../../test/distributed/test_device_mesh.py::InitDeviceMeshTest::test_backend_override_argument_dict_with_idx_and_backend_lazy - RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 505, in wrapper
    raise e
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 502, in wrapper
    func(self, *args, **kwargs)  # type: ignore[misc]
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 628, in test_backend_override_argument_dict_with_idx_and_backend_lazy
    self._test_backend_override_argument_dict_with_idx_and_backend()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 612, in _test_backend_override_argument_dict_with_idx_and_backend
    self.assertIsNone(get_opts(mesh, 0))
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 603, in get_opts
    ._get_backend(torch.device(f"{self.device_type}:{self.rank}"))
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py InitDeviceMeshTest.test_backend_override_argument_dict_with_idx_and_backend_lazy

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [2.6098s] ../../../../test/distributed/test_device_mesh.py::InitDeviceMeshTest::test_backend_override_argument_dict_with_name_and_options - RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 505, in wrapper
    raise e
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 502, in wrapper
    func(self, *args, **kwargs)  # type: ignore[misc]
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 653, in test_backend_override_argument_dict_with_name_and_options
    self.assertIsNone(get_opts(mesh, 0))
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_device_mesh.py", line 649, in get_opts
    ._get_backend(torch.device(f"{self.device_type}:{self.rank}"))
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_device_mesh.py InitDeviceMeshTest.test_backend_override_argument_dict_with_name_and_options

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
============= 7 failed, 43 passed, 6 skipped in 714.62s (0:11:54) ==============
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:37:04.134] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 60 items
Running 60 items in this shard

../../../../test/distributed/test_dynamo_distributed.py::TestFakeDistributedSingleProc::test_call_method_forward PASSED [5.7142s] [  1%]
../../../../test/distributed/test_dynamo_distributed.py::TestFakeDistributedSingleProc::test_ddp_optimizer_inductor_strides_dont_specialize PASSED [1.3116s] [  3%]
../../../../test/distributed/test_dynamo_distributed.py::TestFakeDistributedSingleProc::test_hf_bert_ddp_aot_eager FAILED [2.1697s] [  5%]
../../../../test/distributed/test_dynamo_distributed.py::TestFakeDistributedSingleProc::test_hf_bert_ddp_inductor FAILED [0.9090s] [  6%]
../../../../test/distributed/test_dynamo_distributed.py::TestFakeDistributedSingleProc::test_issue90375 PASSED [0.2919s] [  8%]
../../../../test/distributed/test_dynamo_distributed.py::TestFakeDistributedSingleProc::test_symbol_splitting PASSED [1.2444s] [ 10%]
../../../../test/distributed/test_dynamo_distributed.py::TestFakeDistributedSingleProc::test_unbacked_symbol_splitting_direct PASSED [1.0527s] [ 11%]
../../../../test/distributed/test_dynamo_distributed.py::TestFakeDistributedSingleProc::test_unbacked_symbol_splitting_indirect PASSED [1.5164s] [ 13%]
../../../../test/distributed/test_dynamo_distributed.py::TestFakeDistributedSingleProc::test_unbacked_symbol_splitting_no_binding PASSED [1.6254s] [ 15%]
../../../../test/distributed/test_dynamo_distributed.py::TestFakeDistributedSingleProc::test_unbacked_symbol_splitting_torture_multi PASSED [0.7418s] [ 16%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_asymmetric_compilation SKIPPED [0.0003s] [ 18%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_asymmetric_compilation_with_fx_cache SKIPPED [0.0002s] [ 20%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_compiler_collectives_automatic_dynamic_scalar SKIPPED [0.0002s] [ 21%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_compiler_collectives_automatic_dynamic_speculation_divergence SKIPPED [0.0002s] [ 23%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_compiler_collectives_automatic_dynamic_tensor SKIPPED [0.0002s] [ 25%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_compiler_collectives_dim_mismatch SKIPPED [0.0002s] [ 26%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_compiler_collectives_graph_break_empty_graph_still_collective SKIPPED [0.0001s] [ 28%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_compiler_collectives_missing_source SKIPPED [0.0001s] [ 30%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_compiler_collectives_scalar_missing_source SKIPPED [0.0003s] [ 31%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_compiler_collectives_type_mismatch SKIPPED [0.0001s] [ 33%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_ddp_activation_checkpointing SKIPPED [0.0001s] [ 35%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_ddp_baseline_aot_eager_multiprocess SKIPPED [0.0001s] [ 36%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_ddp_optimizer_cudagraph SKIPPED [0.0001s] [ 38%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_fsdp_activation_checkpointing SKIPPED [0.0001s] [ 40%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_fsdp_aot_eager SKIPPED [0.0001s] [ 41%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_fsdp_inductor SKIPPED [0.0001s] [ 43%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_fsdp_setattr SKIPPED [0.0001s] [ 45%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_fsdp_unspecialized_forced_getattr_inline SKIPPED [0.0001s] [ 46%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_fsdp_unspecialized_forced_getattr_no_inline SKIPPED [0.0001s] [ 48%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_get_pg_attr SKIPPED [0.0001s] [ 50%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_guard_collective SKIPPED [0.0001s] [ 51%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_hf_bert_ddp_aot_eager SKIPPED [0.0001s] [ 53%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_hf_bert_ddp_aot_eager_static_graph SKIPPED [0.0001s] [ 55%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_hf_bert_ddp_inductor SKIPPED [0.0001s] [ 56%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_hf_bert_ddp_inductor_static_graph SKIPPED [0.0001s] [ 58%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_hf_bert_fsdp SKIPPED [0.0001s] [ 60%]
../../../../test/distributed/test_dynamo_distributed.py::TestMultiProc::test_hf_bert_fsdp_activation_checkpointing SKIPPED [0.0001s] [ 61%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_aot_autograd SKIPPED [0.0001s] [ 63%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_async_subclass_no_specialize SKIPPED [0.0001s] [ 65%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_compiled_flex_attention_full_model_ddp SKIPPED [0.0001s] [ 66%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_compiled_flex_attention_local_ddp SKIPPED [0.0001s] [ 68%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_custom_layer SKIPPED [0.0001s] [ 70%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_ddp_baseline_aot_eager SKIPPED [0.0001s] [ 71%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_ddp_baseline_inductor SKIPPED [0.0001s] [ 73%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_empty_graph_inductor SKIPPED [0.0001s] [ 75%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_fsdp_dup_tensors_diff_source SKIPPED [0.0001s] [ 76%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_fsdp_dup_tensors_same_source SKIPPED [0.0001s] [ 78%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_fsdp_orig_params_assert SKIPPED [0.0001s] [ 80%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_fsdp_skip_guards SKIPPED [0.0001s] [ 81%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_fsdp_skip_register_attr_or_module SKIPPED [0.0001s] [ 83%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_fsdp_staticmethod SKIPPED [0.0001s] [ 85%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_graph_split SKIPPED [0.0001s] [ 86%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_graph_split_ctx_manager SKIPPED [0.0001s] [ 88%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_graph_split_inductor SKIPPED [0.0001s] [ 90%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_graph_split_inductor_layout_optimizations_inference SKIPPED [0.0001s] [ 91%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_graph_split_inductor_layout_optimizations_training SKIPPED [0.0001s] [ 93%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_graph_split_inductor_transpose SKIPPED [0.0001s] [ 95%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_higher_order_op SKIPPED [0.0001s] [ 96%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_ignored_parameters SKIPPED [0.0001s] [ 98%]
../../../../test/distributed/test_dynamo_distributed.py::TestSingleProc::test_no_split SKIPPED [0.0001s] [100%]

=================================== FAILURES ===================================
___________ TestFakeDistributedSingleProc.test_hf_bert_ddp_aot_eager ___________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/mock.py", line 1379, in patched
    return func(*newargs, **newkeywargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_dynamo_distributed.py", line 351, in test_hf_bert_ddp_aot_eager
    model, inputs = get_hf_bert(0)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_dynamo_distributed.py", line 274, in get_hf_bert
    model = AutoModelForMaskedLM.from_config(config).to(device)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4459, in to
    return super().to(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1371, in to
    return self._apply(convert)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/modules/module.py", line 930, in _apply
    module._apply(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/modules/module.py", line 930, in _apply
    module._apply(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/modules/module.py", line 930, in _apply
    module._apply(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/modules/module.py", line 957, in _apply
    param_applied = fn(param)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1357, in convert
    return t.to(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_dynamo_distributed.py TestFakeDistributedSingleProc.test_hf_bert_ddp_aot_eager

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
___________ TestFakeDistributedSingleProc.test_hf_bert_ddp_inductor ____________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/mock.py", line 1379, in patched
    return func(*newargs, **newkeywargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_dynamo_distributed.py", line 345, in test_hf_bert_ddp_inductor
    model, inputs = get_hf_bert(0)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_dynamo_distributed.py", line 274, in get_hf_bert
    model = AutoModelForMaskedLM.from_config(config).to(device)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4459, in to
    return super().to(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1371, in to
    return self._apply(convert)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/modules/module.py", line 930, in _apply
    module._apply(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/modules/module.py", line 930, in _apply
    module._apply(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/modules/module.py", line 930, in _apply
    module._apply(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/modules/module.py", line 957, in _apply
    param_applied = fn(param)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1357, in convert
    return t.to(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_dynamo_distributed.py TestFakeDistributedSingleProc.test_hf_bert_ddp_inductor

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_test_dynamo_distributed.py.xml -
=========================== short test summary info ============================
FAILED [2.1697s] ../../../../test/distributed/test_dynamo_distributed.py::TestFakeDistributedSingleProc::test_hf_bert_ddp_aot_eager - AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_dynamo_distributed.py TestFakeDistributedSingleProc.test_hf_bert_ddp_aot_eager

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.9090s] ../../../../test/distributed/test_dynamo_distributed.py::TestFakeDistributedSingleProc::test_hf_bert_ddp_inductor - AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_dynamo_distributed.py TestFakeDistributedSingleProc.test_hf_bert_ddp_inductor

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
=================== 2 failed, 8 passed, 50 skipped in 27.72s ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:37:33.951] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 13 items
Running 13 items in this shard

../../../../test/distributed/test_fake_pg.py::TestFakePG::test_all_reduce PASSED [0.2077s] [  7%]
../../../../test/distributed/test_fake_pg.py::TestFakePG::test_allgather PASSED [0.0010s] [ 15%]
../../../../test/distributed/test_fake_pg.py::TestFakePG::test_alltoall PASSED [0.0008s] [ 23%]
../../../../test/distributed/test_fake_pg.py::TestFakePG::test_alltoall_base PASSED [0.0007s] [ 30%]
../../../../test/distributed/test_fake_pg.py::TestFakePG::test_broadcast PASSED [0.0008s] [ 38%]
../../../../test/distributed/test_fake_pg.py::TestFakePG::test_construct_fsdp PASSED [0.0257s] [ 46%]
../../../../test/distributed/test_fake_pg.py::TestFakePG::test_fake_pg_tracing SKIPPED [0.0005s] [ 53%]
../../../../test/distributed/test_fake_pg.py::TestFakePG::test_fsdp_fake_e2e SKIPPED [0.0004s] [ 61%]
../../../../test/distributed/test_fake_pg.py::TestFakePG::test_fsdp_tp_fake_e2e SKIPPED [0.0004s] [ 69%]
../../../../test/distributed/test_fake_pg.py::TestFakePG::test_recv PASSED [0.0006s] [ 76%]
../../../../test/distributed/test_fake_pg.py::TestFakePG::test_reduce_scatter PASSED [0.0006s] [ 84%]
../../../../test/distributed/test_fake_pg.py::TestFakePG::test_scatter PASSED [0.0007s] [ 92%]
../../../../test/distributed/test_fake_pg.py::TestFakePG::test_send PASSED [0.0006s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_test_fake_pg.py.xml -
======================== 10 passed, 3 skipped in 2.23s =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:37:37.006] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 11 items
Running 11 items in this shard

../../../../test/distributed/test_functional_api.py::TestMetaCollectives::test_all_reduce PASSED [0.0017s] [  9%]
../../../../test/distributed/test_functional_api.py::TestMakeFx::test_all_reduce_tracing PASSED [0.0169s] [ 18%]
../../../../test/distributed/test_functional_api.py::TestCollectivesWithDistributedBackendXPU::test_all_gather_into_tensor_coalesced_xpu [2025-09-12 14:37:48.303] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:37:48.324] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:37:48.442] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:37:48.449] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:37:58:1073856 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:37:58:1073856 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:37:59:1073855 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:37:59:1073855 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:38:00:1073857 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:38:00:1073857 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:38:02:1073858 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:38:02:1073858 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [17.6327s] [ 27%]
../../../../test/distributed/test_functional_api.py::TestCollectivesWithDistributedBackendXPU::test_all_to_all_single_1d_input_xpu [2025-09-12 14:38:05.967] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:38:05.982] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:38:05.982] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:38:06.026] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:38:15:1075704 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:38:15:1075704 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:38:17:1075707 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:38:17:1075707 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:38:18:1075706 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:38:18:1075706 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:38:19:1075705 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:38:19:1075705 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [17.7324s] [ 36%]
../../../../test/distributed/test_functional_api.py::TestCollectivesWithDistributedBackendXPU::test_all_to_all_single_split_sizes_none_xpu [2025-09-12 14:38:23.708] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:38:23.708] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:38:23.726] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:38:23.730] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:38:33:1077550 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:38:33:1077550 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:38:34:1077552 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:38:34:1077552 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:38:36:1077551 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:38:36:1077551 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:38:37:1077549 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:38:37:1077549 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [17.7321s] [ 45%]
../../../../test/distributed/test_functional_api.py::TestCollectivesWithDistributedBackendXPU::test_all_to_all_single_xpu [2025-09-12 14:38:41.390] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:38:41.441] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:38:41.462] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:38:41.478] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:38:51:1079395 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:38:51:1079395 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:38:52:1079393 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:38:52:1079393 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:38:53:1079394 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:38:53:1079394 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:38:55:1079396 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:38:55:1079396 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [17.7309s] [ 54%]
../../../../test/distributed/test_functional_api.py::TestCollectivesWithDistributedBackendXPU::test_tracing_with_dce_code_xpu [2025-09-12 14:38:59.131] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:38:59.132] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:38:59.151] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:38:59.182] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [16.7306s] [ 63%]
../../../../test/distributed/test_functional_api.py::TestCollectivesWithDistributedBackendXPU::test_tracing_with_fakepg_xpu [2025-09-12 14:39:15.835] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:39:15.914] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:39:15.934] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:39:15.947] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
FAILED [12.8268s] [ 72%]
../../../../test/distributed/test_functional_api.py::TestCollectivesWithDistributedBackendXPU::test_tracing_xpu [2025-09-12 14:39:28.681] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:39:28.762] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:39:28.764] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:39:28.839] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:39:39:1084713 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:39:39:1084713 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:39:41:1084712 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:39:41:1084712 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:39:45:1084715 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:39:45:1084715 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:39:47:1084714 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:39:47:1084714 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [34.6614s] [ 81%]
../../../../test/distributed/test_functional_api.py::TestDistributedBackendCollectivesWithWorldSize4XPU::test_permute_tensor_with_sub_group_xpu [2025-09-12 14:40:03.347] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:40:03.386] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:40:03.387] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:40:03.400] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:40:12:1087175 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:40:12:1087175 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:40:14:1087174 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:40:14:1087174 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:40:15:1087173 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:40:15:1087173 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:40:17:1087172 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:40:17:1087172 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:40:18:1087173:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:40:18:1087172:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:40:18:1087175:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:40:18:1087174:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [18.1329s] [ 90%]
../../../../test/distributed/test_functional_api.py::TestFunctionalAutogradWithDistributedBackendXPU::test_all_to_all_single_xpu [2025-09-12 14:40:21.511] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:40:21.520] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:40:21.521] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:40:21.533] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:40:31:1089030 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:40:31:1089030 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:40:32:1089031 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:40:32:1089031 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:40:34:1089032 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:40:34:1089032 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:40:35:1089029 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:40:35:1089029 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [17.7330s] [100%]

=================================== FAILURES ===================================
____ TestCollectivesWithDistributedBackendXPU.test_tracing_with_fakepg_xpu _____
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 446, in instantiated_test
    raise rte
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_functional_api.py", line 599, in test_tracing_with_fakepg
    allreduce(torch.randn(8, device=device), pg=dist.group.WORLD)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_functional_api.py", line 591, in allreduce
    return ft_c.all_reduce(t, "sum", pg)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 170, in all_reduce
    tensor = torch.ops._c10d_functional.all_reduce(self, reduceOp.lower(), group_name)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_functional_api.py TestCollectivesWithDistributedBackendXPU.test_tracing_with_fakepg_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 0 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 14:39:14.034000 1073396 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1083075
I0912 14:39:14.034000 1073396 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1083076
I0912 14:39:14.035000 1073396 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1083077
I0912 14:39:14.035000 1073396 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1083078
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_test_functional_api.py.xml -
=========================== short test summary info ============================
FAILED [12.8268s] ../../../../test/distributed/test_functional_api.py::TestCollectivesWithDistributedBackendXPU::test_tracing_with_fakepg_xpu - RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 446, in instantiated_test
    raise rte
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_device_type.py", line 426, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_functional_api.py", line 599, in test_tracing_with_fakepg
    allreduce(torch.randn(8, device=device), pg=dist.group.WORLD)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_functional_api.py", line 591, in allreduce
    return ft_c.all_reduce(t, "sum", pg)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 170, in all_reduce
    tensor = torch.ops._c10d_functional.all_reduce(self, reduceOp.lower(), group_name)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/test_functional_api.py TestCollectivesWithDistributedBackendXPU.test_tracing_with_fakepg_xpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
=================== 1 failed, 10 passed in 182.14s (0:03:02) ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:40:40.511] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 62 items
Running 62 items in this shard

../../../../test/distributed/test_inductor_collectives.py::TestCollectivesMultiProc::test_all_to_all_recompute_is_always_banned_override_with_ac_False SKIPPED [0.0003s] [  1%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesMultiProc::test_all_to_all_recompute_is_always_banned_override_with_ac_True SKIPPED [0.0002s] [  3%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesMultiProc::test_all_to_all_single_inductor SKIPPED [0.0001s] [  4%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesMultiProc::test_all_to_all_single_inductor_split_sizes_none SKIPPED [0.0001s] [  6%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesMultiProc::test_allgather_contiguous_input SKIPPED [0.0001s] [  8%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesMultiProc::test_allgather_into_tensor_inductor SKIPPED [0.0001s] [  9%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesMultiProc::test_allgather_output_buffer_reuse SKIPPED [0.0001s] [ 11%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesMultiProc::test_allgather_scalar_tensor_input SKIPPED [0.0001s] [ 12%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesMultiProc::test_allreduce_inductor SKIPPED [0.0002s] [ 14%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesMultiProc::test_allreduce_inductor_cudagraph_trees SKIPPED [0.0001s] [ 16%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesMultiProc::test_allreduce_input_buffer_reuse SKIPPED [0.0001s] [ 17%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesMultiProc::test_broadcast_inductor SKIPPED [0.0001s] [ 19%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesMultiProc::test_c10d_functional_tagged_pt2_compliant SKIPPED [0.0001s] [ 20%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesMultiProc::test_eager_allreduce_inductor_wait SKIPPED [0.0001s] [ 22%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesMultiProc::test_eager_async_allreduce_inductor_wait SKIPPED [0.0001s] [ 24%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesMultiProc::test_inductor_allreduce_eager_wait SKIPPED [0.0001s] [ 25%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesMultiProc::test_permute_tensor SKIPPED [0.0001s] [ 27%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesMultiProc::test_reduce_scatter_tensor_inductor SKIPPED [0.0001s] [ 29%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_all_gather_bucket_bucket_mode_all SKIPPED [0.0001s] [ 30%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_all_gather_bucket_bucket_mode_all_custom_ops SKIPPED [0.0001s] [ 32%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_all_gather_bucket_path SKIPPED [0.0001s] [ 33%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_backwards SKIPPED [0.0001s] [ 35%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_get_world_group_source_GroupMember_WORLD SKIPPED [0.0001s] [ 37%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_get_world_group_source__get_default_group SKIPPED [0.0001s] [ 38%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_get_world_group_source_group_WORLD SKIPPED [0.0001s] [ 40%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_graphbreaks_unsupported_async_op SKIPPED [0.0001s] [ 41%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_pg_var SKIPPED [0.0001s] [ 43%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_rewrite_dist_all_gather SKIPPED [0.0001s] [ 45%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_rewrite_dist_all_gather_args_match SKIPPED [0.0008s] [ 46%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_rewrite_dist_all_gather_list SKIPPED [0.0001s] [ 48%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_rewrite_dist_all_to_all_single SKIPPED [0.0001s] [ 50%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_rewrite_dist_allreduce_pg_mode_kwargs SKIPPED [0.0001s] [ 51%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_rewrite_dist_allreduce_pg_mode_kwargs_none SKIPPED [0.0001s] [ 53%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_rewrite_dist_allreduce_pg_mode_positional SKIPPED [0.0001s] [ 54%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_rewrite_dist_allreduce_pg_mode_positional_none SKIPPED [0.0001s] [ 56%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_rewrite_dist_allreduce_pg_mode_unspecified SKIPPED [0.0001s] [ 58%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_rewrite_dist_allreduce_reduce_op_reduce_op0 SKIPPED [0.0001s] [ 59%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_rewrite_dist_allreduce_reduce_op_reduce_op1 SKIPPED [0.0001s] [ 61%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_rewrite_dist_allreduce_reduce_op_reduce_op2 SKIPPED [0.0001s] [ 62%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_rewrite_dist_allreduce_reduce_op_reduce_op3 SKIPPED [0.0001s] [ 64%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_rewrite_dist_allreduce_reduce_op_reduce_op4 SKIPPED [0.0001s] [ 66%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_rewrite_dist_reduce_scatter SKIPPED [0.0001s] [ 67%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_support_collective_op_with_async_op_False SKIPPED [0.0001s] [ 69%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_trace_all_gather_tensor SKIPPED [0.0001s] [ 70%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_trace_all_gather_tensor_pg SKIPPED [0.0001s] [ 72%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_trace_allgather_coalesced SKIPPED [0.0001s] [ 74%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_trace_allreduce SKIPPED [0.0001s] [ 75%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_dynamo_trace_reduce_scatter_tensor SKIPPED [0.0001s] [ 77%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_inductor_all_gather_coalesced SKIPPED [0.0001s] [ 79%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_inductor_doesnt_mutate_shared SKIPPED [0.0001s] [ 80%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_inductor_doesnt_mutate_shared_graph_partition SKIPPED [0.0001s] [ 82%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_inductor_reduce_scatter_coalesced SKIPPED [0.0001s] [ 83%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_inductor_single_op SKIPPED [0.0001s] [ 85%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_inductor_steal_buffer SKIPPED [0.0001s] [ 87%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_meta SKIPPED [0.0001s] [ 88%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_reduce_scatter_bucket_bucket_mode_all SKIPPED [0.0001s] [ 90%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_reduce_scatter_bucket_bucket_mode_all_custom_ops SKIPPED [0.0001s] [ 91%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_reorder_peak_memory SKIPPED [0.0001s] [ 93%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_reorder_peak_memory_bucketed_bucket_mode_all SKIPPED [0.0001s] [ 95%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_reorder_peak_memory_bucketed_bucket_mode_all_custom_ops SKIPPED [0.0003s] [ 96%]
../../../../test/distributed/test_inductor_collectives.py::TestCollectivesInductor::test_reorder_respects_wait_dep SKIPPED [0.0001s] [ 98%]
../../../../test/distributed/test_inductor_collectives.py::TestSyncDecisionCrossRanks::test_sync_decision_cross_ranks SKIPPED [0.0001s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_test_inductor_collectives.py.xml -
============================= 62 skipped in 11.30s =============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:40:53.130] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 22 items
Running 22 items in this shard

../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithWrapper::test_all_to_all_single_list PASSED [0.2095s] [  4%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithWrapper::test_all_to_all_single_none PASSED [0.0037s] [  9%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithWrapper::test_all_to_all_single_tensor PASSED [0.0045s] [ 13%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithWrapper::test_broadcast_object_list PASSED [0.0043s] [ 18%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithWrapper::test_collective_error_on_rank_non_zero PASSED [0.0029s] [ 22%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithWrapper::test_collective_error_on_rank_non_zero_all PASSED [0.0025s] [ 27%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithWrapper::test_collective_error_on_rank_zero PASSED [0.0035s] [ 31%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithWrapper::test_skip PASSED [0.0022s] [ 36%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithBaseClass::test_all_reduce PASSED [0.0036s] [ 40%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithBaseClass::test_all_reduce_coalesced PASSED [0.0040s] [ 45%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithBaseClass::test_all_reduce_ops PASSED [0.0059s] [ 50%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithBaseClass::test_all_to_all PASSED [0.0042s] [ 54%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithBaseClass::test_allgather PASSED [0.0046s] [ 59%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithBaseClass::test_assert_equal_on_rank PASSED [0.0031s] [ 63%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithBaseClass::test_broadcast PASSED [0.0053s] [ 68%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithBaseClass::test_broadcast_object_list PASSED [0.0041s] [ 72%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithBaseClass::test_bwd_sees_fwd_pg SKIPPED [0.0028s]on) [ 77%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithBaseClass::test_gather PASSED [0.0030s] [ 81%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithBaseClass::test_reduce_scatter PASSED [0.0043s] [ 86%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithBaseClass::test_scatter PASSED [0.0031s] [ 90%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithBaseClass::test_subpg PASSED [0.0039s] [ 95%]
../../../../test/distributed/test_multi_threaded_pg.py::TestCollectivesWithBaseClass::test_using_pg_from_another_thread PASSED [0.0035s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_test_multi_threaded_pg.py.xml -
======================== 21 passed, 1 skipped in 2.27s =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:40:56.238] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 120 items
Running 120 items in this shard

../../../../test/distributed/test_store.py::FileStoreTest::test_append PASSED [0.1840s] [  0%]
../../../../test/distributed/test_store.py::FileStoreTest::test_clone PASSED [0.0010s] [  1%]
../../../../test/distributed/test_store.py::FileStoreTest::test_compare_set PASSED [0.0018s] [  2%]
../../../../test/distributed/test_store.py::FileStoreTest::test_init_pg_and_rpc_with_same_file [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
PASSED [0.0848s] [  3%]
../../../../test/distributed/test_store.py::FileStoreTest::test_multi_get PASSED [0.0008s] [  4%]
../../../../test/distributed/test_store.py::FileStoreTest::test_multi_set PASSED [0.0007s] [  5%]
../../../../test/distributed/test_store.py::FileStoreTest::test_queues SKIPPED [0.0010s] [  5%]
../../../../test/distributed/test_store.py::FileStoreTest::test_queues_bidirectional SKIPPED [0.0008s] [  6%]
../../../../test/distributed/test_store.py::FileStoreTest::test_queues_nonblocking SKIPPED [0.0008s] [  7%]
../../../../test/distributed/test_store.py::FileStoreTest::test_queues_timeout SKIPPED [0.0010s] [  8%]
../../../../test/distributed/test_store.py::FileStoreTest::test_refcount PASSED [0.0008s] [  9%]
../../../../test/distributed/test_store.py::FileStoreTest::test_set_get_check PASSED [0.0015s] [ 10%]
../../../../test/distributed/test_store.py::FileStoreTest::test_simple_wait PASSED [1.0064s] [ 10%]
../../../../test/distributed/test_store.py::HashStoreTest::test_append PASSED [0.0008s] [ 11%]
../../../../test/distributed/test_store.py::HashStoreTest::test_clone PASSED [0.0006s] [ 12%]
../../../../test/distributed/test_store.py::HashStoreTest::test_compare_set PASSED [0.0016s] [ 13%]
../../../../test/distributed/test_store.py::HashStoreTest::test_multi_get PASSED [0.0006s] [ 14%]
../../../../test/distributed/test_store.py::HashStoreTest::test_multi_set PASSED [0.0006s] [ 15%]
../../../../test/distributed/test_store.py::HashStoreTest::test_queues PASSED [0.0006s] [ 15%]
../../../../test/distributed/test_store.py::HashStoreTest::test_queues_bidirectional PASSED [0.0013s] [ 16%]
../../../../test/distributed/test_store.py::HashStoreTest::test_queues_nonblocking PASSED [0.0007s] [ 17%]
../../../../test/distributed/test_store.py::HashStoreTest::test_queues_timeout PASSED [0.0106s] [ 18%]
../../../../test/distributed/test_store.py::HashStoreTest::test_set_get_check PASSED [0.0009s] [ 19%]
../../../../test/distributed/test_store.py::HashStoreTest::test_simple_wait PASSED [0.2507s] [ 20%]
../../../../test/distributed/test_store.py::PrefixStoreTest::test_get_underlying_store PASSED [0.0016s] [ 20%]
../../../../test/distributed/test_store.py::PrefixFileStoreTest::test_append PASSED [0.0007s] [ 21%]
../../../../test/distributed/test_store.py::PrefixFileStoreTest::test_clone PASSED [0.0007s] [ 22%]
../../../../test/distributed/test_store.py::PrefixFileStoreTest::test_compare_set PASSED [0.0017s] [ 23%]
../../../../test/distributed/test_store.py::PrefixFileStoreTest::test_multi_get PASSED [0.0006s] [ 24%]
../../../../test/distributed/test_store.py::PrefixFileStoreTest::test_multi_set PASSED [0.0005s] [ 25%]
../../../../test/distributed/test_store.py::PrefixFileStoreTest::test_queues SKIPPED [0.0006s] [ 25%]
../../../../test/distributed/test_store.py::PrefixFileStoreTest::test_queues_bidirectional SKIPPED [0.0006s] [ 26%]
../../../../test/distributed/test_store.py::PrefixFileStoreTest::test_queues_nonblocking SKIPPED [0.0006s] [ 27%]
../../../../test/distributed/test_store.py::PrefixFileStoreTest::test_queues_timeout SKIPPED [0.0006s] [ 28%]
../../../../test/distributed/test_store.py::PrefixFileStoreTest::test_set_get_check PASSED [0.0012s] [ 29%]
../../../../test/distributed/test_store.py::PrefixFileStoreTest::test_simple_wait PASSED [1.0062s] [ 30%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_address_already_in_use PASSED [0.0014s] [ 30%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_agent_store PASSED [0.0017s] [ 31%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_append PASSED [0.0015s] [ 32%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_clone PASSED [0.0014s] [ 33%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_compare_set PASSED [0.0024s] [ 34%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_init_pg_and_rpc_with_same_socket [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
PASSED [0.0213s] [ 35%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_multi_get PASSED [0.0015s] [ 35%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_multi_set PASSED [0.0015s] [ 36%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_multi_worker_with_fixed_world_size PASSED [0.0043s] [ 37%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_multi_worker_with_nonfixed_world_size PASSED [0.0018s] [ 38%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_multitenancy PASSED [0.0015s] [ 39%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_numkeys_delkeys PASSED [2.0043s] [ 40%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_queues SKIPPED [0.0011s] [ 40%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_queues_bidirectional SKIPPED [0.0010s] [ 41%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_queues_nonblocking SKIPPED [0.0010s] [ 42%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_queues_timeout SKIPPED [0.0011s] [ 43%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_repr PASSED [0.0015s] [ 44%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_set_get_check PASSED [0.0020s] [ 45%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_simple_wait PASSED [0.2517s] [ 45%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_store_timeout_on_missing_clients PASSED [3.0096s] [ 46%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_take_over_listen_socket PASSED [0.0011s] [ 47%]
../../../../test/distributed/test_store.py::TCPStoreTest::test_world_size_0_raises PASSED [0.0006s] [ 48%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_address_already_in_use PASSED [0.0013s] [ 49%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_agent_store PASSED [0.0017s] [ 50%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_append PASSED [0.0022s] [ 50%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_clone PASSED [0.0014s] [ 51%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_compare_set PASSED [0.0025s] [ 52%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_init_pg_and_rpc_with_same_socket [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
PASSED [0.0215s] [ 53%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_multi_get PASSED [0.0019s] [ 54%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_multi_set PASSED [0.0016s] [ 55%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_multi_worker_with_fixed_world_size PASSED [0.0042s] [ 55%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_multi_worker_with_nonfixed_world_size PASSED [0.0018s] [ 56%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_multitenancy PASSED [0.0016s] [ 57%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_numkeys_delkeys PASSED [2.0045s] [ 58%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_queues PASSED [0.0017s] [ 59%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_queues_bidirectional PASSED [0.0023s] [ 60%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_queues_nonblocking PASSED [0.0012s] [ 60%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_queues_timeout PASSED [0.0114s] [ 61%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_repr PASSED [0.0013s] [ 62%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_set_get_check PASSED [0.0021s] [ 63%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_simple_wait PASSED [0.2520s] [ 64%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_store_timeout_on_missing_clients PASSED [3.0059s] [ 65%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_take_over_listen_socket PASSED [0.0013s] [ 65%]
../../../../test/distributed/test_store.py::LibUvTCPStoreTest::test_world_size_0_raises PASSED [0.0006s] [ 66%]
../../../../test/distributed/test_store.py::PrefixTCPStoreTest::test_append PASSED [0.0014s] [ 67%]
../../../../test/distributed/test_store.py::PrefixTCPStoreTest::test_clone PASSED [0.0013s] [ 68%]
../../../../test/distributed/test_store.py::PrefixTCPStoreTest::test_compare_set PASSED [0.0025s] [ 69%]
../../../../test/distributed/test_store.py::PrefixTCPStoreTest::test_multi_get PASSED [0.0013s] [ 70%]
../../../../test/distributed/test_store.py::PrefixTCPStoreTest::test_multi_set PASSED [0.0014s] [ 70%]
../../../../test/distributed/test_store.py::PrefixTCPStoreTest::test_queues PASSED [0.0015s] [ 71%]
../../../../test/distributed/test_store.py::PrefixTCPStoreTest::test_queues_bidirectional PASSED [0.0022s] [ 72%]
../../../../test/distributed/test_store.py::PrefixTCPStoreTest::test_queues_nonblocking PASSED [0.0013s] [ 73%]
../../../../test/distributed/test_store.py::PrefixTCPStoreTest::test_queues_timeout PASSED [0.0113s] [ 74%]
../../../../test/distributed/test_store.py::PrefixTCPStoreTest::test_set_get_check PASSED [0.0021s] [ 75%]
../../../../test/distributed/test_store.py::PrefixTCPStoreTest::test_simple_wait PASSED [0.2520s] [ 75%]
../../../../test/distributed/test_store.py::PrefixTCPStoreTest::test_underlying_non_prefix_store PASSED [0.0013s] [ 76%]
../../../../test/distributed/test_store.py::PythonStoreTest::test_set_get PASSED [0.0005s] [ 77%]
../../../../test/distributed/test_store.py::RendezvousTest::test_unknown_handler PASSED [0.0005s] [ 78%]
../../../../test/distributed/test_store.py::RendezvousTest::test_url_with_node_params PASSED [0.0005s] [ 79%]
../../../../test/distributed/test_store.py::RendezvousEnvTest::test_nominal PASSED [0.0014s] [ 80%]
../../../../test/distributed/test_store.py::RendezvousFileTest::test_common_errors PASSED [0.0007s] [ 80%]
../../../../test/distributed/test_store.py::RendezvousFileTest::test_nominal PASSED [0.0010s] [ 81%]
../../../../test/distributed/test_store.py::RendezvousTCPTest::test_common_errors PASSED [0.0006s] [ 82%]
../../../../test/distributed/test_store.py::RendezvousTCPTest::test_dns_timeout PASSED [2.2054s] [ 83%]
../../../../test/distributed/test_store.py::RendezvousTCPTest::test_nominal PASSED [0.0015s] [ 84%]
../../../../test/distributed/test_store.py::RendezvousTCPTest::test_tcp_store_timeout_doest_break_client PASSED [0.1020s] [ 85%]
../../../../test/distributed/test_store.py::RendezvousTCPTest::test_tcp_store_timeout_set PASSED [0.1020s] [ 85%]
../../../../test/distributed/test_store.py::RendezvousTCPTest::test_tcp_store_url_with_libuv PASSED [0.0011s] [ 86%]
../../../../test/distributed/test_store.py::TestPythonStore::test_append_roundtrip PASSED [0.0008s] [ 87%]
../../../../test/distributed/test_store.py::TestPythonStore::test_extended_methods_fallbacks PASSED [0.0008s] [ 88%]
../../../../test/distributed/test_store.py::TestPythonStore::test_has_extended_api_passthrough PASSED [0.0007s] [ 89%]
../../../../test/distributed/test_store.py::TestPythonStore::test_has_extended_api_roundtrip PASSED [0.0005s] [ 90%]
../../../../test/distributed/test_store.py::TestPythonStore::test_multi_get_roundtrip PASSED [0.0006s] [ 90%]
../../../../test/distributed/test_store.py::TestPythonStore::test_multi_set_roundtrip PASSED [0.0006s] [ 91%]
../../../../test/distributed/test_store.py::TestPythonStore::test_optional_methods_fail PASSED [0.0006s] [ 92%]
../../../../test/distributed/test_store.py::TestMultiThreadedWait::test_wait_file_store PASSED [0.0021s] [ 93%]
../../../../test/distributed/test_store.py::TestMultiThreadedWait::test_wait_hash_store PASSED [0.0019s] [ 94%]
../../../../test/distributed/test_store.py::TestMultiThreadedWait::test_wait_prefix_file_store PASSED [0.0014s] [ 95%]
../../../../test/distributed/test_store.py::TestMultiThreadedWait::test_wait_tcp_store PASSED [0.0024s] [ 95%]
../../../../test/distributed/test_store.py::TestMultiThreadedWait::test_wait_tcp_store_uv PASSED [0.0019s] [ 96%]
../../../../test/distributed/test_store.py::TimeoutTest::test_interrupt_doesnt_break_wait PASSED [5.0067s] [ 97%]
../../../../test/distributed/test_store.py::InitPgWithNonUvStore::test_with_env_var [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
PASSED [0.0115s] [ 98%]
../../../../test/distributed/test_store.py::InitPgWithNonUvStore::test_with_url_param [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
PASSED [0.0113s] [ 99%]
../../../../test/distributed/test_store.py::TestClientProtocol::test_client_connect PASSED [0.0013s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_test_store.py.xml -
======================= 108 passed, 12 skipped in 22.94s =======================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:41:20.157] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 10 items
Running 10 items in this shard

../../../../test/distributed/pipelining/test_backward.py::StageBackwardTestsCPU::test_stage_backward_cpu PASSED [0.0174s] [ 10%]
../../../../test/distributed/pipelining/test_backward.py::StageBackwardTestsCPU::test_stage_backward_input_cpu PASSED [0.0091s] [ 20%]
../../../../test/distributed/pipelining/test_backward.py::StageBackwardTestsCPU::test_stage_backward_weight_cpu PASSED [0.0112s] [ 30%]
../../../../test/distributed/pipelining/test_backward.py::StageBackwardTestsCPU::test_stage_backward_weight_grad_validation_cpu PASSED [0.0248s] [ 40%]
../../../../test/distributed/pipelining/test_backward.py::StageBackwardTestsCPU::test_stage_backward_weight_multiple_iters_cpu PASSED [0.0461s] [ 50%]
../../../../test/distributed/pipelining/test_backward.py::StageBackwardTestsXPU::test_stage_backward_input_xpu PASSED [0.3671s] [ 60%]
../../../../test/distributed/pipelining/test_backward.py::StageBackwardTestsXPU::test_stage_backward_weight_grad_validation_xpu PASSED [0.0116s] [ 70%]
../../../../test/distributed/pipelining/test_backward.py::StageBackwardTestsXPU::test_stage_backward_weight_multiple_iters_xpu SKIPPED [0.0006s] [ 80%]
../../../../test/distributed/pipelining/test_backward.py::StageBackwardTestsXPU::test_stage_backward_weight_xpu SKIPPED [0.0004s] [ 90%]
../../../../test/distributed/pipelining/test_backward.py::StageBackwardTestsXPU::test_stage_backward_xpu SKIPPED [0.0004s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_pipelining_test_backward.py.xml -
========================= 7 passed, 3 skipped in 2.59s =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:41:23.824] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 4 items
Running 4 items in this shard

../../../../test/distributed/pipelining/test_microbatch.py::MicrobatchTestsCPU::test_chunk_spec_cpu PASSED [8.9778s] [ 25%]
../../../../test/distributed/pipelining/test_microbatch.py::MicrobatchTestsCPU::test_split_and_merge_cpu PASSED [0.0077s] [ 50%]
../../../../test/distributed/pipelining/test_microbatch.py::MicrobatchTestsXPU::test_chunk_spec_xpu SKIPPED [0.0007s] [ 75%]
../../../../test/distributed/pipelining/test_microbatch.py::MicrobatchTestsXPU::test_split_and_merge_xpu PASSED [0.0067s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_pipelining_test_microbatch.py.xml -
======================== 3 passed, 1 skipped in 11.16s =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:41:35.884] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 3 items
Running 3 items in this shard

../../../../test/distributed/pipelining/test_pipe.py::PipeTests::test_model_split_ModelClass0 PASSED [8.9775s] [ 33%]
../../../../test/distributed/pipelining/test_pipe.py::PipeTests::test_model_split_ModelClass1 PASSED [0.1367s] [ 66%]
../../../../test/distributed/pipelining/test_pipe.py::PipeTests::test_model_split_ModelClass2 PASSED [0.0654s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_pipelining_test_pipe.py.xml -
============================== 3 passed in 11.07s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:41:48.037] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 33 items
Running 33 items in this shard

../../../../test/distributed/pipelining/test_schedule.py::ScheduleTest::test_get_schedule_class PASSED [0.1754s] [  3%]
../../../../test/distributed/pipelining/test_schedule.py::ScheduleTest::test_schedule_with_single_stage_ScheduleClass0 PASSED [0.0258s] [  6%]
../../../../test/distributed/pipelining/test_schedule.py::ScheduleTest::test_schedule_with_single_stage_ScheduleClass1 PASSED [0.0181s] [  9%]
../../../../test/distributed/pipelining/test_schedule.py::ScheduleTest::test_schedule_with_single_stage_ScheduleClass2 PASSED [0.0177s] [ 12%]
../../../../test/distributed/pipelining/test_schedule.py::ScheduleTest::test_schedule_with_single_stage_ScheduleClass3 PASSED [0.0170s] [ 15%]
../../../../test/distributed/pipelining/test_schedule.py::ScheduleTest::test_schedule_with_single_stage_ScheduleClass4 PASSED [0.0167s] [ 18%]
../../../../test/distributed/pipelining/test_schedule.py::ScheduleTest::test_zero_bubble_schedule_errors_with_compile PASSED [0.9423s] [ 21%]
../../../../test/distributed/pipelining/test_schedule.py::TestSchedulePlan::test_pipeline_order_ScheduleClass0 PASSED [7.9442s] [ 24%]
../../../../test/distributed/pipelining/test_schedule.py::TestSchedulePlan::test_pipeline_order_ScheduleClass1 PASSED [7.9830s] [ 27%]
../../../../test/distributed/pipelining/test_schedule.py::TestSchedulePlan::test_pipeline_order_flex_and_zero_bubble_ScheduleClass0 PASSED [8.0430s] [ 30%]
../../../../test/distributed/pipelining/test_schedule.py::TestSchedulePlan::test_pipeline_order_flex_and_zero_bubble_ScheduleClass1 PASSED [5.9051s] [ 33%]
../../../../test/distributed/pipelining/test_schedule.py::TestSchedulePlan::test_pipeline_order_for_v_schedules_ScheduleClass0 PASSED [0.0058s] [ 36%]
../../../../test/distributed/pipelining/test_schedule.py::TestSchedulePlan::test_pipeline_order_for_v_schedules_ScheduleClass1 PASSED [0.0027s] [ 39%]
../../../../test/distributed/pipelining/test_schedule.py::TestScheduleCsv::test_csv_compare_ScheduleClass0_csv_name_dualpipev_4rank_10mb PASSED [0.0186s] [ 42%]
../../../../test/distributed/pipelining/test_schedule.py::TestScheduleLowering::test_action_parse_action_str_and_ref0 PASSED [0.0008s] [ 45%]
../../../../test/distributed/pipelining/test_schedule.py::TestScheduleLowering::test_action_parse_action_str_and_ref1 PASSED [0.0006s] [ 48%]
../../../../test/distributed/pipelining/test_schedule.py::TestScheduleLowering::test_action_parse_action_str_and_ref2 PASSED [0.0006s] [ 51%]
../../../../test/distributed/pipelining/test_schedule.py::TestScheduleLowering::test_action_parse_action_str_and_ref3 PASSED [0.0006s] [ 54%]
../../../../test/distributed/pipelining/test_schedule.py::TestScheduleLowering::test_action_parse_action_str_and_ref4 PASSED [0.0006s] [ 57%]
../../../../test/distributed/pipelining/test_schedule.py::TestScheduleLowering::test_action_parse_action_str_and_ref5 PASSED [0.0006s] [ 60%]
../../../../test/distributed/pipelining/test_schedule.py::TestScheduleLowering::test_action_parse_action_str_and_ref6 PASSED [0.0006s] [ 63%]
../../../../test/distributed/pipelining/test_schedule.py::TestScheduleLowering::test_action_parse_action_str_and_ref7 PASSED [0.0006s] [ 66%]
../../../../test/distributed/pipelining/test_schedule.py::TestScheduleLowering::test_csv_csv_name_zb1p_2rank_2stagep PASSED [0.0141s] [ 69%]
../../../../test/distributed/pipelining/test_schedule.py::TestScheduleLowering::test_grad_with_split_b_w PASSED [0.7187s] [ 72%]
../../../../test/distributed/pipelining/test_schedule.py::TestScheduleLowering::test_grad_with_v_schedule FAILED [0.1270s] [ 75%]
../../../../test/distributed/pipelining/test_schedule.py::TestScheduleLowering::test_merge_bw_test_info0 PASSED [0.0014s] [ 78%]
../../../../test/distributed/pipelining/test_schedule.py::TestScheduleLowering::test_send_recv_test_info0 PASSED [0.0023s] [ 81%]
../../../../test/distributed/pipelining/test_schedule.py::TestScheduleLowering::test_send_recv_test_info1 PASSED [0.0074s] [ 84%]
../../../../test/distributed/pipelining/test_schedule.py::TestScheduleLowering::test_unshard_reshard_test_info0 PASSED [0.0008s] [ 87%]
../../../../test/distributed/pipelining/test_schedule.py::TestValidateSchedule::test_invalid_schedule_missing_action PASSED [0.0004s] [ 90%]
../../../../test/distributed/pipelining/test_schedule.py::TestValidateSchedule::test_invalid_schedule_missing_rank PASSED [0.0003s] [ 93%]
../../../../test/distributed/pipelining/test_schedule.py::TestValidateSchedule::test_valid_schedule PASSED [0.0003s] [ 96%]
../../../../test/distributed/pipelining/test_schedule.py::ScheduleUtilTests::test_generate_stage_to_rank_mapping PASSED [0.0011s] [100%]

=================================== FAILURES ===================================
________________ TestScheduleLowering.test_grad_with_v_schedule ________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/pipelining/test_schedule.py", line 836, in test_grad_with_v_schedule
    out = schedule.step(x, target=target, losses=losses)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/pipelining/schedules.py", line 1554, in step
    self._step_microbatches(args_split, kwargs_split, targets_split, losses)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/pipelining/schedules.py", line 1868, in _step_microbatches
    self._initialize_stages(arg_mbs[0], kwarg_mbs[0])
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/pipelining/schedules.py", line 1461, in _initialize_stages
    _wait_batch_p2p(_batch_p2p(all_ops))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/pipelining/schedules.py", line 490, in _batch_p2p
    return dist.batch_isend_irecv(p2p_ops)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 2766, in batch_isend_irecv
    if type(group) == ProcessGroup and group._get_backend(device).supports_coalescing:
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/pipelining/test_schedule.py TestScheduleLowering.test_grad_with_v_schedule

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_pipelining_test_schedule.py.xml -
=========================== short test summary info ============================
FAILED [0.1270s] ../../../../test/distributed/pipelining/test_schedule.py::TestScheduleLowering::test_grad_with_v_schedule - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/pipelining/test_schedule.py TestScheduleLowering.test_grad_with_v_schedule

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
======================== 1 failed, 32 passed in 33.95s =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:42:23.375] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/pipelining/test_transformer.py::TransformerTestsCPU::test_ir_cpu PASSED [9.0044s] [ 50%]
../../../../test/distributed/pipelining/test_transformer.py::TransformerTestsXPU::test_ir_xpu PASSED [0.4050s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_pipelining_test_transformer.py.xml -
============================== 2 passed in 11.60s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:42:36.067] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/pipelining/test_unflatten.py::UnflattenTestsCPU::test_unflatten_cpu PASSED [9.0123s] [ 50%]
../../../../test/distributed/pipelining/test_unflatten.py::UnflattenTestsXPU::test_unflatten_xpu PASSED [0.3822s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_pipelining_test_unflatten.py.xml -
============================== 2 passed in 11.58s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:42:48.844] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 45 items
Running 45 items in this shard

../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_dtensor_seq_par_shard_dim_0 FAILED [0.0082s] [  2%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_dtensor_seq_par_shard_dim_1 FAILED [0.0032s] [  4%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_find_all_gather_patterns PASSED [0.0346s] [  6%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_find_reduce_scatter_patterns FAILED [0.0039s] [  8%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_2_gather_dim_0_return_A_False FAILED [3.9739s] [ 11%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_2_gather_dim_0_return_A_True FAILED [0.1095s] [ 13%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_2_gather_dim_1_return_A_False FAILED [3.0192s] [ 15%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_2_gather_dim_1_return_A_True FAILED [2.9589s] [ 17%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_2_gather_dim_2_return_A_False PASSED [0.0013s] [ 20%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_2_gather_dim_2_return_A_True PASSED [0.0010s] [ 22%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_3_gather_dim_0_return_A_False FAILED [0.1208s] [ 24%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_3_gather_dim_0_return_A_True FAILED [0.1149s] [ 26%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_3_gather_dim_1_return_A_False FAILED [3.0008s] [ 28%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_3_gather_dim_1_return_A_True FAILED [2.9682s] [ 31%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_3_gather_dim_2_return_A_False FAILED [2.9748s] [ 33%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_3_gather_dim_2_return_A_True FAILED [2.9599s] [ 35%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_0_return_A_False FAILED [0.0229s] [ 37%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_0_return_A_True FAILED [0.0078s] [ 40%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_1_return_A_False FAILED [2.9930s] [ 42%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_1_return_A_True FAILED [3.0069s] [ 44%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_2_return_A_False PASSED [0.0013s] [ 46%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_2_return_A_True PASSED [0.0011s] [ 48%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_0_return_A_False FAILED [0.0125s] [ 51%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_0_return_A_True FAILED [0.0087s] [ 53%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_1_return_A_False FAILED [0.0131s] [ 55%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_1_return_A_True FAILED [0.0113s] [ 57%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_2_return_A_False FAILED [3.2137s] [ 60%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_2_return_A_True FAILED [3.0198s] [ 62%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_matmul_reduce_scatter_A_dims_2_scatter_dim_0 FAILED [0.1213s] [ 64%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_matmul_reduce_scatter_A_dims_2_scatter_dim_1 FAILED [3.0391s] [ 66%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_matmul_reduce_scatter_A_dims_2_scatter_dim_2 PASSED [0.0016s] [ 68%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_matmul_reduce_scatter_A_dims_3_scatter_dim_0 FAILED [0.1211s] [ 71%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_matmul_reduce_scatter_A_dims_3_scatter_dim_1 FAILED [3.0675s] [ 73%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_matmul_reduce_scatter_A_dims_3_scatter_dim_2 FAILED [3.0910s] [ 75%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_scaled_matmul_reduce_scatter_A_dims_2_scatter_dim_0 FAILED [0.0088s] [ 77%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_scaled_matmul_reduce_scatter_A_dims_2_scatter_dim_1 FAILED [0.0092s] [ 80%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_scaled_matmul_reduce_scatter_A_dims_2_scatter_dim_2 PASSED [0.0011s] [ 82%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_scaled_matmul_reduce_scatter_A_dims_3_scatter_dim_0 FAILED [0.0082s] [ 84%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_scaled_matmul_reduce_scatter_A_dims_3_scatter_dim_1 FAILED [0.0097s] [ 86%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_scaled_matmul_reduce_scatter_A_dims_3_scatter_dim_2 FAILED [0.0098s] [ 88%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_scaled_matmul_reduce_scatter_rowwise_scales_reshape_mm_reshape_scatter_dim_0 FAILED [0.0118s] [ 91%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_scaled_matmul_reduce_scatter_rowwise_scales_reshape_mm_reshape_scatter_dim_1 FAILED [0.0105s] [ 93%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_scaled_matmul_reduce_scatter_rowwise_scales_reshape_mm_reshape_scatter_dim_2 FAILED [0.0104s] [ 95%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_get_unexposed_collectives FAILED [0.0189s] [ 97%]
../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTP4GPUTest::test_extra_collectives FAILED [2.9401s] [100%]

=================================== FAILURES ===================================
_____________ MicroPipelineTPTest.test_dtensor_seq_par_shard_dim_0 _____________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 483, in test_dtensor_seq_par
    model = parallelize_module(model, device_mesh, parallelize_plan)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/api.py", line 130, in parallelize_module
    parallelize_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/api.py", line 86, in parallelize_module
    return parallelize_plan._apply(module, device_mesh)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/style.py", line 158, in _apply
    return distribute_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 937, in distribute_module
    partition_fn(name, submod, device_mesh)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/style.py", line 124, in _partition_linear_fn
    distribute_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 771, in distribute_tensor
    local_tensor = placement._shard_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 183, in _shard_tensor
    mesh_scatter(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_collective_utils.py", line 108, in mesh_scatter
    fut = scatter(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4369, in scatter
    work = group.scatter(output_tensors, input_tensors, opts)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_dtensor_seq_par_shard_dim_0

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:42:58.112000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpjs8fagpc
_____________ MicroPipelineTPTest.test_dtensor_seq_par_shard_dim_1 _____________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 483, in test_dtensor_seq_par
    model = parallelize_module(model, device_mesh, parallelize_plan)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/api.py", line 130, in parallelize_module
    parallelize_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/api.py", line 86, in parallelize_module
    return parallelize_plan._apply(module, device_mesh)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/style.py", line 158, in _apply
    return distribute_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 937, in distribute_module
    partition_fn(name, submod, device_mesh)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/style.py", line 124, in _partition_linear_fn
    distribute_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 771, in distribute_tensor
    local_tensor = placement._shard_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 183, in _shard_tensor
    mesh_scatter(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_collective_utils.py", line 108, in mesh_scatter
    fut = scatter(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4369, in scatter
    work = group.scatter(output_tensors, input_tensors, opts)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_dtensor_seq_par_shard_dim_1

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:42:58.121000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpe8na6lgc
____________ MicroPipelineTPTest.test_find_reduce_scatter_patterns _____________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 149, in test_find_reduce_scatter_patterns
    gm = make_fx(func)(inp)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py", line 2429, in wrapped
    return make_fx_tracer.trace(f, *args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py", line 2356, in trace
    return self._trace_inner(f, *args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py", line 2318, in _trace_inner
    t = dispatch_trace(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py", line 1303, in dispatch_trace
    graph = tracer.trace(root, concrete_args)  # type: ignore[arg-type]
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py", line 868, in trace
    (self.create_arg(fn(*args)),),
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py", line 1361, in wrapped
    out = f(*tensors)  # type:ignore[call-arg]
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 143, in func
    a = reduce_scatter_tensor(inp, "sum", scatter_dim=0, group=group.group_name)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 278, in reduce_scatter_tensor
    tensor = torch.ops._c10d_functional.reduce_scatter_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py", line 1409, in __torch_function__
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/utils/_stats.py", line 28, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py", line 1534, in __torch_dispatch__
    return proxy_call(self, func, self.pre_dispatch, args, kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py", line 994, in proxy_call
    out = func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_find_reduce_scatter_patterns

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:42:58.161000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpxudhxu0x
_ MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_2_gather_dim_0_return_A_False _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 232, in test_fuse_all_gather_matmul
    code = run_and_get_triton_code(compiled, A_shard, B)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 212, in func
    def func(A_shard: torch.Tensor, B: torch.Tensor) -> torch.Tensor:
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmpyqkqnysb/eo/ceodyy46lsuwsabqjj3x7yjhg5pa3ix3tams2ycwrzou6udp4fzv.py", line 54, in call
    buf0 = torch.ops._c10d_functional.all_gather_into_tensor.default(arg0_1, 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_2_gather_dim_0_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:02.136000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpyqkqnysb
_ MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_2_gather_dim_0_return_A_True _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 232, in test_fuse_all_gather_matmul
    code = run_and_get_triton_code(compiled, A_shard, B)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 212, in func
    def func(A_shard: torch.Tensor, B: torch.Tensor) -> torch.Tensor:
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmpa0c0qb9y/zd/czd3s4ft2zvjzjycblnwtkchjd34j3ejkssntf6rqzqrgcyov3yi.py", line 54, in call
    buf0 = torch.ops._c10d_functional.all_gather_into_tensor.default(arg0_1, 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_2_gather_dim_0_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:02.248000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpa0c0qb9y
_ MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_2_gather_dim_1_return_A_False _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 232, in test_fuse_all_gather_matmul
    code = run_and_get_triton_code(compiled, A_shard, B)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 212, in func
    def func(A_shard: torch.Tensor, B: torch.Tensor) -> torch.Tensor:
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmpxosvfsqj/ux/cuxsgivuaj2u4piygq6bdq4dynwsd5kpi32ztyerntvexgoldrmm.py", line 109, in call
    buf0 = torch.ops._c10d_functional.all_gather_into_tensor.default(arg0_1, 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_2_gather_dim_1_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:05.268000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpxosvfsqj
_ MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_2_gather_dim_1_return_A_True _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 232, in test_fuse_all_gather_matmul
    code = run_and_get_triton_code(compiled, A_shard, B)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 212, in func
    def func(A_shard: torch.Tensor, B: torch.Tensor) -> torch.Tensor:
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmp3qmjl56s/t6/ct63ivkmniefjxkj3vvu6h6lwl3mjyj3iam4mqugdhp6ulwlswsf.py", line 109, in call
    buf0 = torch.ops._c10d_functional.all_gather_into_tensor.default(arg0_1, 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_2_gather_dim_1_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:08.228000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmp3qmjl56s
_ MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_3_gather_dim_0_return_A_False _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 232, in test_fuse_all_gather_matmul
    code = run_and_get_triton_code(compiled, A_shard, B)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 212, in func
    def func(A_shard: torch.Tensor, B: torch.Tensor) -> torch.Tensor:
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmpfk7yw1xn/wr/cwrdvqneemeq4r62wkucvjkbwrjram6ezu3o6kvciddzcv2j3tik.py", line 54, in call
    buf0 = torch.ops._c10d_functional.all_gather_into_tensor.default(arg0_1, 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_3_gather_dim_0_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:08.354000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpfk7yw1xn
_ MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_3_gather_dim_0_return_A_True _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 232, in test_fuse_all_gather_matmul
    code = run_and_get_triton_code(compiled, A_shard, B)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 212, in func
    def func(A_shard: torch.Tensor, B: torch.Tensor) -> torch.Tensor:
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmpd7owm3pw/zo/czoqrxaetqtyrtnbt2vpwxp2go6ydsabv5p4cphkez4ngsthzhy7.py", line 54, in call
    buf0 = torch.ops._c10d_functional.all_gather_into_tensor.default(arg0_1, 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_3_gather_dim_0_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:08.470000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpd7owm3pw
_ MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_3_gather_dim_1_return_A_False _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 232, in test_fuse_all_gather_matmul
    code = run_and_get_triton_code(compiled, A_shard, B)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 212, in func
    def func(A_shard: torch.Tensor, B: torch.Tensor) -> torch.Tensor:
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmpb4mw4r4c/sh/cshqjlmluzrdvg7t2rp5zmsiv2hoj5xigatstlcuy5tiujtnyhw5.py", line 110, in call
    buf0 = torch.ops._c10d_functional.all_gather_into_tensor.default(arg0_1, 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_3_gather_dim_1_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:11.472000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpb4mw4r4c
_ MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_3_gather_dim_1_return_A_True _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 232, in test_fuse_all_gather_matmul
    code = run_and_get_triton_code(compiled, A_shard, B)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 212, in func
    def func(A_shard: torch.Tensor, B: torch.Tensor) -> torch.Tensor:
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmpoai0dl40/yw/cywvdbbermrviasrgcpcz4e5rezzauo46cryhtmtao33dp7kcuw6.py", line 110, in call
    buf0 = torch.ops._c10d_functional.all_gather_into_tensor.default(arg0_1, 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_3_gather_dim_1_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:14.442000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpoai0dl40
_ MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_3_gather_dim_2_return_A_False _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 232, in test_fuse_all_gather_matmul
    code = run_and_get_triton_code(compiled, A_shard, B)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 212, in func
    def func(A_shard: torch.Tensor, B: torch.Tensor) -> torch.Tensor:
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmpbz9qnopp/br/cbraydm6c63qz5dkbu2k25hgoukxv35n2szr4npp6drookcsvbgh.py", line 109, in call
    buf0 = torch.ops._c10d_functional.all_gather_into_tensor.default(arg0_1, 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_3_gather_dim_2_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:17.418000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpbz9qnopp
_ MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_3_gather_dim_2_return_A_True _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 232, in test_fuse_all_gather_matmul
    code = run_and_get_triton_code(compiled, A_shard, B)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 212, in func
    def func(A_shard: torch.Tensor, B: torch.Tensor) -> torch.Tensor:
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmppm16e812/5v/c5vl62t3xhtx6vdqk2jbdtv3kz53aqibzqh4bti5jflpposnu6yd.py", line 109, in call
    buf0 = torch.ops._c10d_functional.all_gather_into_tensor.default(arg0_1, 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_3_gather_dim_2_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:20.379000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmppm16e812
_ MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_0_return_A_False _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1955, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 303, in test_fuse_all_gather_scaled_matmul
    self.assertIn("fused_all_gather_scaled_matmul", str(gm.graph))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 1112, in assertIn
    self.fail(self._formatMessage(msg, standardMsg))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: 'fused_all_gather_scaled_matmul' not found in 'graph():\n    %a_shard_1 : [num_users=1] = placeholder[target=A_shard_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %all_gather_into_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.all_gather_into_tensor.default](args = (%a_shard_1, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%all_gather_into_tensor,), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%wait_tensor, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    return (None, _scaled_mm)'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_0_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:20.403000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpwu4l25hj
_ MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_0_return_A_True _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1955, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 303, in test_fuse_all_gather_scaled_matmul
    self.assertIn("fused_all_gather_scaled_matmul", str(gm.graph))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 1112, in assertIn
    self.fail(self._formatMessage(msg, standardMsg))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: 'fused_all_gather_scaled_matmul' not found in 'graph():\n    %a_shard_1 : [num_users=1] = placeholder[target=A_shard_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %all_gather_into_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.all_gather_into_tensor.default](args = (%a_shard_1, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=2] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%all_gather_into_tensor,), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%wait_tensor, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    return (wait_tensor, _scaled_mm)'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_0_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:20.412000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmp2cj1l4um
_ MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_1_return_A_False _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1955, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 312, in test_fuse_all_gather_scaled_matmul
    code = run_and_get_triton_code(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 259, in func
    def func(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmpol_truu_/e4/ce4pqe3hknlopr2labfr4yd6dxkftbmvmcdymcpswrm25le674kr.py", line 126, in call
    buf0 = torch.ops._c10d_functional.all_gather_into_tensor.default(arg0_1, 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_1_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:23.406000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpol_truu_
_ MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_1_return_A_True _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1955, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 312, in test_fuse_all_gather_scaled_matmul
    code = run_and_get_triton_code(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 259, in func
    def func(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmpvr01zxgm/bv/cbvukfbnfnxnoc6fm6mqrbken2e7yu3drcpky4affkf4f6enkx6s.py", line 125, in call
    buf0 = torch.ops._c10d_functional.all_gather_into_tensor.default(arg0_1, 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_1_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:26.415000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpvr01zxgm
_ MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_0_return_A_False _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1955, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 303, in test_fuse_all_gather_scaled_matmul
    self.assertIn("fused_all_gather_scaled_matmul", str(gm.graph))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 1112, in assertIn
    self.fail(self._formatMessage(msg, standardMsg))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: 'fused_all_gather_scaled_matmul' not found in 'graph():\n    %a_shard_1 : [num_users=1] = placeholder[target=A_shard_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %all_gather_into_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.all_gather_into_tensor.default](args = (%a_shard_1, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%all_gather_into_tensor,), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%wait_tensor, [128, 32]), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view_1, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_2 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 64, -1]), kwargs = {})\n    return (None, view_2)'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_0_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:26.432000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpch8bx9yb
_ MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_0_return_A_True _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1955, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 303, in test_fuse_all_gather_scaled_matmul
    self.assertIn("fused_all_gather_scaled_matmul", str(gm.graph))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 1112, in assertIn
    self.fail(self._formatMessage(msg, standardMsg))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: 'fused_all_gather_scaled_matmul' not found in 'graph():\n    %a_shard_1 : [num_users=1] = placeholder[target=A_shard_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %all_gather_into_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.all_gather_into_tensor.default](args = (%a_shard_1, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=2] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%all_gather_into_tensor,), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%wait_tensor, [128, 32]), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view_1, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_2 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 64, -1]), kwargs = {})\n    return (wait_tensor, view_2)'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_0_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:26.442000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpwiri7r62
_ MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_1_return_A_False _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1955, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 303, in test_fuse_all_gather_scaled_matmul
    self.assertIn("fused_all_gather_scaled_matmul", str(gm.graph))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 1112, in assertIn
    self.fail(self._formatMessage(msg, standardMsg))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: 'fused_all_gather_scaled_matmul' not found in 'graph():\n    %a_shard_1 : [num_users=1] = placeholder[target=A_shard_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %all_gather_into_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.all_gather_into_tensor.default](args = (%a_shard_1, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%all_gather_into_tensor,), kwargs = {})\n    %split : [num_users=2] = call_function[target=torch.ops.aten.split.Tensor](args = (%wait_tensor, 2), kwargs = {})\n    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%split, 0), kwargs = {})\n    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 1), kwargs = {})\n    %view : [num_users=1] = call_function[target=torch.ops.aten.view.dtype](args = (%getitem, torch.uint8), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.view.dtype](args = (%getitem_1, torch.uint8), kwargs = {})\n    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view, %view_1], 1), kwargs = {})\n    %view_2 : [num_users=1] = call_function[target=torch.ops.aten.view.dtype](args = (%cat, torch.float8_e4m3fn), kwargs = {})\n    %view_3 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%view_2, [128, 32]), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view_3, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_4 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 64, -1]), kwargs = {})\n    return (None, view_4)'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_1_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:26.456000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpdqlqxvlf
_ MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_1_return_A_True _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1955, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 303, in test_fuse_all_gather_scaled_matmul
    self.assertIn("fused_all_gather_scaled_matmul", str(gm.graph))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 1112, in assertIn
    self.fail(self._formatMessage(msg, standardMsg))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: 'fused_all_gather_scaled_matmul' not found in 'graph():\n    %a_shard_1 : [num_users=1] = placeholder[target=A_shard_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %all_gather_into_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.all_gather_into_tensor.default](args = (%a_shard_1, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%all_gather_into_tensor,), kwargs = {})\n    %split : [num_users=2] = call_function[target=torch.ops.aten.split.Tensor](args = (%wait_tensor, 2), kwargs = {})\n    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%split, 0), kwargs = {})\n    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 1), kwargs = {})\n    %view : [num_users=1] = call_function[target=torch.ops.aten.view.dtype](args = (%getitem, torch.uint8), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.view.dtype](args = (%getitem_1, torch.uint8), kwargs = {})\n    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view, %view_1], 1), kwargs = {})\n    %view_2 : [num_users=2] = call_function[target=torch.ops.aten.view.dtype](args = (%cat, torch.float8_e4m3fn), kwargs = {})\n    %view_3 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%view_2, [128, 32]), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view_3, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_4 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 64, -1]), kwargs = {})\n    return (view_2, view_4)'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_1_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:26.468000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmptfsbt4db
_ MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_2_return_A_False _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1955, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 312, in test_fuse_all_gather_scaled_matmul
    code = run_and_get_triton_code(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 259, in func
    def func(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmpq9qe7dzq/mu/cmuwxb4vnvqqe6crbm2l335dqwylslr7u24znui4d2oamcuymv7p.py", line 128, in call
    buf0 = torch.ops._c10d_functional.all_gather_into_tensor.default(arg0_1, 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_2_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:29.683000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpq9qe7dzq
_ MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_2_return_A_True _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1955, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 312, in test_fuse_all_gather_scaled_matmul
    code = run_and_get_triton_code(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 259, in func
    def func(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmp1423cl47/s7/cs7qbcrlv2ylivgct5xx6vc2h3ljongt3g7mki3xqhrezdi4bk5u.py", line 125, in call
    buf0 = torch.ops._c10d_functional.all_gather_into_tensor.default(arg0_1, 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_2_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:32.704000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmp1423cl47
__ MicroPipelineTPTest.test_fuse_matmul_reduce_scatter_A_dims_2_scatter_dim_0 __
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 346, in test_fuse_matmul_reduce_scatter
    code = run_and_get_triton_code(compiled, A, B)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 333, in func
    def func(A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmpjgxk0tvm/a6/ca6svgw4tfsu4iabeaw2qpgzeagj6ivz4ck5d4pitmq564jlcd7q.py", line 59, in call
    buf1 = torch.ops._c10d_functional.reduce_scatter_tensor.default(buf0, 'avg', 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_matmul_reduce_scatter_A_dims_2_scatter_dim_0

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:32.827000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpjgxk0tvm
__ MicroPipelineTPTest.test_fuse_matmul_reduce_scatter_A_dims_2_scatter_dim_1 __
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 346, in test_fuse_matmul_reduce_scatter
    code = run_and_get_triton_code(compiled, A, B)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 333, in func
    def func(A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmp1ws7z2kz/7s/c7sv7i2fpqk752pxjw667fj6fxauzsmsyl7kkecvahvdsyfh63l5.py", line 121, in call
    buf2 = torch.ops._c10d_functional.reduce_scatter_tensor.default(buf1, 'avg', 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_matmul_reduce_scatter_A_dims_2_scatter_dim_1

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:35.866000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmp1ws7z2kz
__ MicroPipelineTPTest.test_fuse_matmul_reduce_scatter_A_dims_3_scatter_dim_0 __
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 346, in test_fuse_matmul_reduce_scatter
    code = run_and_get_triton_code(compiled, A, B)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 333, in func
    def func(A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmpahrstjo4/l5/cl57a5372mbckhjkb4fmfjiytopseeq225sz7q2khuwxz5snrxim.py", line 59, in call
    buf1 = torch.ops._c10d_functional.reduce_scatter_tensor.default(reinterpret_tensor(buf0, (2, 64, 16), (1024, 16, 1), 0), 'avg', 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_matmul_reduce_scatter_A_dims_3_scatter_dim_0

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:35.992000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpahrstjo4
__ MicroPipelineTPTest.test_fuse_matmul_reduce_scatter_A_dims_3_scatter_dim_1 __
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 346, in test_fuse_matmul_reduce_scatter
    code = run_and_get_triton_code(compiled, A, B)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 333, in func
    def func(A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmpqz4pn5cf/nn/cnn5s5jskj6l2asgbzz2nov46vrcukoycqh5owv6ke7qe44xi4yi.py", line 123, in call
    buf2 = torch.ops._c10d_functional.reduce_scatter_tensor.default(buf1, 'avg', 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_matmul_reduce_scatter_A_dims_3_scatter_dim_1

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:39.061000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpqz4pn5cf
__ MicroPipelineTPTest.test_fuse_matmul_reduce_scatter_A_dims_3_scatter_dim_2 __
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 346, in test_fuse_matmul_reduce_scatter
    code = run_and_get_triton_code(compiled, A, B)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 333, in func
    def func(A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmpmk0xyjkz/fc/cfc5snlfizox5dmmv74jmogrlqduuwijh442avw7hsb32bjc2oth.py", line 124, in call
    buf2 = torch.ops._c10d_functional.reduce_scatter_tensor.default(buf1, 'avg', 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_matmul_reduce_scatter_A_dims_3_scatter_dim_2

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:42.153000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpmk0xyjkz
_ MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_A_dims_2_scatter_dim_0 _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1955, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 391, in test_fuse_scaled_matmul_reduce_scatter
    self.assertIn("fused_scaled_matmul_reduce_scatter", str(gm.graph))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 1112, in assertIn
    self.fail(self._formatMessage(msg, standardMsg))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: 'fused_scaled_matmul_reduce_scatter' not found in 'graph():\n    %a_1 : [num_users=1] = placeholder[target=A_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%a_1, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %reduce_scatter_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.reduce_scatter_tensor.default](args = (%_scaled_mm, avg, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%reduce_scatter_tensor,), kwargs = {})\n    return wait_tensor'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_A_dims_2_scatter_dim_0

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:42.163000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmp0nnkjdgx
_ MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_A_dims_2_scatter_dim_1 _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1955, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 391, in test_fuse_scaled_matmul_reduce_scatter
    self.assertIn("fused_scaled_matmul_reduce_scatter", str(gm.graph))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 1112, in assertIn
    self.fail(self._formatMessage(msg, standardMsg))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: 'fused_scaled_matmul_reduce_scatter' not found in 'graph():\n    %a_1 : [num_users=1] = placeholder[target=A_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%a_1, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %split : [num_users=2] = call_function[target=torch.ops.aten.split.Tensor](args = (%_scaled_mm, 8, 1), kwargs = {})\n    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%split, 0), kwargs = {})\n    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 1), kwargs = {})\n    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%getitem, %getitem_1],), kwargs = {})\n    %reduce_scatter_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.reduce_scatter_tensor.default](args = (%cat, avg, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%reduce_scatter_tensor,), kwargs = {})\n    return wait_tensor'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_A_dims_2_scatter_dim_1

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:42.173000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpxp7t7syu
_ MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_A_dims_3_scatter_dim_0 _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1955, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 391, in test_fuse_scaled_matmul_reduce_scatter
    self.assertIn("fused_scaled_matmul_reduce_scatter", str(gm.graph))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 1112, in assertIn
    self.fail(self._formatMessage(msg, standardMsg))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: 'fused_scaled_matmul_reduce_scatter' not found in 'graph():\n    %a_1 : [num_users=1] = placeholder[target=A_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %view : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%a_1, [128, 32]), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 64, 16]), kwargs = {})\n    %reduce_scatter_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.reduce_scatter_tensor.default](args = (%view_1, avg, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%reduce_scatter_tensor,), kwargs = {})\n    return wait_tensor'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_A_dims_3_scatter_dim_0

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:42.184000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpnpfnts07
_ MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_A_dims_3_scatter_dim_1 _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1955, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 391, in test_fuse_scaled_matmul_reduce_scatter
    self.assertIn("fused_scaled_matmul_reduce_scatter", str(gm.graph))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 1112, in assertIn
    self.fail(self._formatMessage(msg, standardMsg))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: 'fused_scaled_matmul_reduce_scatter' not found in 'graph():\n    %a_1 : [num_users=1] = placeholder[target=A_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %view : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%a_1, [128, 32]), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 64, 16]), kwargs = {})\n    %split : [num_users=2] = call_function[target=torch.ops.aten.split.Tensor](args = (%view_1, 32, 1), kwargs = {})\n    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%split, 0), kwargs = {})\n    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 1), kwargs = {})\n    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%getitem, %getitem_1],), kwargs = {})\n    %reduce_scatter_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.reduce_scatter_tensor.default](args = (%cat, avg, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%reduce_scatter_tensor,), kwargs = {})\n    return wait_tensor'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_A_dims_3_scatter_dim_1

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:42.195000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmp_vs6nc9b
_ MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_A_dims_3_scatter_dim_2 _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1955, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 391, in test_fuse_scaled_matmul_reduce_scatter
    self.assertIn("fused_scaled_matmul_reduce_scatter", str(gm.graph))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 1112, in assertIn
    self.fail(self._formatMessage(msg, standardMsg))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: 'fused_scaled_matmul_reduce_scatter' not found in 'graph():\n    %a_1 : [num_users=1] = placeholder[target=A_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %view : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%a_1, [128, 32]), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 64, 16]), kwargs = {})\n    %split : [num_users=2] = call_function[target=torch.ops.aten.split.Tensor](args = (%view_1, 8, 2), kwargs = {})\n    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%split, 0), kwargs = {})\n    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 1), kwargs = {})\n    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%getitem, %getitem_1],), kwargs = {})\n    %reduce_scatter_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.reduce_scatter_tensor.default](args = (%cat, avg, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%reduce_scatter_tensor,), kwargs = {})\n    return wait_tensor'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_A_dims_3_scatter_dim_2

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:42.206000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpb_xh0nwz
_ MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_rowwise_scales_reshape_mm_reshape_scatter_dim_0 _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1955, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 455, in test_fuse_scaled_matmul_reduce_scatter_rowwise_scales_reshape_mm_reshape
    self.assertIn("fused_scaled_matmul_reduce_scatter", str(gm.graph))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 1112, in assertIn
    self.fail(self._formatMessage(msg, standardMsg))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: 'fused_scaled_matmul_reduce_scatter' not found in 'graph():\n    %a_1 : [num_users=1] = placeholder[target=A_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %view : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%a_1, [-1, 32]), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%a_scale_1, [-1, 1]), kwargs = {})\n    %reciprocal : [num_users=1] = call_function[target=torch.ops.aten.reciprocal.default](args = (%view_1,), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view, %b_1, %reciprocal, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_2 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 16, 64]), kwargs = {})\n    %reduce_scatter_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.reduce_scatter_tensor.default](args = (%view_2, sum, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%reduce_scatter_tensor,), kwargs = {})\n    return wait_tensor'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_rowwise_scales_reshape_mm_reshape_scatter_dim_0

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:42.218000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpoymytluc
_ MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_rowwise_scales_reshape_mm_reshape_scatter_dim_1 _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1955, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 455, in test_fuse_scaled_matmul_reduce_scatter_rowwise_scales_reshape_mm_reshape
    self.assertIn("fused_scaled_matmul_reduce_scatter", str(gm.graph))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 1112, in assertIn
    self.fail(self._formatMessage(msg, standardMsg))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: 'fused_scaled_matmul_reduce_scatter' not found in 'graph():\n    %a_1 : [num_users=1] = placeholder[target=A_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %view : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%a_1, [-1, 32]), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%a_scale_1, [-1, 1]), kwargs = {})\n    %reciprocal : [num_users=1] = call_function[target=torch.ops.aten.reciprocal.default](args = (%view_1,), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view, %b_1, %reciprocal, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_2 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 16, 64]), kwargs = {})\n    %split : [num_users=2] = call_function[target=torch.ops.aten.split.Tensor](args = (%view_2, 8, 1), kwargs = {})\n    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%split, 0), kwargs = {})\n    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 1), kwargs = {})\n    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%getitem, %getitem_1],), kwargs = {})\n    %reduce_scatter_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.reduce_scatter_tensor.default](args = (%cat, sum, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%reduce_scatter_tensor,), kwargs = {})\n    return wait_tensor'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_rowwise_scales_reshape_mm_reshape_scatter_dim_1

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:42.230000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmphebmpoo8
_ MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_rowwise_scales_reshape_mm_reshape_scatter_dim_2 _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552, in instantiated_test
    test(self, **param_kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1955, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 455, in test_fuse_scaled_matmul_reduce_scatter_rowwise_scales_reshape_mm_reshape
    self.assertIn("fused_scaled_matmul_reduce_scatter", str(gm.graph))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 1112, in assertIn
    self.fail(self._formatMessage(msg, standardMsg))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: 'fused_scaled_matmul_reduce_scatter' not found in 'graph():\n    %a_1 : [num_users=1] = placeholder[target=A_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %view : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%a_1, [-1, 32]), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%a_scale_1, [-1, 1]), kwargs = {})\n    %reciprocal : [num_users=1] = call_function[target=torch.ops.aten.reciprocal.default](args = (%view_1,), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view, %b_1, %reciprocal, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_2 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 16, 64]), kwargs = {})\n    %split : [num_users=2] = call_function[target=torch.ops.aten.split.Tensor](args = (%view_2, 32, 2), kwargs = {})\n    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%split, 0), kwargs = {})\n    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 1), kwargs = {})\n    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%getitem, %getitem_1],), kwargs = {})\n    %reduce_scatter_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.reduce_scatter_tensor.default](args = (%cat, sum, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%reduce_scatter_tensor,), kwargs = {})\n    return wait_tensor'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_rowwise_scales_reshape_mm_reshape_scatter_dim_2

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:42.241000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmp7xg75llu
______________ MicroPipelineTPTest.test_get_unexposed_collectives ______________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 194, in test_get_unexposed_collectives
    gm = make_fx(func)(inp)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py", line 2429, in wrapped
    return make_fx_tracer.trace(f, *args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py", line 2356, in trace
    return self._trace_inner(f, *args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py", line 2318, in _trace_inner
    t = dispatch_trace(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py", line 1303, in dispatch_trace
    graph = tracer.trace(root, concrete_args)  # type: ignore[arg-type]
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py", line 868, in trace
    (self.create_arg(fn(*args)),),
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py", line 1361, in wrapped
    out = f(*tensors)  # type:ignore[call-arg]
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 184, in func
    b = all_gather_tensor(inp, gather_dim=0, group=group.group_name)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 199, in all_gather_tensor
    tensor = torch.ops._c10d_functional.all_gather_into_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py", line 1409, in __torch_function__
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/utils/_stats.py", line 28, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py", line 1534, in __torch_dispatch__
    return proxy_call(self, func, self.pre_dispatch, args, kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/fx/experimental/proxy_tensor.py", line 994, in proxy_call
    out = func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_get_unexposed_collectives

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:42.261000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpx75jz47y
________________ MicroPipelineTP4GPUTest.test_extra_collectives ________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 545, in test_extra_collectives
    code = run_and_get_triton_code(compiled, inp, w1, w2)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2215, in run_and_get_triton_code
    _, source_codes = run_and_get_code(fn, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2137, in run_and_get_code
    result = fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/parallel/test_micro_pipeline_tp.py", line 532, in func
    def func(inp: torch.Tensor, w1: torch.Tensor, w2: torch.Tensor) -> torch.Tensor:
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/tmpk6czv8lw/yh/cyhb5g77zza4utftmoe5ybmi3ue6rquzwfumxjakvjjzukimk3mq.py", line 120, in call
    buf0 = torch.ops._c10d_functional.all_gather_into_tensor.default(arg0_1, 2, '1')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTP4GPUTest.test_extra_collectives

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stderr call -----------------------------
[rank0]:W0912 14:43:45.202000 1094325 site-packages/torch/_inductor/utils.py:1243] on error, temporary cache dir kept at /tmp/tmpk6czv8lw
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_tensor_parallel_test_micro_pipeline_tp.py.xml -
=========================== short test summary info ============================
FAILED [0.0082s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_dtensor_seq_par_shard_dim_0 - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_dtensor_seq_par_shard_dim_0

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0032s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_dtensor_seq_par_shard_dim_1 - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_dtensor_seq_par_shard_dim_1

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0039s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_find_reduce_scatter_patterns - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_find_reduce_scatter_patterns

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [3.9739s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_2_gather_dim_0_return_A_False - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_2_gather_dim_0_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.1095s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_2_gather_dim_0_return_A_True - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_2_gather_dim_0_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [3.0192s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_2_gather_dim_1_return_A_False - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_2_gather_dim_1_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [2.9589s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_2_gather_dim_1_return_A_True - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_2_gather_dim_1_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.1208s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_3_gather_dim_0_return_A_False - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_3_gather_dim_0_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.1149s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_3_gather_dim_0_return_A_True - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_3_gather_dim_0_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [3.0008s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_3_gather_dim_1_return_A_False - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_3_gather_dim_1_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [2.9682s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_3_gather_dim_1_return_A_True - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_3_gather_dim_1_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [2.9748s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_3_gather_dim_2_return_A_False - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_3_gather_dim_2_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [2.9599s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_matmul_A_dims_3_gather_dim_2_return_A_True - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_matmul_A_dims_3_gather_dim_2_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0229s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_0_return_A_False - AssertionError: 'fused_all_gather_scaled_matmul' not found in 'graph():\n    %a_shard_1 : [num_users=1] = placeholder[target=A_shard_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %all_gather_into_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.all_gather_into_tensor.default](args = (%a_shard_1, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%all_gather_into_tensor,), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%wait_tensor, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    return (None, _scaled_mm)'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_0_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0078s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_0_return_A_True - AssertionError: 'fused_all_gather_scaled_matmul' not found in 'graph():\n    %a_shard_1 : [num_users=1] = placeholder[target=A_shard_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %all_gather_into_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.all_gather_into_tensor.default](args = (%a_shard_1, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=2] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%all_gather_into_tensor,), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%wait_tensor, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    return (wait_tensor, _scaled_mm)'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_0_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [2.9930s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_1_return_A_False - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_1_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [3.0069s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_1_return_A_True - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_2_gather_dim_1_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0125s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_0_return_A_False - AssertionError: 'fused_all_gather_scaled_matmul' not found in 'graph():\n    %a_shard_1 : [num_users=1] = placeholder[target=A_shard_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %all_gather_into_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.all_gather_into_tensor.default](args = (%a_shard_1, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%all_gather_into_tensor,), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%wait_tensor, [128, 32]), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view_1, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_2 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 64, -1]), kwargs = {})\n    return (None, view_2)'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_0_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0087s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_0_return_A_True - AssertionError: 'fused_all_gather_scaled_matmul' not found in 'graph():\n    %a_shard_1 : [num_users=1] = placeholder[target=A_shard_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %all_gather_into_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.all_gather_into_tensor.default](args = (%a_shard_1, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=2] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%all_gather_into_tensor,), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%wait_tensor, [128, 32]), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view_1, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_2 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 64, -1]), kwargs = {})\n    return (wait_tensor, view_2)'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_0_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0131s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_1_return_A_False - AssertionError: 'fused_all_gather_scaled_matmul' not found in 'graph():\n    %a_shard_1 : [num_users=1] = placeholder[target=A_shard_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %all_gather_into_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.all_gather_into_tensor.default](args = (%a_shard_1, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%all_gather_into_tensor,), kwargs = {})\n    %split : [num_users=2] = call_function[target=torch.ops.aten.split.Tensor](args = (%wait_tensor, 2), kwargs = {})\n    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%split, 0), kwargs = {})\n    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 1), kwargs = {})\n    %view : [num_users=1] = call_function[target=torch.ops.aten.view.dtype](args = (%getitem, torch.uint8), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.view.dtype](args = (%getitem_1, torch.uint8), kwargs = {})\n    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view, %view_1], 1), kwargs = {})\n    %view_2 : [num_users=1] = call_function[target=torch.ops.aten.view.dtype](args = (%cat, torch.float8_e4m3fn), kwargs = {})\n    %view_3 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%view_2, [128, 32]), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view_3, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_4 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 64, -1]), kwargs = {})\n    return (None, view_4)'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_1_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0113s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_1_return_A_True - AssertionError: 'fused_all_gather_scaled_matmul' not found in 'graph():\n    %a_shard_1 : [num_users=1] = placeholder[target=A_shard_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %all_gather_into_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.all_gather_into_tensor.default](args = (%a_shard_1, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%all_gather_into_tensor,), kwargs = {})\n    %split : [num_users=2] = call_function[target=torch.ops.aten.split.Tensor](args = (%wait_tensor, 2), kwargs = {})\n    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%split, 0), kwargs = {})\n    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 1), kwargs = {})\n    %view : [num_users=1] = call_function[target=torch.ops.aten.view.dtype](args = (%getitem, torch.uint8), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.view.dtype](args = (%getitem_1, torch.uint8), kwargs = {})\n    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view, %view_1], 1), kwargs = {})\n    %view_2 : [num_users=2] = call_function[target=torch.ops.aten.view.dtype](args = (%cat, torch.float8_e4m3fn), kwargs = {})\n    %view_3 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%view_2, [128, 32]), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view_3, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_4 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 64, -1]), kwargs = {})\n    return (view_2, view_4)'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_1_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [3.2137s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_2_return_A_False - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_2_return_A_False

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [3.0198s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_2_return_A_True - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_all_gather_scaled_matmul_A_dims_3_gather_dim_2_return_A_True

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.1213s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_matmul_reduce_scatter_A_dims_2_scatter_dim_0 - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_matmul_reduce_scatter_A_dims_2_scatter_dim_0

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [3.0391s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_matmul_reduce_scatter_A_dims_2_scatter_dim_1 - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_matmul_reduce_scatter_A_dims_2_scatter_dim_1

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.1211s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_matmul_reduce_scatter_A_dims_3_scatter_dim_0 - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_matmul_reduce_scatter_A_dims_3_scatter_dim_0

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [3.0675s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_matmul_reduce_scatter_A_dims_3_scatter_dim_1 - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_matmul_reduce_scatter_A_dims_3_scatter_dim_1

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [3.0910s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_matmul_reduce_scatter_A_dims_3_scatter_dim_2 - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_matmul_reduce_scatter_A_dims_3_scatter_dim_2

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0088s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_scaled_matmul_reduce_scatter_A_dims_2_scatter_dim_0 - AssertionError: 'fused_scaled_matmul_reduce_scatter' not found in 'graph():\n    %a_1 : [num_users=1] = placeholder[target=A_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%a_1, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %reduce_scatter_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.reduce_scatter_tensor.default](args = (%_scaled_mm, avg, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%reduce_scatter_tensor,), kwargs = {})\n    return wait_tensor'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_A_dims_2_scatter_dim_0

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0092s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_scaled_matmul_reduce_scatter_A_dims_2_scatter_dim_1 - AssertionError: 'fused_scaled_matmul_reduce_scatter' not found in 'graph():\n    %a_1 : [num_users=1] = placeholder[target=A_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%a_1, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %split : [num_users=2] = call_function[target=torch.ops.aten.split.Tensor](args = (%_scaled_mm, 8, 1), kwargs = {})\n    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%split, 0), kwargs = {})\n    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 1), kwargs = {})\n    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%getitem, %getitem_1],), kwargs = {})\n    %reduce_scatter_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.reduce_scatter_tensor.default](args = (%cat, avg, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%reduce_scatter_tensor,), kwargs = {})\n    return wait_tensor'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_A_dims_2_scatter_dim_1

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0082s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_scaled_matmul_reduce_scatter_A_dims_3_scatter_dim_0 - AssertionError: 'fused_scaled_matmul_reduce_scatter' not found in 'graph():\n    %a_1 : [num_users=1] = placeholder[target=A_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %view : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%a_1, [128, 32]), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 64, 16]), kwargs = {})\n    %reduce_scatter_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.reduce_scatter_tensor.default](args = (%view_1, avg, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%reduce_scatter_tensor,), kwargs = {})\n    return wait_tensor'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_A_dims_3_scatter_dim_0

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0097s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_scaled_matmul_reduce_scatter_A_dims_3_scatter_dim_1 - AssertionError: 'fused_scaled_matmul_reduce_scatter' not found in 'graph():\n    %a_1 : [num_users=1] = placeholder[target=A_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %view : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%a_1, [128, 32]), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 64, 16]), kwargs = {})\n    %split : [num_users=2] = call_function[target=torch.ops.aten.split.Tensor](args = (%view_1, 32, 1), kwargs = {})\n    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%split, 0), kwargs = {})\n    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 1), kwargs = {})\n    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%getitem, %getitem_1],), kwargs = {})\n    %reduce_scatter_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.reduce_scatter_tensor.default](args = (%cat, avg, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%reduce_scatter_tensor,), kwargs = {})\n    return wait_tensor'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_A_dims_3_scatter_dim_1

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0098s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_scaled_matmul_reduce_scatter_A_dims_3_scatter_dim_2 - AssertionError: 'fused_scaled_matmul_reduce_scatter' not found in 'graph():\n    %a_1 : [num_users=1] = placeholder[target=A_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %view : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%a_1, [128, 32]), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view, %b_1, %a_scale_1, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 64, 16]), kwargs = {})\n    %split : [num_users=2] = call_function[target=torch.ops.aten.split.Tensor](args = (%view_1, 8, 2), kwargs = {})\n    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%split, 0), kwargs = {})\n    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 1), kwargs = {})\n    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%getitem, %getitem_1],), kwargs = {})\n    %reduce_scatter_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.reduce_scatter_tensor.default](args = (%cat, avg, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%reduce_scatter_tensor,), kwargs = {})\n    return wait_tensor'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_A_dims_3_scatter_dim_2

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0118s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_scaled_matmul_reduce_scatter_rowwise_scales_reshape_mm_reshape_scatter_dim_0 - AssertionError: 'fused_scaled_matmul_reduce_scatter' not found in 'graph():\n    %a_1 : [num_users=1] = placeholder[target=A_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %view : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%a_1, [-1, 32]), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%a_scale_1, [-1, 1]), kwargs = {})\n    %reciprocal : [num_users=1] = call_function[target=torch.ops.aten.reciprocal.default](args = (%view_1,), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view, %b_1, %reciprocal, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_2 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 16, 64]), kwargs = {})\n    %reduce_scatter_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.reduce_scatter_tensor.default](args = (%view_2, sum, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%reduce_scatter_tensor,), kwargs = {})\n    return wait_tensor'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_rowwise_scales_reshape_mm_reshape_scatter_dim_0

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0105s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_scaled_matmul_reduce_scatter_rowwise_scales_reshape_mm_reshape_scatter_dim_1 - AssertionError: 'fused_scaled_matmul_reduce_scatter' not found in 'graph():\n    %a_1 : [num_users=1] = placeholder[target=A_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %view : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%a_1, [-1, 32]), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%a_scale_1, [-1, 1]), kwargs = {})\n    %reciprocal : [num_users=1] = call_function[target=torch.ops.aten.reciprocal.default](args = (%view_1,), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view, %b_1, %reciprocal, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_2 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 16, 64]), kwargs = {})\n    %split : [num_users=2] = call_function[target=torch.ops.aten.split.Tensor](args = (%view_2, 8, 1), kwargs = {})\n    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%split, 0), kwargs = {})\n    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 1), kwargs = {})\n    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%getitem, %getitem_1],), kwargs = {})\n    %reduce_scatter_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.reduce_scatter_tensor.default](args = (%cat, sum, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%reduce_scatter_tensor,), kwargs = {})\n    return wait_tensor'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_rowwise_scales_reshape_mm_reshape_scatter_dim_1

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0104s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_fuse_scaled_matmul_reduce_scatter_rowwise_scales_reshape_mm_reshape_scatter_dim_2 - AssertionError: 'fused_scaled_matmul_reduce_scatter' not found in 'graph():\n    %a_1 : [num_users=1] = placeholder[target=A_1]\n    %b_1 : [num_users=1] = placeholder[target=B_1]\n    %a_scale_1 : [num_users=1] = placeholder[target=A_scale_1]\n    %b_scale_1 : [num_users=1] = placeholder[target=B_scale_1]\n    %out_dtype_1 : [num_users=0] = placeholder[target=out_dtype_1]\n    %view : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%a_1, [-1, 32]), kwargs = {})\n    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%a_scale_1, [-1, 1]), kwargs = {})\n    %reciprocal : [num_users=1] = call_function[target=torch.ops.aten.reciprocal.default](args = (%view_1,), kwargs = {})\n    %_scaled_mm : [num_users=1] = call_function[target=torch.ops.aten._scaled_mm.default](args = (%view, %b_1, %reciprocal, %b_scale_1, None, None, torch.bfloat16), kwargs = {})\n    %view_2 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%_scaled_mm, [2, 16, 64]), kwargs = {})\n    %split : [num_users=2] = call_function[target=torch.ops.aten.split.Tensor](args = (%view_2, 32, 2), kwargs = {})\n    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%split, 0), kwargs = {})\n    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 1), kwargs = {})\n    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%getitem, %getitem_1],), kwargs = {})\n    %reduce_scatter_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.reduce_scatter_tensor.default](args = (%cat, sum, 2, 0), kwargs = {})\n    %wait_tensor : [num_users=1] = call_function[target=torch.ops._c10d_functional.wait_tensor.default](args = (%reduce_scatter_tensor,), kwargs = {})\n    return wait_tensor'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_fuse_scaled_matmul_reduce_scatter_rowwise_scales_reshape_mm_reshape_scatter_dim_2

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0189s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest::test_get_unexposed_collectives - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTPTest.test_get_unexposed_collectives

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [2.9401s] ../../../../test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTP4GPUTest::test_extra_collectives - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/parallel/test_micro_pipeline_tp.py MicroPipelineTP4GPUTest.test_extra_collectives

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
======================== 38 failed, 7 passed in 58.33s =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:43:49.170] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 16 items
Running 16 items in this shard

../../../../test/distributed/tensor/parallel/test_tp_examples.py::DistTensorParallelExampleTest::test_loss_parallel [2025-09-12 14:43:51.338] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:43:51.361] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:43:51.363] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:43:51.406] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:43:51:1095390 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:43:51:1095390 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:43:51:1095387 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:43:51:1095387 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:43:51:1095389 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:43:51:1095389 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:43:51:1095388 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:43:51:1095388 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.5321s] [  6%]
../../../../test/distributed/tensor/parallel/test_tp_examples.py::DistTensorParallelExampleTest::test_mlp_inference [2025-09-12 14:44:07.870] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:44:07.935] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:44:07.937] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:44:07.958] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:44:08:1095708 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:44:08:1095708 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:44:08:1095705 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:44:08:1095705 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:44:08:1095709 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:44:08:1095709 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:44:08:1095706 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:44:08:1095706 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0227s] [ 12%]
../../../../test/distributed/tensor/parallel/test_tp_examples.py::DistTensorParallelExampleTest::test_mlp_training_is_seq_parallel_False_recompute_activation_False [2025-09-12 14:44:23.918] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:44:23.922] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:44:23.929] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:44:23.950] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:44:24:1096009 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:44:24:1096009 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:44:24:1096010 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:44:24:1096010 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:44:24:1096006 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:44:24:1096006 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:44:24:1096007 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:44:24:1096007 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.4234s] [ 18%]
../../../../test/distributed/tensor/parallel/test_tp_examples.py::DistTensorParallelExampleTest::test_mlp_training_is_seq_parallel_True_recompute_activation_False [2025-09-12 14:44:40.323] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:44:40.342] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:44:40.353] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:44:40.374] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:44:40:1096323 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:44:40:1096323 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:44:40:1096325 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:44:40:1096325 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:44:40:1096326 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:44:40:1096326 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:44:41:1096324 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:44:41:1096324 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.3460s] [ 25%]
../../../../test/distributed/tensor/parallel/test_tp_examples.py::DistTensorParallelExampleTest::test_transformer_req_grad_float64_thaw_all [2025-09-12 14:45:11.694] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:11.702] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:11.718] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:11.722] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [3.1090s] [ 31%]
../../../../test/distributed/tensor/parallel/test_tp_examples.py::DistTensorParallelExampleTest::test_transformer_req_grad_seq_parallel_float32_thaw_all [2025-09-12 14:45:14.787] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:14.810] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:14.812] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:14.834] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [3.2090s] [ 37%]
../../../../test/distributed/tensor/parallel/test_tp_examples.py::DistTensorParallelExampleTest::test_transformer_req_grad_seq_parallel_float32_thaw_layers_0_attention_wv__layers_0_feed_forward_w1__layers_1_feed_forward_w2__layers_1_ffn_norm__output__tok_embeddings [2025-09-12 14:45:18.030] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:18.030] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:18.056] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:18.066] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [3.3090s] [ 43%]
../../../../test/distributed/tensor/parallel/test_tp_examples.py::DistTensorParallelExampleTest::test_transformer_req_grad_seq_parallel_float32_thaw_layers_1_ffn_norm__norm__output__tok_embeddings [2025-09-12 14:45:21.304] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:21.310] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:21.313] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:21.361] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [3.2091s] [ 50%]
../../../../test/distributed/tensor/parallel/test_tp_examples.py::DistTensorParallelExampleTest::test_transformer_req_grad_seq_parallel_float32_thaw_norm__output [2025-09-12 14:45:24.531] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:24.540] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:24.540] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:24.562] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [3.1091s] [ 56%]
../../../../test/distributed/tensor/parallel/test_tp_examples.py::DistTensorParallelExampleTest::test_transformer_req_grad_seq_parallel_float32_thaw_norm__output__tok_embeddings [2025-09-12 14:45:27.628] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:27.650] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:27.662] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:27.678] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [3.2090s] [ 62%]
../../../../test/distributed/tensor/parallel/test_tp_examples.py::DistTensorParallelExampleTest::test_transformer_req_grad_seq_parallel_float32_thaw_output__tok_embeddings [2025-09-12 14:45:30.839] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:30.852] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:30.858] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:30.874] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [3.0088s] [ 68%]
../../../../test/distributed/tensor/parallel/test_tp_examples.py::DistTensorParallelExampleTest::test_transformer_training_is_seq_parallel_False_float32 [2025-09-12 14:45:33.886] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:33.918] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:33.978] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:34.046] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [3.2087s] [ 75%]
../../../../test/distributed/tensor/parallel/test_tp_examples.py::DistTensorParallelExampleTest::test_transformer_training_is_seq_parallel_False_float64 [2025-09-12 14:45:37.075] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:37.099] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:37.099] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:37.100] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [3.1084s] [ 81%]
../../../../test/distributed/tensor/parallel/test_tp_examples.py::DistTensorParallelExampleTest::test_transformer_training_is_seq_parallel_True_float32 [2025-09-12 14:45:40.184] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:40.190] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:40.193] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:40.193] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [3.2087s] [ 87%]
../../../../test/distributed/tensor/parallel/test_tp_examples.py::DistTensorParallelExampleTest::test_transformer_training_is_seq_parallel_True_float64 [2025-09-12 14:45:43.406] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:43.420] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:43.422] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:43.438] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [3.2089s] [ 93%]
../../../../test/distributed/tensor/parallel/test_tp_examples.py::DistTensorParallelExampleTest::test_weight_tying [2025-09-12 14:45:46.569] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:46.656] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:46.657] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:45:46.706] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:45:47:1099815 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:45:47:1099815 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:45:47:1099813 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:45:47:1099813 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:45:47:1099812 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:45:47:1099812 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:45:47:1099814 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:45:47:1099814 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.4310s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_tensor_parallel_test_tp_examples.py.xml -
================== 5 passed, 11 skipped in 133.87s (0:02:13) ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:46:03.894] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 1 item
Running 1 items in this shard

../../../../test/distributed/tensor/parallel/test_tp_random_state.py::TensorParallelRandomStateTests::test_model_init [2025-09-12 14:46:06.065] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:46:06.066] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:46:06.189] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:46:06.206] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:46:06:1100202 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:46:06:1100202 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:46:06:1100203 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:46:06:1100203 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:46:06:1100205 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:46:06:1100205 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:46:06:1100204 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:46:06:1100204 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:46:07:1100202:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:46:07:1100203:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:46:07:1100204:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:46:07:1100205:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:46:08:1100203:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:46:08:1100205:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:46:08:1100202:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:46:08:1100204:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [16.7297s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_tensor_parallel_test_tp_random_state.py.xml -
============================== 1 passed in 18.62s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:46:23.522] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 16 items
Running 16 items in this shard

../../../../test/distributed/tensor/parallel/test_parallelize_api.py::TensorParallelAPITests::test_empty_plan [2025-09-12 14:46:25.662] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:46:25.689] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:46:25.713] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:46:25.718] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:46:25:1100591 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:46:25:1100591 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:46:25:1100593 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:46:25:1100593 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:46:25:1100592 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:46:25:1100592 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:46:25:1100594 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:46:25:1100594 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6064s] [  6%]
../../../../test/distributed/tensor/parallel/test_parallelize_api.py::TensorParallelAPITests::test_linear_col_wise_parallel [2025-09-12 14:46:41.116] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:46:41.130] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:46:41.138] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:46:41.148] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:46:41:1100892 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:46:41:1100892 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:46:41:1100894 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:46:41:1100894 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:46:41:1100895 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:46:41:1100895 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:46:41:1100893 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:46:41:1100893 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0342s] [ 12%]
../../../../test/distributed/tensor/parallel/test_parallelize_api.py::TensorParallelAPITests::test_linear_row_wise_parallel [2025-09-12 14:46:57.178] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:46:57.196] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:46:57.202] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:46:57.222] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:46:57:1101211 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:46:57:1101211 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:46:57:1101210 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:46:57:1101210 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:46:57:1101213 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:46:57:1101213 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:46:57:1101212 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:46:57:1101212 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0311s] [ 18%]
../../../../test/distributed/tensor/parallel/test_parallelize_api.py::TensorParallelAPITests::test_parallelize_mlp_with_module_api [2025-09-12 14:47:13.171] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:47:13.186] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:47:13.210] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:47:13.214] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:47:13:1101526 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:47:13:1101526 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:47:13:1101527 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:47:13:1101527 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:47:13:1101529 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:47:13:1101529 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:47:13:1101528 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:47:13:1101528 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9224s] [ 25%]
../../../../test/distributed/tensor/parallel/test_parallelize_api.py::TensorParallelAPITests::test_parallelize_mlp_with_module_api_nested [2025-09-12 14:47:29.098] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:47:29.103] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:47:29.110] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:47:29.128] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:47:29:1101847 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:47:29:1101847 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:47:29:1101844 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:47:29:1101844 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:47:29:1101845 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:47:29:1101845 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:47:29:1101846 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:47:29:1101846 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9303s] [ 31%]
../../../../test/distributed/tensor/parallel/test_parallelize_api.py::TensorParallelAPITests::test_parallelize_module_multi_wildcard [2025-09-12 14:47:45.031] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:47:45.044] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:47:45.044] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:47:45.045] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:47:45:1102163 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:47:45:1102163 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:47:45:1102161 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:47:45:1102161 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:47:45:1102160 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:47:45:1102160 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:47:45:1102162 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:47:45:1102162 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0303s] [ 37%]
../../../../test/distributed/tensor/parallel/test_parallelize_api.py::TensorParallelAPITests::test_parallelize_module_src_data_rank [2025-09-12 14:48:01.063] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:48:01.077] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:48:01.080] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:48:01.082] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:48:01:1102479 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:48:01:1102479 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:48:01:1102477 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:48:01:1102477 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:48:01:1102480 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:48:01:1102480 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:48:01:1102478 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:48:01:1102478 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5277s] [ 43%]
../../../../test/distributed/tensor/parallel/test_parallelize_api.py::TensorParallelAPITests::test_parallelize_module_with_digit [2025-09-12 14:48:16.590] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:48:16.606] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:48:16.620] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:48:16.634] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:48:16:1102778 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:48:16:1102778 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:48:16:1102779 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:48:16:1102779 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:48:16:1102777 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:48:16:1102777 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:48:16:1102780 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:48:16:1102780 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0211s] [ 50%]
../../../../test/distributed/tensor/parallel/test_parallelize_api.py::TensorParallelAPITests::test_parallelize_module_with_no_match [2025-09-12 14:48:32.610] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:48:32.630] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:48:32.631] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:48:32.654] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:48:32:1103094 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:48:32:1103094 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:48:32:1103096 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:48:32:1103096 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:48:32:1103095 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:48:32:1103095 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:48:32:1103093 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:48:32:1103093 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.2301s] [ 56%]
../../../../test/distributed/tensor/parallel/test_parallelize_api.py::TensorParallelAPITests::test_parallelize_module_with_question [2025-09-12 14:48:48.856] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:48:48.856] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:48:48.866] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:48:48.894] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:48:49:1103409 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:48:49:1103409 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:48:49:1103411 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:48:49:1103411 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:48:49:1103412 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:48:49:1103412 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:48:49:1103410 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:48:49:1103410 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9302s] [ 62%]
../../../../test/distributed/tensor/parallel/test_parallelize_api.py::TensorParallelAPITests::test_parallelize_module_with_root_module [2025-09-12 14:49:04.751] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:49:04.778] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:49:04.824] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:49:04.846] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:49:05:1103728 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:49:05:1103728 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:49:05:1103730 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:49:05:1103730 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:49:05:1103729 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:49:05:1103729 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:49:05:1103727 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:49:05:1103727 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.6570s] [ 68%]
../../../../test/distributed/tensor/parallel/test_parallelize_api.py::TensorParallelAPITests::test_parallelize_module_with_star [2025-09-12 14:49:36.415] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:49:36.488] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:49:36.489] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:49:36.506] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:49:36:1104046 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:49:36:1104046 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:49:36:1104045 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:49:36:1104045 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:49:36:1104047 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:49:36:1104047 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:49:36:1104044 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:49:36:1104044 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9321s] [ 75%]
../../../../test/distributed/tensor/parallel/test_parallelize_api.py::TensorParallelAPITests::test_prepare_module_input [2025-09-12 14:49:52.350] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:49:52.375] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:49:52.410] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:49:52.426] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:49:52:1104363 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:49:52:1104363 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:49:52:1104362 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:49:52:1104362 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:49:52:1104365 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:49:52:1104365 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:49:52:1104364 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:49:52:1104364 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8301s] [ 81%]
../../../../test/distributed/tensor/parallel/test_parallelize_api.py::TensorParallelAPITests::test_prepare_module_input_output [2025-09-12 14:50:08.190] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:50:08.222] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:50:08.249] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:50:08.270] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:50:08:1104662 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:50:08:1104662 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:50:08:1104665 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:50:08:1104665 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:50:08:1104664 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:50:08:1104664 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:50:08:1104663 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:50:08:1104663 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0301s] [ 87%]
../../../../test/distributed/tensor/parallel/test_parallelize_api.py::TensorParallelAPITests::test_prepare_module_output [2025-09-12 14:50:24.235] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:50:24.241] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:50:24.245] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:50:24.276] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:50:24:1104963 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:50:24:1104963 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:50:24:1104965 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:50:24:1104965 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:50:24:1104964 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:50:24:1104964 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:50:24:1104962 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:50:24:1104962 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8301s] [ 93%]
../../../../test/distributed/tensor/parallel/test_parallelize_api.py::TensorParallelAPITests::test_under_devicemesh_context [2025-09-12 14:50:40.056] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:50:40.066] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:50:40.069] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:50:40.102] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:50:40:1105264 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:50:40:1105264 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:50:40:1105265 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:50:40:1105265 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:50:40:1105262 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:50:40:1105262 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:50:40:1105263 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:50:40:1105263 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0298s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_tensor_parallel_test_parallelize_api.py.xml -
======================== 16 passed in 272.49s (0:04:32) ========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:50:56.938] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 9 items
Running 9 items in this shard

../../../../test/distributed/tensor/parallel/test_tp_style.py::TensorParallelStyleTest::test_colwise_parallel_embedding [2025-09-12 14:50:59.066] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:50:59.139] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:50:59.159] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:50:59.163] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:50:59:1105655 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:50:59:1105655 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:50:59:1105654 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:50:59:1105654 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:50:59:1105653 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:50:59:1105653 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:50:59:1105652 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:50:59:1105652 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0063s] [ 11%]
../../../../test/distributed/tensor/parallel/test_tp_style.py::TensorParallelStyleTest::test_colwise_parallel_style [2025-09-12 14:51:14.937] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:51:14.938] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:51:14.938] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:51:14.958] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:51:15:1105969 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:51:15:1105969 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:51:15:1105971 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:51:15:1105971 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:51:15:1105968 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:51:15:1105968 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:51:15:1105970 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:51:15:1105970 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.1582s] [ 22%]
../../../../test/distributed/tensor/parallel/test_tp_style.py::TensorParallelStyleTest::test_prepare_module_input [2025-09-12 14:51:46.161] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:51:46.176] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:51:46.178] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:51:46.182] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:51:46:1106288 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:51:46:1106288 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:51:46:1106285 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:51:46:1106285 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:51:46:1106286 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:51:46:1106286 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:51:46:1106287 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:51:46:1106287 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7297s] [ 33%]
../../../../test/distributed/tensor/parallel/test_tp_style.py::TensorParallelStyleTest::test_prepare_module_input_multiple_inputs [2025-09-12 14:52:01.838] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:52:01.865] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:52:01.867] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:52:01.882] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:52:02:1106588 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:52:02:1106588 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:52:02:1106590 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:52:02:1106590 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:52:02:1106587 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:52:02:1106587 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:52:02:1106589 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:52:02:1106589 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7268s] [ 44%]
../../../../test/distributed/tensor/parallel/test_tp_style.py::TensorParallelStyleTest::test_prepare_module_kwargs_input [2025-09-12 14:52:17.526] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:52:17.568] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:52:17.587] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:52:17.610] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:52:17:1106888 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:52:17:1106888 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:52:17:1106890 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:52:17:1106890 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:52:17:1106887 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:52:17:1106887 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:52:17:1106889 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:52:17:1106889 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8288s] [ 55%]
../../../../test/distributed/tensor/parallel/test_tp_style.py::TensorParallelStyleTest::test_prepare_module_output [2025-09-12 14:52:33.373] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:52:33.380] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:52:33.390] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:52:33.394] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:52:33:1107190 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:52:33:1107190 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:52:33:1107191 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:52:33:1107191 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:52:33:1107192 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:52:33:1107192 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:52:33:1107189 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:52:33:1107189 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8299s] [ 66%]
../../../../test/distributed/tensor/parallel/test_tp_style.py::TensorParallelStyleTest::test_rowwise_parallel_embedding [2025-09-12 14:52:49.213] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:52:49.213] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:52:49.218] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:52:49.219] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:52:49:1107490 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:52:49:1107490 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:52:49:1107489 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:52:49:1107489 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:52:49:1107491 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:52:49:1107491 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:52:49:1107492 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:52:49:1107492 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.2560s] [ 77%]
../../../../test/distributed/tensor/parallel/test_tp_style.py::TensorParallelStyleTest::test_rowwise_parallel_style [2025-09-12 14:53:20.447] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:53:20.458] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:53:20.574] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:53:20.594] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:53:20:1107806 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:53:20:1107806 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:53:20:1107809 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:53:20:1107809 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:53:20:1107808 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:53:20:1107808 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:53:20:1107807 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:53:20:1107807 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.1559s] [ 88%]
../../../../test/distributed/tensor/parallel/test_tp_style.py::TensorParallelStyleTest::test_sequence_parallel_style [2025-09-12 14:53:51.602] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:53:51.643] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:53:51.662] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:53:51.665] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:53:51:1108124 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:53:51:1108124 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:53:51:1108125 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:53:51:1108125 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:53:51:1108126 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:53:51:1108126 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:53:51:1108123 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:53:51:1108123 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.3225s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_tensor_parallel_test_tp_style.py.xml -
======================== 9 passed in 190.93s (0:03:10) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:54:08.907] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 8 items
Running 8 items in this shard

../../../../test/distributed/tensor/test_api.py::DTensorAPITest::test_distribute_module [2025-09-12 14:54:11.086] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:54:11.088] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:54:11.101] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:54:11.110] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:54:11:1108516 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:54:11:1108516 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:54:11:1108519 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:54:11:1108519 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:54:11:1108517 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:54:11:1108517 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:54:11:1108518 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:54:11:1108518 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9156s] [ 12%]
../../../../test/distributed/tensor/test_api.py::DTensorAPITest::test_distribute_module_casting [2025-09-12 14:54:26.797] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:54:26.818] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:54:26.828] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:54:26.834] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:54:27:1108816 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:54:27:1108816 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:54:27:1108817 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:54:27:1108817 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:54:27:1108818 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:54:27:1108818 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:54:27:1108819 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:54:27:1108819 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6295s] [ 25%]
../../../../test/distributed/tensor/test_api.py::DTensorAPITest::test_distribute_module_input_fn_output_fn [2025-09-12 14:54:42.439] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:54:42.444] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:54:42.446] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:54:42.460] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:54:42:1109117 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:54:42:1109117 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:54:42:1109118 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:54:42:1109118 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:54:42:1109116 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:54:42:1109116 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:54:42:1109119 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:54:42:1109119 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8301s] [ 37%]
../../../../test/distributed/tensor/test_api.py::DTensorAPITest::test_distribute_module_input_fn_output_fn_warning [2025-09-12 14:54:58.271] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:54:58.274] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:54:58.274] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:54:58.282] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:54:58:1109436 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:54:58:1109436 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:54:58:1109434 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:54:58:1109434 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:54:58:1109435 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:54:58:1109435 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:54:58:1109433 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:54:58:1109433 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6217s] [ 50%]
../../../../test/distributed/tensor/test_api.py::DTensorAPITest::test_distribute_module_meta [2025-09-12 14:55:13.882] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:55:13.907] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:55:13.907] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:55:13.922] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:55:14:1109736 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:55:14:1109736 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:55:14:1109735 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:55:14:1109735 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:55:14:1109734 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:55:14:1109734 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:55:14:1109737 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:55:14:1109737 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6292s] [ 62%]
../../../../test/distributed/tensor/test_api.py::DTensorAPITest::test_distribute_tensor_errors [2025-09-12 14:55:29.498] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:55:29.573] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:55:29.590] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:55:29.614] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:55:29:1110034 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:55:29:1110034 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:55:29:1110035 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:55:29:1110035 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:55:29:1110036 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:55:29:1110036 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:55:29:1110037 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:55:29:1110037 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:55:30:1110034:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:55:30:1110035:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:55:30:1110036:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:55:30:1110037:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:55:30:1110034:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:55:30:1110035:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:55:30:1110036:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-14:55:30:1110037:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [16.0296s] [ 75%]
../../../../test/distributed/tensor/test_api.py::DTensorAPITest::test_distribute_tensor_rank [2025-09-12 14:55:45.562] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:55:45.562] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:55:45.575] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:55:45.614] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:55:45:1110351 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:55:45:1110351 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:55:45:1110353 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:55:45:1110353 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:55:45:1110352 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:55:45:1110352 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:55:45:1110354 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:55:45:1110354 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5309s] [ 87%]
../../../../test/distributed/tensor/test_api.py::DTensorAPITest::test_distribute_tensor_uneven_sharding [2025-09-12 14:56:01.078] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:56:01.110] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:56:01.130] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:56:01.134] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:56:01:1110651 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:56:01:1110651 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:56:01:1110652 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:56:01:1110652 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:56:01:1110654 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:56:01:1110654 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:56:01:1110653 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:56:01:1110653 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7309s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_tensor_test_api.py.xml -
======================== 8 passed in 127.92s (0:02:07) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:56:17.682] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 6 items
Running 6 items in this shard

../../../../test/distributed/tensor/test_attention.py::RingAttentionTest::test_is_causal_behavior PASSED [0.0084s] [ 16%]
../../../../test/distributed/tensor/test_attention.py::RingAttentionTest::test_ring_attention_custom_transformer SKIPPED [0.0002s] [ 33%]
../../../../test/distributed/tensor/test_attention.py::RingAttentionTest::test_ring_attention_native_transformer SKIPPED [0.0001s] [ 50%]
../../../../test/distributed/tensor/test_attention.py::RingAttentionTest::test_ring_attention_sdpa SKIPPED [0.0001s] [ 66%]
../../../../test/distributed/tensor/test_attention.py::RingFlexAttentionTest::test_ring_flex_attention SKIPPED [0.0001s] [ 83%]
../../../../test/distributed/tensor/test_attention.py::RingFlexAttentionTest::test_ring_flex_attention_document_mask SKIPPED [0.0001s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_tensor_test_attention.py.xml -
========================= 1 passed, 5 skipped in 2.22s =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:56:20.468] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 10 items
Running 10 items in this shard

../../../../test/distributed/tensor/test_common_rules.py::CommonRulesTest::test_einop_basic_propagation [2025-09-12 14:56:22.402] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:56:22.404] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:56:22.414] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:56:22.432] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.2146s] [ 10%]
../../../../test/distributed/tensor/test_common_rules.py::CommonRulesTest::test_einop_errors PASSED [0.0025s] [ 20%]
../../../../test/distributed/tensor/test_common_rules.py::CommonRulesTest::test_einop_linearity PASSED [0.0017s] [ 30%]
../../../../test/distributed/tensor/test_common_rules.py::CommonRulesTest::test_einop_merge_sharding PASSED [0.0016s] [ 40%]
../../../../test/distributed/tensor/test_common_rules.py::CommonRulesTest::test_einop_multi_sharding_on_mesh_dim PASSED [0.0013s] [ 50%]
../../../../test/distributed/tensor/test_common_rules.py::CommonRulesTest::test_einop_pointwise_propagation PASSED [0.0015s] [ 60%]
../../../../test/distributed/tensor/test_common_rules.py::CommonRulesTest::test_pointwise_enforce_sharding_multi_sharding_on_mesh_dim PASSED [0.0017s] [ 70%]
../../../../test/distributed/tensor/test_common_rules.py::CommonRulesTest::test_pointwise_multi_sharding_on_mesh_dim PASSED [0.0019s] [ 80%]
../../../../test/distributed/tensor/test_common_rules.py::CommonRulesTest::test_pointwise_rules_broadcasting PASSED [0.0013s] [ 90%]
../../../../test/distributed/tensor/test_common_rules.py::CommonRulesTest::test_pointwise_rules_suggestion PASSED [0.0012s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_tensor_test_common_rules.py.xml -
============================== 10 passed in 4.94s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 14:56:26.798] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 35 items
Running 35 items in this shard

../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_dtensor_async_output [2025-09-12 14:56:29.006] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:56:29.041] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:56:29.155] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:56:29.162] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:56:29:1111504 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:56:29:1111504 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:56:29:1111503 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:56:29:1111503 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:56:29:1111502 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:56:29:1111502 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:56:29:1111505 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:56:29:1111505 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0281s] [  2%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_dtensor_constructor [2025-09-12 14:56:44.883] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:56:44.891] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:56:44.892] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:56:44.898] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:56:45:1111803 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:56:45:1111803 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:56:45:1111804 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:56:45:1111804 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:56:45:1111805 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:56:45:1111805 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:56:45:1111806 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:56:45:1111806 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5300s] [  5%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_dtensor_new_empty_strided [2025-09-12 14:57:00.373] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:57:00.376] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:57:00.385] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:57:00.386] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:57:00:1112105 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:57:00:1112105 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:57:00:1112107 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:57:00:1112107 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:57:00:1112106 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:57:00:1112106 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:57:00:1112104 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:57:00:1112104 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8306s] [  8%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_dtensor_properties [2025-09-12 14:57:16.197] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:57:16.213] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:57:16.214] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:57:16.238] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:57:16:1112421 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:57:16:1112421 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:57:16:1112422 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:57:16:1112422 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:57:16:1112420 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:57:16:1112420 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:57:16:1112423 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:57:16:1112423 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5294s] [ 11%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_dtensor_save_load [2025-09-12 14:57:31.724] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:57:31.726] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:57:31.734] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:57:31.754] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:57:32:1112722 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:57:32:1112722 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:57:32:1112724 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:57:32:1112724 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:57:32:1112725 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:57:32:1112725 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:57:32:1112723 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:57:32:1112723 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5290s] [ 14%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_dtensor_save_load_import [2025-09-12 14:57:47.292] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:57:47.307] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:57:47.308] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:57:47.310] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:57:50:1113025 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:57:50:1113025 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:57:50:1113026 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:57:50:1113026 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:57:50:1113024 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:57:50:1113024 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:57:50:1113023 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:57:50:1113023 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [18.5347s] [ 17%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_dtensor_spec_hash [2025-09-12 14:58:05.782] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:58:05.804] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:58:05.817] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:58:05.822] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:58:05:1113858 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:58:06:1113858 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:58:06:1113857 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:58:06:1113857 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:58:06:1113856 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:58:06:1113856 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:58:06:1113859 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:58:06:1113859 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5295s] [ 20%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_dtensor_spec_read_only_after_set [2025-09-12 14:58:21.370] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:58:21.429] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:58:21.467] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:58:21.616] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:58:21:1114159 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:58:21:1114159 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:58:21:1114157 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:58:21:1114157 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:58:21:1114156 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:58:21:1114156 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:58:21:1114158 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:58:21:1114158 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6303s] [ 22%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_dtensor_stride [2025-09-12 14:58:36.994] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:58:36.997] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:58:37.006] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:58:37.014] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:58:37:1114456 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:58:37:1114456 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:58:37:1114458 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:58:37:1114458 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:58:37:1114457 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:58:37:1114457 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:58:37:1114459 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:58:37:1114459 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5295s] [ 25%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_from_local [2025-09-12 14:58:52.505] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:58:52.526] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:58:52.526] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:58:52.542] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:58:52:1114758 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:58:52:1114758 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:58:52:1114759 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:58:52:1114759 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:58:52:1114756 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:58:52:1114756 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:58:52:1114757 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:58:52:1114757 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6291s] [ 28%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_from_local_negative_dim [2025-09-12 14:59:08.115] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:59:08.129] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:59:08.134] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:59:08.138] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:59:08:1115075 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:59:08:1115075 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:59:08:1115076 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:59:08:1115076 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:59:08:1115073 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:59:08:1115073 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:59:08:1115074 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:59:08:1115074 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6292s] [ 31%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_from_local_then_to_local [2025-09-12 14:59:23.740] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:59:23.758] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:59:23.761] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:59:23.768] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:59:24:1115375 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:59:24:1115375 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:59:24:1115376 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:59:24:1115376 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:59:24:1115373 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:59:24:1115373 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:59:24:1115374 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:59:24:1115374 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7296s] [ 34%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_from_local_uneven_sharding [2025-09-12 14:59:39.542] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:59:39.558] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:59:39.577] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:59:39.589] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:59:39:1115689 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:59:39:1115689 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:59:39:1115691 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:59:39:1115691 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:59:39:1115690 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:59:39:1115690 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:59:39:1115692 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:59:39:1115692 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.4293s] [ 37%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_from_local_uneven_sharding_raise_error [2025-09-12 14:59:54.934] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:59:54.959] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:59:55.059] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 14:59:55.090] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-14:59:55:1115992 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:59:55:1115992 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:59:55:1115993 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:59:55:1115993 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:59:55:1115994 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:59:55:1115994 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-14:59:55:1115991 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-14:59:55:1115991 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7298s] [ 40%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_full_tensor_grad_hint [2025-09-12 15:00:10.640] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:00:10.641] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:00:10.658] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:00:10.661] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:00:10:1116292 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:00:10:1116292 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:00:10:1116291 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:00:10:1116291 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:00:10:1116294 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:00:10:1116294 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:00:10:1116293 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:00:10:1116293 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [30.8553s] [ 42%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_full_tensor_sync [2025-09-12 15:00:41.506] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:00:41.506] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:00:41.561] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:00:41.578] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:00:41:1116607 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:00:41:1116607 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:00:41:1116608 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:00:41:1116608 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:00:41:1116609 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:00:41:1116609 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:00:41:1116610 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:00:41:1116610 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7297s] [ 45%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_meta_dtensor [2025-09-12 15:00:57.212] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:00:57.234] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:00:57.252] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:00:57.271] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:00:57:1116910 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:00:57:1116910 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:00:57:1116911 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:00:57:1116911 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:00:57:1116912 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:00:57:1116912 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:00:57:1116909 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:00:57:1116909 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8305s] [ 48%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_modules_w_meta_dtensor [2025-09-12 15:01:13.096] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:01:13.105] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:01:13.106] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:01:13.122] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:01:13:1117209 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:01:13:1117209 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:01:13:1117212 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:01:13:1117212 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:01:13:1117211 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:01:13:1117211 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:01:13:1117210 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:01:13:1117210 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9306s] [ 51%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_shard_tensor [2025-09-12 15:01:29.010] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:01:29.012] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:01:29.013] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:01:29.014] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:01:29:1117527 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:01:29:1117527 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:01:29:1117525 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:01:29:1117525 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:01:29:1117526 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:01:29:1117526 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:01:29:1117528 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:01:29:1117528 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6298s] [ 54%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_shard_tensor_2d [2025-09-12 15:01:44.654] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:01:44.654] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:01:44.688] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:01:44.722] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:01:44:1117826 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:01:44:1117826 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:01:44:1117828 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:01:44:1117828 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:01:44:1117827 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:01:44:1117827 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:01:44:1117829 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:01:44:1117829 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5293s] [ 57%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_to_local [2025-09-12 15:02:00.112] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:02:00.130] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:02:00.174] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:02:00.182] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:02:00:1118137 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:02:00:1118137 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:02:00:1118135 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:02:00:1118135 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:02:00:1118138 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:02:00:1118138 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:02:00:1118136 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:02:00:1118136 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9304s] [ 60%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorTest::test_to_local_grad_hint [2025-09-12 15:02:16.138] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:02:16.181] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:02:16.239] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:02:16.302] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:02:16:1118452 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:02:16:1118452 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:02:16:1118453 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:02:16:1118453 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:02:16:1118454 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:02:16:1118454 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:02:16:1118451 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:02:16:1118451 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.1560s] [ 62%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorMeshTest::test_auto_implicit_replication [2025-09-12 15:02:47.302] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:02:47.324] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:02:47.424] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:02:47.438] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:02:47:1118770 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:02:47:1118770 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:02:47:1118772 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:02:47:1118772 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:02:47:1118773 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:02:47:1118773 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:02:47:1118771 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:02:47:1118771 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8370s] [ 65%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorMeshTest::test_default_value_sub_mesh [2025-09-12 15:03:03.076] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:03.098] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:03.100] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:03.107] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:03:03:1119073 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:03:03:1119073 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:03:03:1119075 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:03:03:1119075 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:03:03:1119074 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:03:03:1119074 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:03:03:1119072 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:03:03:1119072 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8304s] [ 68%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorMeshTest::test_device_mesh_nd [2025-09-12 15:03:18.925] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:18.936] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:18.942] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:18.946] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [2.7087s] [ 71%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorMeshTest::test_dtensor_2d_mesh [2025-09-12 15:03:21.609] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:21.610] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:21.635] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:21.651] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:03:21:1119666 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:03:21:1119666 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:03:21:1119667 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:03:21:1119667 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:03:21:1119665 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:03:21:1119665 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:03:21:1119664 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:03:21:1119664 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6306s] [ 74%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorMeshTest::test_dtensor_api_device_mesh_context_manager [2025-09-12 15:03:37.258] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:37.266] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:37.281] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:37.286] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [2.8086s] [ 77%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorMeshTest::test_dtensor_device_mesh_device_conversion [2025-09-12 15:03:40.092] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:40.092] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:40.164] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:40.191] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:03:40:1120261 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:03:40:1120261 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:03:40:1120264 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:03:40:1120264 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:03:40:1120262 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:03:40:1120262 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:03:40:1120263 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:03:40:1120263 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.4290s] [ 80%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorMeshTest::test_dtensor_spec_local_shard_offset [2025-09-12 15:03:55.478] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:55.479] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:55.498] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:55.501] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [2.8088s] [ 82%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorMeshTest::test_from_local_sub_mesh [2025-09-12 15:03:58.363] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:58.370] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:58.374] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:03:58.377] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:03:58:1120853 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:03:58:1120853 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:03:58:1120852 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:03:58:1120852 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:03:58:1120851 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:03:58:1120851 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:03:58:1120850 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:03:58:1120850 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5295s] [ 85%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorMeshTest::test_implicit_replication [2025-09-12 15:04:13.873] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:04:13.873] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:04:13.873] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:04:13.874] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:04:14:1121153 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:04:14:1121153 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:04:14:1121152 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:04:14:1121152 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:04:14:1121155 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:04:14:1121155 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:04:14:1121154 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:04:14:1121154 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6306s] [ 88%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorMeshTest::test_metadata_consistency_check [2025-09-12 15:04:29.574] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:04:29.577] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:04:29.581] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:04:29.590] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:04:29:1121453 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:04:29:1121453 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:04:29:1121452 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:04:29:1121452 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:04:29:1121455 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:04:29:1121455 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:04:29:1121454 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:04:29:1121454 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9319s] [ 91%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorMeshTest::test_redistribute_sub_mesh [2025-09-12 15:04:45.383] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:04:45.383] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:04:45.383] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:04:45.406] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:04:45:1121755 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:04:45:1121755 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:04:45:1121752 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:04:45:1121752 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:04:45:1121753 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:04:45:1121753 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:04:45:1121754 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:04:45:1121754 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:04:46:1121752:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:04:46:1121754:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [16.2411s] [ 94%]
../../../../test/distributed/tensor/test_dtensor.py::DTensorMeshTest::test_vmap_embedding [2025-09-12 15:05:01.640] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:05:01.643] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:05:01.658] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:05:01.677] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:05:01:1122058 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:05:01:1122058 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:05:01:1122059 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:05:01:1122059 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:05:01:1122057 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:05:01:1122057 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:05:01:1122060 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:05:01:1122060 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9303s] [ 97%]
../../../../test/distributed/tensor/test_dtensor.py::TestDTensorPlacementTypes::test_split_tensor_1D [2025-09-12 15:05:17.574] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:05:17.593] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:05:17.597] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:05:17.614] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:05:17:1122359 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:05:17:1122359 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:05:17:1122360 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:05:17:1122360 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:05:17:1122357 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:05:17:1122357 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:05:17:1122358 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:05:17:1122358 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.4292s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_tensor_test_dtensor.py.xml -
================== 32 passed, 3 skipped in 546.11s (0:09:06) ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 15:05:34.122] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 42 items
Running 42 items in this shard

../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_device_mesh_compile PASSED [0.0657s] [  2%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_attribute_access_on_intermediate PASSED [0.2262s] [  4%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_basic PASSED [0.1917s] [  7%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_basic_export PASSED [0.1411s] [  9%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_constructor_w_dynamo_disable PASSED [0.0955s] [ 11%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_constructor_w_graph_break PASSED [0.0770s] [ 14%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_contiguous_dtensor_noncontiguous_local_as_tangent FAILED [1.6394s] [ 16%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_different_gradient_placement FAILED [2.4646s] [ 19%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_dont_recompile_on_same_placement_devicemesh PASSED [0.1204s] [ 21%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_dynamic FAILED [0.0023s] [ 23%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_dynamic_cat FAILED [0.0025s] [ 26%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_dynamic_loss_parallel_log_softmax FAILED [0.0346s] [ 28%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_dynamic_slice FAILED [0.0023s] [ 30%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_dynamo_device_mesh_attrs PASSED [0.0777s] [ 33%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_noncontiguous_output PASSED [0.3343s] [ 35%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_partial_placement_graph_output FAILED [0.2872s] [ 38%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_partial_placement_redistribute_unbalanced_correct_strides FAILED [0.0073s] [ 40%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dynamo_dtensor PASSED [0.1011s] [ 42%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dynamo_dtensor_from_local PASSED [0.1308s] [ 45%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dynamo_dtensor_from_local_dynamic_shapes PASSED [1.3928s] [ 47%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dynamo_dtensor_from_local_redistribute FAILED [0.0017s] [ 50%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dynamo_dtensor_from_local_redistribute_async FAILED [0.0011s] [ 52%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dynamo_dtensor_recompile PASSED [0.1215s] [ 54%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dynamo_to_local_kwargs PASSED [0.0742s] [ 57%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dynamo_to_local_kwargs_forward_hook PASSED [0.1755s] [ 59%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_fakify_dtensor PASSED [0.0693s] [ 61%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_graph_input_is_async FAILED [0.0337s] [ 64%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_placement_compile PASSED [0.1511s] [ 66%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_tp_compile_comm_reordering FAILED [0.0019s] [ 69%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_tp_compile_comm_reordering_graph_partition FAILED [0.0017s] [ 71%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_unwrap_async_collective_tensor_tangent PASSED [0.5851s] [ 73%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompileE2E::test_2d_fsdp_tp_ac_compile_use_ca_False [2025-09-12 15:05:54.018] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:05:54.019] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:05:54.026] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:05:54.038] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:06:03:1123346 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:06:03:1123346 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:06:04:1123345 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:06:04:1123345 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:06:06:1123344 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:06:06:1123344 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:06:07:1123343 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:06:07:1123343 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:06:08:1123345:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:06:08:1123343:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:06:08:1123344:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:06:08:1123346:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:06:36:1123343:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:06:36:1123344:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:06:36:1123345:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:06:36:1123346:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [46.2650s] [ 76%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompileE2E::test_2d_fsdp_tp_ac_compile_use_ca_True [2025-09-12 15:06:40.207] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:06:40.232] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:06:40.232] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:06:40.232] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:06:49:1125233 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:06:49:1125233 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:06:51:1125231 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:06:51:1125231 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:06:52:1125232 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:06:52:1125232 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:06:53:1125230 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:06:53:1125230 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:06:54:1125230:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:06:54:1125231:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:06:54:1125232:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:06:54:1125233:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:07:30:1125233:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:07:30:1125232:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:07:30:1125230:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:07:30:1125231:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [54.0874s] [ 78%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompileE2E::test_2d_fsdp_tp_compile_use_ca_False [2025-09-12 15:07:34.358] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:07:34.361] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:07:34.362] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:07:34.366] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:07:43:1128364 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:07:43:1128364 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:07:45:1128361 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:07:45:1128361 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:07:46:1128363 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:07:46:1128363 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:07:48:1128362 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:07:48:1128362 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:07:48:1128362:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:07:48:1128361:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:07:48:1128364:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:07:48:1128363:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:08:17:1128361:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:08:17:1128363:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:08:17:1128364:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:08:17:1128362:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [46.5811s] [ 80%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompileE2E::test_2d_fsdp_tp_compile_use_ca_True [2025-09-12 15:08:20.885] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:08:20.902] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:08:20.916] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:08:20.934] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:08:30:1130250 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:08:30:1130250 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:08:31:1130251 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:08:31:1130251 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:08:33:1130252 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:08:33:1130252 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:08:34:1130249 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:08:34:1130249 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:08:35:1130250:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:08:35:1130252:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:08:35:1130251:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:08:35:1130249:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:09:06:1130250:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:09:06:1130252:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:09:06:1130249:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:09:06:1130251:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [49.5834s] [ 83%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompileE2E::test_compile_dtensor_redistribute_backward_use_ca_False [2025-09-12 15:09:10.486] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:09:10.517] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:09:10.517] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:09:10.538] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:09:20:1132687 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:09:20:1132687 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:09:21:1132689 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:09:21:1132689 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:09:22:1132690 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:09:22:1132690 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:09:24:1132688 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:09:24:1132688 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [45.1750s] [ 85%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompileE2E::test_compile_dtensor_redistribute_backward_use_ca_True [2025-09-12 15:09:55.654] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:09:55.675] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:09:55.681] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:09:55.738] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:10:05:1134559 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:10:05:1134559 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:10:06:1134558 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:10:06:1134558 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:10:07:1134561 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:10:07:1134561 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:10:09:1134560 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:10:09:1134560 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [47.8748s] [ 88%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompileE2E::test_compile_embedding_redistribute [2025-09-12 15:10:43.550] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:10:43.550] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:10:43.706] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:10:43.718] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:10:53:1137048 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:10:53:1137048 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:10:54:1137050 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:10:54:1137050 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:10:56:1137049 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:10:56:1137049 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:10:57:1137047 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:10:57:1137047 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [49.7832s] [ 90%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompileE2E::test_tp_compile_fullgraph_is_seq_parallel_False_use_ca_False [2025-09-12 15:11:33.294] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:11:33.386] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:11:33.386] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:11:33.423] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:11:43:1139693 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:11:43:1139693 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:11:44:1139692 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:11:44:1139692 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:11:45:1139694 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:11:45:1139694 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:11:47:1139695 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:11:47:1139695 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [30.3531s] [ 92%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompileE2E::test_tp_compile_fullgraph_is_seq_parallel_False_use_ca_True [2025-09-12 15:12:03.681] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:12:03.681] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:12:03.683] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:12:03.690] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:12:13:1141564 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:12:13:1141564 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:12:14:1141563 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:12:14:1141563 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:12:16:1141566 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:12:16:1141566 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:12:17:1141565 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:12:17:1141565 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [34.6611s] [ 95%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompileE2E::test_tp_compile_fullgraph_is_seq_parallel_True_use_ca_False [2025-09-12 15:12:38.390] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:12:38.479] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:12:38.495] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:12:38.495] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:12:48:1144220 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:12:48:1144220 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:12:49:1144221 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:12:49:1144221 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:12:50:1144222 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:12:50:1144222 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:12:52:1144219 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:12:52:1144219 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [45.3773s] [ 97%]
../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompileE2E::test_tp_compile_fullgraph_is_seq_parallel_True_use_ca_True [2025-09-12 15:13:23.694] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:13:23.751] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:13:23.751] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:13:23.774] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:13:33:1146092 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:13:33:1146092 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:13:34:1146091 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:13:34:1146091 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:13:35:1146089 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:13:35:1146089 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:13:37:1146090 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:13:37:1146090 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [49.9846s] [100%]

=================================== FAILURES ===================================
_ TestDTensorCompile.test_dtensor_contiguous_dtensor_noncontiguous_local_as_tangent _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 659, in test_dtensor_contiguous_dtensor_noncontiguous_local_as_tangent
    out_dt = torch.compile(fn)(x_dt)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 639, in fn
    def fn(x):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 339, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 103, in g
    return f(*args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 2118, in forward
    fw_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 690, in inner_fn
    unwrapped_outs = compiled_fn(unwrapped_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/torchinductor_jenkins/sv/csvifafjfweek3yebl24ysldpqq2sl24xu3c5zb2y4lqzaml5idr.py", line 157, in call
    buf1 = torch.ops._c10d_functional.reduce_scatter_tensor.default(buf0, 'sum', 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_contiguous_dtensor_noncontiguous_local_as_tangent

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stdout call -----------------------------
frames [('total', 1), ('ok', 1)]
stats [('calls_captured', 1), ('unique_graphs', 1)]
inductor [('triton_bundler_save_kernel', 14), ('extern_calls', 2), ('benchmarking.TritonBenchmarker.benchmark_gpu', 2), ('fxgraph_cache_miss', 1), ('async_compile_cache_miss', 1)]
aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
graph_break []
_________ TestDTensorCompile.test_dtensor_different_gradient_placement _________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 726, in test_dtensor_different_gradient_placement
    tmp_dt = opt_fn(x_dt, y_dt, z_dt)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 709, in fn
    def fn(x, y, z):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 339, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 103, in g
    return f(*args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 2118, in forward
    fw_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 690, in inner_fn
    unwrapped_outs = compiled_fn(unwrapped_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2952, in run
    out = model(new_inputs)
  File "/tmp/torchinductor_jenkins/hv/chvwotqzquc6f6ue2mzmjgmt4x4zyszdpi2ijcwuovqcz5k6wbso.py", line 276, in call
    buf1 = torch.ops._c10d_functional.all_gather_into_tensor.default(buf0, 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_different_gradient_placement

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stdout call -----------------------------
stats [('calls_captured', 4), ('unique_graphs', 1)]
aot_autograd [('total', 1), ('autograd_cache_miss', 1), ('ok', 1)]
inductor [('triton_bundler_save_kernel', 28), ('async_compile_cache_miss', 4), ('extern_calls', 2), ('fxgraph_cache_miss', 1)]
graph_break []
___________________ TestDTensorCompile.test_dtensor_dynamic ____________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 2011, in wrapper
    fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 312, in test_dtensor_dynamic
    ref = fn(x)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 303, in fn
    torch.mul(x, x)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 561, in redistribute
    return Redistribute.apply(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 319, in forward
    output = redistribute_local_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 211, in redistribute_local_tensor
    new_local_tensor = current_placement._to_replicate_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 253, in _to_replicate_tensor
    result = funcol.all_gather_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 199, in all_gather_tensor
    tensor = torch.ops._c10d_functional.all_gather_into_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_dynamic

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
_________________ TestDTensorCompile.test_dtensor_dynamic_cat __________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 378, in test_dtensor_dynamic_cat
    ref = fn(x, y)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 366, in fn
    torch.cat((x, y), dim=0)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 355, in __torch_dispatch__
    return DTensor._op_dispatcher.dispatch(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_dispatch.py", line 183, in dispatch
    self.redistribute_local_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_dispatch.py", line 351, in redistribute_local_args
    resharded_local_tensor = redistribute_local_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 211, in redistribute_local_tensor
    new_local_tensor = current_placement._to_replicate_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 253, in _to_replicate_tensor
    result = funcol.all_gather_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 199, in all_gather_tensor
    tensor = torch.ops._c10d_functional.all_gather_into_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_dynamic_cat

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
______ TestDTensorCompile.test_dtensor_dynamic_loss_parallel_log_softmax _______
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 2011, in wrapper
    fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 352, in test_dtensor_dynamic_loss_parallel_log_softmax
    ref = fn(x)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 345, in fn
    t = torch.nn.functional.log_softmax(x, x.ndim - 1, dtype=torch.float32)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/functional.py", line 2243, in log_softmax
    ret = input.log_softmax(dim, dtype=dtype)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 355, in __torch_dispatch__
    return DTensor._op_dispatcher.dispatch(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_dispatch.py", line 149, in dispatch
    return self._custom_op_handlers[op_call](op_call, args, kwargs)  # type: ignore[operator]
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/loss.py", line 169, in _log_softmax_handler
    res = _log_softmax(x._local_tensor, dim, half_to_float, spec.mesh, mesh_dim)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/loss.py", line 139, in _log_softmax
    x_max = funcol.all_reduce(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 170, in all_reduce
    tensor = torch.ops._c10d_functional.all_reduce(self, reduceOp.lower(), group_name)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_dynamic_loss_parallel_log_softmax

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
________________ TestDTensorCompile.test_dtensor_dynamic_slice _________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 2011, in wrapper
    fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 334, in test_dtensor_dynamic_slice
    ref = fn(x)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 328, in fn
    for t in torch.tensor_split(x, 2)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 355, in __torch_dispatch__
    return DTensor._op_dispatcher.dispatch(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_dispatch.py", line 183, in dispatch
    self.redistribute_local_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_dispatch.py", line 351, in redistribute_local_args
    resharded_local_tensor = redistribute_local_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 211, in redistribute_local_tensor
    new_local_tensor = current_placement._to_replicate_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 253, in _to_replicate_tensor
    result = funcol.all_gather_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 199, in all_gather_tensor
    tensor = torch.ops._c10d_functional.all_gather_into_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_dynamic_slice

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
________ TestDTensorCompile.test_dtensor_partial_placement_graph_output ________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 911, in test_dtensor_partial_placement_graph_output
    out_dt = torch.matmul(tmp_dt, y_dt)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 355, in __torch_dispatch__
    return DTensor._op_dispatcher.dispatch(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_dispatch.py", line 183, in dispatch
    self.redistribute_local_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_dispatch.py", line 351, in redistribute_local_args
    resharded_local_tensor = redistribute_local_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 223, in redistribute_local_tensor
    new_local_tensor = partial_spec._reduce_shard_value(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 695, in _reduce_shard_value
    return shard_spec._reduce_shard_tensor(tensor, mesh, self.reduce_op, mesh_dim)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 221, in _reduce_shard_tensor
    output = funcol.reduce_scatter_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 278, in reduce_scatter_tensor
    tensor = torch.ops._c10d_functional.reduce_scatter_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_partial_placement_graph_output

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
----------------------------- Captured stdout call -----------------------------
stats [('calls_captured', 1), ('unique_graphs', 1)]
aot_autograd [('total', 1), ('autograd_cache_miss', 1), ('ok', 1)]
inductor [('triton_bundler_save_kernel', 7), ('async_compile_cache_miss', 2), ('fxgraph_cache_miss', 1), ('async_compile_cache_hit', 1)]
graph_break []
_ TestDTensorCompile.test_dtensor_partial_placement_redistribute_unbalanced_correct_strides _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 2011, in wrapper
    fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 619, in test_dtensor_partial_placement_redistribute_unbalanced_correct_strides
    tmp_dt = fn(x_dt)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 599, in fn
    out = x.redistribute(mesh, [placement])
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 561, in redistribute
    return Redistribute.apply(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 319, in forward
    output = redistribute_local_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 223, in redistribute_local_tensor
    new_local_tensor = partial_spec._reduce_shard_value(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 695, in _reduce_shard_value
    return shard_spec._reduce_shard_tensor(tensor, mesh, self.reduce_op, mesh_dim)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 221, in _reduce_shard_tensor
    output = funcol.reduce_scatter_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 278, in reduce_scatter_tensor
    tensor = torch.ops._c10d_functional.reduce_scatter_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_partial_placement_redistribute_unbalanced_correct_strides

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
________ TestDTensorCompile.test_dynamo_dtensor_from_local_redistribute ________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 740, in test_dynamo_dtensor_from_local_redistribute
    ref = fn(x)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 737, in fn
    return dt.redistribute(mesh, [Replicate()]).to_local() + 2
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 561, in redistribute
    return Redistribute.apply(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 319, in forward
    output = redistribute_local_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 211, in redistribute_local_tensor
    new_local_tensor = current_placement._to_replicate_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 253, in _to_replicate_tensor
    result = funcol.all_gather_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 199, in all_gather_tensor
    tensor = torch.ops._c10d_functional.all_gather_into_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dynamo_dtensor_from_local_redistribute

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
_____ TestDTensorCompile.test_dynamo_dtensor_from_local_redistribute_async _____
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 2011, in wrapper
    fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 777, in test_dynamo_dtensor_from_local_redistribute_async
    ref = fn(x)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 770, in fn
    out = dt.redistribute(mesh, [Replicate()], async_op=True).to_local()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 561, in redistribute
    return Redistribute.apply(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 319, in forward
    output = redistribute_local_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 211, in redistribute_local_tensor
    new_local_tensor = current_placement._to_replicate_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 253, in _to_replicate_tensor
    result = funcol.all_gather_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 199, in all_gather_tensor
    tensor = torch.ops._c10d_functional.all_gather_into_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dynamo_dtensor_from_local_redistribute_async

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
_________________ TestDTensorCompile.test_graph_input_is_async _________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 2011, in wrapper
    fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 846, in test_graph_input_is_async
    x2 = x_dt.redistribute(mesh, [Replicate()], async_op=True)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 561, in redistribute
    return Redistribute.apply(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 319, in forward
    output = redistribute_local_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 211, in redistribute_local_tensor
    new_local_tensor = current_placement._to_replicate_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 253, in _to_replicate_tensor
    result = funcol.all_gather_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 199, in all_gather_tensor
    tensor = torch.ops._c10d_functional.all_gather_into_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_graph_input_is_async

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
______________ TestDTensorCompile.test_tp_compile_comm_reordering ______________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/mock.py", line 1379, in patched
    return func(*newargs, **newkeywargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 988, in test_tp_compile_comm_reordering
    self._test_tp_compile_comm_reordering()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 962, in _test_tp_compile_comm_reordering
    parallelize_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/api.py", line 122, in parallelize_module
    parallelize_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/api.py", line 130, in parallelize_module
    parallelize_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/api.py", line 86, in parallelize_module
    return parallelize_plan._apply(module, device_mesh)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/style.py", line 158, in _apply
    return distribute_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 937, in distribute_module
    partition_fn(name, submod, device_mesh)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/style.py", line 124, in _partition_linear_fn
    distribute_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 771, in distribute_tensor
    local_tensor = placement._shard_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 183, in _shard_tensor
    mesh_scatter(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_collective_utils.py", line 108, in mesh_scatter
    fut = scatter(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4369, in scatter
    work = group.scatter(output_tensors, input_tensors, opts)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_tp_compile_comm_reordering

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
______ TestDTensorCompile.test_tp_compile_comm_reordering_graph_partition ______
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/mock.py", line 1379, in patched
    return func(*newargs, **newkeywargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 997, in test_tp_compile_comm_reordering_graph_partition
    self._test_tp_compile_comm_reordering()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 962, in _test_tp_compile_comm_reordering
    parallelize_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/api.py", line 122, in parallelize_module
    parallelize_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/api.py", line 130, in parallelize_module
    parallelize_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/api.py", line 86, in parallelize_module
    return parallelize_plan._apply(module, device_mesh)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/style.py", line 158, in _apply
    return distribute_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 937, in distribute_module
    partition_fn(name, submod, device_mesh)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/style.py", line 124, in _partition_linear_fn
    distribute_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 771, in distribute_tensor
    local_tensor = placement._shard_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 183, in _shard_tensor
    mesh_scatter(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_collective_utils.py", line 108, in mesh_scatter
    fut = scatter(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4369, in scatter
    work = group.scatter(output_tensors, input_tensors, opts)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_tp_compile_comm_reordering_graph_partition

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_tensor_test_dtensor_compile.py.xml -
=========================== short test summary info ============================
FAILED [1.6394s] ../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_contiguous_dtensor_noncontiguous_local_as_tangent - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_contiguous_dtensor_noncontiguous_local_as_tangent

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [2.4646s] ../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_different_gradient_placement - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_different_gradient_placement

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0023s] ../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_dynamic - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_dynamic

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0025s] ../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_dynamic_cat - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_dynamic_cat

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0346s] ../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_dynamic_loss_parallel_log_softmax - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_dynamic_loss_parallel_log_softmax

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0023s] ../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_dynamic_slice - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_dynamic_slice

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.2872s] ../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_partial_placement_graph_output - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_partial_placement_graph_output

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0073s] ../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dtensor_partial_placement_redistribute_unbalanced_correct_strides - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_partial_placement_redistribute_unbalanced_correct_strides

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0017s] ../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dynamo_dtensor_from_local_redistribute - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dynamo_dtensor_from_local_redistribute

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0011s] ../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_dynamo_dtensor_from_local_redistribute_async - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dynamo_dtensor_from_local_redistribute_async

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0337s] ../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_graph_input_is_async - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_graph_input_is_async

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0019s] ../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_tp_compile_comm_reordering - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_tp_compile_comm_reordering

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [0.0017s] ../../../../test/distributed/tensor/test_dtensor_compile.py::TestDTensorCompile::test_tp_compile_comm_reordering_graph_partition - RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_tp_compile_comm_reordering_graph_partition

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
================== 13 failed, 29 passed in 519.59s (0:08:39) ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 15:14:15.262] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 3 items
Running 3 items in this shard

../../../../test/distributed/tensor/test_experimental_ops.py::DistOtherOpsTest::test_bernoulli [2025-09-12 15:14:17.422] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:14:17.434] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:14:18:1148742 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:14:18:1148742 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:14:18:1148743 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:14:18:1148743 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.3452s] [ 33%]
../../../../test/distributed/tensor/test_experimental_ops.py::DistOtherOpsTest::test_nll [2025-09-12 15:14:32.546] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:14:32.549] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:14:33:1149091 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:14:33:1149091 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:14:33:1149090 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:14:33:1149090 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.0255s] [ 66%]
../../../../test/distributed/tensor/test_experimental_ops.py::DistOtherOpsTest::test_slice [2025-09-12 15:14:47.573] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:14:47.582] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:14:48:1149248 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:14:48:1149248 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:14:48:1149249 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:14:48:1149249 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.1249s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_tensor_test_experimental_ops.py.xml -
============================== 3 passed in 47.50s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 15:15:03.675] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 7 items
Running 7 items in this shard

../../../../test/distributed/tensor/test_init.py::DTensorInitOpsTest::test_init_ops [2025-09-12 15:15:05.698] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:15:05.707] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:15:05.714] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:15:05.722] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:15:06:1149675 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:15:06:1149675 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:15:06:1149673 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:15:06:1149673 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:15:06:1149674 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:15:06:1149674 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:15:06:1149672 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:15:06:1149672 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7287s] [ 14%]
../../../../test/distributed/tensor/test_init.py::DTensorConstructorTest::test_empty [2025-09-12 15:15:21.371] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:15:21.374] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:15:21.383] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:15:21.395] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:15:22:1149974 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:15:22:1149974 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:15:22:1149972 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:15:22:1149972 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:15:22:1149975 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:15:22:1149975 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:15:22:1149973 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:15:22:1149973 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6299s] [ 28%]
../../../../test/distributed/tensor/test_init.py::DTensorConstructorTest::test_full [2025-09-12 15:15:36.961] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:15:36.963] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:15:36.963] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:15:37.004] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:15:37:1150272 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:15:37:1150272 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:15:37:1150274 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:15:37:1150274 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:15:37:1150275 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:15:37:1150275 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:15:37:1150273 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:15:37:1150273 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.4293s] [ 42%]
../../../../test/distributed/tensor/test_init.py::DTensorConstructorTest::test_ones [2025-09-12 15:15:52.407] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:15:52.418] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:15:52.430] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:15:52.430] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:15:53:1150574 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:15:53:1150574 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:15:53:1150573 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:15:53:1150573 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:15:53:1150575 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:15:53:1150575 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:15:53:1150576 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:15:53:1150576 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5292s] [ 57%]
../../../../test/distributed/tensor/test_init.py::DTensorConstructorTest::test_zeros [2025-09-12 15:16:07.969] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:16:07.978] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:16:07.982] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:16:07.988] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:16:08:1150875 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:16:08:1150875 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:16:08:1150876 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:16:08:1150876 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:16:08:1150873 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:16:08:1150873 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:16:08:1150874 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:16:08:1150874 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8285s] [ 71%]
../../../../test/distributed/tensor/test_init.py::DTensorConstructorTest::test_zeros_full_mesh [2025-09-12 15:16:23.762] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:16:23.782] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:16:23.788] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:16:23.788] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:16:24:1151174 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:16:24:1151174 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:16:24:1151176 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:16:24:1151176 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:16:24:1151175 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:16:24:1151175 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:16:24:1151177 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:16:24:1151177 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6253s] [ 85%]
../../../../test/distributed/tensor/test_init.py::DTensorConstructorTest::test_zeros_submesh [2025-09-12 15:16:39.401] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:16:39.413] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:16:39.413] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:16:39.414] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:16:40:1151484 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:16:40:1151484 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:16:40:1151485 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:16:40:1151485 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:16:40:1151483 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:16:40:1151483 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:16:40:1151486 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:16:40:1151486 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7295s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_tensor_test_init.py.xml -
======================== 7 passed in 111.49s (0:01:51) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 15:16:56.611] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 20 items
Running 20 items in this shard

../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_conj_complex_dtensor [2025-09-12 15:16:58.802] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:16:58.804] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:16:58.806] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:16:58.806] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:16:59:1151868 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:16:59:1151868 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:16:59:1151867 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:16:59:1151867 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:16:59:1151869 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:16:59:1151869 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:16:59:1151866 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:16:59:1151866 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9135s] [  5%]
../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_cumsum [2025-09-12 15:17:14.526] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:17:14.546] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:17:14.578] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:17:14.578] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:17:14:1152172 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:17:14:1152172 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:17:14:1152169 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:17:14:1152169 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:17:14:1152170 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:17:14:1152170 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:17:14:1152171 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:17:14:1152171 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8295s] [ 10%]
../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_foreach_add_different_mesh [2025-09-12 15:17:30.335] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:17:30.337] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:17:30.401] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:17:30.418] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:17:30:1152473 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:17:30:1152473 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:17:30:1152472 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:17:30:1152472 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:17:30:1152471 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:17:30:1152471 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:17:31:1152470 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:17:31:1152470 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9226s] [ 15%]
../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_foreach_norm [2025-09-12 15:17:46.268] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:17:46.290] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:17:46.304] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:17:46.322] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:17:46:1152779 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:17:46:1152779 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:17:46:1152780 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:17:46:1152780 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:17:46:1152778 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:17:46:1152778 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:17:46:1152781 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:17:46:1152781 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6293s] [ 20%]
../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_foreach_norm_different_mesh [2025-09-12 15:18:01.890] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:18:01.937] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:18:01.943] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:18:01.962] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:18:02:1153082 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:18:02:1153082 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:18:02:1153080 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:18:02:1153080 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:18:02:1153081 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:18:02:1153081 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:18:02:1153083 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:18:02:1153083 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.4287s] [ 25%]
../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_histc [2025-09-12 15:18:17.318] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:18:17.383] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:18:17.394] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:18:17.410] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:18:17:1153390 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:18:17:1153390 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:18:17:1153389 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:18:17:1153389 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:18:17:1153388 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:18:17:1153388 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:18:17:1153391 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:18:17:1153391 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9333s] [ 30%]
../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_layer_norm_bwd [2025-09-12 15:18:33.275] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:18:33.287] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:18:33.310] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:18:33.314] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:18:33:1154070 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:18:33:1154070 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:18:33:1154071 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:18:33:1154071 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:18:33:1154069 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:18:33:1154069 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:18:33:1154068 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:18:33:1154068 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.2272s] [ 35%]
../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_layer_norm_bwd_req_grad [2025-09-12 15:18:49.499] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:18:49.510] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:18:49.518] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:18:49.526] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:18:49:1154385 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:18:49:1154385 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:18:49:1154384 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:18:49:1154384 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:18:49:1154387 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:18:49:1154387 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:18:49:1154386 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:18:49:1154386 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.7483s] [ 40%]
../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_layer_norm_fwd [2025-09-12 15:19:21.243] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:19:21.254] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:19:21.270] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:19:21.282] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:19:21:1154704 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:19:21:1154704 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:19:21:1154701 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:19:21:1154701 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:19:21:1154702 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:19:21:1154702 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:19:21:1154703 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:19:21:1154703 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0268s] [ 45%]
../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_linalg_eigh [2025-09-12 15:19:37.269] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:19:37.286] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:19:37.290] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:19:37.326] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:19:37:1155002 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:19:37:1155002 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:19:37:1155005 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:19:37:1155005 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:19:37:1155003 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:19:37:1155003 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:19:37:1155004 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:19:37:1155004 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7245s] [ 50%]
../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_linear_op_reductions [2025-09-12 15:19:53.035] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:19:53.035] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:19:53.044] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:19:53.046] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:19:53:1155305 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:19:53:1155305 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:19:53:1155304 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:19:53:1155304 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:19:53:1155302 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:19:53:1155302 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:19:53:1155303 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:19:53:1155303 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.4275s] [ 55%]
../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_mean [2025-09-12 15:20:09.438] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:20:09.439] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:20:09.450] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:20:09.464] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:20:09:1155985 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:20:09:1155985 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:20:09:1155986 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:20:09:1155986 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:20:09:1155983 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:20:09:1155983 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:20:09:1155984 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:20:09:1155984 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5292s] [ 60%]
../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_nll_loss_and_cross_entropy [2025-09-12 15:20:24.975] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:20:24.993] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:20:24.998] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:20:25.010] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:20:25:1156284 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:20:25:1156284 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:20:25:1156286 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:20:25:1156286 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:20:25:1156285 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:20:25:1156285 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:20:25:1156283 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:20:25:1156283 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.3312s] [ 65%]
../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_rotary_embedding_complex_ops [2025-09-12 15:20:41.362] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:20:41.378] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:20:41.418] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:20:41.434] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:20:41:1156600 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:20:41:1156600 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:20:41:1156602 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:20:41:1156602 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:20:41:1156599 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:20:41:1156599 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:20:41:1156601 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:20:41:1156601 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9300s] [ 70%]
../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_shard0_svd [2025-09-12 15:20:57.214] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:20:57.281] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:20:57.281] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:20:57.334] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:20:57:1156918 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:20:57:1156918 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:20:57:1156917 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:20:57:1156917 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:20:57:1156919 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:20:57:1156919 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:20:57:1156916 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:20:57:1156916 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9299s] [ 75%]
../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_shard_math_ops [2025-09-12 15:21:13.152] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:21:13.174] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:21:13.208] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:21:13.208] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:21:13:1157218 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:21:13:1157218 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:21:13:1157217 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:21:13:1157217 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:21:13:1157216 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:21:13:1157216 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:21:13:1157219 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:21:13:1157219 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:21:14:1157218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:21:14:1157219:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:21:14:1157216:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:21:14:1157217:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:21:14:1157216:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:21:14:1157218:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:21:14:1157219:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:21:14:1157217:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [16.3304s] [ 80%]
../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_softmax_fwd [2025-09-12 15:21:29.471] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:21:29.490] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:21:29.499] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:21:29.506] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:21:29:1157535 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:21:29:1157535 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:21:29:1157533 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:21:29:1157533 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:21:29:1157534 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:21:29:1157534 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:21:29:1157532 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:21:29:1157532 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8296s] [ 85%]
../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_softmax_with_bwd [2025-09-12 15:21:45.407] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:21:45.416] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:21:45.424] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:21:45.436] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:21:45:1157836 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:21:45:1157836 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:21:45:1157835 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:21:45:1157835 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:21:45:1157834 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:21:45:1157834 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:21:45:1157833 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:21:45:1157833 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.1304s] [ 90%]
../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_topk [2025-09-12 15:22:01.443] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:22:01.463] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:22:01.463] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:22:01.514] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:22:01:1158153 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:22:01:1158153 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:22:01:1158151 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:22:01:1158151 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:22:01:1158150 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:22:01:1158150 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:22:01:1158152 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:22:01:1158152 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6293s] [ 95%]
../../../../test/distributed/tensor/test_math_ops.py::DistMathOpsTest::test_upsampling [2025-09-12 15:22:17.085] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:22:17.090] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:22:17.106] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:22:17.122] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:22:17:1158451 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:22:17:1158451 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:22:17:1158452 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:22:17:1158452 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:22:17:1158454 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:22:17:1158454 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:22:17:1158453 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:22:17:1158453 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7295s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_tensor_test_math_ops.py.xml -
======================== 20 passed in 336.21s (0:05:36) ========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 15:22:33.739] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 13 items
Running 13 items in this shard

../../../../test/distributed/tensor/test_random_ops.py::DistTensorRandomInitTest::test_fsdp_tp_model_meta_init [2025-09-12 15:22:35.907] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:22:35.918] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:22:35.919] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:22:35.939] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:22:36:1158827 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:22:36:1158827 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:22:36:1158829 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:22:36:1158829 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:22:36:1158828 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:22:36:1158828 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:22:36:1158830 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:22:36:1158830 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9134s] [  7%]
../../../../test/distributed/tensor/test_random_ops.py::DistTensorRandomInitTest::test_init_ops [2025-09-12 15:22:51.606] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:22:51.668] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:22:51.683] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:22:51.702] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:22:51:1159136 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:22:51:1159136 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:22:51:1159138 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:22:51:1159138 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:22:51:1159137 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:22:51:1159137 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:22:52:1159135 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:22:52:1159135 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7282s] [ 15%]
../../../../test/distributed/tensor/test_random_ops.py::DistTensorRandomInitTest::test_init_with_user_generator [2025-09-12 15:23:07.371] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:23:07.386] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:23:07.390] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:23:07.422] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:23:07:1159437 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:23:07:1159437 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:23:07:1159436 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:23:07:1159436 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:23:07:1159439 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:23:07:1159439 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:23:07:1159438 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:23:07:1159438 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8225s] [ 23%]
../../../../test/distributed/tensor/test_random_ops.py::DistTensorRandomInitTest::test_meta_tensor_init [2025-09-12 15:23:23.180] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:23:23.181] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:23:23.190] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:23:23.222] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:23:23:1159739 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:23:23:1159739 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:23:23:1159737 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:23:23:1159737 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:23:23:1159736 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:23:23:1159736 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:23:23:1159738 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:23:23:1159738 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7296s] [ 30%]
../../../../test/distributed/tensor/test_random_ops.py::DistTensorRandomInitTest::test_tp_model_meta_init [2025-09-12 15:23:38.908] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:23:38.918] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:23:38.936] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:23:38.958] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:23:39:1160038 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:23:39:1160038 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:23:39:1160036 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:23:39:1160036 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:23:39:1160037 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:23:39:1160037 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:23:39:1160039 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:23:39:1160039 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9303s] [ 38%]
../../../../test/distributed/tensor/test_random_ops.py::DistTensorRandomOpTest::test_deterministic_dropout_1d [2025-09-12 15:23:54.839] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:23:54.863] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:23:54.886] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:23:54.889] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:23:55:1160339 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:23:55:1160339 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:23:55:1160336 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:23:55:1160336 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:23:55:1160338 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:23:55:1160338 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:23:55:1160337 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:23:55:1160337 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8279s] [ 46%]
../../../../test/distributed/tensor/test_random_ops.py::DistTensorRandomOpTest::test_deterministic_rand_1d [2025-09-12 15:24:10.673] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:24:10.673] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:24:10.688] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:24:10.692] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:24:10:1160640 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:24:10:1160640 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:24:10:1160641 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:24:10:1160641 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:24:10:1160639 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:24:10:1160639 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:24:10:1160642 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:24:10:1160642 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7295s] [ 53%]
../../../../test/distributed/tensor/test_random_ops.py::DistTensorRandomOpTest::test_deterministic_uniform_2d [2025-09-12 15:24:26.418] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:24:26.430] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:24:26.430] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:24:26.436] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:24:26:1160941 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:24:26:1160941 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:24:26:1160940 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:24:26:1160940 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:24:26:1160942 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:24:26:1160942 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:24:26:1160939 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:24:26:1160939 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:24:27:1160941:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:24:27:1160942:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:24:27:1160939:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:24:27:1160940:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:24:27:1160939:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:24:27:1160940:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:24:27:1160942:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:24:27:1160941:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [16.8317s] [ 61%]
../../../../test/distributed/tensor/test_random_ops.py::DistTensorRandomOpTest::test_manual_seed [2025-09-12 15:24:43.236] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:24:43.236] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:24:43.250] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:24:43.254] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:24:43:1161257 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:24:43:1161257 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:24:43:1161258 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:24:43:1161258 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:24:43:1161255 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:24:43:1161255 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:24:43:1161256 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:24:43:1161256 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6286s] [ 69%]
../../../../test/distributed/tensor/test_random_ops.py::DistTensorRandomOpTest::test_manual_seed_submesh [2025-09-12 15:24:58.861] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:24:58.882] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:24:58.891] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:24:58.914] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:24:59:1161559 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:24:59:1161559 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:24:59:1161558 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:24:59:1161558 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:24:59:1161556 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:24:59:1161556 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:24:59:1161557 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:24:59:1161557 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5291s] [ 76%]
../../../../test/distributed/tensor/test_random_ops.py::DistTensorRandomOpTest::test_pipeline_parallel_manual_seed [2025-09-12 15:25:14.378] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:25:14.455] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:25:14.457] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:25:14.470] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:25:14:1161858 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:25:14:1161858 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:25:14:1161859 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:25:14:1161859 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:25:14:1161857 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:25:14:1161857 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:25:14:1161860 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:25:14:1161860 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7294s] [ 84%]
../../../../test/distributed/tensor/test_random_ops.py::DistTensorRandomOpTest::test_rng_tracker_init [2025-09-12 15:25:30.139] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:25:30.145] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:25:30.145] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:25:30.177] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:25:30:1162168 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:25:30:1162168 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:25:30:1162166 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:25:30:1162166 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:25:30:1162167 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:25:30:1162167 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:25:30:1162165 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:25:30:1162165 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6302s] [ 92%]
../../../../test/distributed/tensor/test_random_ops.py::DistTensorRandomOpsTest3D::test_hsdp_tp_model_meta_init [2025-09-12 15:25:45.846] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:25:45.852] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:25:45.852] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:25:45.859] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:25:45.867] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:25:45.868] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:25:45.878] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:25:45.891] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [3.0113s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_tensor_test_random_ops.py.xml -
================== 12 passed, 1 skipped in 195.05s (0:03:15) ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 15:25:49.727] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 21 items
Running 21 items in this shard

../../../../test/distributed/tensor/test_redistribute.py::RedistributeTest::test_partial_to_replicate_forward_backward_complex64 [2025-09-12 15:25:51.964] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:25:51.974] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:25:51.981] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:25:51.981] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:25:52:1163111 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:25:52:1163111 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:25:52:1163113 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:25:52:1163113 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:25:52:1163110 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:25:52:1163110 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:25:52:1163112 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:25:52:1163112 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0335s] [  4%]
../../../../test/distributed/tensor/test_redistribute.py::RedistributeTest::test_partial_to_replicate_forward_backward_float32 [2025-09-12 15:26:07.723] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:26:07.751] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:26:07.757] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:26:07.765] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:26:07:1163426 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:26:07:1163426 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:26:07:1163429 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:26:07:1163429 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:26:07:1163427 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:26:07:1163427 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:26:08:1163428 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:26:08:1163428 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5292s] [  9%]
../../../../test/distributed/tensor/test_redistribute.py::RedistributeTest::test_partial_to_shard_complex64 [2025-09-12 15:26:23.246] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:26:23.321] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:26:23.321] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:26:23.343] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:26:23:1163743 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:26:23:1163743 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:26:23:1163745 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:26:23:1163745 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:26:23:1163742 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:26:23:1163742 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:26:23:1163744 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:26:23:1163744 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [30.5532s] [ 14%]
../../../../test/distributed/tensor/test_redistribute.py::RedistributeTest::test_partial_to_shard_float32 [2025-09-12 15:26:53.828] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:26:53.846] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:26:53.858] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:26:53.878] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:26:54:1164045 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:26:54:1164045 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:26:54:1164043 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:26:54:1164043 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:26:54:1164046 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:26:54:1164046 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:26:54:1164044 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:26:54:1164044 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [30.8551s] [ 19%]
../../../../test/distributed/tensor/test_redistribute.py::RedistributeTest::test_redistribute_negative_shard_dim [2025-09-12 15:27:24.706] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:27:24.708] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:27:24.726] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:27:24.730] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:27:24:1164347 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:27:24:1164347 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:27:24:1164345 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:27:24:1164345 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:27:24:1164346 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:27:24:1164346 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:27:24:1164348 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:27:24:1164348 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6294s] [ 23%]
../../../../test/distributed/tensor/test_redistribute.py::RedistributeTest::test_redistribute_shard_dim_change_complex64 [2025-09-12 15:27:40.290] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:27:40.366] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:27:40.383] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:27:40.387] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:27:40:1164649 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:27:40:1164649 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:27:40:1164647 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:27:40:1164647 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:27:40:1164648 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:27:40:1164648 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:27:40:1164650 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:27:40:1164650 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:27:42:1164647:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:27:42:1164650:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:27:42:1164648:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:27:42:1164649:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:27:42:1164647:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:27:42:1164648:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:27:42:1164649:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:27:42:1164650:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [16.7307s] [ 28%]
../../../../test/distributed/tensor/test_redistribute.py::RedistributeTest::test_redistribute_shard_dim_change_float32 [2025-09-12 15:27:57.102] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:27:57.114] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:27:57.122] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:27:57.130] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:27:57:1164967 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:27:57:1164967 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:27:57:1164964 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:27:57:1164964 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:27:57:1164965 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:27:57:1164965 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:27:57:1164966 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:27:57:1164966 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:27:58:1164966:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:27:58:1164964:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:27:58:1164965:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:27:58:1164967:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:27:59:1164964:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:27:59:1164965:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:27:59:1164966:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:27:59:1164967:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [16.8314s] [ 33%]
../../../../test/distributed/tensor/test_redistribute.py::RedistributeTest::test_redistribute_uneven_sharding [2025-09-12 15:28:13.882] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:28:13.882] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:28:13.895] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:28:13.906] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:28:14:1165281 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:28:14:1165281 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:28:14:1165284 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:28:14:1165282 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:28:14:1165284 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:28:14:1165282 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:28:14:1165283 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:28:14:1165283 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:28:14:1165281:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:28:14:1165282:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:28:14:1165283:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:28:14:1165284:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:28:15:1165283:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:28:15:1165284:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:28:15:1165281:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:28:15:1165282:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [16.5310s] [ 38%]
../../../../test/distributed/tensor/test_redistribute.py::RedistributeTest::test_replicate_to_local_partial_grad_complex64 [2025-09-12 15:28:30.400] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:28:30.414] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:28:30.434] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:28:30.446] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:28:30:1165601 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:28:30:1165601 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:28:30:1165598 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:28:30:1165598 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:28:30:1165599 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:28:30:1165599 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:28:30:1165600 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:28:30:1165600 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.4290s] [ 42%]
../../../../test/distributed/tensor/test_redistribute.py::RedistributeTest::test_replicate_to_local_partial_grad_float32 [2025-09-12 15:28:45.832] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:28:45.834] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:28:45.850] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:28:45.859] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:28:46:1165916 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:28:46:1165916 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:28:46:1165914 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:28:46:1165914 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:28:46:1165915 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:28:46:1165915 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:28:46:1165917 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:28:46:1165917 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5297s] [ 47%]
../../../../test/distributed/tensor/test_redistribute.py::RedistributeTest::test_replicate_to_partial [2025-09-12 15:29:01.364] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:29:01.382] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:29:01.390] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:29:01.414] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:29:01:1166231 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:29:01:1166231 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:29:01:1166234 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:29:01:1166234 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:29:01:1166233 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:29:01:1166233 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:29:01:1166232 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:29:01:1166232 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:29:02:1166232:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:29:02:1166234:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:29:02:1166231:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:29:02:1166233:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:29:03:1166233:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:29:03:1166234:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:29:03:1166231:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:29:03:1166232:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [16.4306s] [ 52%]
../../../../test/distributed/tensor/test_redistribute.py::RedistributeTest::test_replicate_to_replicate_forward_backward [2025-09-12 15:29:17.790] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:29:17.850] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:29:17.854] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:29:17.862] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:29:17:1166550 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:29:17:1166550 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:29:18:1166549 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:29:18:1166549 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:29:18:1166548 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:29:18:1166548 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:29:18:1166547 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:29:18:1166547 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8293s] [ 57%]
../../../../test/distributed/tensor/test_redistribute.py::RedistributeTest::test_replicate_to_replicate_forward_backward_datatype_conversion [2025-09-12 15:29:33.615] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:29:33.641] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:29:33.641] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:29:33.648] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:29:33:1166866 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:29:33:1166866 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:29:33:1166863 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:29:33:1166863 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:29:33:1166864 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:29:33:1166864 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:29:33:1166865 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:29:33:1166865 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5290s] [ 61%]
../../../../test/distributed/tensor/test_redistribute.py::RedistributeTest::test_replicate_to_shard_forward_backward [2025-09-12 15:29:49.206] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:29:49.210] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:29:49.221] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:29:49.228] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:29:49:1167182 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:29:49:1167182 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:29:49:1167180 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:29:49:1167180 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:29:49:1167181 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:29:49:1167181 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:29:49:1167179 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:29:49:1167179 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8302s] [ 66%]
../../../../test/distributed/tensor/test_redistribute.py::RedistributeTest::test_shard_dim_alltoall_complex64 [2025-09-12 15:30:05.042] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:30:05.048] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:30:05.050] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:30:05.054] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:30:05:1167497 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:30:05:1167497 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:30:05:1167496 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:30:05:1167496 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:30:05:1167498 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:30:05:1167498 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:30:05:1167499 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:30:05:1167499 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:30:06:1167496:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:30:06:1167497:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:30:06:1167498:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:30:06:1167499:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [16.1366s] [ 71%]
../../../../test/distributed/tensor/test_redistribute.py::RedistributeTest::test_shard_dim_alltoall_float32 [2025-09-12 15:30:21.122] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:30:21.138] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:30:21.170] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:30:21.170] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:30:21:1167812 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:30:21:1167812 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:30:21:1167811 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:30:21:1167811 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:30:21:1167809 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:30:21:1167809 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:30:21:1167810 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:30:21:1167810 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:30:22:1167809:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:30:22:1167811:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:30:22:1167812:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:30:22:1167810:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [16.0299s] [ 76%]
../../../../test/distributed/tensor/test_redistribute.py::RedistributeTest::test_shard_to_replicate_forward_backward_complex64 [2025-09-12 15:30:37.234] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:30:37.238] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:30:37.244] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:30:37.266] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:30:37:1168127 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:30:37:1168127 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:30:37:1168129 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:30:37:1168129 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:30:37:1168128 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:30:37:1168128 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:30:37:1168126 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:30:37:1168126 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9302s] [ 80%]
../../../../test/distributed/tensor/test_redistribute.py::RedistributeTest::test_shard_to_replicate_forward_backward_datatype_conversion [2025-09-12 15:30:53.087] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:30:53.113] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:30:53.113] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:30:53.116] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:30:53:1168445 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:30:53:1168445 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:30:53:1168444 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:30:53:1168444 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:30:53:1168447 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:30:53:1168447 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:30:53:1168446 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:30:53:1168446 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0301s] [ 85%]
../../../../test/distributed/tensor/test_redistribute.py::RedistributeTest::test_shard_to_replicate_forward_backward_float32 [2025-09-12 15:31:09.124] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:31:09.142] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:31:09.152] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:31:09.170] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:31:09:1168761 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:31:09:1168761 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:31:09:1168763 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:31:09:1168763 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:31:09:1168760 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:31:09:1168760 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:31:09:1168762 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:31:09:1168762 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9298s] [ 90%]
../../../../test/distributed/tensor/test_redistribute.py::MultiDimRedistributeTest::test_multi_dim_mesh [2025-09-12 15:31:25.057] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:31:25.066] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:31:25.130] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:31:25.154] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [2.9089s] [ 95%]
../../../../test/distributed/tensor/test_redistribute.py::MultiDimRedistributeTest::test_redistribute_shard_dim_multi_dim_mesh [2025-09-12 15:31:27.975] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:31:27.976] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:31:27.990] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:31:27.992] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [2.8084s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_tensor_test_redistribute.py.xml -
================== 19 passed, 2 skipped in 341.06s (0:05:41) ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 15:31:31.606] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 30 items
Running 30 items in this shard

../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_aten_contiguous [2025-09-12 15:31:33.795] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:31:33.808] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:31:33.822] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:31:33.824] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:31:34:1169726 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:31:34:1169726 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:31:34:1169728 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:31:34:1169728 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:31:34:1169727 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:31:34:1169727 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:31:34:1169729 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:31:34:1169729 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8052s] [  3%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_clone [2025-09-12 15:31:49.416] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:31:49.424] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:31:49.438] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:31:49.462] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:31:49:1170027 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:31:49:1170027 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:31:49:1170030 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:31:49:1170030 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:31:49:1170028 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:31:49:1170028 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:31:49:1170029 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:31:49:1170029 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7261s] [  6%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_contiguous [2025-09-12 15:32:05.166] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:32:05.166] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:32:05.173] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:32:05.190] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:32:05:1170330 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:32:05:1170330 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:32:05:1170331 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:32:05:1170331 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:32:05:1170329 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:32:05:1170329 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:32:05:1170332 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:32:05:1170332 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5309s] [ 10%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_copy_ [2025-09-12 15:32:20.679] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:32:20.700] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:32:20.700] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:32:20.701] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:32:20:1170649 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:32:20:1170649 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:32:20:1170647 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:32:20:1170647 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:32:20:1170646 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:32:20:1170646 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:32:20:1170648 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:32:20:1170648 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [17.5365s] [ 13%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_detach [2025-09-12 15:32:38.235] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:32:38.244] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:32:38.244] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:32:38.245] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:32:38:1171328 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:32:38:1171328 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:32:38:1171329 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:32:38:1171329 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:32:38:1171331 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:32:38:1171331 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:32:38:1171330 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:32:38:1171330 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5295s] [ 16%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_dtensor_dtype_conversion [2025-09-12 15:32:53.738] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:32:53.750] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:32:53.763] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:32:53.782] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:32:53:1171629 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:32:53:1171629 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:32:53:1171631 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:32:53:1171631 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:32:54:1171630 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:32:54:1171630 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:32:54:1171628 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:32:54:1171628 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7300s] [ 20%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_empty_like [2025-09-12 15:33:09.455] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:33:09.469] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:33:09.479] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:33:09.501] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:33:09:1171931 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:33:09:1171931 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:33:09:1171933 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:33:09:1171933 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:33:09:1171930 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:33:09:1171930 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:33:09:1171932 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:33:09:1171932 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5296s] [ 23%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_equal [2025-09-12 15:33:25.046] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:33:25.057] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:33:25.078] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:33:25.086] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:33:25:1172232 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:33:25:1172232 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:33:25:1172233 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:33:25:1172233 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:33:25:1172230 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:33:25:1172230 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:33:25:1172231 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:33:25:1172231 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0302s] [ 26%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_fill_inplace [2025-09-12 15:33:41.014] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:33:41.061] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:33:41.061] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:33:41.061] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:33:41:1172532 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:33:41:1172532 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:33:41:1172534 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:33:41:1172534 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:33:41:1172531 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:33:41:1172531 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:33:41:1172533 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:33:41:1172533 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6293s] [ 30%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_fill_inplace_partial_sum [2025-09-12 15:33:56.658] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:33:56.704] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:33:56.710] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:33:56.738] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:33:56:1172834 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:33:56:1172834 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:33:56:1172833 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:33:56:1172833 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:33:56:1172832 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:33:56:1172832 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:33:57:1172831 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:33:57:1172831 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6293s] [ 33%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_full_like [2025-09-12 15:34:12.310] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:34:12.311] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:34:12.326] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:34:12.350] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:34:12:1173134 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:34:12:1173134 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:34:12:1173135 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:34:12:1173135 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:34:12:1173132 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:34:12:1173132 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:34:12:1173133 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:34:12:1173133 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.4284s] [ 36%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_gather [2025-09-12 15:34:27.734] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:34:27.738] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:34:27.742] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:34:27.762] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:34:27:1173435 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:34:27:1173435 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:34:27:1173433 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:34:27:1173433 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:34:27:1173432 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:34:27:1173432 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:34:27:1173434 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:34:27:1173434 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9305s] [ 40%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_index [2025-09-12 15:34:43.649] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:34:43.670] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:34:43.675] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:34:43.675] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:34:43:1173734 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:34:43:1173734 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:34:43:1173732 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:34:43:1173732 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:34:43:1173733 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:34:43:1173733 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:34:43:1173735 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:34:43:1173735 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [164.3249s] [ 43%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_index_put_scalar [2025-09-12 15:37:28.075] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:37:28.076] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:37:28.077] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:37:28.086] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:37:28:1174437 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:37:28:1174437 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:37:28:1174435 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:37:28:1174435 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:37:28:1174434 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:37:28:1174434 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:37:28:1174436 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:37:28:1174436 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:37:29:1174436:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:37:29:1174437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:37:29:1174434:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:37:29:1174435:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:37:29:1174434:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:37:29:1174435:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:37:29:1174436:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:37:29:1174437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [16.6312s] [ 46%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_index_put_tensor [2025-09-12 15:37:44.602] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:37:44.659] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:37:44.675] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:37:44.694] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:37:44:1174752 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:37:44:1174752 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:37:44:1174754 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:37:44:1174754 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:37:44:1174753 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:37:44:1174753 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:37:44:1174751 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:37:44:1174751 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:37:45:1174753:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:37:45:1174752:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:37:45:1174751:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:37:45:1174754:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:37:46:1174751:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:37:46:1174753:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:37:46:1174754:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:37:46:1174752:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [17.0316s] [ 50%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_inplace_op [2025-09-12 15:38:01.659] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:38:01.679] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:38:01.706] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:38:01.710] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:38:01:1175071 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:38:01:1175071 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:38:01:1175070 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:38:01:1175070 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:38:01:1175069 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:38:01:1175069 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:38:01:1175072 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:38:01:1175072 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [30.7516s] [ 53%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_new_empty_strided [2025-09-12 15:38:32.381] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:38:32.401] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:38:32.402] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:38:32.447] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:38:32:1175371 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:38:32:1175371 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:38:32:1175370 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:38:32:1175370 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:38:32:1175372 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:38:32:1175372 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:38:32:1175369 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:38:32:1175369 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7219s] [ 56%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_new_full [2025-09-12 15:38:48.131] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:38:48.133] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:38:48.146] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:38:48.158] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:38:48:1175671 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:38:48:1175671 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:38:48:1175672 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:38:48:1175672 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:38:48:1175670 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:38:48:1175670 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:38:48:1175669 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:38:48:1175669 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6300s] [ 60%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_ones_like [2025-09-12 15:39:03.769] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:39:03.773] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:39:03.773] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:39:03.784] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:39:03:1175970 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:39:03:1175970 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:39:03:1175973 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:39:03:1175973 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:39:04:1175971 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:39:04:1175971 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:39:04:1175972 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:39:04:1175972 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5296s] [ 63%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_ones_like_partial_sum [2025-09-12 15:39:19.302] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:39:19.302] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:39:19.314] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:39:19.326] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:39:19:1176270 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:39:19:1176270 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:39:19:1176272 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:39:19:1176272 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:39:19:1176273 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:39:19:1176273 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:39:19:1176271 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:39:19:1176271 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6294s] [ 66%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_op_out_variant [2025-09-12 15:39:34.887] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:39:34.906] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:39:34.967] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:39:34.979] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:39:35:1176577 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:39:35:1176577 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:39:35:1176574 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:39:35:1176574 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:39:35:1176576 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:39:35:1176576 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:39:35:1176575 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:39:35:1176575 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8222s] [ 70%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_scatter [2025-09-12 15:39:50.739] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:39:50.755] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:39:50.755] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:39:50.763] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:39:50:1176877 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:39:50:1176877 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:39:50:1176876 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:39:50:1176876 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:39:50:1176875 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:39:50:1176875 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:39:50:1176878 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:39:50:1176878 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6259s] [ 73%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_slice [2025-09-12 15:40:06.387] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:40:06.406] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:40:06.410] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:40:06.418] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:40:06:1177179 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:40:06:1177179 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:40:06:1177178 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:40:06:1177178 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:40:06:1177177 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:40:06:1177177 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:40:06:1177176 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:40:06:1177176 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5208s] [ 76%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_split_on_partial [2025-09-12 15:40:21.914] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:40:21.917] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:40:21.918] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:40:21.926] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:40:22:1177493 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:40:22:1177493 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:40:22:1177492 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:40:22:1177492 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:40:22:1177495 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:40:22:1177495 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:40:22:1177494 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:40:22:1177494 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0276s] [ 80%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_stack [2025-09-12 15:40:37.911] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:40:37.925] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:40:37.934] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:40:37.962] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:40:38:1177795 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:40:38:1177795 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:40:38:1177792 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:40:38:1177792 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:40:38:1177793 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:40:38:1177793 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:40:38:1177794 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:40:38:1177794 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5246s] [ 83%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_unbind [2025-09-12 15:40:53.422] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:40:53.474] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:40:53.477] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:40:53.495] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:40:53:1178101 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:40:53:1178101 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:40:53:1178104 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:40:53:1178104 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:40:53:1178103 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:40:53:1178103 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:40:53:1178102 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:40:53:1178102 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8294s] [ 86%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_where_type_promotion [2025-09-12 15:41:09.259] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:41:09.274] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:41:09.284] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:41:09.285] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:41:09:1178401 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:41:09:1178401 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:41:09:1178403 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:41:09:1178403 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:41:09:1178404 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:41:09:1178404 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:41:09:1178402 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:41:09:1178402 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6289s] [ 90%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_zero_inplace [2025-09-12 15:41:24.929] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:41:24.936] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:41:24.946] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:41:24.958] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:41:25:1178701 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:41:25:1178701 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:41:25:1178702 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:41:25:1178702 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:41:25:1178704 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:41:25:1178704 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:41:25:1178703 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:41:25:1178703 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5295s] [ 93%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_zeros_like [2025-09-12 15:41:40.430] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:41:40.431] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:41:40.442] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:41:40.470] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:41:40:1179005 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:41:40:1179005 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:41:40:1179003 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:41:40:1179003 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:41:40:1179004 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:41:40:1179004 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:41:40:1179006 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:41:40:1179006 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5297s] [ 96%]
../../../../test/distributed/tensor/test_tensor_ops.py::DistTensorOpsTest::test_zeros_like_partial_sum [2025-09-12 15:41:56.019] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:41:56.029] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:41:56.034] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:41:56.050] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:41:56:1179305 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:41:56:1179305 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:41:56:1179303 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:41:56:1179303 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:41:56:1179304 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:41:56:1179304 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:41:56:1179306 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:41:56:1179306 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6299s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_tensor_test_tensor_ops.py.xml -
======================== 30 passed in 639.90s (0:10:39) ========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 15:42:12.076] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/tensor/experimental/test_register_sharding.py::TestRegisterSharding::test_argmax [2025-09-12 15:42:14.242] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:42:14.247] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:42:14.249] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:42:14.258] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:42:15:1179680 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:42:15:1179680 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:42:15:1179681 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:42:15:1179681 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:42:15:1179678 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:42:15:1179678 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:42:15:1179679 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:42:15:1179679 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8284s] [ 50%]
../../../../test/distributed/tensor/experimental/test_register_sharding.py::TestRegisterSharding::test_softmax_fwd [2025-09-12 15:42:29.890] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:42:29.902] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:42:29.909] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:42:29.914] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:42:30:1179983 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:42:30:1179983 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:42:30:1179980 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:42:30:1179980 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:42:30:1179982 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:42:30:1179982 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:42:30:1179981 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:42:30:1179981 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7300s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_tensor_experimental_test_register_sharding.py.xml -
============================== 2 passed in 33.58s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 15:42:47.103] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 5 items
Running 5 items in this shard

../../../../test/distributed/_composable/fsdp/test_fully_shard_autograd.py::TestFullyShardAutograd::test_nontensor_activations [2025-09-12 15:42:49.268] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:42:49.276] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:42:49.292] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:42:49.308] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:42:49:1180355 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:42:49:1180355 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:42:49:1180357 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:42:49:1180357 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:42:49:1180358 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:42:49:1180358 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:42:49:1180356 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:42:49:1180356 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
PASSED [32.5423s] [ 20%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_autograd.py::TestFullyShardAutograd::test_unused_forward_module [2025-09-12 15:43:21.639] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:43:21.645] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:43:21.658] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:43:21.666] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:43:21:1180677 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:43:21:1180677 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:43:21:1180680 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:43:21:1180680 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:43:21:1180679 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:43:21:1180679 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:43:21:1180678 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:43:21:1180678 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:43:50:1180977:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:43:50:1180982:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:43:50:1180987:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:43:50:1180992:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [32.0569s] [ 40%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_autograd.py::TestFullyShardAutograd::test_unused_forward_output [2025-09-12 15:43:53.697] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:43:53.702] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:43:53.702] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:43:53.714] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:43:53:1181023 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:43:53:1181023 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:43:53:1181022 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:43:53:1181022 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:43:53:1181024 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:43:53:1181024 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:43:53:1181025 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:43:53:1181025 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:44:22:1181328:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:44:22:1181333:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:44:22:1181339:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:44:22:1181326:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:44:22:1181326:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:44:22:1181339:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:44:22:1181328:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:44:22:1181333:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [31.9558s] [ 60%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_autograd.py::TestFullyShardPostAccGradHookMultiThread::test_post_acc_grad_hook_runs SKIPPED [0.0003s] [ 80%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_autograd.py::TestFullyShardPostAccGradHookMultiProcess::test_post_acc_grad_hook_optim_parity [2025-09-12 15:44:25.623] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:44:25.646] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:44:25:1181367 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:44:25:1181367 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:44:25:1181366 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:44:25:1181366 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [31.1496s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__composable_fsdp_test_fully_shard_autograd.py.xml -
=================== 4 passed, 1 skipped in 129.70s (0:02:09) ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 15:44:57.739] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/_composable/fsdp/test_fully_shard_clip_grad_norm_.py::TestClipGradNormWorldSize2::test_clip_grad_norm_1d [2025-09-12 15:44:59.914] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:44:59.914] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:45:00:1181600 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:45:00:1181600 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:45:00:1181601 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:45:00:1181601 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [32.2338s] [ 50%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_clip_grad_norm_.py::TestClipGradNormWorldSize4::test_clip_grad_norm_2d [2025-09-12 15:45:31.978] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:45:31.978] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:45:31.986] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:45:31.990] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:45:32:1181761 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:45:32:1181761 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:45:32:1181760 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:45:32:1181760 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:45:32:1181759 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:45:32:1181759 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:45:32:1181762 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:45:32:1181762 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:45:45:1181759:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:45:45:1181760:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:45:45:1181761:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:45:45:1181762:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:45:45:1181760:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:45:45:1181759:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:45:45:1181761:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:45:45:1181762:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:46:02:1181761:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:46:02:1181762:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:46:02:1181759:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:46:02:1181760:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:46:02:1181760:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:46:02:1181759:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:46:02:1181762:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:46:02:1181761:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
FAILED [33.1558s] [100%]

=================================== FAILURES ===================================
______________ TestClipGradNormWorldSize4.test_clip_grad_norm_2d _______________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_clip_grad_norm_.py", line 151, in test_clip_grad_norm_2d
    self._test_clip_grad_norm(
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_clip_grad_norm_.py", line 74, in _test_clip_grad_norm
    self.assertEqual(ref_total_norm, total_norm.full_tensor())
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Scalars are not close!

Expected 23.613964080810547 but got 23.613920211791992.
Absolute difference: 4.38690185546875e-05 (up to 1e-05 allowed)
Relative difference: 1.8577574863991958e-06 (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_clip_grad_norm_.py TestClipGradNormWorldSize4.test_clip_grad_norm_2d

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 3 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 15:45:30.103000 1181526 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1181759
I0912 15:45:30.103000 1181526 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1181760
I0912 15:45:30.104000 1181526 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1181761
I0912 15:45:30.104000 1181526 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1181762
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__composable_fsdp_test_fully_shard_clip_grad_norm_.py.xml -
=========================== short test summary info ============================
FAILED [33.1558s] ../../../../test/distributed/_composable/fsdp/test_fully_shard_clip_grad_norm_.py::TestClipGradNormWorldSize4::test_clip_grad_norm_2d - RuntimeError: Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_clip_grad_norm_.py", line 151, in test_clip_grad_norm_2d
    self._test_clip_grad_norm(
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_clip_grad_norm_.py", line 74, in _test_clip_grad_norm
    self.assertEqual(ref_total_norm, total_norm.full_tensor())
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Scalars are not close!

Expected 23.613964080810547 but got 23.613920211791992.
Absolute difference: 4.38690185546875e-05 (up to 1e-05 allowed)
Relative difference: 1.8577574863991958e-06 (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_clip_grad_norm_.py TestClipGradNormWorldSize4.test_clip_grad_norm_2d

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
==================== 1 failed, 1 passed in 67.38s (0:01:07) ====================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 15:46:05.986] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 21 items / 1 deselected / 20 selected
Running 20 items in this shard

../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardCollectiveOps::test_all_gather_fp32 SKIPPED [0.0003s] [  5%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardCollectiveOps::test_reduce_scatter_fp16 SKIPPED [0.0003s] [ 10%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardCollectiveOps::test_reduce_scatter_fp32 SKIPPED [0.0001s] [ 15%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardCommunication::test_fully_shard_communication_count [2025-09-12 15:46:08.166] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:46:08.171] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:46:08.210] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:46:08.230] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:46:08:1182187 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:46:08:1182187 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:46:08:1182184 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:46:08:1182184 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:46:08:1182185 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:46:08:1182185 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:46:08:1182186 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:46:08:1182186 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:46:37:1182498:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:46:37:1182487:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:46:37:1182492:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:46:37:1182489:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:46:37:1182498:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:46:37:1182487:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:46:37:1182492:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:46:37:1182489:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:46:38:1182498:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:46:38:1182492:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:46:38:1182487:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:46:38:1182489:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [33.0336s] [ 20%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardCommunication::test_manual_reshard_with_reshard_after_forward_false [2025-09-12 15:46:41.034] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:46:41.034] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:46:41.050] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:46:41.067] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:46:41:1182538 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:46:41:1182538 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:46:41:1182539 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:46:41:1182539 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:46:41:1182540 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:46:41:1182540 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:46:41:1182541 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:46:41:1182541 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
PASSED [31.4566s] [ 25%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardCommunication::test_set_reshard_after_forward [2025-09-12 15:47:12.514] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:47:12.523] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:47:12.534] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:47:12.535] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:47:12:1182856 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:47:12:1182856 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:47:12:1182858 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:47:12:1182858 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:47:12:1182855 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:47:12:1182855 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:47:12:1182857 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:47:12:1182857 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [31.8441s] [ 30%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardPrefetch::test_backward_misprefetch [2025-09-12 15:47:44.318] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:47:44.346] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:47:44.370] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:47:44.370] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:47:44:1183173 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:47:44:1183173 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:47:44:1183174 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:47:44:1183174 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:47:44:1183176 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:47:44:1183176 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:47:44:1183175 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:47:44:1183175 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [30.9510s] [ 35%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardPrefetch::test_fully_shard_backward_prefetch [2025-09-12 15:48:15.246] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:48:15.339] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:48:15.374] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:48:15.374] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:48:15:1183495 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:48:15:1183495 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:48:15:1183493 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:48:15:1183493 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:48:15:1183494 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:48:15:1183494 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:48:15:1183492 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:48:15:1183492 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:48:44:1183798:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:44:1183803:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:44:1183793:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:44:1183804:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:45:1183798:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:45:1183803:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:45:1183804:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:45:1183793:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:45:1183798:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:45:1183803:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:45:1183804:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:45:1183793:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:45:1183798:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:45:1183803:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:45:1183804:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:45:1183793:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:46:1183804:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:46:1183793:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:46:1183798:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:46:1183803:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:46:1183804:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:46:1183793:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:46:1183798:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:46:1183803:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:46:1183804:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:46:1183793:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:46:1183798:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:46:1183803:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:47:1183804:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:47:1183793:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:47:1183798:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:47:1183803:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:47:1183798:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:47:1183803:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:47:1183804:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:47:1183793:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:47:1183804:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:47:1183793:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:47:1183798:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:47:1183803:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:48:1183804:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:48:1183793:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:48:1183798:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:48:1183803:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:48:1183804:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:48:1183793:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:48:1183798:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:48:1183803:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:49:1183492:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:49:1183495:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:49:1183494:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:49:1183493:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:49:1183492:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:49:1183494:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:49:1183493:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:49:1183495:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:50:1183494:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:50:1183495:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:50:1183492:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:50:1183493:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:50:1183492:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:50:1183493:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:50:1183494:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:50:1183495:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:51:1183494:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:51:1183495:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:51:1183493:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:51:1183492:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:51:1183494:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:51:1183495:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:51:1183492:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:51:1183493:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:51:1183492:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:51:1183493:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:51:1183494:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:51:1183495:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:52:1183492:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:52:1183493:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:52:1183494:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:52:1183495:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:52:1183494:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:52:1183495:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:52:1183492:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:52:1183493:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:52:1183494:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:52:1183495:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:52:1183492:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:52:1183493:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:53:1183494:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:53:1183495:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:53:1183492:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:53:1183493:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:53:1183494:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:53:1183495:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:53:1183492:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-15:48:53:1183493:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [41.2677s] [ 40%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardPrefetch::test_fully_shard_multi_module_backward_prefetch [2025-09-12 15:48:56.558] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:48:56.558] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:48:56.562] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:48:56.586] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:48:56:1184100 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:48:56:1184100 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:48:56:1184101 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:48:56:1184101 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:48:56:1184102 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:48:56:1184102 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:48:56:1184099 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:48:56:1184099 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [31.8568s] [ 45%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardPrefetch::test_fully_shard_multi_module_unused_module [2025-09-12 15:49:28.378] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:49:28.429] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:49:28.429] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:49:28.450] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:49:28:1184417 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:49:28:1184417 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:49:28:1184419 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:49:28:1184419 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:49:28:1184420 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:49:28:1184420 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:49:28:1184418 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:49:28:1184418 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [31.1513s] [ 50%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardPrefetch::test_set_modules_to_backward_prefetch [2025-09-12 15:49:59.580] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:49:59.580] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:49:59.590] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:49:59.594] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:49:59:1184739 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:49:59:1184739 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:49:59:1184736 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:49:59:1184736 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:49:59:1184738 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:49:59:1184738 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:49:59:1184737 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:49:59:1184737 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [31.3509s] [ 55%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardPrefetch::test_set_modules_to_forward_prefetch [2025-09-12 15:50:30.898] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:50:30.962] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:50:30.963] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:50:30.982] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:50:31:1185056 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:50:31:1185056 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:50:31:1185053 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:50:31:1185053 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:50:31:1185055 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:50:31:1185055 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:50:31:1185054 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:50:31:1185054 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [31.8562s] [ 60%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardUnshardMultiProcess::test_unshard_async [2025-09-12 15:51:02.814] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:51:02.817] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:51:03:1185372 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:51:03:1185372 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:51:03:1185371 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:51:03:1185371 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [30.1476s] [ 65%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardUnshardMultiThread::test_unshard_no_param_group SKIPPED [0.0002s] [ 70%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardUnshardMultiThread::test_unshard_without_lazy_init SKIPPED [0.0001s] [ 75%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardAllocFromPG::test_exception_when_used_together_with_comm_hooks [2025-09-12 15:51:32.909] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:51:32.910] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:51:32.910] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:51:32.934] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:51:33:1185533 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:51:33:1185533 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:51:33:1185531 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:51:33:1185531 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:51:33:1185530 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:51:33:1185530 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:51:33:1185532 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:51:33:1185532 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [15.5281s] [ 80%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardAllocFromPG::test_fully_shard_alloc_from_pg SKIPPED [0.0002s] [ 85%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardForceSumReduction::test_fully_shard_force_sum_both_reductions [2025-09-12 15:51:48.458] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:51:48.462] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:51:48.483] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:51:48.502] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:51:48:1185835 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:51:48:1185835 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:51:48:1185833 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:51:48:1185833 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:51:48:1185832 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:51:48:1185832 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:51:48:1185834 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:51:48:1185834 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
FAILED [15.6282s] [ 90%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardForceSumReduction::test_fully_shard_force_sum_reduce_scatter [2025-09-12 15:52:04.046] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:52:04.102] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:52:04.124] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:52:04.138] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:52:04:1186144 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:52:04:1186144 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:52:04:1186141 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:52:04:1186141 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:52:04:1186143 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:52:04:1186143 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:52:04:1186142 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:52:04:1186142 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
FAILED [15.3221s] [ 95%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardReduceOpWorldSize1::test_size1_reduceop [2025-09-12 15:52:19.402] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:52:19:1186441 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:52:19:1186441 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.4078s] [100%]

=================================== FAILURES ===================================
__ TestFullyShardForceSumReduction.test_fully_shard_force_sum_both_reductions __
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py", line 1540, in test_fully_shard_force_sum_both_reductions
    inp = torch.randint(0, model_args.vocab_size, (2, 16), device="cuda")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_both_reductions

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py", line 1540, in test_fully_shard_force_sum_both_reductions
    inp = torch.randint(0, model_args.vocab_size, (2, 16), device="cuda")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_both_reductions

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py", line 1540, in test_fully_shard_force_sum_both_reductions
    inp = torch.randint(0, model_args.vocab_size, (2, 16), device="cuda")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_both_reductions

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py", line 1540, in test_fully_shard_force_sum_both_reductions
    inp = torch.randint(0, model_args.vocab_size, (2, 16), device="cuda")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_both_reductions

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 0 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 15:51:46.585000 1182112 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1185832
I0912 15:51:46.586000 1182112 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1185833
I0912 15:51:46.586000 1182112 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1185834
I0912 15:51:46.587000 1182112 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1185835
__ TestFullyShardForceSumReduction.test_fully_shard_force_sum_reduce_scatter ___
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py", line 1478, in test_fully_shard_force_sum_reduce_scatter
    inp = torch.randint(0, model_args.vocab_size, (2, 16), device="cuda")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_reduce_scatter

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 3 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 15:52:02.215000 1182112 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1186141
I0912 15:52:02.215000 1182112 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1186142
I0912 15:52:02.216000 1182112 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1186143
I0912 15:52:02.216000 1182112 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1186144
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__composable_fsdp_test_fully_shard_comm.py.xml -
=========================== short test summary info ============================
FAILED [15.6282s] ../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardForceSumReduction::test_fully_shard_force_sum_both_reductions - RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py", line 1540, in test_fully_shard_force_sum_both_reductions
    inp = torch.randint(0, model_args.vocab_size, (2, 16), device="cuda")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_both_reductions

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py", line 1540, in test_fully_shard_force_sum_both_reductions
    inp = torch.randint(0, model_args.vocab_size, (2, 16), device="cuda")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_both_reductions

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py", line 1540, in test_fully_shard_force_sum_both_reductions
    inp = torch.randint(0, model_args.vocab_size, (2, 16), device="cuda")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_both_reductions

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py", line 1540, in test_fully_shard_force_sum_both_reductions
    inp = torch.randint(0, model_args.vocab_size, (2, 16), device="cuda")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_both_reductions

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [15.3221s] ../../../../test/distributed/_composable/fsdp/test_fully_shard_comm.py::TestFullyShardForceSumReduction::test_fully_shard_force_sum_reduce_scatter - RuntimeError: Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py", line 1478, in test_fully_shard_force_sum_reduce_scatter
    inp = torch.randint(0, model_args.vocab_size, (2, 16), device="cuda")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_reduce_scatter

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
====== 2 failed, 12 passed, 6 skipped, 1 deselected in 376.74s (0:06:16) =======
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 15:52:23.894] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 18 items
Running 18 items in this shard

../../../../test/distributed/_composable/fsdp/test_fully_shard_compile.py::TestFullyShardCompileCompute::test_disable_compiling_hooks [2025-09-12 15:52:35.210] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:52:35.210] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:52:35.214] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:52:35.217] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:52:44:1187082 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:52:44:1187082 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:52:46:1187083 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:52:46:1187083 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:52:47:1187080 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:52:47:1187080 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:52:48:1187081 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:52:48:1187081 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [33.8624s] [  5%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_compile.py::TestFullyShardCompile::test_compiled_autograd_ctx [2025-09-12 15:53:08.962] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:53:08.962] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:53:08.970] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:53:08.982] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:53:18:1189592 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:53:18:1189592 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:53:19:1189593 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:53:19:1189593 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:53:21:1189591 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:53:21:1189591 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:53:22:1189594 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:53:22:1189594 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [49.8845s] [ 11%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_compile.py::TestFullyShardCompile::test_dynamo_recompiles_on_fsdp_layers [2025-09-12 15:53:58.858] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:53:58.863] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:53:58.874] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:53:58.890] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:54:08:1192275 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:54:08:1192275 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:54:09:1192273 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:54:09:1192273 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:54:11:1192276 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:54:11:1192276 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:54:12:1192274 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:54:12:1192274 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [35.5607s] [ 16%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_compile.py::TestFullyShardCompile::test_dynamo_trace_use_training_state [2025-09-12 15:54:34.422] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:54:34.446] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:54:34.458] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:54:34.472] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:54:43:1195040 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:54:43:1195040 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:54:45:1195043 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:54:45:1195043 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:54:46:1195042 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:54:46:1195042 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:54:48:1195041 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:54:48:1195041 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [29.2504s] [ 22%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_compile.py::TestFullyShardCompile::test_nested_fully_shard_backend_aot_eager [2025-09-12 15:55:03.737] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:55:03.739] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:55:03.746] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:55:03.746] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:55:13:1196894 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:55:13:1196894 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:55:14:1196896 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:55:14:1196896 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:55:16:1196893 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:55:16:1196893 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:55:17:1196895 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:55:17:1196895 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [52.7894s] [ 27%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_compile.py::TestFullyShardCompile::test_nested_fully_shard_backend_aot_eager_decomp_partition [2025-09-12 15:55:56.470] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:55:56.488] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:55:56.494] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:55:56.498] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:56:06:1198764 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:56:06:1198764 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:56:07:1198766 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:56:07:1198766 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:56:08:1198763 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:56:08:1198763 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:56:10:1198765 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:56:10:1198765 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
PASSED [53.1913s] [ 33%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_compile.py::TestFullyShardCompile::test_nested_fully_shard_backend_inductor_fullgraph_False SKIPPED [0.0003s] [ 38%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_compile.py::TestFullyShardCompile::test_nested_fully_shard_backend_inductor_fullgraph_True [2025-09-12 15:56:49.653] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:56:49.653] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:56:49.656] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:56:49.667] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:56:59:1200635 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:56:59:1200635 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:57:00:1200633 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:57:00:1200633 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:57:02:1200634 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:57:02:1200634 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:57:03:1200636 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:57:03:1200636 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
final peak_memory=3676
final peak_memory=3676
final peak_memory=3676
final peak_memory=10352
final peak_memory=10352
final peak_memory=10352
dist init r=1, world=4
final peak_memory=3676
final peak_memory=3676
final peak_memory=3676
final peak_memory=10352
final peak_memory=10352
final peak_memory=10352
dist init r=0, world=4
final peak_memory=3676
final peak_memory=3676
final peak_memory=3676
final peak_memory=10352
final peak_memory=10352
final peak_memory=10352
dist init r=2, world=4
final peak_memory=3676
final peak_memory=3676
final peak_memory=3676
final peak_memory=10352
final peak_memory=10352
final peak_memory=10352
PASSED [68.5191s] [ 44%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_compile.py::TestFullyShardCompile::test_nested_fully_shard_backend_inductor_fullgraph_True_graph_partition [2025-09-12 15:57:58.175] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:57:58.178] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:57:58.178] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:57:58.179] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:58:07:1203582 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:58:07:1203582 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:58:09:1203579 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:58:09:1203579 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:58:10:1203580 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:58:10:1203580 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:58:11:1203581 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:58:11:1203581 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
final peak_memory=3676
final peak_memory=3676
final peak_memory=3676
final peak_memory=10352
final peak_memory=10352
final peak_memory=10352
dist init r=2, world=4
final peak_memory=3676
final peak_memory=3676
final peak_memory=3676
final peak_memory=10352
final peak_memory=10352
final peak_memory=10352
dist init r=0, world=4
final peak_memory=3676
final peak_memory=3676
final peak_memory=3676
final peak_memory=10352
final peak_memory=10352
final peak_memory=10352
dist init r=3, world=4
final peak_memory=3676
final peak_memory=3676
final peak_memory=3676
final peak_memory=10352
final peak_memory=10352
final peak_memory=10352
PASSED [67.4109s] [ 50%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_compile.py::TestFullyShardCompile::test_simple_mlp_fullgraph_backend_aot_eager [2025-09-12 15:59:05.626] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:59:05.634] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:59:05.642] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:59:05.645] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-15:59:15:1206527 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:59:15:1206527 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:59:16:1206526 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:59:16:1206526 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:59:18:1206528 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:59:18:1206528 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-15:59:19:1206525 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-15:59:19:1206525 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [47.4793s] [ 55%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_compile.py::TestFullyShardCompile::test_simple_mlp_fullgraph_backend_aot_eager_decomp_partition [2025-09-12 15:59:53.062] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:59:53.086] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:59:53.106] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 15:59:53.122] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:00:02:1208396 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:00:02:1208396 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:00:04:1208397 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:00:04:1208397 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:00:05:1208395 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:00:05:1208395 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:00:06:1208394 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:00:06:1208394 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [46.9787s] [ 61%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_compile.py::TestFullyShardCompile::test_simple_mlp_fullgraph_backend_inductor [2025-09-12 16:00:40.041] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:00:40.041] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:00:40.054] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:00:40.054] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:00:49:1210264 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:00:49:1210264 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:00:50:1210266 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:00:50:1210266 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:00:52:1210267 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:00:52:1210267 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:00:53:1210265 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:00:53:1210265 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
final peak_memory=7084
final peak_memory=7084
final peak_memory=7084
final peak_memory=9792
final peak_memory=9792
final peak_memory=9792
dist init r=2, world=4
final peak_memory=7084
final peak_memory=7084
final peak_memory=7084
final peak_memory=9792
final peak_memory=9792
final peak_memory=9792
dist init r=1, world=4
final peak_memory=7084
final peak_memory=7084
final peak_memory=7084
final peak_memory=9792
final peak_memory=9792
final peak_memory=9792
dist init r=0, world=4
final peak_memory=7084
final peak_memory=7084
final peak_memory=7084
final peak_memory=9792
final peak_memory=9792
final peak_memory=9792
PASSED [58.7028s] [ 66%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_compile.py::TestFullyShardCompile::test_trace_fsdp_copy_ [2025-09-12 16:01:38.770] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:01:38.774] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:01:38.786] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:01:38.814] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:01:48:1213088 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:01:48:1213088 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:01:49:1213089 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:01:49:1213089 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:01:51:1213087 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:01:51:1213087 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:01:52:1213086 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:01:52:1213086 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [29.3472s] [ 72%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_compile.py::TestFullyShardCompile::test_transformer_backend_aot_eager [2025-09-12 16:02:08.080] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:02:08.094] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:02:08.130] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:02:08.134] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:02:17:1214942 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:02:17:1214942 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:02:19:1214943 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:02:19:1214943 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:02:20:1214941 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:02:20:1214941 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:02:21:1214940 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:02:21:1214940 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [66.6063s] [ 77%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_compile.py::TestFullyShardCompile::test_transformer_backend_aot_eager_decomp_partition [2025-09-12 16:03:14.704] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:03:14.706] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:03:14.750] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:03:14.762] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:03:24:1216816 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:03:24:1216816 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:03:25:1216818 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:03:25:1216818 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:03:27:1216815 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:03:27:1216815 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:03:28:1216817 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:03:28:1216817 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [68.1848s] [ 83%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_compile.py::TestFullyShardCompile::test_transformer_backend_inductor_fullgraph_False SKIPPED [0.0002s] [ 88%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_compile.py::TestFullyShardCompile::test_transformer_backend_inductor_fullgraph_True SKIPPED [0.0001s] [ 94%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_compile.py::TestFullyShardCompile::test_transformer_backend_inductor_fullgraph_True_graph_partition SKIPPED [0.0001s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__composable_fsdp_test_fully_shard_compile.py.xml -
================== 14 passed, 4 skipped in 718.98s (0:11:58) ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:04:23.962] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 5 items
Running 5 items in this shard

../../../../test/distributed/_composable/fsdp/test_fully_shard_extensions.py::TestFullyShardAllGatherExtensionsMultiProcess::test_all_gather_extensions_train_parity [2025-09-12 16:04:26.115] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:04:26.130] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:04:26:1218760 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:04:26:1218760 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:04:26:1218759 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:04:26:1218759 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
PASSED [34.4329s] [ 20%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_extensions.py::TestFullyShardAllGatherExtensionsMultiThread::test_all_gather_extension_hsdp_mesh SKIPPED [0.0003s] [ 40%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_extensions.py::TestFullyShardAllGatherExtensionsMultiThread::test_all_gather_extension_outer_size_stride SKIPPED [0.0001s] [ 60%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_extensions.py::TestFullyShardAllGatherExtensionsMultiThread::test_all_gather_extensions_end_to_end SKIPPED [0.0001s] [ 80%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_extensions.py::TestFullyShardAllGatherExtensionsMultiThread::test_all_gather_extensions_monkey_patch SKIPPED [0.0001s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__composable_fsdp_test_fully_shard_extensions.py.xml -
======================== 1 passed, 4 skipped in 36.33s =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:05:01.286] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 3 items
Running 3 items in this shard

../../../../test/distributed/_composable/fsdp/test_fully_shard_frozen.py::TestFullyShardFrozen::test_multi_forward_mixed_requires_grad [2025-09-12 16:05:03.447] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:05:03.466] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:05:03.472] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:05:03.494] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:05:03:1218996 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:05:03:1218996 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:05:03:1218997 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:05:03:1218997 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:05:03:1218995 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:05:03:1218995 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:05:03:1218994 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:05:03:1218994 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:05:32:1218995:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:05:32:1218994:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:05:32:1218996:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:05:32:1218997:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:05:32:1218994:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:05:32:1218995:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:05:32:1218996:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:05:32:1218997:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:05:33:1219296:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:05:33:1219301:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:05:33:1219302:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:05:33:1219307:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
PASSED [33.0548s] [ 33%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_frozen.py::TestFullyShardFrozen::test_train_mixed_requires_grad_across_groups [2025-09-12 16:05:36.343] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:05:36.344] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:05:36.351] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:05:36.362] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:05:36:1219358 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:05:36:1219358 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:05:36:1219356 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:05:36:1219356 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:05:36:1219355 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:05:36:1219355 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:05:36:1219357 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:05:36:1219357 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:06:05:1219655:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:05:1219662:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:05:1219669:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:05:1219664:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:05:1219669:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:05:1219662:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:05:1219655:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:05:1219664:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:05:1219669:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:05:1219662:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:05:1219655:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:05:1219664:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:06:1219669:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:06:1219662:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:06:1219655:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:06:1219664:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:06:1219669:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:06:1219662:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:06:1219655:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:06:1219664:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:06:1219357:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:06:1219358:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:06:1219355:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:06:1219356:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:07:1219655:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:07:1219664:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:07:1219669:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:07:1219662:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:07:1219655:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:07:1219664:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:07:1219669:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:07:1219662:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:07:1219669:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:07:1219662:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:07:1219655:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:07:1219664:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:08:1219669:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:08:1219662:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:08:1219664:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:08:1219655:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:08:1219669:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:08:1219662:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:08:1219655:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:08:1219664:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:08:1219357:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:08:1219358:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:08:1219355:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:08:1219356:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=1, world=4
PASSED [35.3610s] [ 66%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_frozen.py::TestFullyShardFrozen::test_train_mixed_requires_grad_per_group [2025-09-12 16:06:11.698] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:06:11.698] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:06:11.707] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:06:11.734] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:06:11:1219820 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:06:11:1219820 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:06:11:1219821 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:06:11:1219821 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:06:11:1219819 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:06:11:1219819 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:06:12:1219818 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:06:12:1219818 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:06:42:1220126:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:42:1220119:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:42:1220124:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:42:1220133:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:43:1220124:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:43:1220133:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:43:1220126:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:43:1220119:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:43:1220124:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:43:1220133:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:43:1220126:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:43:1220119:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:44:1220126:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:44:1220119:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:44:1220124:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:44:1220133:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:44:1220124:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:44:1220133:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:44:1220119:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:44:1220126:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:44:1220124:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:44:1220133:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:44:1220126:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:44:1220119:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:45:1220124:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:45:1220133:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:45:1220126:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:45:1220119:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:45:1220124:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:45:1220133:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:45:1220126:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:45:1220119:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:46:1220124:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:46:1220133:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:46:1220126:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:46:1220119:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:46:1220126:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:46:1220124:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:46:1220119:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:46:1220133:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:47:1220126:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:47:1220124:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:47:1220133:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:47:1220119:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:47:1220124:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:47:1220133:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:47:1220126:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:06:47:1220119:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [38.7672s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__composable_fsdp_test_fully_shard_frozen.py.xml -
======================== 3 passed in 109.07s (0:01:49) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:06:51.399] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 1 item
Running 1 items in this shard

../../../../test/distributed/_composable/fsdp/test_fully_shard_grad_scaler.py::TestFullyShardGradientScaler::test_gradient_scaler [2025-09-12 16:06:53.523] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:06:53.562] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:06:53.574] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:06:53.597] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:06:53:1220386 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:06:53:1220386 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:06:53:1220387 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:06:53:1220387 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:06:53:1220388 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:06:53:1220388 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:06:53:1220385 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:06:53:1220385 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:07:06:1220387:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:07:06:1220388:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:07:06:1220385:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:07:06:1220386:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:07:07:1220386:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:07:07:1220388:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:07:07:1220385:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:07:07:1220387:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:07:23:1220387:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:07:23:1220386:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:07:23:1220385:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:07:23:1220388:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:07:23:1220386:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:07:23:1220388:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:07:23:1220385:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:07:23:1220387:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [33.3466s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__composable_fsdp_test_fully_shard_grad_scaler.py.xml -
============================== 1 passed in 35.33s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:07:27.671] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 1 item
Running 1 items in this shard

../../../../test/distributed/_composable/fsdp/test_fully_shard_ignore_params.py::TestFullyShardIgnoreParams::test_ddp_A_fsdp_B_ddp_C [2025-09-12 16:07:29.830] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:07:29.853] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:07:29.858] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:07:29.870] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:07:30:1220810 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:07:30:1220810 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:07:30:1220811 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:07:30:1220811 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:07:30:1220808 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:07:30:1220808 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:07:30:1220809 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:07:30:1220809 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
PASSED [31.6428s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__composable_fsdp_test_fully_shard_ignore_params.py.xml -
============================== 1 passed in 33.63s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:08:02.247] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 42 items
Running 42 items in this shard

../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardDeviceTensor::test_move_states_to_device_ignored_param_device SKIPPED [0.0003s] [  2%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardDeviceTensor::test_move_states_to_device_tensor SKIPPED [0.0002s] [  4%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardDeviceDTensor::test_move_states_to_device_dtensor_invalid SKIPPED [0.0001s] [  7%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardDeviceDTensor::test_move_states_to_device_dtensor_valid SKIPPED [0.0001s] [  9%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardMeshArg::test_2d_mesh_without_mesh_dim_names SKIPPED [0.0001s] [ 11%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardMeshArg::test_invalid_mesh_ndim SKIPPED [0.0001s] [ 14%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardManagedModulesAndStates::test_managed_modules_duplicate SKIPPED [0.0001s] [ 16%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardManagedModulesAndStates::test_managed_modules_list_of_mlps SKIPPED [0.0001s] [ 19%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardManagedModulesAndStates::test_managed_modules_nested SKIPPED [0.0002s] [ 21%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardManagedModulesAndStates::test_managed_modules_nested_fully_shard_and_replicate SKIPPED [0.0001s] [ 23%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardManagedModulesAndStates::test_managed_modules_single SKIPPED [0.0001s] [ 26%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardManagedModulesAndStates::test_managed_states_list_of_mlps SKIPPED [0.0001s] [ 28%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardManagedModulesAndStates::test_managed_states_nested_fully_shard SKIPPED [0.0001s] [ 30%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardManagedModulesAndStates::test_managed_states_shared_params_and_buffers SKIPPED [0.0001s] [ 33%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardParamModuleInfos::test_get_param_module_infos_duplicates SKIPPED [0.0001s] [ 35%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardParamModuleInfos::test_get_param_module_infos_list_of_mlps SKIPPED [0.0001s] [ 38%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardParamModuleInfos::test_get_param_module_infos_shared_params SKIPPED [0.0001s] [ 40%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardShardedParameterTensor::test_raise_noncontiguous_parameter SKIPPED [0.0001s] [ 42%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardShardedParameterTensor::test_raise_scalar_parameter SKIPPED [0.0001s] [ 45%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardShardedParameterTensor::test_shard_tensor_parameters SKIPPED [0.0001s] [ 47%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardShardedParameterDTensor::test_shard_dtensor_parameters SKIPPED [0.0001s] [ 50%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardLazyInit::test_fully_shard_double_lazy_init SKIPPED [0.0001s] [ 52%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardLazyInit::test_fully_shard_is_root SKIPPED [0.0001s] [ 54%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardLazyInit::test_fully_shard_module_and_param_fqns SKIPPED [0.0001s] [ 57%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardLazyInit::test_fully_shard_multi_module_root SKIPPED [0.0001s] [ 59%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardLazyInit::test_reset_sharded_param_in_lazy_init SKIPPED [0.0001s] [ 61%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardMetaDeviceInit::test_invalid_meta_device_init SKIPPED [0.0001s] [ 64%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardMetaDeviceInit::test_meta_device_1d_init SKIPPED [0.0001s] [ 66%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardMetaDeviceInit::test_meta_device_2d_init SKIPPED [0.0002s] [ 69%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardMetaDeviceInit::test_rank0_broadcast_meta_device_init SKIPPED [0.0001s] [ 71%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardProcessGroupInit::test_1d_process_group_init SKIPPED [0.0001s] [ 73%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardProcessGroupInit::test_2d_process_group_init SKIPPED [0.0001s] [ 76%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardHSDPBroadcast::test_hsdp_broadcast_across_replicas SKIPPED [0.0001s] [ 78%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestHSDPWithCustomHook::test_custom_hook_custom_stream SKIPPED [0.0001s] [ 80%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestHSDPWithCustomHook::test_custom_hsdp_all_reduce_hook SKIPPED [0.0001s] [ 83%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardShardPlacementFn::test_init_1d_transformer_shard_dim_neg1 SKIPPED [0.0001s] [ 85%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardShardPlacementFn::test_init_1d_transformer_shard_largest_dim SKIPPED [0.0001s] [ 88%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardShardPlacementFn::test_init_1d_uneven_shard_largest_dim SKIPPED [0.0001s] [ 90%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardShardPlacementFn::test_init_2d_transformer_shard_diff_dim SKIPPED [0.0003s] [ 92%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardShardPlacementFn::test_invalid_shard_dim SKIPPED [0.0001s] [ 95%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardOldImport::test_old_import_training SKIPPED [0.0001s] [ 97%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_init.py::TestFullyShardMixedDtypeParam::test_mixed_dtypes_no_grad_param SKIPPED [0.0001s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__composable_fsdp_test_fully_shard_init.py.xml -
============================= 42 skipped in 2.02s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:08:05.058] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 0 items
Running 0 items in this shard

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__composable_fsdp_test_fully_shard_logging.py.xml -
============================ no tests ran in 1.88s =============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:08:07.927] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/_composable/fsdp/test_fully_shard_memory.py::TestFullyShardMemory::test_fully_shard_del_memory [2025-09-12 16:08:10.087] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:08:10.102] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:08:10:1221347 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:08:10:1221347 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:08:10:1221346 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:08:10:1221346 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
FAILED [15.1254s] [ 50%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_memory.py::TestFullyShardMemory::test_fully_shard_training_memory [2025-09-12 16:08:25.014] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:08:25.026] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:08:25:1221496 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:08:25:1221496 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:08:25:1221497 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:08:25:1221497 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
FAILED [15.0253s] [100%]

=================================== FAILURES ===================================
_______________ TestFullyShardMemory.test_fully_shard_del_memory _______________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_memory.py", line 228, in test_fully_shard_del_memory
    self.assertLessEqual(mem_mb - base_mem_mb, expected_mb)
TypeError: unsupported operand type(s) for -: 'NoneType' and 'NoneType'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_memory.py TestFullyShardMemory.test_fully_shard_del_memory

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_memory.py", line 228, in test_fully_shard_del_memory
    self.assertLessEqual(mem_mb - base_mem_mb, expected_mb)
TypeError: unsupported operand type(s) for -: 'NoneType' and 'NoneType'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_memory.py TestFullyShardMemory.test_fully_shard_del_memory

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 0 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 16:08:08.255000 1221273 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1221346
I0912 16:08:08.256000 1221273 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1221347
____________ TestFullyShardMemory.test_fully_shard_training_memory _____________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_memory.py", line 30, in test_fully_shard_training_memory
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_memory.py", line 112, in _test_fully_shard_training_memory
    self.assertLessEqual(peak_mem_mb - base_mem_mb, init_mem_mb + buffer_mb)
TypeError: unsupported operand type(s) for -: 'NoneType' and 'NoneType'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_memory.py TestFullyShardMemory.test_fully_shard_training_memory

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_memory.py", line 30, in test_fully_shard_training_memory
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_memory.py", line 112, in _test_fully_shard_training_memory
    self.assertLessEqual(peak_mem_mb - base_mem_mb, init_mem_mb + buffer_mb)
TypeError: unsupported operand type(s) for -: 'NoneType' and 'NoneType'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_memory.py TestFullyShardMemory.test_fully_shard_training_memory

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 0 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 16:08:23.180000 1221273 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1221496
I0912 16:08:23.180000 1221273 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1221497
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__composable_fsdp_test_fully_shard_memory.py.xml -
=========================== short test summary info ============================
FAILED [15.1254s] ../../../../test/distributed/_composable/fsdp/test_fully_shard_memory.py::TestFullyShardMemory::test_fully_shard_del_memory - RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_memory.py", line 228, in test_fully_shard_del_memory
    self.assertLessEqual(mem_mb - base_mem_mb, expected_mb)
TypeError: unsupported operand type(s) for -: 'NoneType' and 'NoneType'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_memory.py TestFullyShardMemory.test_fully_shard_del_memory

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_memory.py", line 228, in test_fully_shard_del_memory
    self.assertLessEqual(mem_mb - base_mem_mb, expected_mb)
TypeError: unsupported operand type(s) for -: 'NoneType' and 'NoneType'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_memory.py TestFullyShardMemory.test_fully_shard_del_memory

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [15.0253s] ../../../../test/distributed/_composable/fsdp/test_fully_shard_memory.py::TestFullyShardMemory::test_fully_shard_training_memory - RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_memory.py", line 30, in test_fully_shard_training_memory
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_memory.py", line 112, in _test_fully_shard_training_memory
    self.assertLessEqual(peak_mem_mb - base_mem_mb, init_mem_mb + buffer_mb)
TypeError: unsupported operand type(s) for -: 'NoneType' and 'NoneType'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_memory.py TestFullyShardMemory.test_fully_shard_training_memory

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_memory.py", line 30, in test_fully_shard_training_memory
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_memory.py", line 112, in _test_fully_shard_training_memory
    self.assertLessEqual(peak_mem_mb - base_mem_mb, init_mem_mb + buffer_mb)
TypeError: unsupported operand type(s) for -: 'NoneType' and 'NoneType'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_memory.py TestFullyShardMemory.test_fully_shard_training_memory

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
============================== 2 failed in 32.14s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:08:40.991] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 9 items
Running 9 items in this shard

../../../../test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py::TestFullyShardMixedPrecisionTraining::test_compute_dtype [2025-09-12 16:08:43.179] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:08:43.194] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:08:43.194] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:08:43.214] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:08:43:1221920 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:08:43:1221920 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:08:43:1221921 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:08:43:1221921 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:08:43:1221922 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:08:43:1221922 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:08:43:1221919 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:08:43:1221919 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:09:12:1222221:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:12:1222224:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:12:1222225:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:12:1222234:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:13:1222224:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:13:1222221:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:13:1222225:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:13:1222234:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:13:1222224:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:13:1222221:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:13:1222225:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:13:1222234:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:14:1222221:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:14:1222224:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:14:1222225:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:14:1222234:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:15:1222224:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:15:1222221:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:15:1222225:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:15:1222234:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:15:1222221:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:15:1222224:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:15:1222225:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:09:15:1222234:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=3, world=4
PASSED [35.7315s] [ 11%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py::TestFullyShardMixedPrecisionTraining::test_grad_acc_with_reduce_dtype [2025-09-12 16:09:18.718] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:09:18.734] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:09:18.742] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:09:18.750] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:09:18:1222329 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:09:18:1222329 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:09:18:1222326 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:09:18:1222326 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:09:18:1222327 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:09:18:1222327 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:09:18:1222328 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:09:18:1222328 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [32.4565s] [ 22%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py::TestFullyShardMixedPrecisionTraining::test_reduce_dtype [2025-09-12 16:09:51.171] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:09:51.182] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:09:51.195] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:09:51.202] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:09:51:1222643 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:09:51:1222643 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:09:51:1222645 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:09:51:1222645 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:09:51:1222644 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:09:51:1222644 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:09:51:1222642 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:09:51:1222642 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:10:20:1222944:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:20:1222951:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:20:1222950:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:20:1222957:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:21:1222944:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:21:1222951:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:21:1222950:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:21:1222957:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:21:1222951:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:21:1222957:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:21:1222944:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:21:1222950:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:23:1222951:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:23:1222957:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:23:1222944:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:23:1222950:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:23:1222951:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:23:1222957:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:23:1222944:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:23:1222950:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:23:1222951:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:23:1222957:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:23:1222944:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:23:1222950:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [35.6621s] [ 33%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py::TestFullyShardMixedPrecisionCasts::test_clamp_reduce_dtype SKIPPED [0.0003s] [ 44%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py::TestFullyShardMixedPrecisionCasts::test_dataclass_input SKIPPED [0.0002s] [ 55%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py::TestFullyShardMixedPrecisionCasts::test_float16_on_one_submodule SKIPPED [0.0002s] [ 66%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py::TestFullyShardMixedPrecisionCasts::test_norm_modules_bf16 SKIPPED [0.0002s] [ 77%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py::TestFullyShardMixedPrecisionCasts::test_norm_modules_fp16 SKIPPED [0.0002s] [ 88%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py::TestFullyShardMixedPrecisionCasts::test_submodules_with_external_inputs SKIPPED [0.0002s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__composable_fsdp_test_fully_shard_mixed_precision.py.xml -
=================== 3 passed, 6 skipped in 105.86s (0:01:45) ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:10:27.783] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items / 1 deselected / 1 selected
Running 1 items in this shard

../../../../test/distributed/_composable/fsdp/test_fully_shard_overlap.py::TestFullyShardOverlap::test_fully_shard_post_optim_event_overlap SKIPPED [0.0003s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__composable_fsdp_test_fully_shard_overlap.py.xml -
======================= 1 skipped, 1 deselected in 2.00s =======================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:10:30.675] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 6 items
Running 6 items in this shard

../../../../test/distributed/_composable/fsdp/test_fully_shard_state_dict.py::TestFullyShardStateDictMultiProcess::test_2d_state_dict_correctness [2025-09-12 16:10:32.824] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:10:32.846] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:10:32.848] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:10:32.870] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:10:33:1223194 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:10:33:1223194 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:10:33:1223195 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:10:33:1223195 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:10:33:1223196 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:10:33:1223196 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:10:33:1223197 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:10:33:1223197 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:10:45:1223194:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:45:1223195:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:45:1223196:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:45:1223197:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:46:1223195:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:46:1223197:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:46:1223194:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:10:46:1223196:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [16.5092s] [ 16%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_state_dict.py::TestFullyShardStateDictMultiProcess::test_dp_state_dict_cpu_offload [2025-09-12 16:10:49.126] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:10:49.214] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:10:49.240] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:10:49.262] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:10:49:1223510 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:10:49:1223510 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:10:49:1223512 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:10:49:1223512 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:10:49:1223511 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:10:49:1223511 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:10:49:1223513 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:10:49:1223513 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [15.8275s] [ 33%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_state_dict.py::TestFullyShardStateDictMultiProcess::test_dp_state_dict_save_load [2025-09-12 16:11:04.992] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:11:04.994] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:11:04.997] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:11:04.998] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:11:05:1223812 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:11:05:1223812 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:11:05:1223813 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:11:05:1223813 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:11:05:1223814 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:11:05:1223814 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:11:05:1223815 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:11:05:1223815 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:11:19:1223812:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:11:19:1223813:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:11:19:1223815:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:11:19:1223814:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [17.7244s] [ 50%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_state_dict.py::TestFullyShardStateDictMultiProcess::test_dp_tp_state_dict_save_load [2025-09-12 16:11:22.715] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:11:22.727] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:11:22.727] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:11:22.728] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:11:22:1224127 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:11:22:1224127 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:11:22:1224124 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:11:22:1224124 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:11:22:1224125 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:11:22:1224125 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:11:22:1224126 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:11:22:1224126 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:11:35:1224126:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:11:35:1224127:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:11:35:1224124:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:11:35:1224125:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [16.1303s] [ 66%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_state_dict.py::TestFullyShardStateDictMultiProcess::test_hsdp_tp_state_dict_save_load [2025-09-12 16:11:38.828] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:11:38.842] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:11:38.864] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:11:38.882] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:11:39:1224438 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:11:39:1224438 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:11:39:1224437 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:11:39:1224437 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:11:39:1224439 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:11:39:1224439 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:11:39:1224436 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:11:39:1224436 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:11:51:1224438:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:11:51:1224439:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:11:51:1224437:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:11:51:1224436:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
PASSED [16.3264s] [ 83%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_state_dict.py::TestFullyShardStateDictMultiThread::test_rank0_offload_full_state_dict SKIPPED [0.0003s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__composable_fsdp_test_fully_shard_state_dict.py.xml -
=================== 5 passed, 1 skipped in 84.51s (0:01:24) ====================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:11:56.167] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 5 items
Running 5 items in this shard

../../../../test/distributed/_composable/fsdp/test_fully_shard_state.py::TestFullyShardState::test_fully_shard_cls SKIPPED [0.0003s] [ 20%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_state.py::TestFullyShardState::test_fully_shard_deepcopy SKIPPED [0.0002s] [ 40%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_state.py::TestFullyShardState::test_fully_shard_reapply SKIPPED [0.0002s] [ 60%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_state.py::TestFullyShardState::test_fully_shard_state SKIPPED [0.0001s] [ 80%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_state.py::TestFullyShardState::test_fully_shard_unsupported_module_cls SKIPPED [0.0001s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__composable_fsdp_test_fully_shard_state.py.xml -
============================== 5 skipped in 1.99s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:11:59.055] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 24 items
Running 24 items in this shard

../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShardForwardInputs::test_root_move_forward_input_to_device SKIPPED [0.0003s] [  4%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShardRegisteredParams::test_param_registration_after_backward SKIPPED [0.0002s] [  8%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShardRegisteredParams::test_param_registration_after_forward SKIPPED [0.0001s] [ 12%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShardCastAfterInit::test_to_float64_after_init SKIPPED [0.0001s] [ 16%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShard1DTrainingCore::test_explicit_prefetching [2025-09-12 16:12:01.243] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:12:01.262] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:12:01.278] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:12:01.322] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:12:01:1224900 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:12:01:1224900 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:12:01:1224901 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:12:01:1224901 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:12:01:1224903 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:12:01:1224903 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:12:01:1224902 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:12:01:1224902 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
PASSED [32.7615s] [ 20%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShard1DTrainingCore::test_multi_forward_module [2025-09-12 16:12:33.798] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:12:33.814] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:12:33.817] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:12:33.818] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:12:33:1225222 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:12:33:1225222 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:12:33:1225220 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:12:33:1225220 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:12:34:1225223 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:12:34:1225223 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:12:34:1225221 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:12:34:1225221 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=0, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [31.5568s] [ 25%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShard1DTrainingCore::test_non_root_forward_backward [2025-09-12 16:13:05.352] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:13:05.362] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:13:05.370] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:13:05.384] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:13:05:1225540 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:13:05:1225540 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:13:05:1225539 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:13:05:1225539 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:13:05:1225538 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:13:05:1225538 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:13:05:1225541 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:13:05:1225541 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
FAILED [30.8562s] [ 29%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShard1DTrainingCore::test_post_optim_event [2025-09-12 16:13:36.291] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:13:36.294] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:13:36.298] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:13:36.310] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:13:36:1225857 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:13:36:1225857 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:13:36:1225854 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:13:36:1225854 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:13:36:1225856 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:13:36:1225856 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:13:36:1225855 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:13:36:1225855 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=1, world=4
FAILED [31.7582s] [ 33%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShard1DTrainingCore::test_train_parity_multi_group [2025-09-12 16:14:07.977] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:14:07.994] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:14:08.022] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:14:08.033] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:14:08:1226173 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:14:08:1226173 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:14:08:1226176 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:14:08:1226176 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:14:08:1226175 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:14:08:1226175 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:14:08:1226174 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:14:08:1226174 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
FAILED [43.5779s] [ 37%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShard1DTrainingCore::test_train_parity_multi_group_cpu_offload_eager [2025-09-12 16:14:51.588] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:14:51.596] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:14:51.606] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:14:51.606] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:14:51:1226492 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:14:51:1226492 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:14:51:1226493 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:14:51:1226493 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:14:51:1226491 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:14:51:1226491 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:14:51:1226490 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:14:51:1226490 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
FAILED [43.4750s] [ 41%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShard1DTrainingCore::test_train_parity_multi_group_unshard_async_op [2025-09-12 16:15:35.065] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:15:35.078] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:15:35.090] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:15:35.093] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:15:35:1227188 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:15:35:1227188 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:15:35:1227190 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:15:35:1227190 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:15:35:1227187 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:15:35:1227187 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:15:35:1227189 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:15:35:1227189 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=0, world=4
FAILED [43.2760s] [ 45%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShard1DTrainingCore::test_train_parity_single_group_shard_dim0 [2025-09-12 16:16:18.352] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:16:18.370] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:16:18.378] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:16:18.379] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:16:18:1227509 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:16:18:1227509 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:16:18:1227507 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:16:18:1227507 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:16:18:1227506 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:16:18:1227506 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:16:18:1227508 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:16:18:1227508 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [31.4555s] [ 50%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShard1DTrainingCore::test_train_parity_single_group_shard_largest_dim [2025-09-12 16:16:49.805] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:16:49.814] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:16:49.890] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:16:49.919] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:16:50:1227825 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:16:50:1227825 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:16:50:1227828 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:16:50:1227828 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:16:50:1227827 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:16:50:1227827 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:16:50:1227826 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:16:50:1227826 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [31.5569s] [ 54%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShard1DTrainingCompose::test_train_parity_with_activation_checkpointing [2025-09-12 16:17:21.328] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:17:21.330] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:17:21:1228148 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:17:21:1228148 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:17:21:1228147 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:17:21:1228147 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=2
dist init r=0, world=2
FAILED [42.4660s] [ 58%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShardShardPlacementFnMultiProcess::test_train_parity_shard_placement_fn_shard_largest_dim [2025-09-12 16:18:03.767] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:18:03.820] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:18:03.822] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:18:03.837] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:18:03:1228306 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:18:03:1228306 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:18:04:1228307 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:18:04:1228307 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:18:04:1228309 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:18:04:1228309 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:18:04:1228308 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:18:04:1228308 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
dist init r=3, world=4
PASSED [31.6560s] [ 62%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShardShardPlacementFnMultiThread::test_shard_placement_fn_contiguous_params_grads SKIPPED [0.0002s] [ 66%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShardSharedParams::test_train_parity_with_shared_params [2025-09-12 16:18:35.459] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:18:35.470] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:18:35.477] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:18:35.478] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:18:35:1228625 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:18:35:1228625 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:18:35:1228626 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:18:35:1228626 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:18:35:1228628 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:18:35:1228628 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:18:35:1228627 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:18:35:1228627 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=0, world=4
dist init r=2, world=4
dist init r=1, world=4
PASSED [33.2589s] [ 70%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShardGradientAccumulation::test_1f1b_microbatching [2025-09-12 16:19:08.721] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:19:08.728] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:19:08.730] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:19:08.764] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:19:08:1228944 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:19:08:1228944 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:19:08:1228945 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:19:08:1228945 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:19:08:1228942 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:19:08:1228942 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:19:08:1228943 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:19:08:1228943 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [32.3578s] [ 75%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShardGradientAccumulation::test_gradient_accumulation [2025-09-12 16:19:41.080] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:19:41.090] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:19:41.102] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:19:41.114] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:19:41:1229259 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:19:41:1229259 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:19:41:1229260 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:19:41:1229260 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:19:41:1229262 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:19:41:1229262 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:19:41:1229261 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:19:41:1229261 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:20:16:1229569:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:16:1229577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:16:1229582:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:16:1229573:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:16:1229569:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:16:1229577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:16:1229582:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:16:1229573:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:16:1229569:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:16:1229577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:16:1229582:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:16:1229573:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:17:1229569:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:17:1229577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:17:1229582:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:17:1229573:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:17:1229569:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:17:1229577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:17:1229582:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:17:1229573:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:18:1229569:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:18:1229577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:18:1229582:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:18:1229573:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:18:1229569:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:18:1229577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:18:1229582:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:18:1229573:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:18:1229569:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:18:1229577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:18:1229582:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:18:1229573:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:19:1229582:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:19:1229569:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:19:1229573:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:19:1229577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:20:1229569:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:20:1229582:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:20:1229577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:20:1229573:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:20:1229569:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:20:1229582:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:20:1229577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:20:1229573:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:20:1229569:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:20:1229582:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:20:1229577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:20:1229573:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:21:1229259:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:21:1229260:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:21:1229261:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:21:1229262:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:33:1229569:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:33:1229582:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:33:1229573:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:20:33:1229577:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=3, world=4
dist init r=1, world=4
dist init r=0, world=4
dist init r=2, world=4
PASSED [71.8178s] [ 79%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShardNDTraining::test_2d_mlp_with_nd_mesh [2025-09-12 16:20:52.878] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:20:52.922] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:20:52.942] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:20:52.958] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:20:53:1229740 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:20:53:1229740 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:20:53:1229742 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:20:53:1229742 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:20:53:1229739 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:20:53:1229739 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:20:53:1229741 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:20:53:1229741 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:21:06:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:06:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:06:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:06:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:06:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:06:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:06:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:06:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:22:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:22:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:22:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:22:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:23:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:23:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:23:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:23:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:23:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:23:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:23:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:23:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:24:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:24:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:24:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:24:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:24:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:24:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:24:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:24:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:25:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:25:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:25:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:25:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:25:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:25:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:25:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:25:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:26:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:26:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:26:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:26:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:26:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:26:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:26:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:26:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:27:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:27:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:27:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:27:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:27:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:27:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:27:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:27:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:28:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:28:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:28:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:28:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:28:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:28:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:28:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:28:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:29:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:29:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:29:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:29:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:29:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:29:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:29:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:29:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:30:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:30:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:30:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:30:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:30:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:30:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:30:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:30:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:30:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:30:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:30:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:30:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:31:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:31:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:31:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:31:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:31:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:31:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:31:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:31:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:32:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:32:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:32:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:32:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:32:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:32:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:32:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:32:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:33:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:33:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:33:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:33:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:33:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:33:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:33:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:33:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:34:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:34:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:34:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:34:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:34:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:34:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:34:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:34:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:35:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:35:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:35:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:35:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:35:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:35:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:35:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:35:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:35:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:35:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:35:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:35:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:36:1229739:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:36:1229740:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:36:1229742:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:21:36:1229741:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [46.4789s] [ 83%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShardHSDP3DTraining::test_3d_mlp_with_nd_mesh [2025-09-12 16:21:39.386] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:21:39.386] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:21:39.401] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:21:39.422] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:21:39:1230390 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:21:39:1230390 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:21:39:1230391 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:21:39:1230391 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:21:39:1230389 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:21:39:1230389 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:21:39:1230392 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:21:39:1230392 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=2, world=4
SKIPPED [15.5297s] [ 87%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShardHSDPTraining::test_train_parity_hsdp [2025-09-12 16:21:54.899] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:21:54.916] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:21:54.934] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:21:54.937] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:21:55:1230691 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:21:55:1230691 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:21:55:1230692 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:21:55:1230692 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:21:55:1230693 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:21:55:1230693 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:21:55:1230690 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:21:55:1230690 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:22:08:1230691:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:22:08:1230693:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:22:08:1230692:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:22:08:1230690:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:22:08:1230692:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:22:08:1230693:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:22:08:1230690:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:22:08:1230691:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [49.9832s] [ 91%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShardCustomForwardMethod::test_register_fsdp_forward_method [2025-09-12 16:22:44.886] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:22:44.886] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:22:45:1231027 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:22:45:1231027 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:22:45:1231028 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:22:45:1231028 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=2
dist init r=1, world=2
PASSED [41.6653s] [ 95%]
../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShardWorldSize1::test_train_parity_single_worldsize1 [2025-09-12 16:23:26.538] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:23:26:1231378 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:23:26:1231378 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=1
PASSED [3.6076s] [100%]

=================================== FAILURES ===================================
_________ TestFullyShard1DTrainingCore.test_non_root_forward_backward __________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 532, in test_non_root_forward_backward
    torch.get_device_module(device_type)._sleep(int(100 * get_cycles_per_ms()))
AttributeError: module 'torch.xpu' has no attribute '_sleep'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCore.test_non_root_forward_backward

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 1 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 16:13:03.513000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1225538
I0912 16:13:03.514000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1225539
I0912 16:13:03.515000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1225540
I0912 16:13:03.515000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1225541
______________ TestFullyShard1DTrainingCore.test_post_optim_event ______________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 667, in test_post_optim_event
    torch.get_device_module(device_type)._sleep(int(25 * get_cycles_per_ms()))
AttributeError: module 'torch.xpu' has no attribute '_sleep'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCore.test_post_optim_event

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 667, in test_post_optim_event
    torch.get_device_module(device_type)._sleep(int(25 * get_cycles_per_ms()))
AttributeError: module 'torch.xpu' has no attribute '_sleep'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCore.test_post_optim_event

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 667, in test_post_optim_event
    torch.get_device_module(device_type)._sleep(int(25 * get_cycles_per_ms()))
AttributeError: module 'torch.xpu' has no attribute '_sleep'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCore.test_post_optim_event

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 1 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 16:13:34.372000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1225854
I0912 16:13:34.373000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1225855
I0912 16:13:34.373000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1225856
I0912 16:13:34.374000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1225857
__________ TestFullyShard1DTrainingCore.test_train_parity_multi_group __________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1540, in wrapper
    func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 335, in test_train_parity_multi_group
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 491, in _test_train_parity_multi_group
    torch.get_device_module(test_device_type)._sleep(
AttributeError: module 'torch.xpu' has no attribute '_sleep'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCore.test_train_parity_multi_group

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 3 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 16:14:06.131000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1226173
I0912 16:14:06.131000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1226174
I0912 16:14:06.132000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1226175
I0912 16:14:06.132000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1226176
_ TestFullyShard1DTrainingCore.test_train_parity_multi_group_cpu_offload_eager _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 356, in test_train_parity_multi_group_cpu_offload_eager
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 491, in _test_train_parity_multi_group
    torch.get_device_module(test_device_type)._sleep(
AttributeError: module 'torch.xpu' has no attribute '_sleep'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCore.test_train_parity_multi_group_cpu_offload_eager

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 1 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 16:14:49.710000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1226490
I0912 16:14:49.711000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1226491
I0912 16:14:49.711000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1226492
I0912 16:14:49.712000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1226493
_ TestFullyShard1DTrainingCore.test_train_parity_multi_group_unshard_async_op __
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1540, in wrapper
    func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 381, in test_train_parity_multi_group_unshard_async_op
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 495, in _test_train_parity_multi_group
    self.assertEqual(losses[0], losses[1])
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Scalars are not close!

Expected nan but got 8957.5947265625.
Absolute difference: nan (up to 1e-05 allowed)
Relative difference: nan (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCore.test_train_parity_multi_group_unshard_async_op

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1540, in wrapper
    func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 381, in test_train_parity_multi_group_unshard_async_op
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 495, in _test_train_parity_multi_group
    self.assertEqual(losses[0], losses[1])
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Scalars are not close!

Expected nan but got 7376.07421875.
Absolute difference: nan (up to 1e-05 allowed)
Relative difference: nan (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCore.test_train_parity_multi_group_unshard_async_op

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 1 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 16:15:33.187000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1227187
I0912 16:15:33.187000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1227188
I0912 16:15:33.188000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1227189
I0912 16:15:33.188000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1227190
_ TestFullyShard1DTrainingCompose.test_train_parity_with_activation_checkpointing _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1540, in wrapper
    func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 686, in test_train_parity_with_activation_checkpointing
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 775, in _test_train_parity_with_activation_checkpointing
    check_sharded_parity(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1123, in check_sharded_parity
    cls.assertEqual(sharded_param.grad.to_local(), sharded_ref_grad.to_local())
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 2 / 128 (1.6%)
Greatest absolute difference: 1.621246337890625e-05 at index (3, 3) (up to 1e-05 allowed)
Greatest relative difference: 7.053498393361224e-06 at index (2, 6) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCompose.test_train_parity_with_activation_checkpointing

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1540, in wrapper
    func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 686, in test_train_parity_with_activation_checkpointing
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 775, in _test_train_parity_with_activation_checkpointing
    check_sharded_parity(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1123, in check_sharded_parity
    cls.assertEqual(sharded_param.grad.to_local(), sharded_ref_grad.to_local())
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 1 / 128 (0.8%)
Greatest absolute difference: 1.0728836059570312e-05 at index (3, 12) (up to 1e-05 allowed)
Greatest relative difference: 0.00028740588459186256 at index (3, 12) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCompose.test_train_parity_with_activation_checkpointing

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 0 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 16:17:19.479000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1228147
I0912 16:17:19.480000 1224828 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1228148
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__composable_fsdp_test_fully_shard_training.py.xml -
=========================== short test summary info ============================
FAILED [30.8562s] ../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShard1DTrainingCore::test_non_root_forward_backward - RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 532, in test_non_root_forward_backward
    torch.get_device_module(device_type)._sleep(int(100 * get_cycles_per_ms()))
AttributeError: module 'torch.xpu' has no attribute '_sleep'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCore.test_non_root_forward_backward

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [31.7582s] ../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShard1DTrainingCore::test_post_optim_event - RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 667, in test_post_optim_event
    torch.get_device_module(device_type)._sleep(int(25 * get_cycles_per_ms()))
AttributeError: module 'torch.xpu' has no attribute '_sleep'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCore.test_post_optim_event

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 667, in test_post_optim_event
    torch.get_device_module(device_type)._sleep(int(25 * get_cycles_per_ms()))
AttributeError: module 'torch.xpu' has no attribute '_sleep'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCore.test_post_optim_event

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 667, in test_post_optim_event
    torch.get_device_module(device_type)._sleep(int(25 * get_cycles_per_ms()))
AttributeError: module 'torch.xpu' has no attribute '_sleep'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCore.test_post_optim_event

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [43.5779s] ../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShard1DTrainingCore::test_train_parity_multi_group - RuntimeError: Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1540, in wrapper
    func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 335, in test_train_parity_multi_group
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 491, in _test_train_parity_multi_group
    torch.get_device_module(test_device_type)._sleep(
AttributeError: module 'torch.xpu' has no attribute '_sleep'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCore.test_train_parity_multi_group

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [43.4750s] ../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShard1DTrainingCore::test_train_parity_multi_group_cpu_offload_eager - RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 356, in test_train_parity_multi_group_cpu_offload_eager
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 491, in _test_train_parity_multi_group
    torch.get_device_module(test_device_type)._sleep(
AttributeError: module 'torch.xpu' has no attribute '_sleep'

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCore.test_train_parity_multi_group_cpu_offload_eager

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [43.2760s] ../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShard1DTrainingCore::test_train_parity_multi_group_unshard_async_op - RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1540, in wrapper
    func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 381, in test_train_parity_multi_group_unshard_async_op
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 495, in _test_train_parity_multi_group
    self.assertEqual(losses[0], losses[1])
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Scalars are not close!

Expected nan but got 8957.5947265625.
Absolute difference: nan (up to 1e-05 allowed)
Relative difference: nan (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCore.test_train_parity_multi_group_unshard_async_op

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1540, in wrapper
    func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 381, in test_train_parity_multi_group_unshard_async_op
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 495, in _test_train_parity_multi_group
    self.assertEqual(losses[0], losses[1])
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Scalars are not close!

Expected nan but got 7376.07421875.
Absolute difference: nan (up to 1e-05 allowed)
Relative difference: nan (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCore.test_train_parity_multi_group_unshard_async_op

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [42.4660s] ../../../../test/distributed/_composable/fsdp/test_fully_shard_training.py::TestFullyShard1DTrainingCompose::test_train_parity_with_activation_checkpointing - RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1540, in wrapper
    func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 686, in test_train_parity_with_activation_checkpointing
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 775, in _test_train_parity_with_activation_checkpointing
    check_sharded_parity(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1123, in check_sharded_parity
    cls.assertEqual(sharded_param.grad.to_local(), sharded_ref_grad.to_local())
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 2 / 128 (1.6%)
Greatest absolute difference: 1.621246337890625e-05 at index (3, 3) (up to 1e-05 allowed)
Greatest relative difference: 7.053498393361224e-06 at index (2, 6) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCompose.test_train_parity_with_activation_checkpointing

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1540, in wrapper
    func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 686, in test_train_parity_with_activation_checkpointing
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1147, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_training.py", line 775, in _test_train_parity_with_activation_checkpointing
    check_sharded_parity(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1123, in check_sharded_parity
    cls.assertEqual(sharded_param.grad.to_local(), sharded_ref_grad.to_local())
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Tensor-likes are not close!

Mismatched elements: 1 / 128 (0.8%)
Greatest absolute difference: 1.0728836059570312e-05 at index (3, 12) (up to 1e-05 allowed)
Greatest relative difference: 0.00028740588459186256 at index (3, 12) (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_training.py TestFullyShard1DTrainingCompose.test_train_parity_with_activation_checkpointing

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
============= 6 failed, 12 passed, 6 skipped in 691.13s (0:11:31) ==============
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:23:31.046] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 10 items
Running 10 items in this shard

../../../../test/distributed/_composable/test_replicate_with_compiler.py::ReplicateTest::test_bucketing_coalesced_op [2025-09-12 16:23:42.290] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:23:42.298] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
PASSED [24.7439s] [ 10%]
../../../../test/distributed/_composable/test_replicate_with_compiler.py::ReplicateTest::test_bucketing_concat_op [2025-09-12 16:24:06.947] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:24:06.954] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
PASSED [25.0412s] [ 20%]
../../../../test/distributed/_composable/test_replicate_with_compiler.py::ReplicateTest::test_compile_backward_only [2025-09-12 16:24:31.989] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:24:32.006] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:24:45:1236416 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:24:45:1236416 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:24:46:1236417 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:24:46:1236417 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [60.0964s] [ 30%]
../../../../test/distributed/_composable/test_replicate_with_compiler.py::ReplicateTest::test_compile_bf16 [2025-09-12 16:25:32.086] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:25:32.086] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:25:45:1238008 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:25:45:1238008 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:25:47:1238009 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:25:47:1238009 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [57.7877s] [ 40%]
../../../../test/distributed/_composable/test_replicate_with_compiler.py::ReplicateTest::test_compile_cpu [2025-09-12 16:26:29.882] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:26:29.890] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
PASSED [24.3417s] [ 50%]
../../../../test/distributed/_composable/test_replicate_with_compiler.py::ReplicateTest::test_compile_cpu_no_sync [2025-09-12 16:26:54.307] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:26:54.314] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
PASSED [25.6427s] [ 60%]
../../../../test/distributed/_composable/test_replicate_with_compiler.py::ReplicateTest::test_compile_fp16 [2025-09-12 16:27:19.860] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:27:19.874] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:27:33:1246027 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:27:33:1246027 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:27:34:1246026 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:27:34:1246026 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [24.3383s] [ 70%]
../../../../test/distributed/_composable/test_replicate_with_compiler.py::ReplicateTest::test_compile_gpu [2025-09-12 16:27:44.202] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:27:44.215] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:27:57:1247485 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:27:57:1247485 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:27:58:1247484 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:27:58:1247484 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [61.6954s] [ 80%]
../../../../test/distributed/_composable/test_replicate_with_compiler.py::ReplicateTest::test_compile_gpu_ac [2025-09-12 16:28:45.902] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:28:45.902] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:28:59:1249090 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:28:59:1249090 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:29:00:1249091 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:29:00:1249091 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [62.1997s] [ 90%]
../../../../test/distributed/_composable/test_replicate_with_compiler.py::DDP_TP_Test::test_ddp_tp SKIPPED [0.0003s] SymInt`) [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__composable_test_replicate_with_compiler.py.xml -
=================== 9 passed, 1 skipped in 376.97s (0:06:16) ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:29:49.270] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/_shard/test_sharder.py::TestCustomSharder::test_custom_sharder [2025-09-12 16:29:51.407] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:29:51.418] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:29:51.419] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:29:51.440] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:29:51:1250774 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:29:51:1250774 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:29:51:1250773 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:29:51:1250773 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:29:51:1250772 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:29:51:1250772 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:29:51:1250771 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:29:51:1250771 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [31.8142s] [ 50%]
../../../../test/distributed/_shard/test_sharder.py::TestCustomSharder::test_custom_sharder_errors [2025-09-12 16:30:23.062] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:30:23.074] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:30:23.078] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:30:23.098] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:30:23:1251072 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:30:23:1251072 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:30:23:1251073 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:30:23:1251073 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:30:23:1251075 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:30:23:1251075 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:30:23:1251074 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:30:23:1251074 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6246s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__shard_test_sharder.py.xml -
============================== 2 passed in 49.32s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:30:39.023] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 1 item
Running 1 items in this shard

../../../../test/distributed/_shard/sharded_tensor/test_logger.py::ShardingSpecLoggerTest::test_get_or_create_logger PASSED [0.1894s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__shard_sharded_tensor_test_logger.py.xml -
============================== 1 passed in 2.07s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:30:42.671] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 74 items
Running 74 items in this shard

../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorMetadata::test_serialize_and_deserialize PASSED [0.2236s] [  1%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestCreateTensorFromParams::test_empty PASSED [0.0016s] [  2%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardParameter::test_shard_parameter [2025-09-12 16:30:44.867] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:30:44.898] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:30:44.914] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:30:44.914] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:30:45:1251521 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:30:45:1251521 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:30:45:1251522 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:30:45:1251522 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:30:45:1251520 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:30:45:1251520 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:30:45:1251519 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:30:45:1251519 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9304s] [  4%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardParameter::test_shard_parameter_errors [2025-09-12 16:31:00.798] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:31:00.846] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:31:00.850] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:31:00.858] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:31:01:1251822 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:31:01:1251822 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:31:01:1251820 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:31:01:1251820 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:31:01:1251821 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:31:01:1251821 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:31:01:1251823 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:31:01:1251823 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8283s] [  5%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardTensor::test_shard_tensor [2025-09-12 16:31:16.657] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:31:16.658] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:31:16.668] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:31:16.678] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:31:16:1252121 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:31:16:1252121 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:31:16:1252124 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:31:16:1252124 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:31:16:1252123 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:31:16:1252123 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:31:16:1252122 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:31:16:1252122 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9302s] [  6%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardTensor::test_shard_tensor_errors [2025-09-12 16:31:32.575] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:31:32.578] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:31:32.591] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:31:32.618] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:31:32:1252425 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:31:32:1252425 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:31:32:1252422 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:31:32:1252422 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:31:32:1252423 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:31:32:1252423 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:31:32:1252424 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:31:32:1252424 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9300s] [  8%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardTensor::test_shard_tensor_with_empty_shard [2025-09-12 16:31:48.474] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:31:48.563] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:31:48.578] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:31:48.587] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:31:48:1252723 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:31:48:1252723 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:31:48:1252724 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:31:48:1252724 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:31:48:1252726 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:31:48:1252726 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:31:48:1252725 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:31:48:1252725 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8296s] [  9%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestModuleHookApi::test_collect_local_shard [2025-09-12 16:32:04.342] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:32:04.358] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:32:04.358] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:32:04.378] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:32:04:1253025 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:32:04:1253025 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:32:04:1253026 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:32:04:1253026 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:32:04:1253023 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:32:04:1253023 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:32:04:1253024 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:32:04:1253024 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6291s] [ 10%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestModuleHookApi::test_reshard_output [2025-09-12 16:32:19.986] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:32:19.998] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:32:20.010] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:32:20.014] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:32:20:1253328 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:32:20:1253328 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:32:20:1253325 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:32:20:1253325 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:32:20:1253326 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:32:20:1253326 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:32:20:1253327 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:32:20:1253327 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0301s] [ 12%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestLocalTensor::test_local_tensor [2025-09-12 16:32:35.966] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:32:36.030] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:32:36.032] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:32:36.050] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:32:36:1253628 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:32:36:1253628 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:32:36:1253630 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:32:36:1253630 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:32:36:1253629 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:32:36:1253629 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:32:36:1253631 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:32:36:1253631 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7293s] [ 13%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestLocalTensor::test_local_tensor_error [2025-09-12 16:32:51.751] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:32:51.778] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:32:51.785] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:32:51.791] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:32:51:1253931 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:32:51:1253931 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:32:51:1253929 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:32:51:1253929 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:32:51:1253932 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:32:51:1253932 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:32:52:1253930 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:32:52:1253930 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6293s] [ 14%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_cleanup [2025-09-12 16:33:07.362] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:33:07.409] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:33:07.414] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:33:07.415] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:33:07:1254231 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:33:07:1254231 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:33:07:1254233 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:33:07:1254233 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:33:07:1254232 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:33:07:1254232 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:33:07:1254230 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:33:07:1254230 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0289s] [ 16%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_complete_world_size [2025-09-12 16:33:23.366] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:33:23.412] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:33:23.442] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:33:23.450] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
FAILED [3.1096s] [ 17%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_create_sharded_tensor_like [2025-09-12 16:33:26.519] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:33:26.537] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:33:26.546] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:33:26.547] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:33:27:1255240 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:33:27:1255240 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:33:27:1255241 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:33:27:1255241 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:33:27:1255238 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:33:27:1255238 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:33:27:1255239 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:33:27:1255239 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.2308s] [ 18%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_create_sharded_tensor_with_full [2025-09-12 16:33:42.738] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:33:42.748] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:33:42.770] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:33:42.782] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:33:43:1255740 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:33:43:1255740 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:33:43:1255742 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:33:43:1255742 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:33:43:1255743 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:33:43:1255743 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:33:43:1255741 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:33:43:1255741 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6288s] [ 20%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_create_sharded_tensor_with_ones [2025-09-12 16:33:58.346] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:33:58.411] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:33:58.411] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:33:58.434] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:33:58:1256225 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:33:58:1256225 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:33:58:1256226 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:33:58:1256226 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:33:58:1256227 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:33:58:1256227 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:33:58:1256228 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:33:58:1256228 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0304s] [ 21%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_create_sharded_tensor_with_rand [2025-09-12 16:34:14.397] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:34:14.397] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:34:14.419] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:34:14.419] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:34:14:1256712 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:34:14:1256712 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:34:14:1256711 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:34:14:1256711 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:34:15:1256714 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:34:15:1256713 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:34:15:1256714 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:34:15:1256713 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9300s] [ 22%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_create_sharded_tensor_with_zeros [2025-09-12 16:34:30.339] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:34:30.346] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:34:30.353] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:34:30.367] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:34:30:1257195 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:34:30:1257195 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:34:30:1257196 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:34:30:1257196 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:34:30:1257198 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:34:30:1257197 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:34:30:1257198 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:34:30:1257197 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7297s] [ 24%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_gather_even [2025-09-12 16:34:46.050] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:34:46.065] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:34:46.086] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:34:46.090] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:34:46:1257679 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:34:46:1257679 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:34:46:1257680 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:34:46:1257680 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:34:46:1257681 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:34:46:1257681 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:34:46:1257682 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:34:46:1257682 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0299s] [ 25%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_gather_uneven [2025-09-12 16:35:02.079] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:02.098] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:02.126] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:02.126] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:35:02:1258166 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:35:02:1258166 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:35:02:1258163 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:35:02:1258163 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:35:02:1258164 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:35:02:1258164 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:35:02:1258165 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:35:02:1258165 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9286s] [ 27%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_insufficient_sharding_dims [2025-09-12 16:35:18.004] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:18.022] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:18.034] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:18.050] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.8084s] [ 28%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_invalid_pg_rpc_ranks [2025-09-12 16:35:20.827] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:20.834] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:20.852] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:20.874] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
PASSED [3.1090s] [ 29%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_invalid_sharding [2025-09-12 16:35:23.930] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:23.946] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:23.953] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:23.974] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
PASSED [3.0089s] [ 31%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_load_state_dict_errors [2025-09-12 16:35:26.985] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:26.991] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:27.002] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:27.019] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
PASSED [3.0201s] [ 32%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_multiple_local_shards [2025-09-12 16:35:29.942] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:30.009] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:30.030] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:30.038] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
FAILED [3.1093s] [ 33%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_new_group [2025-09-12 16:35:33.082] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:33.129] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:33.158] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:33.162] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
FAILED [3.1088s] [ 35%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_partial_world_size [2025-09-12 16:35:36.208] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:36.230] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:36.252] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:36.254] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
FAILED [3.0088s] [ 36%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_sharded_tensor_metadata [2025-09-12 16:35:39.225] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:39.225] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:39.225] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:39.232] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:35:39:1261783 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:35:39:1261783 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:35:39:1261781 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:35:39:1261781 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:35:39:1261782 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:35:39:1261782 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:35:39:1261780 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:35:39:1261780 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9303s] [ 37%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_sharded_tensor_sizes [2025-09-12 16:35:55.129] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:55.149] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:55.171] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:35:55.174] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:35:55:1262267 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:35:55:1262267 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:35:55:1262265 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:35:55:1262268 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:35:55:1262266 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:35:55:1262265 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:35:55:1262268 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:35:55:1262266 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.2315s] [ 39%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_sharding_columns [2025-09-12 16:36:11.369] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:36:11.390] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:36:11.406] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:36:11.410] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.8080s] [ 40%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_state_dict [2025-09-12 16:36:14.150] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:36:14.226] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:36:14.228] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:36:14.251] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:36:14:1263041 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:36:14:1263041 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:36:14:1263040 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:36:14:1263040 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:36:14:1263043 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:36:14:1263043 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:36:14:1263042 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:36:14:1263042 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0297s] [ 41%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_state_dict_new_group [2025-09-12 16:36:30.238] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:36:30.246] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:36:30.250] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:36:30.266] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:36:30:1263524 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:36:30:1263524 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:36:30:1263525 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:36:30:1263525 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:36:30:1263526 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:36:30:1263526 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:36:30:1263527 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:36:30:1263527 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:36:43:1263526:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:36:43:1263527:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [28.0378s] [ 43%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_state_dict_no_sharded_tensors [2025-09-12 16:36:58.229] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:36:58.234] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:36:58.236] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:36:58.270] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:36:58:1264013 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:36:58:1264013 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:36:58:1264015 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:36:58:1264015 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:36:58:1264016 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:36:58:1264016 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:36:58:1264014 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:36:58:1264014 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8303s] [ 44%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorEnumerable::test_create_sharded_tensor_with_ones [2025-09-12 16:37:14.023] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:37:14.098] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:37:14.147] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:37:14.164] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:37:14:1264500 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:37:14:1264500 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:37:14:1264502 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:37:14:1264502 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:37:14:1264499 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:37:14:1264499 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:37:14:1264501 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:37:14:1264501 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0305s] [ 45%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorEnumerable::test_gather_even [2025-09-12 16:37:30.130] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:37:30.145] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:37:30.250] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:37:30.262] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:37:30:1264986 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:37:30:1264986 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:37:30:1264985 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:37:30:1264985 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:37:30:1264984 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:37:30:1264984 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:37:30:1264987 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:37:30:1264987 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9299s] [ 47%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorEnumerable::test_gather_uneven [2025-09-12 16:37:46.055] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:37:46.067] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:37:46.080] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:37:46.086] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:37:46:1265472 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:37:46:1265472 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:37:46:1265473 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:37:46:1265473 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:37:46:1265470 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:37:46:1265470 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:37:46:1265471 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:37:46:1265471 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.1296s] [ 48%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorEnumerable::test_grid_sharding [2025-09-12 16:38:02.150] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:02.226] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:02.246] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:02.263] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
FAILED [3.1100s] [ 50%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorEnumerable::test_multiple_local_shards [2025-09-12 16:38:05.315] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:05.325] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:05.325] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:05.325] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
FAILED [3.0091s] [ 51%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorEnumerable::test_new_group [2025-09-12 16:38:08.319] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:08.319] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:08.334] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:08.346] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
FAILED [3.0089s] [ 52%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorEnumerable::test_partial_world_size [2025-09-12 16:38:11.334] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:11.336] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:11.338] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:11.346] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
FAILED [3.0088s] [ 54%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorEnumerable::test_sharded_tensor_device [2025-09-12 16:38:14.328] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:14.342] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:14.364] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:14.378] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:38:14:1267852 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:38:14:1267852 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:38:14:1267853 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:38:14:1267853 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:38:14:1267855 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:38:14:1267855 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:38:14:1267854 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:38:14:1267854 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0307s] [ 55%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorEnumerable::test_sharded_tensor_metadata [2025-09-12 16:38:30.363] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:30.366] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:30.366] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:30.386] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:38:30:1268336 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:38:30:1268336 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:38:30:1268338 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:38:30:1268338 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:38:30:1268337 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:38:30:1268337 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:38:30:1268339 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:38:30:1268339 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8286s] [ 56%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorEnumerable::test_sharded_tensor_to_accelerator [2025-09-12 16:38:46.167] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:46.170] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:46.182] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:38:46.210] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:38:46:1268820 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:38:46:1268820 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:38:46:1268822 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:38:46:1268822 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:38:46:1268823 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:38:46:1268823 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:38:46:1268821 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:38:46:1268821 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0310s] [ 58%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorEnumerable::test_sharded_tensor_to_cpu [2025-09-12 16:39:02.214] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:02.217] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:02.230] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:02.266] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:39:02:1269317 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:39:02:1269317 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:39:02:1269319 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:39:02:1269319 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:39:02:1269316 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:39:02:1269316 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:39:02:1269318 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:39:02:1269318 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.1310s] [ 59%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorEnumerable::test_sharded_tensor_to_test [2025-09-12 16:39:18.302] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:18.355] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:18.374] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:18.380] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:39:18:1269816 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:39:18:1269816 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:39:18:1269817 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:39:18:1269817 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:39:18:1269815 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:39:18:1269814 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:39:18:1269815 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:39:18:1269814 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.3311s] [ 60%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorEnumerable::test_uneven_shards [2025-09-12 16:39:34.691] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:34.714] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:34.722] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:34.734] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.8086s] [ 62%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorEnumerable::test_with_rpc_names [2025-09-12 16:39:37.482] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:37.518] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:37.534] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:37.546] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
FAILED [3.1089s] [ 63%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalTensor::test_init_from_local_tensor [2025-09-12 16:39:40.590] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:40.610] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:40.613] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:40.626] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
FAILED [3.2088s] [ 64%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalTensor::test_init_from_local_tensor_errors [2025-09-12 16:39:43.830] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:43.830] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:43.842] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:43.878] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:39:44:1271547 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:39:44:1271547 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:39:44:1271546 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:39:44:1271546 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:39:44:1271548 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:39:44:1271548 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:39:44:1271549 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:39:44:1271549 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0298s] [ 66%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalShards::test_init_from_local_shards [2025-09-12 16:39:59.823] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:59.846] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:59.876] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:39:59.902] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:40:00:1272031 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:00:1272031 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:40:00:1272032 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:00:1272032 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:40:00:1272034 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:00:1272034 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:40:00:1272033 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:00:1272033 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
write: error: buf 0x55d1155aec30, size 394, shift 0
write: error: buf 0x563ae7a32190, size 394, shift 0
FAILED [4.3105s] [ 67%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalShards::test_init_from_local_shards_and_global_metadata [2025-09-12 16:40:04.151] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:40:04.161] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:40:04.162] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:40:04.185] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
FAILED [3.0089s] [ 68%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalShards::test_init_from_local_shards_and_global_metadata_invalid_shards [2025-09-12 16:40:07.152] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:40:07.172] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:40:07.177] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:40:07.198] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:40:07:1272996 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:07:1272996 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:40:07:1272997 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:07:1272997 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:40:07:1272998 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:07:1272998 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:40:07:1272999 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:07:1272999 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.1311s] [ 70%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalShards::test_init_from_local_shards_and_global_metadata_with_all_zeros [2025-09-12 16:40:23.283] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:40:23.292] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:40:23.294] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:40:23.305] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:40:23:1273480 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:23:1273480 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:40:23:1273482 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:23:1273482 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:40:23:1273483 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:23:1273483 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:40:23:1273481 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:23:1273481 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.4290s] [ 71%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalShards::test_init_from_local_shards_and_global_metadata_with_local_view [2025-09-12 16:40:38.762] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:40:38.762] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:40:38.772] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:40:38.778] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:40:38:1273782 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:38:1273782 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:40:38:1273783 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:38:1273783 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:40:39:1273781 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:39:1273781 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:40:39:1273780 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:39:1273780 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6288s] [ 72%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalShards::test_init_from_local_shards_invalid_local_shards [2025-09-12 16:40:54.343] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:40:54.345] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:40:54.362] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:40:54.363] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:40:54:1274081 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:54:1274081 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:40:54:1274083 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:54:1274083 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:40:54:1274084 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:54:1274082 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:40:54:1274084 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:40:54:1274082 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.3311s] [ 74%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalShards::test_init_from_local_shards_invalid_pin_memory [2025-09-12 16:41:10.678] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:41:10.678] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:41:10.692] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:41:10.710] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:41:10:1274567 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:41:10:1274567 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:41:10:1274568 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:41:10:1274568 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:41:10:1274570 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:41:10:1274570 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:41:10:1274569 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:41:10:1274569 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7293s] [ 75%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalShards::test_init_from_local_shards_invalid_property_cross_ranks [2025-09-12 16:41:26.387] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:41:26.426] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:41:26.426] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:41:26.430] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:41:26:1274869 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:41:26:1274869 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:41:26:1274870 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:41:26:1274870 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:41:26:1274872 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:41:26:1274872 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:41:26:1274871 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:41:26:1274871 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.3312s] [ 77%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalShards::test_init_from_local_shards_invalid_shards_gaps [2025-09-12 16:41:42.718] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:41:42.746] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:41:42.774] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:41:42.835] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:41:43:1275353 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:41:43:1275353 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:41:43:1275354 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:41:43:1275355 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:41:43:1275354 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:41:43:1275355 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:41:43:1275356 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:41:43:1275356 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.1285s] [ 78%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalShards::test_init_from_local_shards_invalid_shards_overlap [2025-09-12 16:41:58.859] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:41:58.876] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:41:58.878] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:41:58.890] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:41:59:1275839 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:41:59:1275839 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:41:59:1275842 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:41:59:1275842 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:41:59:1275841 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:41:59:1275840 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:41:59:1275841 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:41:59:1275840 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.3305s] [ 79%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalShards::test_init_from_local_shards_new_group [2025-09-12 16:42:15.286] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:42:15.290] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:42:15.297] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:42:15.306] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:42:15:1276324 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:42:15:1276324 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:42:15:1276325 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:42:15:1276326 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:42:15:1276327 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:42:15:1276325 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:42:15:1276327 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:42:15:1276326 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:42:16:1276326:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:42:16:1276325:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:42:16:1276327:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [16.7310s] [ 81%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalShards::test_init_from_local_shards_with_different_glb_size [2025-09-12 16:42:31.930] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:42:31.942] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:42:32.071] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:42:32.095] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:42:32:1276816 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:42:32:1276816 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:42:32:1276817 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:42:32:1276817 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:42:32:1276815 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:42:32:1276815 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:42:32:1276818 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:42:32:1276818 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8296s] [ 82%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalShards::test_local_shards [2025-09-12 16:42:47.763] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:42:47.775] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:42:47.775] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:42:47.790] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:42:47:1277118 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:42:47:1277118 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:42:47:1277119 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:42:47:1277119 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:42:48:1277116 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:42:48:1277116 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:42:48:1277117 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:42:48:1277117 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.5294s] [ 83%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalShards::test_non_rw_sharded_recalc_for_metadata [2025-09-12 16:43:03.279] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:43:03.294] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:43:03.301] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:43:03.306] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:43:03:1277419 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:43:03:1277419 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:43:03:1277417 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:43:03:1277417 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:43:03:1277418 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:43:03:1277418 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:43:03:1277416 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:43:03:1277416 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7298s] [ 85%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalShards::test_recalc_for_metadata [2025-09-12 16:43:19.021] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:43:19.038] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:43:19.066] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:43:19.074] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:43:19:1277718 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:43:19:1277718 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:43:19:1277720 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:43:19:1277720 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:43:19:1277721 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:43:19:1277721 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:43:19:1277719 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:43:19:1277719 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8303s] [ 86%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalShards::test_st_base_init_from_local_shards_and_global_metadata [2025-09-12 16:43:34.845] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:43:34.862] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:43:34.864] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:43:34.886] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.8082s] [ 87%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorCustomOps::test_custom_op [2025-09-12 16:43:37.662] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:43:37.706] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:43:37.714] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:43:37.718] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:43:38:1278302 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:43:38:1278302 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:43:38:1278305 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:43:38:1278305 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:43:38:1278304 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:43:38:1278304 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:43:38:1278303 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:43:38:1278303 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0296s] [ 89%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorCustomOps::test_custom_op_errors [2025-09-12 16:43:53.758] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:43:53.801] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:43:53.822] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:43:53.838] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:43:54:1278786 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:43:54:1278786 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:43:54:1278787 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:43:54:1278787 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:43:54:1278789 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:43:54:1278788 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:43:54:1278789 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:43:54:1278788 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0300s] [ 90%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorCustomOps::test_custom_op_override [2025-09-12 16:44:09.702] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:44:09.748] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:44:09.765] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:44:09.786] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:44:10:1279272 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:44:10:1279272 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:44:10:1279273 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:44:10:1279273 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:44:10:1279275 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:44:10:1279275 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:44:10:1279274 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:44:10:1279274 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.4314s] [ 91%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardMetadata::test_create_shard_with_no_placement [2025-09-12 16:44:26.166] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:44:26.173] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:44:26.202] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:44:26.206] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:44:26:1279756 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:44:26:1279756 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:44:26:1279757 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:44:26:1279757 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:44:26:1279758 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:44:26:1279759 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:44:26:1279758 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:44:26:1279759 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9299s] [ 93%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardMetadata::test_shard_metadata_init [2025-09-12 16:44:42.153] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:44:42.174] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:44:42.190] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:44:42.206] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:44:42:1280240 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:44:42:1280240 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:44:42:1280241 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:44:42:1280241 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:44:42:1280243 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:44:42:1280243 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:44:42:1280242 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:44:42:1280242 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9298s] [ 94%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorSubGroupInit::test_sub_process_group_placement_validation PASSED [0.0228s] [ 95%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorSubGroupInit::test_sub_process_group_sharded_tensor_init PASSED [0.0069s] [ 97%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestCreateTensorNoProcessGroupMode::test_init_from_local_shards_and_global_metadata PASSED [0.0005s] [ 98%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestCreateTensorNoProcessGroupMode::test_non_contiguous_local_shards PASSED [0.0005s] [100%]

=================================== FAILURES ===================================
______________ TestShardedTensorChunked.test_complete_world_size _______________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 566, in test_complete_world_size
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorChunked.test_complete_world_size

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 2 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 16:33:21.539000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1254765
I0912 16:33:21.540000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1254766
I0912 16:33:21.541000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1254767
I0912 16:33:21.541000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1254768
_____________ TestShardedTensorChunked.test_multiple_local_shards ______________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 999, in test_multiple_local_shards
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorChunked.test_multiple_local_shards

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 3 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 16:35:28.117000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1260356
I0912 16:35:28.118000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1260357
I0912 16:35:28.118000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1260358
I0912 16:35:28.119000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1260359
___________________ TestShardedTensorChunked.test_new_group ____________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 942, in test_new_group
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorChunked.test_new_group

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 0 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 16:35:31.228000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1260829
I0912 16:35:31.229000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1260830
I0912 16:35:31.230000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1260831
I0912 16:35:31.230000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1260832
_______________ TestShardedTensorChunked.test_partial_world_size _______________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 886, in test_partial_world_size
    shard = remote_shard.to_here()
RuntimeError: ECONNRESET: connection reset by peer (this error originated at tensorpipe/transport/uv/connection_impl.cc:132)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorChunked.test_partial_world_size

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 1 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 16:35:34.339000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1261306
I0912 16:35:34.339000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1261307
I0912 16:35:34.340000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1261308
I0912 16:35:34.340000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1261309
________________ TestShardedTensorEnumerable.test_grid_sharding ________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 1561, in test_grid_sharding
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorEnumerable.test_grid_sharding

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 2 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 16:38:00.316000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1265954
I0912 16:38:00.317000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1265955
I0912 16:38:00.317000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1265956
I0912 16:38:00.318000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1265957
____________ TestShardedTensorEnumerable.test_multiple_local_shards ____________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 2233, in test_multiple_local_shards
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorEnumerable.test_multiple_local_shards

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 3 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 16:38:03.429000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1266427
I0912 16:38:03.430000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1266428
I0912 16:38:03.430000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1266429
I0912 16:38:03.431000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1266430
__________________ TestShardedTensorEnumerable.test_new_group __________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 2148, in test_new_group
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorEnumerable.test_new_group

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 2 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 16:38:06.439000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1266902
I0912 16:38:06.440000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1266903
I0912 16:38:06.440000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1266904
I0912 16:38:06.441000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1266905
_____________ TestShardedTensorEnumerable.test_partial_world_size ______________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 2078, in test_partial_world_size
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorEnumerable.test_partial_world_size

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 2 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 16:38:09.450000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1267379
I0912 16:38:09.450000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1267380
I0912 16:38:09.451000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1267381
I0912 16:38:09.451000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1267382
_______________ TestShardedTensorEnumerable.test_with_rpc_names ________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 2305, in test_with_rpc_names
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorEnumerable.test_with_rpc_names

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 2305, in test_with_rpc_names
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorEnumerable.test_with_rpc_names

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 2 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 16:39:35.627000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1270598
I0912 16:39:35.628000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1270599
I0912 16:39:35.629000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1270600
I0912 16:39:35.629000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1270601
_________ TestShardedTensorFromLocalTensor.test_init_from_local_tensor _________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 2379, in test_init_from_local_tensor
    self._generate_st_from_chunk_local_tensor([20, 10], spec)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 2367, in _generate_st_from_chunk_local_tensor
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorFromLocalTensor.test_init_from_local_tensor

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 1 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 16:39:38.738000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1271072
I0912 16:39:38.739000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1271073
I0912 16:39:38.739000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1271074
I0912 16:39:38.740000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1271075
_________ TestShardedTensorFromLocalShards.test_init_from_local_shards _________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1056, in _check_return_codes
    self.assertEqual(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4180, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Scalars are not equal!

Expected 0 but got -6.
Absolute difference: 6
Relative difference: inf
Expected exit code 0 but got -6 for pid: 1272031
----------------------------- Captured stderr call -----------------------------
I0912 16:39:57.979000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1272031
I0912 16:39:57.980000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1272032
I0912 16:39:57.980000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1272033
I0912 16:39:57.981000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1272034
_ TestShardedTensorFromLocalShards.test_init_from_local_shards_and_global_metadata _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 2950, in test_init_from_local_shards_and_global_metadata
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorFromLocalShards.test_init_from_local_shards_and_global_metadata

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 2 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 16:40:02.291000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1272520
I0912 16:40:02.292000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1272521
I0912 16:40:02.292000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1272522
I0912 16:40:02.293000 1251447 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1272523
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__shard_sharded_tensor_test_sharded_tensor.py.xml -
=========================== short test summary info ============================
FAILED [3.1096s] ../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_complete_world_size - RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 566, in test_complete_world_size
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorChunked.test_complete_world_size

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [3.1093s] ../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_multiple_local_shards - RuntimeError: Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 999, in test_multiple_local_shards
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorChunked.test_multiple_local_shards

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [3.1088s] ../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_new_group - RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 942, in test_new_group
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorChunked.test_new_group

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [3.0088s] ../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorChunked::test_partial_world_size - RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 886, in test_partial_world_size
    shard = remote_shard.to_here()
RuntimeError: ECONNRESET: connection reset by peer (this error originated at tensorpipe/transport/uv/connection_impl.cc:132)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorChunked.test_partial_world_size

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [3.1100s] ../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorEnumerable::test_grid_sharding - RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 1561, in test_grid_sharding
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorEnumerable.test_grid_sharding

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [3.0091s] ../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorEnumerable::test_multiple_local_shards - RuntimeError: Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 2233, in test_multiple_local_shards
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorEnumerable.test_multiple_local_shards

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [3.0089s] ../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorEnumerable::test_new_group - RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 2148, in test_new_group
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorEnumerable.test_new_group

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [3.0088s] ../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorEnumerable::test_partial_world_size - RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 2078, in test_partial_world_size
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorEnumerable.test_partial_world_size

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [3.1089s] ../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorEnumerable::test_with_rpc_names - RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 2305, in test_with_rpc_names
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorEnumerable.test_with_rpc_names

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 2305, in test_with_rpc_names
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorEnumerable.test_with_rpc_names

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [3.2088s] ../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalTensor::test_init_from_local_tensor - RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 2379, in test_init_from_local_tensor
    self._generate_st_from_chunk_local_tensor([20, 10], spec)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 2367, in _generate_st_from_chunk_local_tensor
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorFromLocalTensor.test_init_from_local_tensor

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
FAILED [4.3105s] ../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalShards::test_init_from_local_shards - AssertionError: Scalars are not equal!

Expected 0 but got -6.
Absolute difference: 6
Relative difference: inf
Expected exit code 0 but got -6 for pid: 1272031
FAILED [3.0089s] ../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor.py::TestShardedTensorFromLocalShards::test_init_from_local_shards_and_global_metadata - RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 1918, in wrapper
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102, in wrapper
    func(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_shard/sharded_tensor/test_sharded_tensor.py", line 2950, in test_init_from_local_shards_and_global_metadata
    shard = remote_shard.to_here()
RuntimeError: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_shard/sharded_tensor/test_sharded_tensor.py TestShardedTensorFromLocalShards.test_init_from_local_shards_and_global_metadata

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
================== 12 failed, 62 passed in 855.39s (0:14:15) ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:44:59.002] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor_reshard.py::TestReshard::test_sharded_tensor_reshard [2025-09-12 16:45:01.188] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:45:01.194] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:45:01.206] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:45:01.226] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:45:01:1280813 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:45:01:1280813 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:45:01:1280814 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:45:01:1280814 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:45:01:1280812 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:45:01:1280812 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:45:01:1280815 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:45:01:1280815 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.3178s] [ 50%]
../../../../test/distributed/_shard/sharded_tensor/test_sharded_tensor_reshard.py::TestReshard::test_sharded_tensor_reshard_errors [2025-09-12 16:45:17.301] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:45:17.318] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:45:17.319] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:45:17.342] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:45:17:1281116 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:45:17:1281116 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:45:17:1281115 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:45:17:1281115 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:45:17:1281114 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:45:17:1281114 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:45:17:1281113 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:45:17:1281113 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6293s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__shard_sharded_tensor_test_sharded_tensor_reshard.py.xml -
============================== 2 passed in 33.94s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:45:33.758] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 3 items
Running 3 items in this shard

../../../../test/distributed/_shard/sharding_plan/test_sharding_plan.py::TestShardingPlan::test_custom_sharding_planner [2025-09-12 16:45:35.906] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:45:35.908] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:45:35.939] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:45:35.958] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:45:36:1281488 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:45:36:1281488 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:45:36:1281489 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:45:36:1281489 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:45:36:1281491 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:45:36:1281491 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:45:36:1281490 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:45:36:1281490 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9969s] [ 33%]
../../../../test/distributed/_shard/sharding_plan/test_sharding_plan.py::TestShardingPlan::test_shard_module_sub_process_group [2025-09-12 16:45:51.724] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:45:51.742] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:45:51.754] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:45:51.770] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:45:51:1281789 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:45:51:1281789 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:45:51:1281791 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:45:51:1281791 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:45:51:1281790 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:45:51:1281790 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:45:52:1281788 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:45:52:1281788 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:45:53:1281790:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:45:53:1281791:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [16.4298s] [ 66%]
../../../../test/distributed/_shard/sharding_plan/test_sharding_plan.py::TestShardingPlan::test_sharding_plan_errors [2025-09-12 16:46:08.170] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:46:08.170] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:46:08.171] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:46:08.194] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:46:08:1282096 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:46:08:1282096 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:46:08:1282095 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:46:08:1282095 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:46:08:1282094 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:46:08:1282094 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:46:08:1282093 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:46:08:1282093 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7296s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__shard_sharding_plan_test_sharding_plan.py.xml -
============================== 3 passed in 50.04s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:46:24.246] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 11 items
Running 11 items in this shard

../../../../test/distributed/_shard/sharding_spec/test_sharding_spec.py::TestShardingSpec::test_check_overlapping PASSED [0.0731s] [  9%]
../../../../test/distributed/_shard/sharding_spec/test_sharding_spec.py::TestShardingSpec::test_chunked_sharding_spec SKIPPED [0.0002s] [ 18%]
../../../../test/distributed/_shard/sharding_spec/test_sharding_spec.py::TestShardingSpec::test_device_placement SKIPPED [0.0001s] [ 27%]
../../../../test/distributed/_shard/sharding_spec/test_sharding_spec.py::TestShardingSpec::test_enumerable_sharding_spec SKIPPED [0.0003s] [ 36%]
../../../../test/distributed/_shard/sharding_spec/test_sharding_spec.py::TestShardingSpec::test_get_chunk_sharding_params PASSED [0.0008s] [ 45%]
../../../../test/distributed/_shard/sharding_spec/test_sharding_spec.py::TestShardingSpec::test_get_chunked_dim_size PASSED [0.0006s] [ 54%]
../../../../test/distributed/_shard/sharding_spec/test_sharding_spec.py::TestShardingSpec::test_get_split_size PASSED [0.0006s] [ 63%]
../../../../test/distributed/_shard/sharding_spec/test_sharding_spec.py::TestShardingSpec::test_infer_sharding_spec_from_shards_metadata PASSED [0.0050s] [ 72%]
../../../../test/distributed/_shard/sharding_spec/test_sharding_spec.py::TestCustomShardingSpec::test_custom_sharding_spec [2025-09-12 16:46:26.338] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:46:26.362] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:46:26.362] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:46:26.380] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [3.0087s] [ 81%]
../../../../test/distributed/_shard/sharding_spec/test_sharding_spec.py::TestCustomShardingSpec::test_custom_sharding_spec_shard_tensor SKIPPED [0.0004s] [ 90%]
../../../../test/distributed/_shard/sharding_spec/test_sharding_spec.py::TestCustomShardingSpec::test_custom_sharding_spec_tensor_ctor SKIPPED [0.0001s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__shard_sharding_spec_test_sharding_spec.py.xml -
========================= 6 passed, 5 skipped in 5.09s =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:46:30.883] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 3 items
Running 3 items in this shard

../../../../test/distributed/_tools/test_fsdp2_mem_tracker.py::TestTrackerFullyShard1DTrainingCore::test_tracker_multi_group_eager [2025-09-12 16:46:33.106] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:46:33.110] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:46:33.114] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:46:33.118] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:46:33:1282826 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:46:33:1282826 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:46:33:1282827 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:46:33:1282827 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:46:33:1282825 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:46:33:1282825 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:46:33:1282828 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:46:33:1282828 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
PASSED [28.3727s] [ 33%]
../../../../test/distributed/_tools/test_fsdp2_mem_tracker.py::TestTrackerFullyShard1DTrainingCore::test_tracker_non_root_forward_backward [2025-09-12 16:47:01.230] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:47:01.232] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:47:01.246] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:47:01.246] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:47:01:1283526 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:47:01:1283526 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:47:01:1283525 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:47:01:1283525 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:47:01:1283523 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:47:01:1283523 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:47:01:1283524 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:47:01:1283524 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=0, world=4
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
PASSED [22.1293s] [ 66%]
../../../../test/distributed/_tools/test_fsdp2_mem_tracker.py::TestTrackerFullyShard1DTrainingCompose::test_tracker_with_activation_checkpointing [2025-09-12 16:47:23.355] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:47:23.370] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:47:23.370] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:47:23.372] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:47:23:1283844 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:47:23:1283844 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:47:23:1283842 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:47:23:1283842 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:47:23:1283841 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:47:23:1283841 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:47:23:1283843 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:47:23:1283843 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=3, world=4
dist init r=1, world=4
dist init r=2, world=4
dist init r=0, world=4
PASSED [36.6645s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__tools_test_fsdp2_mem_tracker.py.xml -
========================= 3 passed in 89.16s (0:01:29) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:48:00.878] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 3 items
Running 3 items in this shard

../../../../test/distributed/_tools/test_mem_tracker.py::TestMemTracker::test_accelerator_tracker_equivalence PASSED [0.4146s] [ 33%]
../../../../test/distributed/_tools/test_mem_tracker.py::TestMemTracker::test_tracker_attribution PASSED [0.0520s] [ 66%]
../../../../test/distributed/_tools/test_mem_tracker.py::TestMemTracker::test_tracker_with_activation_checkpointing PASSED [0.3522s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__tools_test_mem_tracker.py.xml -
============================== 3 passed in 2.71s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:48:04.727] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 1 item
Running 1 items in this shard

../../../../test/distributed/_tools/test_memory_tracker.py::TestMemoryTracker::test_local_model PASSED [0.5712s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__tools_test_memory_tracker.py.xml -
============================== 1 passed in 2.57s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:48:08.299] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 4 items
Running 4 items in this shard

../../../../test/distributed/_tools/test_mod_tracker.py::TestModTracker::test_ac PASSED [0.1931s] [ 25%]
../../../../test/distributed/_tools/test_mod_tracker.py::TestModTracker::test_bw_detection PASSED [0.0012s] [ 50%]
../../../../test/distributed/_tools/test_mod_tracker.py::TestModTracker::test_module_hierarchy PASSED [0.0023s] [ 75%]
../../../../test/distributed/_tools/test_mod_tracker.py::TestModTracker::test_user_hooks PASSED [0.0026s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed__tools_test_mod_tracker.py.xml -
============================== 4 passed in 2.18s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:48:10.942] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 19 items
Running 19 items in this shard

../../../../test/distributed/checkpoint/e2e/test_e2e_save_and_load.py::TestE2ESaveAndLoad::test_different_ordered_state_dict_keys [2025-09-12 16:48:13.131] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:48:13.149] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:48:13.154] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:48:13.162] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:48:14:1285016 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:48:14:1285016 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:48:14:1285017 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:48:14:1285017 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:48:14:1285014 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:48:14:1285014 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:48:14:1285015 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:48:14:1285015 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmp5scnl7dk
PASSED [16.1873s] [  5%]
../../../../test/distributed/checkpoint/e2e/test_e2e_save_and_load.py::TestE2ESaveAndLoad::test_e2e_async_cached_cache_staged_state_dict_False_async_checkpointer_type0_zoc_False [2025-09-12 16:48:29.155] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:48:29.156] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:48:29.157] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:48:29.166] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:48:30:1285328 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:48:30:1285328 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:48:30:1285329 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:48:30:1285329 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:48:30:1285327 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:48:30:1285327 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:48:30:1285326 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:48:30:1285326 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
still waiting... 1.0010238149989164
still waiting... 1.001002366989269
Using temp directory: /tmp/tmp4l1morpo
still waiting... 1.0010175189963775
still waiting... 1.0010265430028085
PASSED [32.8576s] [ 10%]
../../../../test/distributed/checkpoint/e2e/test_e2e_save_and_load.py::TestE2ESaveAndLoad::test_e2e_async_cached_cache_staged_state_dict_False_async_checkpointer_type2_zoc_False [2025-09-12 16:49:02.002] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:49:02.015] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:49:02.018] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:49:02.030] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:49:03:1285661 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:49:03:1285662 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:49:03:1285660 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:49:03:1285662 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:49:03:1285661 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:49:03:1285660 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:49:03:1285659 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:49:03:1285659 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmpn30otw1g
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[2025-09-12 16:49:21.471] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:49:21.471] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:49:21.471] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:49:21.471] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
still waiting... 1.0010185120045207
still waiting... 2.0020952220074832
still waiting... 3.0031249390012817
still waiting... 1.0010454279981786
still waiting... 2.002127327999915
still waiting... 3.003173692995915
still waiting... 1.0010272890067426
still waiting... 2.002099265999277
still waiting... 3.0031322080030804
still waiting... 1.0010376999998698
still waiting... 2.0021461060096044
still waiting... 3.003195933008101
PASSED [34.8599s] [ 15%]
../../../../test/distributed/checkpoint/e2e/test_e2e_save_and_load.py::TestE2ESaveAndLoad::test_e2e_async_cached_cache_staged_state_dict_False_async_checkpointer_type4_zoc_True [2025-09-12 16:49:36.865] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:49:36.882] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:49:36.923] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:49:36.927] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:49:37:1286288 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:49:37:1286288 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:49:37:1286290 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:49:37:1286290 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:49:38:1286289 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:49:38:1286289 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:49:38:1286287 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:49:38:1286287 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmpdhc8df7a
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[2025-09-12 16:49:56.057] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:49:56.057] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:49:56.057] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:49:56.057] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
still waiting... 1.0010192420013482
still waiting... 2.0020842730009463
still waiting... 1.0010272150102537
still waiting... 2.002098234006553
still waiting... 1.0010380189924035
still waiting... 2.0015637400065316
still waiting... 1.0010390609968454
still waiting... 2.002101064004819
PASSED [33.8596s] [ 21%]
../../../../test/distributed/checkpoint/e2e/test_e2e_save_and_load.py::TestE2ESaveAndLoad::test_e2e_async_cached_cache_staged_state_dict_False_async_checkpointer_type5_zoc_True [2025-09-12 16:50:10.742] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:50:10.759] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:50:10.765] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:50:10.775] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:50:11:1286921 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:50:11:1286921 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:50:11:1286922 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:50:11:1286922 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:50:11:1286920 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:50:11:1286920 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:50:11:1286919 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:50:11:1286919 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
still waiting... 1.0010240799892927
Using temp directory: /tmp/tmp7r4xfavh
still waiting... 1.0009993359999498
still waiting... 1.0010250119958073
still waiting... 1.00100087300234
PASSED [32.7533s] [ 26%]
../../../../test/distributed/checkpoint/e2e/test_e2e_save_and_load.py::TestE2ESaveAndLoad::test_e2e_async_cached_cache_staged_state_dict_True_async_checkpointer_type1_zoc_False [2025-09-12 16:50:43.494] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:50:43.510] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:50:43.520] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:50:43.526] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:50:44:1287261 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:50:44:1287261 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:50:44:1287260 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:50:44:1287260 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:50:44:1287259 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:50:44:1287259 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:50:44:1287258 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:50:44:1287258 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
still waiting... 1.001003325000056
still waiting... 1.0010307479969924
still waiting... 1.001016702997731
Using temp directory: /tmp/tmpkuqm8ti8
still waiting... 1.0010135990014533
PASSED [32.8506s] [ 31%]
../../../../test/distributed/checkpoint/e2e/test_e2e_save_and_load.py::TestE2ESaveAndLoad::test_e2e_async_cached_cache_staged_state_dict_True_async_checkpointer_type3_zoc_False [2025-09-12 16:51:16.371] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:51:16.378] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:51:16.384] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:51:16.385] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:51:17:1287593 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:51:17:1287593 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:51:17:1287592 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:51:17:1287592 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:51:17:1287591 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:51:17:1287591 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:51:17:1287594 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:51:17:1287594 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmps6r_p1oh
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[2025-09-12 16:51:35.243] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:51:35.243] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:51:35.243] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:51:35.243] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
still waiting... 1.0010197539959336
still waiting... 2.0020808660046896
still waiting... 1.0010280970018357
still waiting... 2.0021021090069553
still waiting... 1.0010314640094293
still waiting... 2.0013292960065883
still waiting... 1.0010421410115669
still waiting... 2.002126526000211
PASSED [33.8499s] [ 36%]
../../../../test/distributed/checkpoint/e2e/test_e2e_save_and_load.py::TestE2ESaveAndLoad::test_e2e_compile_False_model_type0 [2025-09-12 16:51:50.206] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:51:50.224] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:51:50.247] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:51:50.263] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:51:51:1288220 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:51:51:1288220 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:51:51:1288222 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:51:51:1288222 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:51:51:1288219 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:51:51:1288219 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:51:51:1288221 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:51:51:1288221 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmpk5ellty2
PASSED [31.5420s] [ 42%]
../../../../test/distributed/checkpoint/e2e/test_e2e_save_and_load.py::TestE2ESaveAndLoad::test_e2e_compile_False_model_type1 [2025-09-12 16:52:21.739] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:52:21.757] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:52:21.758] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:52:21.769] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2025:09:12-16:52:22:1288550 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:52:22:1288550 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:52:22:1288549 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:52:22:1288549 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:52:22:1288552 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:52:22:1288552 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:52:22:1288551 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:52:22:1288551 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:52:39:1288862:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:52:39:1288852:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:52:39:1288855:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:52:39:1288861:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2025:09:12-16:52:51:1288552:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:52:51:1288551:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:52:51:1288549:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:52:51:1288550:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:52:51:1288855:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:52:51:1288862:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:52:51:1288852:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:52:51:1288861:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:52:52:1288549:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:52:52:1288552:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:52:52:1288550:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:52:52:1288551:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
Using temp directory: /tmp/tmpk2avoi4q
PASSED [32.9594s] [ 47%]
../../../../test/distributed/checkpoint/e2e/test_e2e_save_and_load.py::TestE2ESaveAndLoad::test_e2e_compile_False_model_type2 [2025-09-12 16:52:54.711] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:52:54.712] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:52:54.716] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:52:54.718] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:52:55:1288962 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:52:55:1288962 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:52:55:1288963 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:52:55:1288963 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:52:55:1288961 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:52:55:1288961 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:52:55:1288960 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:52:55:1288960 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmplj61zli5
PASSED [16.2311s] [ 52%]
../../../../test/distributed/checkpoint/e2e/test_e2e_save_and_load.py::TestE2ESaveAndLoad::test_e2e_compile_True_model_type0 [2025-09-12 16:53:10.947] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:53:10.947] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:53:11.042] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:53:11.070] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:53:17:1289289 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:53:17:1289289 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:53:17:1289290 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:53:17:1289290 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:53:18:1289292 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:53:18:1289292 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:53:18:1289291 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:53:18:1289291 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmpeekk20jw
PASSED [40.6651s] [ 57%]
../../../../test/distributed/checkpoint/e2e/test_e2e_save_and_load.py::TestE2ESaveAndLoad::test_e2e_compile_True_model_type1 [2025-09-12 16:53:51.587] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:53:51.602] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:53:51.610] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:53:51.614] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2025:09:12-16:53:57:1291522 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:53:57:1291522 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:53:57:1291524 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:53:57:1291524 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:53:57:1291523 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:53:57:1291523 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:53:57:1291525 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:53:57:1291525 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:54:13:1292093:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:54:13:1292271:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:54:13:1292173:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:54:13:1292319:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2025:09:12-16:54:25:1291524:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:54:25:1291525:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:54:25:1291522:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:54:25:1291523:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:54:26:1292093:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:54:26:1292271:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:54:26:1292173:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:54:26:1292319:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:54:26:1291522:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:54:26:1291524:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:54:26:1291525:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:54:26:1291523:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
Using temp directory: /tmp/tmpa5_8gs8k
PASSED [38.5686s] [ 63%]
../../../../test/distributed/checkpoint/e2e/test_e2e_save_and_load.py::TestE2ESaveAndLoad::test_e2e_compile_True_model_type2 [2025-09-12 16:54:30.166] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:54:30.178] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:54:30.184] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:54:30.195] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:54:33:1292552 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:54:33:1292552 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:54:33:1292554 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:54:33:1292554 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:54:33:1292551 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:54:33:1292551 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:54:33:1292553 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:54:33:1292553 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmpk48m8l6h
PASSED [19.3360s] [ 68%]
../../../../test/distributed/checkpoint/e2e/test_e2e_save_and_load.py::TestE2ESaveAndLoad::test_no_dist [2025-09-12 16:54:49.507] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:54:49.522] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:54:49.522] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:54:49.534] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
No process group initialized, using temp directory: /tmp/tmpzzsa3m7c
No process group initialized, using temp directory: /tmp/tmp04p496h8
No process group initialized, using temp directory: /tmp/tmpxylrs_b7
No process group initialized, using temp directory: /tmp/tmpmgrud8aw
PASSED [2.9089s] [ 73%]
../../../../test/distributed/checkpoint/e2e/test_e2e_save_and_load.py::TestE2ESaveAndLoad::test_overwrite [2025-09-12 16:54:52.407] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:54:52.422] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:54:52.439] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:54:52.440] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:54:53:1293720 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:54:53:1293721 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:54:53:1293721 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:54:53:1293720 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:54:53:1293719 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:54:53:1293719 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:54:53:1293722 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:54:53:1293722 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmpg0zzlc16
PASSED [15.6293s] [ 78%]
../../../../test/distributed/checkpoint/e2e/test_e2e_save_and_load.py::TestE2ESaveAndLoad::test_partial_load [2025-09-12 16:55:08.035] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:55:08.053] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:55:08.062] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:55:08.066] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:55:09:1294036 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:55:09:1294036 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:55:09:1294034 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:55:09:1294034 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:55:09:1294035 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:55:09:1294035 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:55:09:1294033 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:55:09:1294033 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmpmnyb0ci_
PASSED [31.8568s] [ 84%]
../../../../test/distributed/checkpoint/e2e/test_e2e_save_and_load.py::TestE2ESaveAndLoad::test_stateful_and_non_stateful_loads [2025-09-12 16:55:39.893] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:55:39.914] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:55:39.923] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:55:39.923] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
No process group initialized, using temp directory: /tmp/tmp7xuo8ijm
No process group initialized, using temp directory: /tmp/tmp7xuphli3
No process group initialized, using temp directory: /tmp/tmpxlzpvjxk
No process group initialized, using temp directory: /tmp/tmpm7sjk522
PASSED [3.0087s] [ 89%]
../../../../test/distributed/checkpoint/e2e/test_e2e_save_and_load.py::TestNoCPU::test_no_cpu [2025-09-12 16:55:42.928] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:55:42.941] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:55:42.942] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:55:42.959] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:55:43:1294648 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:55:43:1294648 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:55:43:1294647 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:55:43:1294647 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:55:43:1294649 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:55:43:1294649 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:55:43:1294646 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:55:43:1294646 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7299s] [ 94%]
../../../../test/distributed/checkpoint/e2e/test_e2e_save_and_load.py::TestInitStateDict::test_init_state_dict [2025-09-12 16:55:58.646] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:55:58.662] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:55:58.664] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:55:58.692] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
No process group initialized, using temp directory: /tmp/tmp62cbzsw5
No process group initialized, using temp directory: /tmp/tmpu315i7e_
No process group initialized, using temp directory: /tmp/tmpvvhvicxw
No process group initialized, using temp directory: /tmp/tmpr6fgug89
PASSED [3.0088s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_e2e_test_e2e_save_and_load.py.xml -
======================== 19 passed in 470.64s (0:07:50) ========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:56:03.075] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 1 item
Running 1 items in this shard

../../../../test/distributed/checkpoint/e2e/test_fine_tuning.py::TestFineTuning::test_fine_tuning [2025-09-12 16:56:05.330] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:56:05.330] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:56:05.450] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:56:05.450] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-16:56:05:1295309 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:56:05:1295309 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:56:05:1295308 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:56:05:1295308 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:56:05:1295307 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:56:05:1295307 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:56:05:1295306 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:56:05:1295306 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
/tmp/tmpsylvo8yv/pretrain /tmp/tmpsylvo8yv/finetune
Using temp directory: /tmp/tmpsylvo8yv
/tmp/tmpsylvo8yv/pretrain /tmp/tmpsylvo8yv/finetune
/tmp/tmpsylvo8yv/pretrain /tmp/tmpsylvo8yv/finetune
/tmp/tmpsylvo8yv/pretrain /tmp/tmpsylvo8yv/finetune
PASSED [22.4510s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_e2e_test_fine_tuning.py.xml -
============================== 1 passed in 24.47s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:56:27.943] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 1 item
Running 1 items in this shard

../../../../test/distributed/checkpoint/e2e/test_fsdp_ep.py::TestFSDPWithEP::test_e2e [2025-09-12 16:56:30.143] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:56:30.149] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:56:30.150] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:56:30.192] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
SKIPPED [2.9923s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_e2e_test_fsdp_ep.py.xml -
============================== 1 skipped in 4.92s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:56:34.387] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 6 items
Running 6 items in this shard

../../../../test/distributed/checkpoint/fsdp/test_fsdp_dsd.py::TestFullyShardWithDistributedStateDict::test_1d_fsdp_cpu_offload_full_model_state_dict [2025-09-12 16:56:36.694] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:56:36.725] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:56:36.725] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:56:36.739] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:56:36:1296071 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:56:36:1296071 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:56:36:1296069 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:56:36:1296069 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:56:36:1296070 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:56:36:1296070 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:56:36:1296068 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:56:36:1296068 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=1, world=4
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [16.0320s] [ 16%]
../../../../test/distributed/checkpoint/fsdp/test_fsdp_dsd.py::TestFullyShardWithDistributedStateDict::test_1d_fsdp_get_model_state_dict [2025-09-12 16:56:52.455] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:56:52.470] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:56:52.470] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:56:52.510] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:56:52:1296372 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:56:52:1296372 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:56:52:1296373 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:56:52:1296373 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:56:52:1296371 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:56:52:1296371 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:56:52:1296374 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:56:52:1296374 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=3, world=4
dist init r=0, world=4
PASSED [16.4234s] [ 33%]
../../../../test/distributed/checkpoint/fsdp/test_fsdp_dsd.py::TestFullyShardWithDistributedStateDict::test_save_with_fsdp1_and_load_with_fsdp2 [2025-09-12 16:57:08.883] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:57:08.884] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:57:09.034] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:57:09.038] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:57:09:1296674 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:57:09:1296674 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:57:09:1296672 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:57:09:1296672 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:57:09:1296673 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:57:09:1296673 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:57:09:1296671 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:57:09:1296671 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
Using temp directory: /tmp/tmpqafqqp2m
Using temp directory: /tmp/tmpqr2webut
dist init r=3, world=4
PASSED [31.9571s] [ 50%]
../../../../test/distributed/checkpoint/fsdp/test_fsdp_dsd.py::TestFullyShardWithDistributedStateDict::test_save_with_fsdp1_and_load_with_fsdp2_tp [2025-09-12 16:57:40.834] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:57:40.834] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:57:40.866] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:57:40.870] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:57:41:1296990 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:57:41:1296990 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:57:41:1296992 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:57:41:1296992 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:57:41:1296991 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:57:41:1296991 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:57:41:1296989 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:57:41:1296989 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:57:54:1296990:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:57:54:1296992:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:57:54:1296989:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:57:54:1296991:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:10:1296989:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:10:1296990:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:10:1296991:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:10:1296992:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=2, world=4
dist init r=3, world=4
dist init r=0, world=4
Using temp directory: /tmp/tmpcfya0i29
dist init r=1, world=4
PASSED [32.2573s] [ 66%]
../../../../test/distributed/checkpoint/fsdp/test_fsdp_dsd.py::TestFullyShardWithDistributedStateDict::test_save_with_fsdp2_tp_and_load_with_tp [2025-09-12 16:58:13.132] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:58:13.134] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:58:13.142] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:58:13.146] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:58:13:1297322 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:58:13:1297322 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:58:13:1297325 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:58:13:1297325 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:58:13:1297323 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:58:13:1297323 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:58:13:1297324 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:58:13:1297324 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:58:26:1297322:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:26:1297323:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:26:1297325:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:26:1297324:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:26:1297325:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:26:1297323:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:26:1297322:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:26:1297324:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:42:1297322:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:42:1297323:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:42:1297325:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:42:1297324:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:43:1297322:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:43:1297324:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:43:1297325:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:43:1297323:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=3, world=4
dist init r=0, world=4
Using temp directory: /tmp/tmpw15teecr
Using temp directory: /tmp/tmp0in23zkt
dist init r=1, world=4
dist init r=2, world=4
PASSED [33.1577s] [ 83%]
../../../../test/distributed/checkpoint/fsdp/test_fsdp_dsd.py::TestFullyShardWithDistributedStateDict::test_save_with_tp_and_load_with_fsdp2_tp [2025-09-12 16:58:46.260] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:58:46.274] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:58:46.290] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:58:46.290] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:58:46:1297673 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:58:46:1297673 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:58:46:1297672 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:58:46:1297672 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:58:46:1297671 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:58:46:1297671 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:58:46:1297674 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:58:46:1297674 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:58:59:1297671:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:59:1297672:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:59:1297674:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:58:59:1297673:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:59:00:1297671:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:59:00:1297672:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:59:00:1297673:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-16:59:00:1297674:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
dist init r=3, world=4
dist init r=2, world=4
dist init r=1, world=4
dist init r=0, world=4
Using temp directory: /tmp/tmp7cndouya
PASSED [16.9310s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_fsdp_test_fsdp_dsd.py.xml -
======================== 6 passed in 148.81s (0:02:28) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 16:59:04.046] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 8 items
Running 8 items in this shard

../../../../test/distributed/checkpoint/test_checkpoint.py::TestDistributedCheckpointing::test_default_metadata [2025-09-12 16:59:06.371] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:59:06.390] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:59:06:1298077 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:59:06:1298077 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:59:06:1298078 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:59:06:1298078 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.1210s] [ 12%]
../../../../test/distributed/checkpoint/test_checkpoint.py::TestDistributedCheckpointing::test_tensor_metadata_with_missing_rank_spec [2025-09-12 16:59:21.184] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:59:21.186] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:59:21:1298229 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:59:21:1298229 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:59:21:1298228 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:59:21:1298228 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [14.8253s] [ 25%]
../../../../test/distributed/checkpoint/test_checkpoint.py::TestDistributedFailure::test_dummy_reader_works [2025-09-12 16:59:36.013] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:59:36.034] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:59:36.038] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:59:36.050] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:59:36:1298380 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:59:36:1298380 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:59:36:1298381 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:59:36:1298381 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:59:36:1298378 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:59:36:1298378 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:59:36:1298379 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:59:36:1298379 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9303s] [ 37%]
../../../../test/distributed/checkpoint/test_checkpoint.py::TestDistributedFailure::test_dummy_writer_works [2025-09-12 16:59:51.970] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:59:51.970] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:59:51.986] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 16:59:51.998] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-16:59:52:1298679 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:59:52:1298679 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:59:52:1298680 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:59:52:1298680 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:59:52:1298678 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:59:52:1298678 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-16:59:52:1298681 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-16:59:52:1298681 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8295s] [ 50%]
../../../../test/distributed/checkpoint/test_checkpoint.py::TestDistributedFailure::test_load_error_handling [2025-09-12 17:00:07.779] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:00:07.794] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:00:07.814] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:00:07.814] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:00:07:1298979 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:00:07:1298979 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:00:08:1298981 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:00:08:1298981 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:00:08:1298980 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:00:08:1298980 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:00:08:1298978 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:00:08:1298978 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.3225s] [ 62%]
../../../../test/distributed/checkpoint/test_checkpoint.py::TestDistributedFailure::test_load_error_handling_no_dist [2025-09-12 17:00:24.070] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:00:24.166] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:00:24.168] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:00:24.174] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.9086s] [ 75%]
../../../../test/distributed/checkpoint/test_checkpoint.py::TestDistributedFailure::test_save_error_handling [2025-09-12 17:00:26.999] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:00:27.006] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:00:27.026] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:00:27.028] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:00:27:1299565 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:00:27:1299565 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:00:27:1299566 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:00:27:1299566 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:00:27:1299564 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:00:27:1299564 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:00:27:1299563 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:00:27:1299563 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.3308s] [ 87%]
../../../../test/distributed/checkpoint/test_checkpoint.py::TestDistributedFailure::test_save_error_handling_no_dist [2025-09-12 17:00:43.352] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:00:43.370] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:00:43.392] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:00:43.402] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.9086s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_checkpoint.py.xml -
======================== 8 passed in 102.12s (0:01:42) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:00:46.728] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 4 items
Running 4 items in this shard

../../../../test/distributed/checkpoint/test_compatibility.py::TestDCPCompatbility::test_metadata PASSED [0.1619s] [ 25%]
../../../../test/distributed/checkpoint/test_compatibility.py::TestDCPCompatbility::test_sharded_tensor_dependency PASSED [0.0079s] [ 50%]
../../../../test/distributed/checkpoint/test_compatibility.py::TestDCPCompatbility::test_storage_meta PASSED [0.0026s] [ 75%]
../../../../test/distributed/checkpoint/test_compatibility.py::TestDCPCompatbility::test_with_v_2_3 PASSED [0.0124s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_compatibility.py.xml -
============================== 4 passed in 2.24s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:00:49.951] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 1 item
Running 1 items in this shard

../../../../test/distributed/checkpoint/test_dedup_tensors.py::TestDedupTensor::test_dedup_shards PASSED [0.1668s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_dedup_tensors.py.xml -
============================== 1 passed in 2.18s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:00:53.056] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 1 item
Running 1 items in this shard

../../../../test/distributed/checkpoint/test_dtensor_checkpoint.py::DTensorPlanner::test_distributed_tensor_planner [2025-09-12 17:00:55.261] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:00:55.262] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:00:55.282] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:00:55.282] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:00:55:1300368 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:00:55:1300368 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:00:55:1300365 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:00:55:1300365 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:00:55:1300367 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:00:55:1300367 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:00:56:1300366 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:00:56:1300366 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmp7djlo46s
PASSED [16.2186s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_dtensor_checkpoint.py.xml -
============================== 1 passed in 18.24s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:01:12.133] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 7 items
Running 7 items in this shard

../../../../test/distributed/checkpoint/test_dtensor_resharding.py::TestDTensorReshardPlacementChange::test_1d_to_1d_reshard_placement_change_extensions0 [2025-09-12 17:01:14.318] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:01:14.361] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:01:14.401] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:01:14.403] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:01:15:1300745 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:01:15:1300745 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:01:15:1300743 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:01:15:1300743 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:01:15:1300746 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:01:15:1300746 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:01:15:1300744 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:01:15:1300744 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmpz6tqyvjh
PASSED [16.1148s] [ 14%]
../../../../test/distributed/checkpoint/test_dtensor_resharding.py::TestDTensorReshardPlacementChange::test_1d_to_1d_reshard_placement_change_extensions1 [2025-09-12 17:01:30.285] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:01:30.286] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:01:30.288] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:01:30.298] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:01:30:1301044 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:01:30:1301044 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:01:30:1301046 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:01:30:1301046 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:01:31:1301045 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:01:31:1301045 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:01:31:1301043 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:01:31:1301043 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmp7edoe9f0
PASSED [16.2308s] [ 28%]
../../../../test/distributed/checkpoint/test_dtensor_resharding.py::TestDTensorReshardPlacementChange::test_1d_to_1d_reshard_placement_change_extensions2 [2025-09-12 17:01:46.498] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:01:46.505] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:01:46.522] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:01:46.546] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:01:47:1301343 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:01:47:1301343 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:01:47:1301344 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:01:47:1301344 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:01:47:1301345 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:01:47:1301345 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:01:47:1301346 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:01:47:1301346 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmpy3esat9e
PASSED [16.1228s] [ 42%]
../../../../test/distributed/checkpoint/test_dtensor_resharding.py::TestDTensorReshardPlacementChange::test_2d_to_2d_reshard_placement_change [2025-09-12 17:02:02.608] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:02:02.616] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:02:02.626] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:02:02.638] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:02:03:1301647 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:02:03:1301647 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:02:03:1301645 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:02:03:1301645 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:02:03:1301646 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:02:03:1301646 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:02:03:1301644 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:02:03:1301644 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:02:04:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:04:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:04:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:04:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:04:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:04:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:04:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:04:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:05:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:05:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:05:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:05:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:05:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:05:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:05:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:05:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:06:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:06:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:06:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:06:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:06:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:06:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:06:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:06:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:06:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:06:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:06:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:06:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:07:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:07:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:07:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:07:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:07:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:07:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:07:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:07:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:07:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:07:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:07:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:07:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:08:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:08:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:08:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:08:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:08:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:08:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:08:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:08:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:08:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:08:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:08:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:08:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:09:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:09:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:09:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:09:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:09:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:09:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:09:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:09:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:09:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:09:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:09:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:09:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:10:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:10:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:10:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:10:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:10:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:10:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:10:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:10:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:10:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:10:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:10:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:10:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:11:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:11:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:11:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:11:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:11:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:11:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:11:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:11:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:11:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:11:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:11:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:11:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:12:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:12:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:12:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:12:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:12:1301644:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:12:1301645:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:12:1301646:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:12:1301647:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
Using temp directory: /tmp/tmp7i3z8c3_
PASSED [24.2419s] [ 57%]
../../../../test/distributed/checkpoint/test_dtensor_resharding.py::TestDTensorReshardMeshChange::test_1d_to_2d_reshard_mesh_change [2025-09-12 17:02:26.851] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:02:26.871] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:02:26.873] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:02:26.896] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:02:27:1302141 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:02:27:1302141 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:02:27:1302139 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:02:27:1302139 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:02:27:1302140 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:02:27:1302140 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:02:27:1302142 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:02:27:1302142 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:02:29:1302141:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:29:1302139:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:29:1302142:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:29:1302140:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:29:1302139:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:29:1302141:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:29:1302140:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:29:1302142:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:29:1302141:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:29:1302139:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:29:1302142:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:29:1302140:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:30:1302140:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:30:1302139:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:30:1302142:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:30:1302141:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:30:1302141:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:30:1302142:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:30:1302139:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:30:1302140:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:30:1302139:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:30:1302141:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:30:1302140:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:30:1302142:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:31:1302139:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:31:1302141:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:31:1302142:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:31:1302140:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:31:1302139:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:31:1302141:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:31:1302142:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:31:1302140:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
Using temp directory: /tmp/tmph07fooh4
PASSED [18.6338s] [ 71%]
../../../../test/distributed/checkpoint/test_dtensor_resharding.py::TestDTensorReshardMeshChange::test_2d_to_1d_reshard_mesh_change [2025-09-12 17:02:45.489] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:02:45.500] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:02:45.500] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:02:45.513] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:02:46:1302538 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:02:46:1302538 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:02:46:1302536 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:02:46:1302536 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:02:46:1302537 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:02:46:1302537 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:02:46:1302539 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:02:46:1302539 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:02:47:1302536:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:47:1302538:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:47:1302537:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:47:1302539:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:47:1302538:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:47:1302539:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:47:1302536:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:47:1302537:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:48:1302537:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:48:1302539:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:48:1302538:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:48:1302536:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:48:1302537:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:48:1302536:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:48:1302538:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:48:1302539:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:49:1302537:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:49:1302536:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:49:1302539:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:49:1302538:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:49:1302537:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:49:1302536:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:49:1302538:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:49:1302539:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:49:1302537:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:49:1302539:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:49:1302536:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:49:1302538:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:49:1302538:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:49:1302536:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:49:1302539:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:02:49:1302537:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
Using temp directory: /tmp/tmpgatqxn_9
PASSED [18.6339s] [ 85%]
../../../../test/distributed/checkpoint/test_dtensor_resharding.py::TestDTensorReshardMeshChange::test_dtensor_checkpoint_resharding_with_empty_shard [2025-09-12 17:03:04.126] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:03:04.163] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:03:04.204] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:03:04.227] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:03:04:1302902 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:03:04:1302902 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:03:04:1302903 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:03:04:1302903 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:03:04:1302900 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:03:04:1302900 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:03:05:1302901 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:03:05:1302901 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:03:06:1302900:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:03:06:1302902:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:03:06:1302901:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:03:06:1302903:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:03:06:1302902:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:03:06:1302903:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:03:06:1302900:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:03:06:1302901:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
Using temp directory: /tmp/tmpmsudd2ir
PASSED [16.6227s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_dtensor_resharding.py.xml -
======================== 7 passed in 128.54s (0:02:08) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:03:22.082] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 9 items
Running 9 items in this shard

../../../../test/distributed/checkpoint/test_file_system_checkpoint.py::TestDistributedStateDictSaveLoad::test_read_write_only_tensor PASSED [0.1912s] [ 11%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint.py::TestDistributedStateDictSaveLoadWithSharedTensor::test_read_write_shard_tensor_extensions0 [2025-09-12 17:03:24.273] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:03:24.286] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:03:24:1303293 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:03:24:1303293 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:03:24:1303292 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:03:24:1303292 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.1245s] [ 22%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint.py::TestDistributedStateDictSaveLoadWithSharedTensor::test_read_write_shard_tensor_extensions1 [2025-09-12 17:03:39.408] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:03:39.410] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:03:39:1303444 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:03:39:1303444 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:03:39:1303443 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:03:39:1303443 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.1256s] [ 33%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint.py::TestDistributedStateDictSaveLoadWithSharedTensor::test_read_write_shard_tensor_extensions2 [2025-09-12 17:03:54.534] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:03:54.537] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:03:54:1303595 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:03:54:1303595 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:03:54:1303594 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:03:54:1303594 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.2260s] [ 44%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint.py::TestDistributedReshardOnLoad::test_load_rowwise_to_colwise [2025-09-12 17:04:09.749] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:04:09.766] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:04:09:1303745 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:04:09:1303745 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:04:09:1303744 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:04:09:1303744 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.2256s] [ 55%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint.py::TestDistributedReshardOnLoad::test_load_with_different_shard_plan [2025-09-12 17:04:24.980] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:04:24.986] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:04:25:1303896 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:04:25:1303896 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:04:25:1303895 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:04:25:1303895 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.4259s] [ 66%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint.py::TestDistributedReshardOnLoad::test_save_load_bytes [2025-09-12 17:04:40.370] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:04:40.410] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:04:40:1304046 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:04:40:1304046 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:04:40:1304047 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:04:40:1304047 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.2255s] [ 77%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint.py::TestDistributedReshardOnLoad::test_switch_between_sharded_tensor_to_tensor [2025-09-12 17:04:55.623] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:04:55.638] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:04:55:1304197 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:04:55:1304197 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:04:55:1304196 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:04:55:1304196 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.4256s] [ 88%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint.py::TestDistributedStateDictSaveLoadWithCaching::test_read_write_shard_tensor [2025-09-12 17:05:11.059] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:05:11.078] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:05:11:1304348 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:05:11:1304348 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:05:11:1304347 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:05:11:1304347 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmp65jzkbvz
PASSED [15.2258s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_file_system_checkpoint.py.xml -
======================== 9 passed in 124.13s (0:02:04) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:05:26.767] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 16 items
Running 16 items in this shard

../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedStateDictSaveLoad::test_read_write_only_tensor_thread_count_1 PASSED [0.1725s] [  6%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedStateDictSaveLoad::test_read_write_only_tensor_thread_count_2 PASSED [0.0058s] [ 12%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedStateDictSaveLoadRot13::test_read_write_tensor_and_blob_thread_count_1 PASSED [0.0097s] [ 18%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedStateDictSaveLoadRot13::test_read_write_tensor_and_blob_thread_count_2 PASSED [0.0103s] [ 25%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedStateDictSaveLoadZStandard::test_read_write_only_tensor_thread_count_1 PASSED [0.0065s] [ 31%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedStateDictSaveLoadZStandard::test_read_write_only_tensor_thread_count_2 PASSED [0.0061s] [ 37%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedStateDictSaveLoadWithSharedTensor::test_read_write_shard_tensor_thread_count_1 [2025-09-12 17:05:29.022] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:05:29.038] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:05:29:1304575 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:05:29:1304575 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:05:29:1304574 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:05:29:1304574 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.2257s] [ 43%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedStateDictSaveLoadWithSharedTensor::test_read_write_shard_tensor_thread_count_2 [2025-09-12 17:05:44.333] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:05:44.354] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:05:45:1304724 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:05:45:1304724 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:05:45:1304725 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:05:45:1304725 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.2262s] [ 50%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedReshardOnLoad::test_load_rowwise_to_colwise_thread_count_1 [2025-09-12 17:05:59.467] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:05:59.470] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:06:00:1304878 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:06:00:1304878 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:06:00:1304877 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:06:00:1304877 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
FAILED [300.0701s] [ 56%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedReshardOnLoad::test_load_rowwise_to_colwise_thread_count_2 [2025-09-12 17:10:59.537] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:10:59.578] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:11:00:1305039 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:11:00:1305039 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:11:00:1305038 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:11:00:1305038 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
FAILED [300.0163s] [ 62%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedReshardOnLoad::test_load_with_different_shard_plan_thread_count_1 [2025-09-12 17:15:59.568] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:15:59.586] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:16:00:1305206 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:16:00:1305206 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:16:00:1305205 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:16:00:1305205 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
FAILED [300.0236s] [ 68%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedReshardOnLoad::test_load_with_different_shard_plan_thread_count_2 [2025-09-12 17:20:59.612] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:20:59.631] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:21:00:1305369 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:21:00:1305369 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:21:00:1305370 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:21:00:1305370 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
FAILED [300.0245s] [ 75%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedReshardOnLoad::test_save_load_bytes_thread_count_1 [2025-09-12 17:25:59.621] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:25:59.644] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:26:00:1305538 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:26:00:1305538 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:26:00:1305537 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:26:00:1305537 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.1243s] [ 81%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedReshardOnLoad::test_save_load_bytes_thread_count_2 [2025-09-12 17:26:14.809] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:26:14.813] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:26:15:1305693 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:26:15:1305693 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:26:15:1305692 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:26:15:1305692 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.3199s] [ 87%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedReshardOnLoad::test_switch_between_sharded_tensor_to_tensor_thread_count_1 SKIPPED [0.0002s] [ 93%]
../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedReshardOnLoad::test_switch_between_sharded_tensor_to_tensor_thread_count_2 SKIPPED [0.0001s] [100%]

=================================== FAILURES ===================================
___ TestDistributedReshardOnLoad.test_load_rowwise_to_colwise_thread_count_1 ___
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1025, in _check_return_codes
    raise RuntimeError(
RuntimeError: Process 0 terminated or timed out after 300.06723737716675 seconds
----------------------------- Captured stdout call -----------------------------
Timing out after 300 seconds and killing subprocesses.
----------------------------- Captured stderr call -----------------------------
I0912 17:05:58.052000 1304498 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1304877
I0912 17:05:58.053000 1304498 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1304878
E0912 17:10:58.117000 1304498 site-packages/torch/testing/_internal/common_distributed.py:909] Encountered error while trying to get traceback for process 0: [Errno 32] Broken pipe
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] Process 1 timed out with traceback: 
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] Current thread 0x00007f6a5088f640 (most recent call first):
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 825 in _event_listener
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 953 in run
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 1016 in _bootstrap_inner
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 973 in _bootstrap
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] Thread 0x00007f6b51e86e00 (most recent call first):
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4264 in gather
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81 in wrapper
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_shard/sharded_tensor/api.py", line 477 in gather
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/checkpoint/test_file_system_checkpoint_cpu.py", line 295 in load_tensor
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/checkpoint/test_file_system_checkpoint_cpu.py", line 451 in test_load_rowwise_to_colwise
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102 in wrapper
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552 in instantiated_test
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225 in wrapper
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718 in wrapper
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864 in run_test
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 843 in _run
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/process.py", line 108 in run
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/process.py", line 314 in _bootstrap
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/spawn.py", line 129 in _main
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/spawn.py", line 116 in spawn_main
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "<string>", line 1 in <module>
E0912 17:10:58.119000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] 
___ TestDistributedReshardOnLoad.test_load_rowwise_to_colwise_thread_count_2 ___
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1025, in _check_return_codes
    raise RuntimeError(
RuntimeError: Process 0 terminated or timed out after 300.0124866962433 seconds
----------------------------- Captured stdout call -----------------------------
Timing out after 300 seconds and killing subprocesses.
----------------------------- Captured stderr call -----------------------------
I0912 17:10:58.125000 1304498 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1305038
I0912 17:10:58.125000 1304498 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1305039
E0912 17:15:58.135000 1304498 site-packages/torch/testing/_internal/common_distributed.py:909] Encountered error while trying to get traceback for process 0: [Errno 32] Broken pipe
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] Process 1 timed out with traceback: 
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] Current thread 0x00007fad1395f640 (most recent call first):
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 825 in _event_listener
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 953 in run
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 1016 in _bootstrap_inner
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 973 in _bootstrap
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] Thread 0x00007fae1443be00 (most recent call first):
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4264 in gather
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81 in wrapper
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_shard/sharded_tensor/api.py", line 477 in gather
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/checkpoint/test_file_system_checkpoint_cpu.py", line 295 in load_tensor
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/checkpoint/test_file_system_checkpoint_cpu.py", line 451 in test_load_rowwise_to_colwise
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102 in wrapper
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552 in instantiated_test
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225 in wrapper
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718 in wrapper
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864 in run_test
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 843 in _run
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/process.py", line 108 in run
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/process.py", line 314 in _bootstrap
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/spawn.py", line 129 in _main
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/spawn.py", line 116 in spawn_main
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "<string>", line 1 in <module>
E0912 17:15:58.137000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] 
_ TestDistributedReshardOnLoad.test_load_with_different_shard_plan_thread_count_1 _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1025, in _check_return_codes
    raise RuntimeError(
RuntimeError: Process 0 terminated or timed out after 300.02021622657776 seconds
----------------------------- Captured stdout call -----------------------------
Timing out after 300 seconds and killing subprocesses.
----------------------------- Captured stderr call -----------------------------
I0912 17:15:58.141000 1304498 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1305205
I0912 17:15:58.142000 1304498 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1305206
E0912 17:20:58.160000 1304498 site-packages/torch/testing/_internal/common_distributed.py:909] Encountered error while trying to get traceback for process 0: [Errno 32] Broken pipe
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] Process 1 timed out with traceback: 
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] Current thread 0x00007f1d3f5ef640 (most recent call first):
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 825 in _event_listener
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 953 in run
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 1016 in _bootstrap_inner
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 973 in _bootstrap
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] Thread 0x00007f1e400d2e00 (most recent call first):
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4264 in gather
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81 in wrapper
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_shard/sharded_tensor/api.py", line 477 in gather
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/checkpoint/test_file_system_checkpoint_cpu.py", line 295 in load_tensor
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/checkpoint/test_file_system_checkpoint_cpu.py", line 399 in test_load_with_different_shard_plan
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102 in wrapper
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552 in instantiated_test
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225 in wrapper
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718 in wrapper
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864 in run_test
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 843 in _run
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/process.py", line 108 in run
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/process.py", line 314 in _bootstrap
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/spawn.py", line 129 in _main
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/spawn.py", line 116 in spawn_main
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "<string>", line 1 in <module>
E0912 17:20:58.162000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] 
_ TestDistributedReshardOnLoad.test_load_with_different_shard_plan_thread_count_2 _
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1025, in _check_return_codes
    raise RuntimeError(
RuntimeError: Process 0 terminated or timed out after 300.01855969429016 seconds
----------------------------- Captured stdout call -----------------------------
Timing out after 300 seconds and killing subprocesses.
----------------------------- Captured stderr call -----------------------------
I0912 17:20:58.169000 1304498 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1305369
I0912 17:20:58.170000 1304498 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1305370
E0912 17:25:58.185000 1304498 site-packages/torch/testing/_internal/common_distributed.py:909] Encountered error while trying to get traceback for process 0: [Errno 32] Broken pipe
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] Process 1 timed out with traceback: 
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] Current thread 0x00007f9d24a7f640 (most recent call first):
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 825 in _event_listener
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 953 in run
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 1016 in _bootstrap_inner
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 973 in _bootstrap
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] Thread 0x00007f9e2687de00 (most recent call first):
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4264 in gather
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81 in wrapper
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_shard/sharded_tensor/api.py", line 477 in gather
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/checkpoint/test_file_system_checkpoint_cpu.py", line 295 in load_tensor
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/checkpoint/test_file_system_checkpoint_cpu.py", line 399 in test_load_with_different_shard_plan
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_shard/sharded_tensor/__init__.py", line 102 in wrapper
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 552 in instantiated_test
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225 in wrapper
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718 in wrapper
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864 in run_test
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 843 in _run
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/process.py", line 108 in run
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/process.py", line 314 in _bootstrap
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/spawn.py", line 129 in _main
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/spawn.py", line 116 in spawn_main
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928]   File "<string>", line 1 in <module>
E0912 17:25:58.187000 1304498 site-packages/torch/testing/_internal/common_distributed.py:928] 
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_file_system_checkpoint_cpu.py.xml -
=========================== short test summary info ============================
FAILED [300.0701s] ../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedReshardOnLoad::test_load_rowwise_to_colwise_thread_count_1 - RuntimeError: Process 0 terminated or timed out after 300.06723737716675 seconds
FAILED [300.0163s] ../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedReshardOnLoad::test_load_rowwise_to_colwise_thread_count_2 - RuntimeError: Process 0 terminated or timed out after 300.0124866962433 seconds
FAILED [300.0236s] ../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedReshardOnLoad::test_load_with_different_shard_plan_thread_count_1 - RuntimeError: Process 0 terminated or timed out after 300.02021622657776 seconds
FAILED [300.0245s] ../../../../test/distributed/checkpoint/test_file_system_checkpoint_cpu.py::TestDistributedReshardOnLoad::test_load_with_different_shard_plan_thread_count_2 - RuntimeError: Process 0 terminated or timed out after 300.01855969429016 seconds
============= 4 failed, 10 passed, 2 skipped in 1263.27s (0:21:03) =============
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:26:31.406] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 3 items
Running 3 items in this shard

../../../../test/distributed/checkpoint/test_format_utils.py::TestFormatUtils::test_dcp_to_torch_save [2025-09-12 17:26:33.579] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:26:33.619] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:26:33.641] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:26:33.666] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
No process group initialized, using temp directory: /tmp/tmp_hz3wrfx
No process group initialized, using temp directory: /tmp/tmpjqwb5e9d
No process group initialized, using temp directory: /tmp/tmpfwn6g7ua
No process group initialized, using temp directory: /tmp/tmpw7v15dax
PASSED [3.0859s] [ 33%]
../../../../test/distributed/checkpoint/test_format_utils.py::TestFormatUtils::test_online_torch_save_to_dcp [2025-09-12 17:26:36.502] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:26:36.502] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:26:36.514] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:26:36.526] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:26:36:1306209 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:26:36:1306209 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:26:36:1306210 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:26:36:1306210 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:26:36:1306207 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:26:36:1306207 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:26:36:1306208 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:26:36:1306208 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmp6rcwee8g
PASSED [15.9311s] [ 66%]
../../../../test/distributed/checkpoint/test_format_utils.py::TestFormatUtils::test_torch_save_to_dcp [2025-09-12 17:26:52.446] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:26:52.464] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:26:52.464] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:26:52.482] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
No process group initialized, using temp directory: /tmp/tmp5evvkdjk
No process group initialized, using temp directory: /tmp/tmpxk7gm_vb
No process group initialized, using temp directory: /tmp/tmplh5s7ywm
No process group initialized, using temp directory: /tmp/tmpwek1jewh
PASSED [2.9080s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_format_utils.py.xml -
============================== 3 passed in 23.86s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:26:56.290] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/checkpoint/test_fsdp_model_state.py::FsdpModelStateCheckpoint::test_fsdp_model_state_no_resharding [2025-09-12 17:26:58.503] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:26:58.518] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:26:58.579] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:26:58.598] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-17:26:58:1306869 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:26:58:1306869 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:26:58:1306867 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:26:58:1306867 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:26:58:1306868 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:26:58:1306870 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:26:58:1306870 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:26:58:1306868 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmpxsu2stnj
PASSED [31.7674s] [ 50%]
../../../../test/distributed/checkpoint/test_fsdp_model_state.py::FsdpModelStateCheckpoint::test_fsdp_model_state_with_resharding [2025-09-12 17:27:30.141] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:27:30.154] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:27:30.169] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:27:30.182] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2025:09:12-17:27:30:1307199 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:27:30:1307199 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:27:30:1307197 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:27:30:1307197 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:27:30:1307198 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:27:30:1307198 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:27:30:1307200 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:27:30:1307200 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:27:47:1307197:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:27:47:1307199:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:27:47:1307200:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:27:47:1307198:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
Using temp directory: /tmp/tmpvow1ozbu
PASSED [31.9556s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_fsdp_model_state.py.xml -
========================= 2 passed in 65.74s (0:01:05) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:28:02.987] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/checkpoint/test_fsdp_optim_state.py::FsdpOptimStateCheckpoint::test_load_sharded_optimizer_state_dict_pass_planner_False [2025-09-12 17:28:05.183] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:28:05.184] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:28:05.198] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:28:05.222] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-17:28:05:1307622 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:28:05:1307622 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:28:05:1307623 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:28:05:1307623 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:28:05:1307624 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:28:05:1307624 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:28:05:1307621 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:28:05:1307621 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmpzj3bqsvc
PASSED [31.9451s] [ 50%]
../../../../test/distributed/checkpoint/test_fsdp_optim_state.py::FsdpOptimStateCheckpoint::test_load_sharded_optimizer_state_dict_pass_planner_True [2025-09-12 17:28:36.933] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:28:36.938] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:28:36.963] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:28:36.984] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2025:09:12-17:28:37:1307954 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:28:37:1307954 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:28:37:1307955 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:28:37:1307955 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:28:37:1307953 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:28:37:1307953 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:28:37:1307952 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:28:37:1307952 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmp210z4qh4
PASSED [31.6568s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_fsdp_optim_state.py.xml -
========================= 2 passed in 65.62s (0:01:05) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:29:09.077] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 1 item
Running 1 items in this shard

../../../../test/distributed/checkpoint/test_fsdp_tp_checkpoint_conversion.py::TestFsdpTpCheckpointConversion::test_fsdp_to_tp [2025-09-12 17:29:11.281] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:29:11.282] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:29:11.302] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:29:11.303] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:29:11:1308358 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:29:11:1308358 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:29:11:1308359 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:29:11:1308359 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:29:12:1308361 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:29:12:1308361 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:29:12:1308360 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:29:12:1308360 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmpg687gsly
PASSED [16.6180s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_fsdp_tp_checkpoint_conversion.py.xml -
============================== 1 passed in 18.64s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:29:29.138] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 3 items
Running 3 items in this shard

../../../../test/distributed/checkpoint/test_fsspec.py::TestFSSpec::test_fsspec [2025-09-12 17:29:31.379] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:29:31.390] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:29:31:1308750 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:29:31:1308750 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:29:31:1308749 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:29:31:1308749 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmp_rbb1xnj
PASSED [30.6358s] [ 33%]
../../../../test/distributed/checkpoint/test_fsspec.py::TestFSSpec::test_overwrite [2025-09-12 17:30:01.774] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:30:01.806] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:30:01:1308908 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:30:01:1308908 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:30:02:1308907 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:30:02:1308907 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmpwi77f1vb
PASSED [15.2238s] [ 66%]
../../../../test/distributed/checkpoint/test_fsspec.py::TestFileSystem::test_remove_on_fail PASSED [0.0027s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_fsspec.py.xml -
============================== 3 passed in 47.89s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:30:17.919] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 4 items
Running 4 items in this shard

../../../../test/distributed/checkpoint/test_hsdp_checkpoint.py::TestHSDPCheckpoint::test_hsdp_checkpoint_is_even_sharded_model_False [2025-09-12 17:30:20.109] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:30:20.114] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:30:20.125] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:30:20.151] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2025:09:12-17:30:20:1309132 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:30:20:1309132 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:30:20:1309134 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:30:20:1309134 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:30:20:1309135 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:30:20:1309135 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:30:20:1309133 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:30:20:1309133 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:30:37:1309487:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:30:37:1309481:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:30:37:1309488:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:30:37:1309478:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:30:49:1309134:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:30:49:1309135:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:30:49:1309132:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:30:49:1309133:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
Using temp directory: /tmp/tmp1z095i3j
PASSED [32.5416s] [ 25%]
../../../../test/distributed/checkpoint/test_hsdp_checkpoint.py::TestHSDPCheckpoint::test_hsdp_checkpoint_is_even_sharded_model_True [2025-09-12 17:30:52.456] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:30:52.459] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:30:52.474] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:30:52.479] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2025:09:12-17:30:52:1309501 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:30:52:1309502 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:30:52:1309501 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:30:52:1309502 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:30:52:1309503 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:30:52:1309503 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:30:52:1309504 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:30:52:1309504 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:31:09:1309860:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:31:09:1309846:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:31:09:1309855:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:31:09:1309849:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:31:21:1309501:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:31:21:1309503:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:31:21:1309504:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:31:21:1309502:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
Using temp directory: /tmp/tmptryxr_o1
PASSED [32.3580s] [ 50%]
../../../../test/distributed/checkpoint/test_hsdp_checkpoint.py::TestHSDPCheckpoint::test_hsdp_fsdp_checkpoint_conversion_is_even_sharded_model_False [2025-09-12 17:31:24.816] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:31:24.838] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:31:24.842] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:31:24.858] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2025:09:12-17:31:25:1309870 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:31:25:1309870 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:31:25:1309873 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:31:25:1309873 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:31:25:1309871 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:31:25:1309871 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:31:25:1309872 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:31:25:1309872 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:31:26:1309870:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:31:26:1309873:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:31:26:1309872:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:31:26:1309871:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
Using temp directory: /tmp/tmpkt6b5zbp
PASSED [16.4221s] [ 75%]
../../../../test/distributed/checkpoint/test_hsdp_checkpoint.py::TestHSDPCheckpoint::test_hsdp_fsdp_checkpoint_conversion_is_even_sharded_model_True [2025-09-12 17:31:41.244] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:31:41.266] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:31:41.268] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:31:41.268] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2025:09:12-17:31:41:1310219 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:31:41:1310219 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:31:41:1310221 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:31:41:1310221 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:31:41:1310220 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:31:41:1310220 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:31:41:1310222 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:31:41:1310222 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:31:42:1310221:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:31:42:1310219:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:31:42:1310220:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:31:42:1310222:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
Using temp directory: /tmp/tmp2ltx4jxi
PASSED [16.3234s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_hsdp_checkpoint.py.xml -
========================= 4 passed in 99.63s (0:01:39) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:31:58.046] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/checkpoint/test_nested_dict.py::TestFlattening::test_flattening_round_trip PASSED [0.1927s] [ 50%]
../../../../test/distributed/checkpoint/test_nested_dict.py::TestFlattening::test_mapping PASSED [0.0011s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_nested_dict.py.xml -
============================== 2 passed in 2.21s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:32:01.236] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 15 items
Running 15 items in this shard

../../../../test/distributed/checkpoint/test_planner.py::TestSavePlan::test_dedup_plans PASSED [0.1649s] [  6%]
../../../../test/distributed/checkpoint/test_planner.py::TestSavePlan::test_finish_plan_with_caching PASSED [0.0009s] [ 13%]
../../../../test/distributed/checkpoint/test_planner.py::TestSavePlan::test_global_plan PASSED [0.0028s] [ 20%]
../../../../test/distributed/checkpoint/test_planner.py::TestSavePlan::test_global_plan_with_caching PASSED [0.0047s] [ 26%]
../../../../test/distributed/checkpoint/test_planner.py::TestSavePlan::test_load_with_resharding PASSED [0.0019s] [ 33%]
../../../../test/distributed/checkpoint/test_planner.py::TestSavePlan::test_load_with_world_size_diff_by_one PASSED [0.0014s] [ 40%]
../../../../test/distributed/checkpoint/test_planner.py::TestSavePlan::test_local_load_plan PASSED [0.0015s] [ 46%]
../../../../test/distributed/checkpoint/test_planner.py::TestSavePlan::test_local_plan PASSED [0.0015s] [ 53%]
../../../../test/distributed/checkpoint/test_planner.py::TestSavePlan::test_local_plan_with_caching PASSED [0.0009s] [ 60%]
../../../../test/distributed/checkpoint/test_planner.py::TestPlannerHelpers::test_compare_save_plans PASSED [0.0010s] [ 66%]
../../../../test/distributed/checkpoint/test_planner.py::TestPlannerHelpers::test_create_read_item_from_chunks PASSED [0.0009s] [ 73%]
../../../../test/distributed/checkpoint/test_planner.py::TestPlannerHelpers::test_merge_delta_local_plans PASSED [0.0040s] [ 80%]
../../../../test/distributed/checkpoint/test_planner.py::TestLoadPlanner::test_load_different_sizes_throws PASSED [0.0135s] [ 86%]
../../../../test/distributed/checkpoint/test_planner.py::TestLoadPlanner::test_strict PASSED [0.0046s] [ 93%]
../../../../test/distributed/checkpoint/test_planner.py::TestLoadPlanner::test_version_key_in_planner_data PASSED [0.0038s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_planner.py.xml -
============================== 15 passed in 2.24s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:32:04.418] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/checkpoint/test_save_load_api.py::TestSaveAndLoadAPI::test_assert_same_keys [2025-09-12 17:32:06.621] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:32:06.634] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:32:07:1310787 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:32:07:1310787 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:32:07:1310786 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:32:07:1310786 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.1891s] [ 50%]
../../../../test/distributed/checkpoint/test_save_load_api.py::TestSaveAndLoadAPI::test_auto_detect [2025-09-12 17:32:21.621] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:32:21.667] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:32:22:1310938 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:32:22:1310938 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:32:22:1310937 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:32:22:1310937 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmp8jurn3tu
PASSED [15.2255s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_save_load_api.py.xml -
============================== 2 passed in 32.45s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:32:38.346] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 25 items
Running 25 items in this shard

../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_activation_ckpt_fqns_ddp [2025-09-12 17:32:40.706] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:32:40.718] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:32:40.727] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:32:40.746] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:32:40:1311162 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:32:40:1311162 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:32:40:1311163 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:32:40:1311163 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:32:40:1311164 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:32:40:1311164 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:32:40:1311161 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:32:40:1311161 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0107s] [  4%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_activation_ckpt_fqns_fsdp1 [2025-09-12 17:32:56.530] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:32:56.557] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:32:56.559] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:32:56.579] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:32:56:1311464 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:32:56:1311464 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:32:56:1311463 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:32:56:1311463 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:32:56:1311462 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:32:56:1311462 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:32:56:1311465 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:32:56:1311465 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8219s] [  8%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_broadcast_from_rank0 [2025-09-12 17:33:12.334] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:33:12.406] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:33:12.409] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:33:12.418] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:33:12:1311767 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:33:12:1311767 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:33:12:1311765 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:33:12:1311765 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:33:12:1311766 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:33:12:1311766 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:33:12:1311764 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:33:12:1311764 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:33:28:1311764:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:33:28:1311765:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:33:28:1311766:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:33:28:1311767:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:33:29:1312073:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:33:29:1312071:[2] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:33:29:1312066:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:33:29:1312064:[3] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [32.3556s] [ 12%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_compiled_fsdp [2025-09-12 17:33:44.663] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:33:44.721] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:33:44.766] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:33:44.778] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:33:45:1312483 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:33:45:1312483 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:33:45:1312481 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:33:45:1312481 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:33:45:1312480 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:33:45:1312480 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:33:45:1312482 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:33:45:1312482 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [28.6517s] [ 16%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_cpu_offload_full_state_dict [2025-09-12 17:34:13.387] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:34:13.398] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:34:13.406] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:34:13.410] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:34:13:1312796 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:34:13:1312796 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:34:13:1312797 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:34:13:1312797 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:34:13:1312798 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:34:13:1312798 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:34:13:1312799 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:34:13:1312799 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.2307s] [ 20%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_ddp [2025-09-12 17:34:29.597] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:34:29.606] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:34:29.610] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:34:29.614] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:34:30:1313101 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:34:30:1313101 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:34:30:1313099 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:34:30:1313099 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:34:30:1313102 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:34:30:1313102 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:34:30:1313100 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:34:30:1313100 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [18.0338s] [ 24%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_deprecate_api [2025-09-12 17:34:47.701] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:34:47.718] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:34:47.718] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:34:47.722] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:34:48:1313418 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:34:48:1313418 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:34:48:1313417 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:34:48:1313417 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:34:48:1313416 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:34:48:1313416 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:34:48:1313419 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:34:48:1313419 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0311s] [ 28%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_extra_state [2025-09-12 17:35:03.667] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:35:03.669] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:35:03.674] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:35:03.694] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [3.2091s] [ 32%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_flattened_osd [2025-09-12 17:35:06.888] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:35:06.890] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:35:06.891] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:35:06.895] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:35:07:1314001 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:35:07:1314001 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:35:07:1314003 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:35:07:1314003 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:35:07:1314002 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:35:07:1314002 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:35:07:1314000 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:35:07:1314000 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [18.8351s] [ 36%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_fsdp [2025-09-12 17:35:25.707] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:35:25.728] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:35:25.729] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:35:25.752] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:35:25:1314319 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:35:25:1314319 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:35:25:1314320 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:35:25:1314320 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:35:25:1314318 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:35:25:1314318 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:35:25:1314317 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:35:25:1314317 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [45.1788s] [ 40%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_fsdp2 [2025-09-12 17:36:10.858] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:36:10.941] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:36:10.948] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:36:10.949] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:36:12:1314638 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:36:12:1314638 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:36:12:1314637 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:36:12:1314637 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:36:12:1314635 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:36:12:1314635 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:36:12:1314636 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:36:12:1314636 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [21.8396s] [ 44%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_fsdp_ddp [2025-09-12 17:36:32.803] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:36:32.806] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:36:32.818] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:36:32.822] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:36:33:1314953 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:36:33:1314953 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:36:33:1314951 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:36:33:1314951 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:36:33:1314954 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:36:33:1314954 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:36:33:1314952 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:36:33:1314952 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [28.2500s] [ 48%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_fsdp_root_not_initialized [2025-09-12 17:37:00.962] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:37:01.029] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:37:01.040] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:37:01.043] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:37:01:1315272 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:37:01:1315272 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:37:01:1315274 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:37:01:1315274 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:37:01:1315275 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:37:01:1315275 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:37:01:1315273 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:37:01:1315273 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0311s] [ 52%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_multi_device_load_model_state_dict [2025-09-12 17:37:16.998] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:37:17.014] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:37:17.058] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:37:17.061] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:37:17:1315575 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:37:17:1315575 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:37:17:1315574 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:37:17:1315574 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:37:17:1315573 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:37:17:1315573 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:37:17:1315576 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:37:17:1315576 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8300s] [ 56%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_multi_param_groups [2025-09-12 17:37:32.810] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:37:32.905] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:37:32.911] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:37:32.938] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:37:33:1315877 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:37:33:1315877 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:37:33:1315874 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:37:33:1315874 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:37:33:1315876 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:37:33:1315876 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:37:33:1315875 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:37:33:1315875 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.6313s] [ 60%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_non_persistent_buffers [2025-09-12 17:37:49.478] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:37:49.478] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:37:49.486] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:37:49.516] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [3.2091s] [ 64%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_optim_state_dict_param_matching [2025-09-12 17:37:52.680] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:37:52.698] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:37:52.702] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:37:52.718] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:37:52:1316475 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:37:52:1316475 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:37:53:1316477 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:37:53:1316477 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:37:53:1316478 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:37:53:1316478 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:37:53:1316476 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:37:53:1316476 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9305s] [ 68%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_set_cpu_model_state_dict_broadcast_from_rank0 [2025-09-12 17:38:08.602] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:38:08.642] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:38:08.667] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:38:08.688] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:38:08:1316776 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:38:08:1316776 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:38:08:1316775 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:38:08:1316775 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:38:08:1316778 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:38:08:1316778 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:38:08:1316777 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:38:08:1316777 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7296s] [ 72%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_setting_meta_device_model [2025-09-12 17:38:24.408] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:38:24.428] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:38:24.511] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:38:24.550] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:38:24:1317076 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:38:24:1317076 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:38:24:1317078 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:38:24:1317078 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:38:24:1317075 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:38:24:1317075 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:38:24:1317077 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:38:24:1317077 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9301s] [ 76%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_setting_meta_device_model_broadcasting_and_memory [2025-09-12 17:38:40.289] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:38:40.294] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:38:40.298] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:38:40.310] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:38:42:1317377 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:38:42:1317377 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:38:42:1317376 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:38:42:1317376 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:38:42:1317378 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:38:42:1317378 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:38:42:1317379 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:38:42:1317379 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
FAILED [300.0534s] [ 80%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_shared_weight [2025-09-12 17:43:40.379] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:43:40.388] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:43:40.395] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:43:40.401] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:43:40:1318066 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:43:40:1318066 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:43:40:1318069 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:43:40:1318069 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:43:40:1318068 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:43:40:1318068 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:43:41:1318067 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:43:41:1318067 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [23.0426s] [ 84%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_single_gpu [2025-09-12 17:44:03.355] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:44:03.390] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:44:03.410] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:44:03.416] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [4.8119s] [ 88%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_state_dict_with_hook_on_keys [2025-09-12 17:44:08.179] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:44:08.201] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:44:08.215] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:44:08.218] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:44:08:1319073 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:44:08:1319073 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:44:08:1319075 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:44:08:1319075 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:44:08:1319074 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:44:08:1319074 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:44:08:1319076 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:44:08:1319076 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.8296s] [ 92%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_strict [2025-09-12 17:44:24.032] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:44:24.050] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:44:24.062] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:44:24.062] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:44:24:1319375 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:44:24:1319375 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:44:24:1319374 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:44:24:1319374 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:44:24:1319376 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:44:24:1319376 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:44:24:1319377 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:44:24:1319377 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9297s] [ 96%]
../../../../test/distributed/checkpoint/test_state_dict.py::TestNoComm::test_no_dist [2025-09-12 17:44:39.939] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:44:39.954] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:44:39.994] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:44:39.994] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [3.2090s] [100%]

=================================== FAILURES ===================================
_____ TestStateDict.test_setting_meta_device_model_broadcasting_and_memory _____
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1025, in _check_return_codes
    raise RuntimeError(
RuntimeError: Process 0 terminated or timed out after 300.04876494407654 seconds
----------------------------- Captured stdout call -----------------------------
Timing out after 300 seconds and killing subprocesses.
----------------------------- Captured stderr call -----------------------------
I0912 17:38:38.252000 1311089 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1317376
I0912 17:38:38.252000 1311089 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1317377
I0912 17:38:38.253000 1311089 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1317378
I0912 17:38:38.254000 1311089 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1317379
E0912 17:43:38.297000 1311089 site-packages/torch/testing/_internal/common_distributed.py:909] Encountered error while trying to get traceback for process 0: [Errno 32] Broken pipe
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928] Process 1 timed out with traceback: 
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928] Current thread 0x00007f4ce763f640 (most recent call first):
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 825 in _event_listener
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 953 in run
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 1016 in _bootstrap_inner
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 973 in _bootstrap
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928] Thread 0x00007f4df493ce00 (most recent call first):
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4881 in barrier
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81 in wrapper
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 437 in destroy_pg
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 507 in wrapper
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225 in wrapper
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718 in wrapper
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864 in run_test
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 843 in _run
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/process.py", line 108 in run
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/process.py", line 314 in _bootstrap
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/spawn.py", line 129 in _main
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/spawn.py", line 116 in spawn_main
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "<string>", line 1 in <module>
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928] Process 2 timed out with traceback: 
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928] Current thread 0x00007f7b6674f640 (most recent call first):
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 825 in _event_listener
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 953 in run
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 1016 in _bootstrap_inner
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 973 in _bootstrap
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928] Thread 0x00007f7c7272be00 (most recent call first):
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4881 in barrier
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81 in wrapper
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 437 in destroy_pg
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 507 in wrapper
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225 in wrapper
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718 in wrapper
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864 in run_test
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 843 in _run
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/process.py", line 108 in run
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/process.py", line 314 in _bootstrap
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/spawn.py", line 129 in _main
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/spawn.py", line 116 in spawn_main
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "<string>", line 1 in <module>
E0912 17:43:38.299000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928] Process 3 timed out with traceback: 
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928] Current thread 0x00007f9a8dcaf640 (most recent call first):
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 825 in _event_listener
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 953 in run
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 1016 in _bootstrap_inner
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/threading.py", line 973 in _bootstrap
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928] 
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928] Thread 0x00007f9b99c87e00 (most recent call first):
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4881 in barrier
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81 in wrapper
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 437 in destroy_pg
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py", line 507 in wrapper
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225 in wrapper
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718 in wrapper
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864 in run_test
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 843 in _run
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/process.py", line 108 in run
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/process.py", line 314 in _bootstrap
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/spawn.py", line 129 in _main
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/multiprocessing/spawn.py", line 116 in spawn_main
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928]   File "<string>", line 1 in <module>
E0912 17:43:38.300000 1311089 site-packages/torch/testing/_internal/common_distributed.py:928] 
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_state_dict.py.xml -
=========================== short test summary info ============================
FAILED [300.0534s] ../../../../test/distributed/checkpoint/test_state_dict.py::TestStateDict::test_setting_meta_device_model_broadcasting_and_memory - RuntimeError: Process 0 terminated or timed out after 300.04876494407654 seconds
=================== 1 failed, 24 passed in 724.74s (0:12:04) ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:44:43.367] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 7 items
Running 7 items in this shard

../../../../test/distributed/checkpoint/test_state_dict_utils.py::TestStateDictUtils::test_complicated_dict [2025-09-12 17:44:45.470] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:44:45.486] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:44:45.495] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:44:45.496] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:44:46:1320040 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:44:46:1320040 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:44:46:1320038 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:44:46:1320038 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:44:46:1320037 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:44:46:1320037 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:44:46:1320039 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:44:46:1320039 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7907s] [ 14%]
../../../../test/distributed/checkpoint/test_state_dict_utils.py::TestStateDictUtils::test_cpu_and_ranks_only [2025-09-12 17:45:01.098] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:45:01.100] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:45:01.101] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:45:01.125] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:45:01:1320341 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:45:01:1320341 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:45:01:1320338 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:45:01:1320338 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:45:01:1320340 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:45:01:1320340 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:45:01:1320339 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:45:01:1320339 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6293s] [ 28%]
../../../../test/distributed/checkpoint/test_state_dict_utils.py::TestStateDictUtils::test_cpu_offload_for_dtensor [2025-09-12 17:45:16.794] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:45:16.810] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:45:16.810] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:45:16.810] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:45:17:1320638 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:45:17:1320638 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:45:17:1320641 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:45:17:1320641 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:45:17:1320640 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:45:17:1320640 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:45:17:1320639 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:45:17:1320639 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.0329s] [ 42%]
../../../../test/distributed/checkpoint/test_state_dict_utils.py::TestStateDictUtils::test_create_cpu_state_dict SKIPPED [0.0004s] [ 57%]
../../../../test/distributed/checkpoint/test_state_dict_utils.py::TestStateDictUtils::test_gather_state_dict_dtensor [2025-09-12 17:45:32.786] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:45:32.804] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:45:32.804] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:45:32.826] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:45:33:1320939 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:45:33:1320939 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:45:33:1320941 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:45:33:1320941 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:45:33:1320942 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:45:33:1320942 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:45:33:1320940 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:45:33:1320940 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9291s] [ 71%]
../../../../test/distributed/checkpoint/test_state_dict_utils.py::TestStateDictUtils::test_gather_with_cpu_and_ranks_only [2025-09-12 17:45:48.694] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:45:48.699] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:45:48.700] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:45:48.719] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:45:49:1321241 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:45:49:1321241 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:45:49:1321239 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:45:49:1321239 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:45:49:1321242 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:45:49:1321242 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:45:49:1321240 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:45:49:1321240 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7218s] [ 85%]
../../../../test/distributed/checkpoint/test_state_dict_utils.py::TestStateDictUtils::test_state_dict_util_distribute_tensors [2025-09-12 17:46:04.418] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:46:04.430] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:46:04.430] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:46:04.490] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:46:05:1321542 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:46:05:1321542 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:46:05:1321541 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:46:05:1321541 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:46:05:1321543 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:46:05:1321543 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:46:05:1321540 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:46:05:1321540 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9303s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_state_dict_utils.py.xml -
=================== 6 passed, 1 skipped in 96.93s (0:01:36) ====================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:46:21.346] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/checkpoint/test_tp_checkpoint.py::TestTpCheckpoint::test_tp_checkpoint [2025-09-12 17:46:23.541] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:46:23.554] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:46:23.580] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:46:23.599] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:46:24:1321917 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:46:24:1321917 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:46:24:1321919 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:46:24:1321919 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:46:24:1321916 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:46:24:1321916 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:46:24:1321918 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:46:24:1321918 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmp_igreyk1
PASSED [16.7090s] [ 50%]
../../../../test/distributed/checkpoint/test_tp_checkpoint.py::TestTpCheckpoint::test_tp_checkpoint_load_on_meta_device [2025-09-12 17:46:40.070] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:46:40.073] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:46:40.078] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:46:40.108] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:46:40:1322232 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:46:40:1322232 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:46:40:1322235 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:46:40:1322235 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:46:40:1322234 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:46:40:1322234 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:46:40:1322233 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:46:40:1322233 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Using temp directory: /tmp/tmpo53ca5l1
PASSED [16.1280s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_tp_checkpoint.py.xml -
============================== 2 passed in 34.78s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:46:57.167] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 7 items
Running 7 items in this shard

../../../../test/distributed/checkpoint/test_traverse.py::TestTraverse::test_get_element PASSED [0.1641s] [ 14%]
../../../../test/distributed/checkpoint/test_traverse.py::TestTraverse::test_set_element PASSED [0.0009s] [ 28%]
../../../../test/distributed/checkpoint/test_traverse.py::TestTraverse::test_traverse_doesnt_ignore_intermediate_collections PASSED [0.0030s] [ 42%]
../../../../test/distributed/checkpoint/test_traverse.py::TestTraverse::test_traverse_nested_dict PASSED [0.0007s] [ 57%]
../../../../test/distributed/checkpoint/test_traverse.py::TestTraverse::test_traverse_nested_list PASSED [0.0008s] [ 71%]
../../../../test/distributed/checkpoint/test_traverse.py::TestTraverse::test_traverse_shallow PASSED [0.0007s] [ 85%]
../../../../test/distributed/checkpoint/test_traverse.py::TestTraverse::test_traverse_with_ordered_dict PASSED [0.0006s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_traverse.py.xml -
============================== 7 passed in 2.18s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:47:00.191] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 16 items
Running 16 items in this shard

../../../../test/distributed/checkpoint/test_utils.py::TestMedatadaIndex::test_dcp_logger PASSED [0.1672s] [  6%]
../../../../test/distributed/checkpoint/test_utils.py::TestMedatadaIndex::test_flat_data PASSED [0.0038s] [ 12%]
../../../../test/distributed/checkpoint/test_utils.py::TestMedatadaIndex::test_index_hint_ignored_on_equals PASSED [0.0006s] [ 18%]
../../../../test/distributed/checkpoint/test_utils.py::TestMedatadaIndex::test_index_hint_ignored_on_hash PASSED [0.0005s] [ 25%]
../../../../test/distributed/checkpoint/test_utils.py::TestMedatadaIndex::test_init_convert_offset PASSED [0.0005s] [ 31%]
../../../../test/distributed/checkpoint/test_utils.py::TestMedatadaIndex::test_sharded_tensor_lookup PASSED [0.0015s] [ 37%]
../../../../test/distributed/checkpoint/test_utils.py::TestReaderView::testAllRead PASSED [0.0005s] [ 43%]
../../../../test/distributed/checkpoint/test_utils.py::TestReaderView::testLongRead PASSED [0.0004s] [ 50%]
../../../../test/distributed/checkpoint/test_utils.py::TestReaderView::testLongReadinto PASSED [0.0010s] [ 56%]
../../../../test/distributed/checkpoint/test_utils.py::TestReaderView::testShortRead PASSED [0.0003s] [ 62%]
../../../../test/distributed/checkpoint/test_utils.py::TestReaderView::testShortReadinto PASSED [0.0004s] [ 68%]
../../../../test/distributed/checkpoint/test_utils.py::TestDistWrapper::test_barrier [2025-09-12 17:47:02.370] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:47:02.386] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:47:02.394] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:47:02.435] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:47:03:1322682 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:47:03:1322682 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:47:03:1322679 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:47:03:1322679 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:47:03:1322681 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:47:03:1322681 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:47:03:1322680 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:47:03:1322680 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:47:15:1322680:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:47:15:1322681:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:47:15:1322679:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:47:15:1322682:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [27.1355s] [ 75%]
../../../../test/distributed/checkpoint/test_utils.py::TestDistWrapper::test_broadcast_object_global_local_mismatch [2025-09-12 17:47:29.544] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:47:29.554] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:47:29.574] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:47:29.606] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:47:30:1322995 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:47:30:1322995 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:47:30:1322993 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:47:30:1322993 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:47:30:1322996 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:47:30:1322996 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:47:30:1322994 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:47:30:1322994 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:47:31:1322993:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:47:31:1322996:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:47:31:1322994:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:47:31:1322995:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [15.8289s] [ 81%]
../../../../test/distributed/checkpoint/test_utils.py::TestDistWrapper::test_broadcast_object_with_nonzero_coordinator [2025-09-12 17:47:45.422] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:47:45.423] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:47:45.442] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:47:45.442] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:47:46:1323309 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:47:46:1323309 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:47:46:1323308 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:47:46:1323308 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:47:46:1323307 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:47:46:1323307 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:47:46:1323306 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:47:46:1323306 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.7294s] [ 87%]
../../../../test/distributed/checkpoint/test_utils.py::TestDistWrapper::test_gather_object [2025-09-12 17:48:01.079] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:48:01.096] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:48:01.144] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:48:01.170] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:48:01:1323607 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:48:01:1323607 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:48:01:1323608 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:48:01:1323608 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:48:01:1323610 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:48:01:1323610 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:48:01:1323609 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:48:01:1323609 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:48:02:1323607:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:48:02:1323609:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:48:02:1323610:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:48:02:1323608:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [15.9296s] [ 93%]
../../../../test/distributed/checkpoint/test_utils.py::TestDistWrapper::test_scatter_object [2025-09-12 17:48:17.005] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:48:17.016] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:48:17.026] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:48:17.032] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:48:17:1323922 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:48:17:1323922 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:48:17:1323921 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:48:17:1323921 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:48:17:1323920 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:48:17:1323920 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:48:17:1323919 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:48:17:1323919 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:48:18:1323919:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:48:18:1323921:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:48:18:1323920:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-17:48:18:1323922:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [15.9303s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint_test_utils.py.xml -
======================== 16 passed in 92.67s (0:01:32) =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:48:33.898] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/checkpoint/_experimental/test_barriers.py::TestBarriers::test_execute_barrier PASSED [0.1637s] [ 50%]
../../../../test/distributed/checkpoint/_experimental/test_barriers.py::TestBarriers::test_tcpstore_barrier_initialization PASSED [0.0011s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint__experimental_test_barriers.py.xml -
============================== 2 passed in 2.18s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:48:36.924] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 4 items
Running 4 items in this shard

../../../../test/distributed/checkpoint/_experimental/test_builder.py::TestMakeCheckpointer::test_make_async_checkpointer PASSED [1.5639s] [ 25%]
../../../../test/distributed/checkpoint/_experimental/test_builder.py::TestMakeCheckpointer::test_make_sync_checkpointer PASSED [0.0020s] [ 50%]
../../../../test/distributed/checkpoint/_experimental/test_builder.py::TestMakeCheckpointer::test_make_sync_checkpointer_with_config_first PASSED [0.0009s] [ 75%]
../../../../test/distributed/checkpoint/_experimental/test_builder.py::TestMakeCheckpointer::test_make_sync_checkpointer_with_custom_config PASSED [0.0014s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint__experimental_test_builder.py.xml -
============================== 4 passed in 3.50s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:48:41.308] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 15 items
Running 15 items in this shard

../../../../test/distributed/checkpoint/_experimental/test_checkpoint_process.py::TestRequestTypes::test_request_type_enum PASSED [0.1647s] [  6%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_process.py::TestRequestTypes::test_worker_request PASSED [0.0009s] [ 13%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_process.py::TestRequestTypes::test_worker_response PASSED [0.0006s] [ 20%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_process.py::TestCheckpointProcessConfig::test_custom_options PASSED [0.0006s] [ 26%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_process.py::TestCheckpointProcessConfig::test_default_options PASSED [0.0005s] [ 33%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_process.py::TestCheckpointProcess::test_checkpoint_process_initialization [2025-09-12 17:48:43.567] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.5479s] [ 40%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_process.py::TestCheckpointProcess::test_checkpoint_write_future_state_dict [2025-09-12 17:48:46.066] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.5747s] [ 46%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_process.py::TestCheckpointProcess::test_checkpoint_write_sync_state_dict [2025-09-12 17:48:48.630] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.5114s] [ 53%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_process.py::TestCheckpointProcess::test_checkpoint_write_with_kwargs [2025-09-12 17:48:51.146] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.4906s] [ 60%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_process.py::TestCheckpointProcess::test_communication_error_handling [2025-09-12 17:48:53.645] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.0519s] [ 66%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_process.py::TestCheckpointProcess::test_forced_termination [2025-09-12 17:48:55.776] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.1297s] [ 73%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_process.py::TestCheckpointProcess::test_graceful_termination [2025-09-12 17:48:57.833] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.5005s] [ 80%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_process.py::TestCheckpointProcess::test_shared_memory_tensor_ipc [2025-09-12 17:49:00.334] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.5110s] [ 86%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_process.py::TestCheckpointProcess::test_subprocess_initialization_failure [2025-09-12 17:49:02.830] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.0342s] [ 93%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_process.py::TestCheckpointProcess::test_subprocess_initialization_timeout PASSED [1.0035s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint__experimental_test_checkpoint_process.py.xml -
============================= 15 passed in 24.48s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:49:06.874] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 7 items
Running 7 items in this shard

../../../../test/distributed/checkpoint/_experimental/test_checkpoint_reader.py::TestCheckpointReader::test_partial_read PASSED [0.0273s] [ 14%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_reader.py::TestCheckpointReader::test_partial_read_different_dtypes PASSED [0.0049s] [ 28%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_reader.py::TestCheckpointReader::test_partial_read_missing_keys PASSED [0.0034s] [ 42%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_reader.py::TestCheckpointReader::test_read_checkpoint PASSED [0.0014s] [ 57%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_reader.py::TestCheckpointReader::test_read_nonexistent_checkpoint PASSED [0.0010s] [ 71%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_reader.py::TestCheckpointReader::test_read_with_kwargs PASSED [0.0012s] [ 85%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_reader.py::TestCheckpointReader::test_read_with_map_location PASSED [0.0020s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint__experimental_test_checkpoint_reader.py.xml -
============================== 7 passed in 2.04s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:49:09.742] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 8 items
Running 8 items in this shard

../../../../test/distributed/checkpoint/_experimental/test_checkpoint_writer.py::TestCheckpointWriterConfig::test_custom_values PASSED [0.1870s] [ 12%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_writer.py::TestCheckpointWriterConfig::test_default_values PASSED [0.0006s] [ 25%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_writer.py::TestCheckpointWriter::test_close PASSED [0.0028s] [ 37%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_writer.py::TestCheckpointWriter::test_write_calls_barrier PASSED [0.0023s] [ 50%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_writer.py::TestCheckpointWriter::test_write_calls_commit_hooks PASSED [0.0014s] [ 62%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_writer.py::TestCheckpointWriter::test_write_creates_checkpoint_file PASSED [0.0020s] [ 75%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_writer.py::TestCheckpointWriter::test_write_without_barrier PASSED [0.0009s] [ 87%]
../../../../test/distributed/checkpoint/_experimental/test_checkpoint_writer.py::TestCheckpointWriter::test_write_without_commit_hook PASSED [0.0012s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint__experimental_test_checkpoint_writer.py.xml -
============================== 8 passed in 2.15s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:49:12.853] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 11 items
Running 11 items in this shard

../../../../test/distributed/checkpoint/_experimental/test_checkpointer.py::TestCheckpointer::test_load_strict_mode [2025-09-12 17:49:14.857] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.4705s] [  9%]
../../../../test/distributed/checkpoint/_experimental/test_checkpointer.py::TestCheckpointer::test_load_with_map_location [2025-09-12 17:49:17.341] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.4579s] [ 18%]
../../../../test/distributed/checkpoint/_experimental/test_checkpointer.py::TestCheckpointer::test_nested_dict_partial_load [2025-09-12 17:49:19.802] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.4640s] [ 27%]
../../../../test/distributed/checkpoint/_experimental/test_checkpointer.py::TestCheckpointer::test_partial_load [2025-09-12 17:49:22.268] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.4699s] [ 36%]
../../../../test/distributed/checkpoint/_experimental/test_checkpointer.py::TestCheckpointer::test_save_and_load_basic [2025-09-12 17:49:24.731] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.4675s] [ 45%]
../../../../test/distributed/checkpoint/_experimental/test_checkpointer.py::TestCheckpointer::test_save_with_kwargs [2025-09-12 17:49:27.206] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.4893s] [ 54%]
../../../../test/distributed/checkpoint/_experimental/test_checkpointer.py::TestAsyncCheckpointerSpecific::test_async_error_handling PASSED [0.0017s] [ 63%]
../../../../test/distributed/checkpoint/_experimental/test_checkpointer.py::TestAsyncCheckpointerSpecific::test_async_future_results [2025-09-12 17:49:29.694] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.5035s] [ 72%]
../../../../test/distributed/checkpoint/_experimental/test_checkpointer.py::TestAsyncCheckpointerSpecific::test_async_multiple_saves_ordering [2025-09-12 17:49:32.199] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.4592s] [ 81%]
../../../../test/distributed/checkpoint/_experimental/test_checkpointer.py::TestAsyncCheckpointerSpecific::test_async_returns_futures [2025-09-12 17:49:34.660] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.4840s] [ 90%]
../../../../test/distributed/checkpoint/_experimental/test_checkpointer.py::TestAsyncCheckpointerSpecific::test_async_sequential_saves_wait [2025-09-12 17:49:37.166] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.5089s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint__experimental_test_checkpointer.py.xml -
============================= 11 passed in 26.74s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:49:40.535] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 7 items
Running 7 items in this shard

../../../../test/distributed/checkpoint/_experimental/test_staging.py::TestDefaultStager::test_async_staging PASSED [0.0041s] [ 14%]
../../../../test/distributed/checkpoint/_experimental/test_staging.py::TestDefaultStager::test_cuda_non_blocking_without_cuda SKIPPED [0.0004s] [ 28%]
../../../../test/distributed/checkpoint/_experimental/test_staging.py::TestDefaultStager::test_cuda_tensors_staging PASSED [0.0014s] [ 42%]
../../../../test/distributed/checkpoint/_experimental/test_staging.py::TestDefaultStager::test_different_option_combinations PASSED [0.0010s] [ 57%]
../../../../test/distributed/checkpoint/_experimental/test_staging.py::TestDefaultStager::test_multiple_staging_operations PASSED [0.0009s] [ 71%]
../../../../test/distributed/checkpoint/_experimental/test_staging.py::TestDefaultStager::test_resource_cleanup PASSED [0.0003s] [ 85%]
../../../../test/distributed/checkpoint/_experimental/test_staging.py::TestDefaultStager::test_sync_staging PASSED [0.0006s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint__experimental_test_staging.py.xml -
========================= 6 passed, 1 skipped in 2.03s =========================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:49:43.502] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 3 items
Running 3 items in this shard

../../../../test/distributed/checkpoint/_experimental/test_types.py::TestRankInfo::test_rank_info_default_initialization PASSED [0.1869s] [ 33%]
../../../../test/distributed/checkpoint/_experimental/test_types.py::TestRankInfo::test_rank_info_initialization PASSED [0.0006s] [ 66%]
../../../../test/distributed/checkpoint/_experimental/test_types.py::TestRankInfo::test_state_dict_type_alias PASSED [0.0006s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_checkpoint__experimental_test_types.py.xml -
============================== 3 passed in 2.23s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:49:46.583] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 8 items
Running 8 items in this shard

../../../../test/distributed/elastic/events/lib_test.py::EventLibTest::test_event_created PASSED [0.1613s] [ 12%]
../../../../test/distributed/elastic/events/lib_test.py::EventLibTest::test_event_deser PASSED [0.0008s] [ 25%]
../../../../test/distributed/elastic/events/lib_test.py::EventLibTest::test_get_or_create_logger PASSED [0.0010s] [ 37%]
../../../../test/distributed/elastic/events/lib_test.py::RdzvEventLibTest::test_construct_and_record_rdzv_event PASSED [0.0020s] [ 50%]
../../../../test/distributed/elastic/events/lib_test.py::RdzvEventLibTest::test_construct_and_record_rdzv_event_does_not_run_if_invalid_dest PASSED [0.0008s] [ 62%]
../../../../test/distributed/elastic/events/lib_test.py::RdzvEventLibTest::test_rdzv_event_created PASSED [0.0008s] [ 75%]
../../../../test/distributed/elastic/events/lib_test.py::RdzvEventLibTest::test_rdzv_event_deserialize PASSED [0.0010s] [ 87%]
../../../../test/distributed/elastic/events/lib_test.py::RdzvEventLibTest::test_rdzv_event_str PASSED [0.0006s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_elastic_events_lib_test.py.xml -
============================== 8 passed in 2.17s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:49:49.579] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 3 items
Running 3 items in this shard

../../../../test/distributed/elastic/metrics/api_test.py::MetricsApiTest::test_get_metric_name PASSED [0.1628s] [ 33%]
../../../../test/distributed/elastic/metrics/api_test.py::MetricsApiTest::test_inheritance PASSED [0.0009s] [ 66%]
../../../../test/distributed/elastic/metrics/api_test.py::MetricsApiTest::test_profile PASSED [0.0010s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_elastic_metrics_api_test.py.xml -
============================== 3 passed in 2.05s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:49:52.552] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 25 items
Running 25 items in this shard

../../../../test/distributed/elastic/multiprocessing/api_test.py::RunProcResultsTest::test_get_failures PASSED [0.1639s] [  4%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::RunProcResultsTest::test_is_failed PASSED [0.0007s] [  8%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StdTest::test_from_str_bad_input PASSED [0.0007s] [ 12%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StdTest::test_from_value PASSED [0.0007s] [ 16%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StdTest::test_from_value_map PASSED [0.0006s] [ 20%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesAsFuncTest::test_args_env_len_mismatch PASSED [0.0007s] [ 24%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesAsFuncTest::test_function_large_ret_val [2025-09-12 17:49:54.699] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:49:54.714] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:49:54.714] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:49:54.715] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [3.1113s] [ 28%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesAsFuncTest::test_function_raise [2025-09-12 17:49:57.787] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:49:57.802] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.6358s] [ 32%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesAsFuncTest::test_function_with_tensor [2025-09-12 17:50:00.428] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.4163s] [ 36%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesAsFuncTest::test_invalid_log_dir PASSED [0.0011s] [ 40%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesAsFuncTest::test_multiprocess_context_close PASSED [0.0026s] [ 44%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesAsFuncTest::test_multiprocessing_context_poll_raises_exception PASSED [0.0031s] [ 48%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesAsFuncTest::test_pcontext_wait PASSED [2.4872s] [ 52%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesAsFuncTest::test_pcontext_wait_on_a_child_thread PASSED [2.5893s] [ 56%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesAsFuncTest::test_to_map PASSED [0.0012s] [ 60%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesAsFuncTest::test_void_function [2025-09-12 17:50:07.970] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:07.974] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
hello
world
PASSED [2.6858s] [ 64%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesAsFuncTest::test_wait_for_all_child_procs_to_exit PASSED [0.0034s] [ 68%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesAsBinaryTest::test_binary_exit bar stdout from 1
PASSED [0.1035s] [ 72%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesAsBinaryTest::test_binary_incorrect_entrypoint PASSED [0.0020s] [ 76%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesAsBinaryTest::test_binary_raises bar from 1
PASSED [0.1024s] [ 80%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesAsBinaryTest::test_subprocess_context_close PASSED [0.0028s] [ 84%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesAsBinaryTest::test_validate_full_rank PASSED [0.0006s] [ 88%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesListAsFuncTest::test_function [2025-09-12 17:50:10.851] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:10.862] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
hello stdout from 0
hello stdout from 1
PASSED [2.6900s] [ 92%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesListAsBinaryTest::test_binary hello stdout from 0
hello stdout from 1
PASSED [0.1029s] [ 96%]
../../../../test/distributed/elastic/multiprocessing/api_test.py::StartProcessesListAsBinaryTest::test_binary_redirect_and_tee world stdout from 1
PASSED [1.0045s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_elastic_multiprocessing_api_test.py.xml -
============================= 25 passed in 22.05s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:50:15.668] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 9 items / 1 deselected / 8 selected
Running 8 items in this shard

../../../../test/distributed/elastic/test_control_plane.py::WorkerServerTest::test_dump_nccl_trace_pickle SKIPPED [0.0002s] [ 12%]
../../../../test/distributed/elastic/test_control_plane.py::WorkerServerTest::test_dump_nccl_trace_pickle_with_json SKIPPED [0.0002s] [ 25%]
../../../../test/distributed/elastic/test_control_plane.py::WorkerServerTest::test_dump_nccl_trace_pickle_with_params SKIPPED [0.0001s] [ 37%]
../../../../test/distributed/elastic/test_control_plane.py::WorkerServerTest::test_dump_traceback PASSED [0.1775s] [ 50%]
../../../../test/distributed/elastic/test_control_plane.py::WorkerServerTest::test_get_handler_names PASSED [0.0007s] [ 62%]
../../../../test/distributed/elastic/test_control_plane.py::WorkerServerTest::test_get_handler_nonexistant PASSED [0.0009s] [ 75%]
../../../../test/distributed/elastic/test_control_plane.py::WorkerServerTest::test_run_handler PASSED [0.0009s] [ 87%]
../../../../test/distributed/elastic/test_control_plane.py::WorkerServerTest::test_worker_server PASSED [0.0193s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_elastic_test_control_plane.py.xml -
================== 5 passed, 3 skipped, 1 deselected in 2.18s ==================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... collected 1 item
Running 1 items in this shard

../../../../test/distributed/elastic/timer/api_test.py::TimerApiTest::test_run_watchdog PASSED [0.0017s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_elastic_timer_api_test.py.xml -
============================== 1 passed in 1.09s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:50:20.506] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/elastic/timer/local_timer_example.py::LocalTimerExample::test_example_start_method_spawn [2025-09-12 17:50:22.666] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:22.674] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:22.675] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:22.678] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:22.696] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:22.696] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:22.697] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:22.705] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [3.5321s] [ 50%]
../../../../test/distributed/elastic/timer/local_timer_example.py::LocalTimerExample::test_torch_mp_example [2025-09-12 17:50:26.006] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:26.009] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:26.011] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:26.041] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:26.049] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:26.049] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:26.082] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:26.089] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:29.594] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:29.595] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:29.603] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:29.608] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:29.609] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:29.627] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:29.631] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:50:29.633] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [6.7820s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_elastic_timer_local_timer_example.py.xml -
============================== 2 passed in 12.31s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:50:33.671] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 14 items
Running 14 items in this shard

../../../../test/distributed/elastic/timer/local_timer_test.py::LocalTimerTest::test_client_interaction PASSED [0.1667s] [  7%]
../../../../test/distributed/elastic/timer/local_timer_test.py::LocalTimerTest::test_exception_propagation PASSED [0.0109s] [ 14%]
../../../../test/distributed/elastic/timer/local_timer_test.py::LocalTimerTest::test_get_timer_recursive [2025-09-12 17:50:35.961] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.3164s] [ 21%]
../../../../test/distributed/elastic/timer/local_timer_test.py::LocalTimerTest::test_happy_path PASSED [0.1025s] [ 28%]
../../../../test/distributed/elastic/timer/local_timer_test.py::LocalTimerTest::test_no_client PASSED [0.0110s] [ 35%]
../../../../test/distributed/elastic/timer/local_timer_test.py::LocalTimerTest::test_timer PASSED [0.1478s] [ 42%]
../../../../test/distributed/elastic/timer/local_timer_test.py::MultiprocessingRequestQueueTest::test_get PASSED [0.0215s] [ 50%]
../../../../test/distributed/elastic/timer/local_timer_test.py::MultiprocessingRequestQueueTest::test_get_less_than_size PASSED [0.5072s] [ 57%]
../../../../test/distributed/elastic/timer/local_timer_test.py::MultiprocessingRequestQueueTest::test_get_size PASSED [0.9087s] [ 64%]
../../../../test/distributed/elastic/timer/local_timer_test.py::LocalTimerServerTest::test_acquire_release PASSED [0.0021s] [ 71%]
../../../../test/distributed/elastic/timer/local_timer_test.py::LocalTimerServerTest::test_expired_timers PASSED [0.0016s] [ 78%]
../../../../test/distributed/elastic/timer/local_timer_test.py::LocalTimerServerTest::test_valid_timers PASSED [0.0014s] [ 85%]
../../../../test/distributed/elastic/timer/local_timer_test.py::LocalTimerServerTest::test_watchdog_call_count PASSED [0.1025s] [ 92%]
../../../../test/distributed/elastic/timer/local_timer_test.py::LocalTimerServerTest::test_watchdog_empty_queue PASSED [0.0108s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_elastic_timer_local_timer_test.py.xml -
============================== 14 passed in 6.21s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:50:40.897] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 8 items
Running 8 items in this shard

../../../../test/distributed/elastic/utils/distributed_test.py::DistributedUtilTest::test_create_store_multi PASSED [0.1886s] [ 12%]
../../../../test/distributed/elastic/utils/distributed_test.py::DistributedUtilTest::test_create_store_no_port_multi PASSED [0.0010s] [ 25%]
../../../../test/distributed/elastic/utils/distributed_test.py::DistributedUtilTest::test_create_store_single_server PASSED [0.0015s] [ 37%]
../../../../test/distributed/elastic/utils/distributed_test.py::DistributedUtilTest::test_create_store_timeout_on_server PASSED [2.0088s] [ 50%]
../../../../test/distributed/elastic/utils/distributed_test.py::DistributedUtilTest::test_create_store_timeout_on_worker PASSED [2.5470s] [ 62%]
../../../../test/distributed/elastic/utils/distributed_test.py::DistributedUtilTest::test_create_store_with_libuv_support PASSED [0.0015s] [ 75%]
../../../../test/distributed/elastic/utils/distributed_test.py::DistributedUtilTest::test_port_already_in_use_on_server PASSED [0.0014s] [ 87%]
../../../../test/distributed/elastic/utils/distributed_test.py::DistributedUtilTest::test_port_already_in_use_on_worker PASSED [1.3475s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_elastic_utils_distributed_test.py.xml -
============================== 8 passed in 7.99s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:50:49.978] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 2 items
Running 2 items in this shard

../../../../test/distributed/elastic/utils/logging_test.py::LoggingTest::test_derive_module_name PASSED [0.1640s] [ 50%]
../../../../test/distributed/elastic/utils/logging_test.py::LoggingTest::test_logger_name PASSED [0.0018s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_elastic_utils_logging_test.py.xml -
============================== 2 passed in 2.16s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:50:53.050] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 12 items
Running 12 items in this shard

../../../../test/distributed/elastic/utils/util_test.py::StoreUtilTest::test_barrier PASSED [0.1601s] [  8%]
../../../../test/distributed/elastic/utils/util_test.py::StoreUtilTest::test_barrier_hash_store PASSED [0.0043s] [ 16%]
../../../../test/distributed/elastic/utils/util_test.py::StoreUtilTest::test_barrier_timeout_operations PASSED [0.0012s] [ 25%]
../../../../test/distributed/elastic/utils/util_test.py::StoreUtilTest::test_barrier_timeout_rank_tracing PASSED [0.1126s] [ 33%]
../../../../test/distributed/elastic/utils/util_test.py::StoreUtilTest::test_get_all_rank_0 PASSED [0.0005s] [ 41%]
../../../../test/distributed/elastic/utils/util_test.py::StoreUtilTest::test_get_all_rank_n PASSED [0.0004s] [ 50%]
../../../../test/distributed/elastic/utils/util_test.py::StoreUtilTest::test_synchronize PASSED [0.0005s] [ 58%]
../../../../test/distributed/elastic/utils/util_test.py::StoreUtilTest::test_synchronize_hash_store PASSED [0.0023s] [ 66%]
../../../../test/distributed/elastic/utils/util_test.py::UtilTest::test_get_logger PASSED [0.0014s] [ 75%]
../../../../test/distributed/elastic/utils/util_test.py::UtilTest::test_get_logger_custom_name PASSED [0.0006s] [ 83%]
../../../../test/distributed/elastic/utils/util_test.py::UtilTest::test_get_logger_different PASSED [0.0007s] [ 91%]
../../../../test/distributed/elastic/utils/util_test.py::UtilTest::test_get_logger_none PASSED [0.0010s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_elastic_utils_util_test.py.xml -
============================== 12 passed in 2.26s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... collected 5 items
Running 5 items in this shard

../../../../test/distributed/optim/test_apply_optimizer_in_backward.py::ApplyOverlappedOptimizerTest::test_apply_optimizer_in_backward [2025-09-12 17:50:56.807] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [0.6307s] [ 20%]
../../../../test/distributed/optim/test_apply_optimizer_in_backward.py::ApplyOverlappedOptimizerTest::test_apply_optimizer_in_backward_shared_params PASSED [0.0054s] [ 40%]
../../../../test/distributed/optim/test_apply_optimizer_in_backward.py::ApplyOverlappedOptimizerTest::test_get_optimizers_in_backward PASSED [0.0004s] [ 60%]
../../../../test/distributed/optim/test_apply_optimizer_in_backward.py::ApplyOverlappedOptimizerTest::test_multiple_optim_for_params PASSED [0.0066s] [ 80%]
../../../../test/distributed/optim/test_apply_optimizer_in_backward.py::ApplyOverlappedOptimizerTest::test_no_register_hook PASSED [0.0025s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_optim_test_apply_optimizer_in_backward.py.xml -
============================== 5 passed in 2.02s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... collected 8 items
Running 8 items in this shard

../../../../test/distributed/optim/test_named_optimizer.py::NamedOptimizerTest::test_add_param_group [2025-09-12 17:50:59.590] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [0.6251s] [ 12%]
../../../../test/distributed/optim/test_named_optimizer.py::NamedOptimizerTest::test_add_param_group_error PASSED [0.0014s] [ 25%]
../../../../test/distributed/optim/test_named_optimizer.py::NamedOptimizerTest::test_init_state PASSED [0.0011s] [ 37%]
../../../../test/distributed/optim/test_named_optimizer.py::NamedOptimizerTest::test_load_state_dict PASSED [0.0026s] [ 50%]
../../../../test/distributed/optim/test_named_optimizer.py::NamedOptimizerTest::test_load_state_dict_conditional_training PASSED [0.0024s] [ 62%]
../../../../test/distributed/optim/test_named_optimizer.py::NamedOptimizerTest::test_load_state_dict_error PASSED [0.0017s] [ 75%]
../../../../test/distributed/optim/test_named_optimizer.py::NamedOptimizerTest::test_state_dict PASSED [0.0042s] [ 87%]
../../../../test/distributed/optim/test_named_optimizer.py::NamedOptimizerTest::test_state_dict_multi_param_group PASSED [0.0043s] [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_optim_test_named_optimizer.py.xml -
============================== 8 passed in 1.94s ===============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 17:51:02.498] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 42 items
Running 42 items in this shard

../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerSingleRank::test_constructor [2025-09-12 17:51:04.834] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.8046s] [  2%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerSingleRank::test_lr_scheduler [2025-09-12 17:51:07.574] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:51:07:1330645 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:51:07:1330645 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [3.3069s] [  4%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerSingleRank::test_same_dense_param_type [2025-09-12 17:51:10.866] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.7059s] [  7%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerSingleRank::test_state_dict [2025-09-12 17:51:13.582] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:51:13:1330796 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:51:13:1330796 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [3.4071s] [  9%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerSingleRank::test_step_with_extra_inner_key [2025-09-12 17:51:16.994] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:51:17:1330874 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:51:17:1330874 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [3.3069s] [ 11%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerSingleRank::test_step_with_kwargs [2025-09-12 17:51:20.310] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:51:20:1330952 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:51:20:1330952 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [3.4071s] [ 14%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerSingleRank::test_step_without_closure [2025-09-12 17:51:23.710] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:51:23:1331030 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:51:23:1331030 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [3.3069s] [ 16%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerSingleRank::test_zero_grad [2025-09-12 17:51:27.018] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [2.8062s] [ 19%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_add_param_group [2025-09-12 17:51:29.855] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:51:29.870] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:51:29.930] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:51:29.955] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [3.1093s] [ 21%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_collect_shards [2025-09-12 17:51:32.961] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:51:32.978] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:51:32.995] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:51:33.000] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:51:33:1331475 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:51:33:1331475 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:51:33:1331473 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:51:33:1331473 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:51:33:1331474 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:51:33:1331474 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:51:33:1331472 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:51:33:1331472 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [4.3111s] [ 23%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_False_gradient_as_bucket_view_False_static_graph_False_shard_buckets_False [2025-09-12 17:51:37.341] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:51:37.346] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:51:37.415] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:51:37.454] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:51:37:1331791 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:51:37:1331791 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:51:37:1331789 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:51:37:1331789 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:51:37:1331792 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:51:37:1331792 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:51:37:1331790 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:51:37:1331790 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [40.5702s] [ 26%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_False_gradient_as_bucket_view_False_static_graph_False_shard_buckets_True [2025-09-12 17:52:17.842] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:52:17.854] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:52:17.938] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:52:17.971] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:52:18:1332488 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:52:18:1332488 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:52:18:1332486 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:52:18:1332486 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:52:18:1332489 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:52:18:1332489 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:52:18:1332487 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:52:18:1332487 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [40.5694s] [ 28%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_False_gradient_as_bucket_view_False_static_graph_True_shard_buckets_False [2025-09-12 17:52:58.430] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:52:58.451] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:52:58.452] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:52:58.482] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:52:58:1333187 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:52:58:1333187 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:52:58:1333188 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:52:58:1333188 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:52:59:1333189 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:52:59:1333189 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:52:59:1333190 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:52:59:1333190 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [40.7744s] [ 30%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_False_gradient_as_bucket_view_False_static_graph_True_shard_buckets_True [2025-09-12 17:53:39.233] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:53:39.241] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:53:39.243] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:53:39.250] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:53:39:1333889 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:53:39:1333889 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:53:39:1333888 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:53:39:1333888 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:53:39:1333887 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:53:39:1333887 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:53:39:1333886 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:53:39:1333886 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [40.8726s] [ 33%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_False_gradient_as_bucket_view_True_static_graph_False_shard_buckets_False [2025-09-12 17:54:20.099] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:54:20.118] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:54:20.162] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:54:20.173] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:54:20:1334585 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:54:20:1334585 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:54:20:1334588 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:54:20:1334588 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:54:20:1334586 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:54:20:1334586 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:54:20:1334587 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:54:20:1334587 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [40.7707s] [ 35%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_False_gradient_as_bucket_view_True_static_graph_False_shard_buckets_True [2025-09-12 17:55:00.868] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:55:00.869] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:55:00.876] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:55:00.882] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:55:01:1335284 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:55:01:1335284 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:55:01:1335283 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:55:01:1335283 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:55:01:1335285 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:55:01:1335285 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:55:01:1335286 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:55:01:1335286 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [40.6726s] [ 38%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_False_gradient_as_bucket_view_True_static_graph_True_shard_buckets_False [2025-09-12 17:55:41.530] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:55:41.530] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:55:41.545] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:55:41.551] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:55:42:1335984 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:55:42:1335984 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:55:42:1335983 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:55:42:1335983 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:55:42:1335982 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:55:42:1335982 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:55:42:1335981 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:55:42:1335981 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [40.8705s] [ 40%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_False_gradient_as_bucket_view_True_static_graph_True_shard_buckets_True [2025-09-12 17:56:22.423] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:56:22.423] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:56:22.426] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:56:22.432] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:56:22:1336680 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:56:22:1336680 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:56:22:1336683 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:56:22:1336683 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:56:23:1336681 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:56:23:1336681 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:56:23:1336682 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:56:23:1336682 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [40.7704s] [ 42%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_True_gradient_as_bucket_view_False_static_graph_False_shard_buckets_False [2025-09-12 17:57:03.181] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:57:03.198] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:57:03.310] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:57:03.313] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:57:03:1337381 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:57:03:1337381 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:57:03:1337378 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:57:03:1337378 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:57:03:1337380 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:57:03:1337380 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:57:03:1337379 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:57:03:1337379 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [40.6706s] [ 45%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_True_gradient_as_bucket_view_False_static_graph_False_shard_buckets_True [2025-09-12 17:57:43.837] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:57:43.838] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:57:43.839] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:57:43.852] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:57:44:1338076 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:57:44:1338076 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:57:44:1338079 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:57:44:1338079 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:57:44:1338077 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:57:44:1338077 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:57:44:1338078 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:57:44:1338078 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [40.5775s] [ 47%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_True_gradient_as_bucket_view_False_static_graph_True_shard_buckets_False [2025-09-12 17:58:24.415] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:58:24.420] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:58:24.426] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:58:24.434] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:58:24:1338776 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:58:24:1338776 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:58:24:1338775 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:58:24:1338775 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:58:25:1338777 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:58:25:1338777 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:58:25:1338778 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:58:25:1338778 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [40.7697s] [ 50%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_True_gradient_as_bucket_view_False_static_graph_True_shard_buckets_True [2025-09-12 17:59:05.182] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:59:05.186] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:59:05.331] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:59:05.332] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:59:05:1339473 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:59:05:1339473 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:59:05:1339476 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:59:05:1339476 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:59:05:1339474 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:59:05:1339474 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:59:06:1339475 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:59:06:1339475 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [40.7778s] [ 52%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_True_gradient_as_bucket_view_True_static_graph_False_shard_buckets_False [2025-09-12 17:59:45.938] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:59:45.954] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:59:46.026] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 17:59:46.105] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-17:59:46:1340171 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:59:46:1340171 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:59:46:1340173 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:59:46:1340173 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:59:46:1340174 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:59:46:1340174 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-17:59:46:1340172 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-17:59:46:1340172 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [40.8707s] [ 54%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_True_gradient_as_bucket_view_True_static_graph_False_shard_buckets_True [2025-09-12 18:00:26.915] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:00:26.939] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:00:26.945] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:00:26.951] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:00:27:1340869 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:00:27:1340869 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:00:27:1340872 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:00:27:1340872 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:00:27:1340871 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:00:27:1340871 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:00:27:1340870 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:00:27:1340870 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [40.8803s] [ 57%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_True_gradient_as_bucket_view_True_static_graph_True_shard_buckets_False [2025-09-12 18:01:07.718] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:01:07.734] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:01:07.734] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:01:07.741] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:01:08:1341568 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:01:08:1341568 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:01:08:1341569 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:01:08:1341569 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:01:08:1341567 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:01:08:1341567 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:01:08:1341566 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:01:08:1341566 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [40.7720s] [ 59%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_True_gradient_as_bucket_view_True_static_graph_True_shard_buckets_True [2025-09-12 18:01:48.491] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:01:48.506] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:01:48.509] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:01:48.513] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:01:49:1342265 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:01:49:1342265 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:01:49:1342266 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:01:49:1342266 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:01:49:1342267 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:01:49:1342267 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:01:49:1342264 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:01:49:1342264 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [40.9640s] [ 61%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_local_optimizer_parity_optimizer_class_str_AdamW_maximize_False [2025-09-12 18:02:29.473] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:02:29.474] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:02:29.490] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:02:29.495] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:02:29:1342964 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:02:29:1342964 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:02:29:1342965 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:02:29:1342965 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:02:29:1342967 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:02:29:1342967 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:02:29:1342966 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:02:29:1342966 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.7295s] [ 64%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_local_optimizer_parity_optimizer_class_str_AdamW_maximize_True [2025-09-12 18:02:46.186] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:02:46.196] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:02:46.215] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:02:46.225] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:02:46:1343282 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:02:46:1343282 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:02:46:1343283 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:02:46:1343283 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:02:46:1343281 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:02:46:1343281 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:02:46:1343284 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:02:46:1343284 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.7290s] [ 66%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_local_optimizer_parity_optimizer_class_str_Adam_maximize_False [2025-09-12 18:03:02.886] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:03:02.907] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:03:02.913] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:03:02.923] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:03:03:1343598 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:03:03:1343601 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:03:03:1343598 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:03:03:1343601 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:03:03:1343599 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:03:03:1343599 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:03:03:1343600 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:03:03:1343600 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.7293s] [ 69%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_local_optimizer_parity_optimizer_class_str_Adam_maximize_True [2025-09-12 18:03:19.674] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:03:19.683] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:03:19.694] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:03:19.696] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:03:19:1343915 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:03:19:1343915 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:03:19:1343914 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:03:19:1343914 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:03:20:1343917 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:03:20:1343917 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:03:20:1343916 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:03:20:1343916 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.7293s] [ 71%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_local_optimizer_parity_optimizer_class_str_SGD_maximize_False [2025-09-12 18:03:36.375] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:03:36.390] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:03:36.497] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:03:36.499] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:03:36:1344231 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:03:36:1344231 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:03:36:1344232 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:03:36:1344232 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:03:36:1344233 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:03:36:1344233 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:03:36:1344234 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:03:36:1344234 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.7287s] [ 73%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_local_optimizer_parity_optimizer_class_str_SGD_maximize_True [2025-09-12 18:03:53.111] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:03:53.128] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:03:53.130] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:03:53.141] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:03:53:1344547 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:03:53:1344547 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:03:53:1344550 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:03:53:1344550 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:03:53:1344549 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:03:53:1344549 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:03:53:1344548 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:03:53:1344548 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [16.7376s] [ 76%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_lr_scheduler [2025-09-12 18:04:09.863] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:04:09.874] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:04:09.891] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:04:09.906] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:04:10:1344864 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:04:10:1344864 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:04:10:1344865 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:04:10:1344865 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:04:10:1344867 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:04:10:1344867 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:04:10:1344866 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:04:10:1344866 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [4.2128s] [ 78%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_multiple_param_groups [2025-09-12 18:04:14.043] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:04:14.062] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:04:14.068] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:04:14.098] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:04:14:1345182 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:04:14:1345182 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:04:14:1345183 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:04:14:1345183 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:04:14:1345180 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:04:14:1345180 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:04:14:1345181 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:04:14:1345181 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [4.4133s] [ 80%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_nondefault_process_group [2025-09-12 18:04:18.488] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:04:18.506] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:04:18.537] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:04:18.546] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:04:19:1345498 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:04:19:1345496 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:04:19:1345496 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:04:19:1345498 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.6595s] [ 83%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_sharding [2025-09-12 18:04:34.166] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:04:34.179] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:04:34.181] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:04:34.197] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [3.1112s] [ 85%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_step [2025-09-12 18:04:37.244] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:04:37.262] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:04:37.275] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:04:37.279] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:04:37:1346088 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:04:37:1346088 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:04:37:1346089 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:04:37:1346089 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:04:37:1346091 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:04:37:1346091 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:04:37:1346090 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:04:37:1346090 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9313s] [ 88%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_step_with_closure [2025-09-12 18:04:53.182] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:04:53.191] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:04:53.217] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:04:53.220] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:04:53:1346406 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:04:53:1346406 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:04:53:1346405 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:04:53:1346405 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:04:53:1346404 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:04:53:1346404 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:04:53:1346407 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:04:53:1346407 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [15.9323s] [ 90%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_zero_join_cpu [2025-09-12 18:05:09.096] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:05:09.102] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:05:09.111] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:05:09.134] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
PASSED [3.2113s] [ 92%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_zero_join_gpu [2025-09-12 18:05:12.298] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:05:12.344] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:05:12.347] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:05:12.350] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:05:12:1347035 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:05:12:1347035 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:05:12:1347034 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:05:12:1347034 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:05:12:1347032 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:05:12:1347032 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:05:12:1347033 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:05:12:1347033 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
FAILED [16.5340s] [ 95%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_zero_model_parallel_parameters_as_bucket_view_False [2025-09-12 18:05:28.900] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:05:28.904] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:05:28.914] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:05:28.943] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:05:29:1347729 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:05:29:1347729 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:05:29:1347730 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:05:29:1347730 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:05:30:1347729:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-18:05:30:1347730:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [27.3486s] [ 97%]
../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_zero_model_parallel_parameters_as_bucket_view_True [2025-09-12 18:05:56.238] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:05:56.249] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:05:56.272] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:05:56.286] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:05:56:1348032 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:05:56:1348032 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:05:56:1348033 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:05:56:1348033 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:05:57:1348032:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-18:05:57:1348033:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [27.3489s] [100%]

=================================== FAILURES ===================================
__________ TestZeroRedundancyOptimizerDistributed.test_zero_join_gpu ___________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 139, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py", line 1083, in test_zero_join_gpu
    self._test_zero_join(self.device)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py", line 1070, in _test_zero_join
    torch.testing.assert_close(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Parameters differ between using ZeRO and local optimizer

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/optim/test_zero_redundancy_optimizer.py TestZeroRedundancyOptimizerDistributed.test_zero_join_gpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 139, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py", line 1083, in test_zero_join_gpu
    self._test_zero_join(self.device)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py", line 1070, in _test_zero_join
    torch.testing.assert_close(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Parameters differ between using ZeRO and local optimizer

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/optim/test_zero_redundancy_optimizer.py TestZeroRedundancyOptimizerDistributed.test_zero_join_gpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0


----------------------------- Captured stdout call -----------------------------
Process 2 terminated with exit code 10, terminating remaining processes.
----------------------------- Captured stderr call -----------------------------
I0912 18:05:10.309000 1330501 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1347032
I0912 18:05:10.310000 1330501 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1347033
I0912 18:05:10.311000 1330501 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 2 with pid 1347034
I0912 18:05:10.312000 1330501 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 3 with pid 1347035
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_optim_test_zero_redundancy_optimizer.py.xml -
=========================== short test summary info ============================
FAILED [16.5340s] ../../../../test/distributed/optim/test_zero_redundancy_optimizer.py::TestZeroRedundancyOptimizerDistributed::test_zero_join_gpu - RuntimeError: Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 139, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py", line 1083, in test_zero_join_gpu
    self._test_zero_join(self.device)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py", line 1070, in _test_zero_join
    torch.testing.assert_close(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Parameters differ between using ZeRO and local optimizer

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/optim/test_zero_redundancy_optimizer.py TestZeroRedundancyOptimizerDistributed.test_zero_join_gpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 139, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py", line 1083, in test_zero_join_gpu
    self._test_zero_join(self.device)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py", line 1070, in _test_zero_join
    torch.testing.assert_close(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Parameters differ between using ZeRO and local optimizer

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/optim/test_zero_redundancy_optimizer.py TestZeroRedundancyOptimizerDistributed.test_zero_join_gpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0
=================== 1 failed, 41 passed in 920.97s (0:15:20) ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 18:06:23.790] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 28 items

distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_all_to_all [2025-09-12 18:06:25.806] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:06:25.806] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:06:25.833] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:06:25.837] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:06:26:1348409 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:06:26:1348409 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:06:26:1348411 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:06:26:1348411 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:06:26:1348412 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:06:26:1348412 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:06:26:1348410 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:06:26:1348410 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [  3%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_all_to_all_single PASSED [  7%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_all_to_all_single_none PASSED [ 10%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_all_to_all_single_unequal_split PASSED [ 14%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_allgather_base_basics PASSED [ 17%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_allgather_base_ops PASSED [ 21%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_allgather_ops PASSED [ 25%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_allreduce_ops_complex64 PASSED [ 28%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_allreduce_ops_float32 PASSED [ 32%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_alltoall_ops_with_xpufree_race PASSED [ 35%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_barrier PASSED [ 39%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_batch_isend_irecv PASSED [ 42%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_broadcast_ops_complex64 PASSED [ 46%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_broadcast_ops_float32 PASSED [ 50%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_empty_tensors PASSED [ 53%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_gather_checks PASSED [ 57%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_gather_ops PASSED [ 60%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_gather_stress PASSED [ 64%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_reduce_ops PASSED [ 67%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_reduce_scatter_base_basics PASSED [ 71%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_reduce_scatter_base_ops PASSED [ 75%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_reduce_scatter_ops PASSED [ 78%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_scatter_checks PASSED [ 82%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_scatter_ops PASSED [ 85%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_scatter_stress PASSED [ 89%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_send_recv 2025:09:12-18:06:58:1348409:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-18:06:58:1348410:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [ 92%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_send_recv_complex PASSED [ 96%]
distributed/test_c10d_ops_xccl.py::ProcessGroupXCCLOpTest::test_send_recv_object_list PASSED [100%]

- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_distributed_test_c10d_ops_xccl.py.xml -
============================= 28 passed in 37.10s ==============================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 18:07:01.896] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 22 items

distributed/test_c10d_xccl.py::RendezvousEnvTest::test_common_errors PASSED [  4%]
distributed/test_c10d_xccl.py::ProcessGroupXCCLTest::test_close_multi_pg_unordered [2025-09-12 18:07:04.038] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:07:04.054] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:07:04:1348817 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:07:04:1348817 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:07:04:1348818 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:07:04:1348818 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:07:17:1348818:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-18:07:17:1348817:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-18:07:17:1348817:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-18:07:17:1348818:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED [  9%]
distributed/test_c10d_xccl.py::ProcessGroupXCCLTest::test_file_store_check [2025-09-12 18:07:19.548] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:07:19.572] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [ 13%]
distributed/test_c10d_xccl.py::ProcessGroupXCCLTest::test_nan_assert_bfloat16 [2025-09-12 18:07:24.259] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:07:24.262] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:07:25:1349119 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:07:25:1349119 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:07:25:1349120 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:07:25:1349120 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [ 18%]
distributed/test_c10d_xccl.py::ProcessGroupXCCLTest::test_nan_assert_float16 [2025-09-12 18:07:27.189] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:07:27.205] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:07:27:1349270 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:07:27:1349270 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:07:27:1349271 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:07:27:1349271 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [ 22%]
distributed/test_c10d_xccl.py::ProcessGroupXCCLTest::test_nan_assert_float32 [2025-09-12 18:07:29.981] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:07:30.004] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:07:30:1349422 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:07:30:1349422 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:07:30:1349421 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:07:30:1349421 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [ 27%]
distributed/test_c10d_xccl.py::ProcessGroupXCCLTest::test_nan_assert_float64 [2025-09-12 18:07:32.794] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:07:32.795] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:07:33:1349571 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:07:33:1349571 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:07:33:1349572 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:07:33:1349572 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [ 31%]
distributed/test_c10d_xccl.py::ProcessGroupXCCLTest::test_nan_assert_float8_e4m3fn [2025-09-12 18:07:35.593] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:07:35.618] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:07:36:1349722 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:07:36:1349722 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:07:36:1349721 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:07:36:1349721 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [ 36%]
distributed/test_c10d_xccl.py::ProcessGroupXCCLTest::test_nan_assert_float8_e5m2 [2025-09-12 18:07:39.116] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:07:39.138] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:07:39:1349871 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:07:39:1349871 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:07:39:1349872 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:07:39:1349872 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [ 40%]
distributed/test_c10d_xccl.py::ProcessGroupXCCLTest::test_set_process_group_desc [2025-09-12 18:07:42.677] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:07:42.678] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
PASSED [ 45%]
distributed/test_c10d_xccl.py::CommTest::test_all_gather_into_tensor [2025-09-12 18:07:45.416] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:07:45.429] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:07:46:1350170 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:07:46:1350170 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:07:46:1350169 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:07:46:1350169 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:07:46:1350169:[0] |CCL_WARN| topology recognition shows PCIe connection between devices. If this is not correct, you can disable topology recognition, with CCL_TOPO_FABRIC_VERTEX_CONNECTION_CHECK=0. This will assume XeLinks across devices
2025:09:12-18:07:46:1350170:[1] |CCL_WARN| topology recognition shows PCIe connection between devices. If this is not correct, you can disable topology recognition, with CCL_TOPO_FABRIC_VERTEX_CONNECTION_CHECK=0. This will assume XeLinks across devices
PASSED [ 50%]
distributed/test_c10d_xccl.py::CommTest::test_all_reduce_coalesced_manager_xccl [2025-09-12 18:07:48.832] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:07:48.838] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:07:49:1350317 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:07:49:1350317 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:07:49:1350318 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:07:49:1350318 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [ 54%]
distributed/test_c10d_xccl.py::CommTest::test_all_reduce_coalesced_xccl [2025-09-12 18:08:04.038] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:08:04.041] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:08:04:1350469 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:08:04:1350469 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:08:04:1350468 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:08:04:1350468 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [ 59%]
distributed/test_c10d_xccl.py::CommTest::test_broadcast_coalesced_xccl [2025-09-12 18:08:18.982] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:08:18.986] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:08:19:1350618 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:08:19:1350618 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:08:20:1350619 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:08:20:1350619 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [ 63%]
distributed/test_c10d_xccl.py::CommTest::test_reduce_scatter_base_k [2025-09-12 18:08:23.281] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:08:23.299] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:08:24:1350769 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:08:24:1350769 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:08:24:1350768 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:08:24:1350768 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [ 68%]
distributed/test_c10d_xccl.py::CommTest::test_reduce_scatter_tensor_coalesced [2025-09-12 18:08:41.712] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:08:41.730] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:08:42:1350920 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:08:42:1350920 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:08:42:1350919 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:08:42:1350919 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [ 72%]
distributed/test_c10d_xccl.py::CommTest::test_single_p2p [2025-09-12 18:09:00.066] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:09:00.067] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:09:00:1351071 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:09:00:1351071 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:09:00:1351070 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:09:00:1351070 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED          [ 77%]
distributed/test_c10d_xccl.py::CommTest::test_tensor_dtype_complex [2025-09-12 18:09:03.459] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:09:03.468] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:09:04:1351220 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:09:04:1351220 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:09:04:1351221 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:09:04:1351221 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [ 81%]
distributed/test_c10d_xccl.py::CommTest::test_unwaited [2025-09-12 18:09:06.982] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:09:06.984] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:09:07:1351371 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:09:07:1351371 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:09:07:1351370 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:09:07:1351370 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
Segmentation fault from GPU at 0xff01000373803000, ctx_id: 1 (CCS) type: 0 (NotPresent), level: 1 (PDE), access: 0 (Read), banned: 1, aborting.
Abort was called at 288 line in file:
./shared/source/os_interface/linux/drm_neo.cpp
FAILED            [ 86%]
distributed/test_c10d_xccl.py::CommTest::test_wait_tensor [2025-09-12 18:14:07.006] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:14:07.032] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:14:07:1351536 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:14:07:1351536 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:14:07:1351537 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:14:07:1351537 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED         [ 90%]
distributed/test_c10d_xccl.py::CommTest::test_xccl_barrier [2025-09-12 18:14:22.009] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:14:22.022] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:14:22:1351689 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:14:22:1351689 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:14:22:1351690 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:14:22:1351690 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:14:35:1351689:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-18:14:35:1351690:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-18:14:35:1351690:[1] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
2025:09:12-18:14:35:1351689:[0] |CCL_WARN| Warning: CCL_OFI_ENABLE_HOSTNAME_SHARING is enabled; this feature is deprecated and might contain security vulnerabilities.
PASSED        [ 95%]
distributed/test_c10d_xccl.py::CommTest::test_xccl_barrier_device_ids [2025-09-12 18:14:37.521] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:14:37.533] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:14:38:1351851 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:14:38:1351850 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:14:38:1351850 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:14:38:1351851 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
PASSED [100%]

=================================== FAILURES ===================================
____________________________ CommTest.test_unwaited ____________________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1025, in _check_return_codes
    raise RuntimeError(
RuntimeError: Process 0 terminated or timed out after 300.0147752761841 seconds
----------------------------- Captured stdout call -----------------------------
Timing out after 300 seconds and killing subprocesses.
----------------------------- Captured stderr call -----------------------------
I0912 18:09:05.684000 1348734 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 0 with pid 1351370
I0912 18:09:05.685000 1348734 site-packages/torch/testing/_internal/common_distributed.py:789] Started process 1 with pid 1351371
E0912 18:14:05.699000 1348734 site-packages/torch/testing/_internal/common_distributed.py:909] Encountered error while trying to get traceback for process 0: [Errno 32] Broken pipe
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_distributed_test_c10d_xccl.py.xml -
=========================== short test summary info ============================
FAILED distributed/test_c10d_xccl.py::CommTest::test_unwaited - RuntimeError: Process 0 terminated or timed out after 300.0147752761841 seconds
=================== 1 failed, 21 passed in 470.50s (0:07:50) ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 18:14:53.846] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 32 items
Running 32 items in this shard

../../../../test/distributed/test_c10d_functional_native.py::TestWithNCCL::test_all_gather_into_tensor_coalesced SKIPPED [0.0003s] [  3%]
../../../../test/distributed/test_c10d_functional_native.py::TestWithNCCL::test_all_gather_into_tensor_single SKIPPED [0.0002s] [  6%]
../../../../test/distributed/test_c10d_functional_native.py::TestWithNCCL::test_all_reduce_coalesced SKIPPED [0.0001s] [  9%]
../../../../test/distributed/test_c10d_functional_native.py::TestWithNCCL::test_all_reduce_coalesced_ SKIPPED [0.0001s] [ 12%]
../../../../test/distributed/test_c10d_functional_native.py::TestWithNCCL::test_all_reduce_single SKIPPED [0.0001s] [ 15%]
../../../../test/distributed/test_c10d_functional_native.py::TestWithNCCL::test_all_reduce_single_ SKIPPED [0.0001s] [ 18%]
../../../../test/distributed/test_c10d_functional_native.py::TestWithNCCL::test_all_to_all_single SKIPPED [0.0001s] [ 21%]
../../../../test/distributed/test_c10d_functional_native.py::TestWithNCCL::test_broadcast SKIPPED [0.0001s] [ 25%]
../../../../test/distributed/test_c10d_functional_native.py::TestWithNCCL::test_fixed_striding SKIPPED [0.0001s] [ 28%]
../../../../test/distributed/test_c10d_functional_native.py::TestWithNCCL::test_functional_collectives_inference_mode SKIPPED [0.0001s] [ 31%]
../../../../test/distributed/test_c10d_functional_native.py::TestWithNCCL::test_inductor_dtypeview_memory_leak SKIPPED [0.0001s] [ 34%]
../../../../test/distributed/test_c10d_functional_native.py::TestWithNCCL::test_reduce_scatter_tensor_coalesced SKIPPED [0.0001s] [ 37%]
../../../../test/distributed/test_c10d_functional_native.py::TestWithNCCL::test_reduce_scatter_tensor_single SKIPPED [0.0001s] [ 40%]
../../../../test/distributed/test_c10d_functional_native.py::TestWithNCCL::test_threading SKIPPED [0.0002s] [ 43%]
../../../../test/distributed/test_c10d_functional_native.py::TestWithNCCL::test_unwaited SKIPPED [0.0001s] [ 46%]
../../../../test/distributed/test_c10d_functional_native.py::TestWithNCCL::test_wait_tensor SKIPPED [0.0001s] [ 50%]
../../../../test/distributed/test_c10d_functional_native.py::PyWorkTest::test_collectives [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
PASSED [0.3624s] [ 53%]
../../../../test/distributed/test_c10d_functional_native.py::PyWorkTest::test_wait_tensor PASSED [0.0786s] [ 56%]
../../../../test/distributed/test_c10d_functional_native.py::CompileTestCPU::test_inductor_all_reduce_cpu PASSED [18.0560s] [ 59%]
../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_all_gather_into_tensor_coalesced FAILED [0.0006s] [ 62%]
../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_all_gather_into_tensor_single FAILED [0.0004s] [ 65%]
../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_all_reduce_coalesced FAILED [0.0004s] [ 68%]
../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_all_reduce_non_contig_input FAILED [0.0004s] [ 71%]
../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_all_reduce_single FAILED [0.0004s] [ 75%]
../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_all_to_all_single FAILED [0.0004s] [ 78%]
../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_broadcast FAILED [0.0005s] [ 81%]
../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_inplace_op_on_view FAILED [0.0004s] [ 84%]
../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_reduce_scatter_tensor_coalesced FAILED [0.0004s] [ 87%]
../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_reduce_scatter_tensor_single FAILED [0.0004s] [ 90%]
../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_reuse_buffer_after_inplace_collective FAILED [0.0004s] [ 93%]
../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_ranks_and_tag FAILED [0.0004s] [ 96%]
../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_wait_tensor FAILED [0.0004s] [100%]

=================================== FAILURES ===================================
__________ CompileTest.test_inductor_all_gather_into_tensor_coalesced __________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 587, in run
    self._callSetUp()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 546, in _callSetUp
    self.setUp()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_c10d_functional_native.py", line 782, in setUp
    torch.cuda.set_device("cuda:0")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 567, in set_device
    torch._C._cuda_setDevice(device)
AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
___________ CompileTest.test_inductor_all_gather_into_tensor_single ____________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 587, in run
    self._callSetUp()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 546, in _callSetUp
    self.setUp()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_c10d_functional_native.py", line 782, in setUp
    torch.cuda.set_device("cuda:0")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 567, in set_device
    torch._C._cuda_setDevice(device)
AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
________________ CompileTest.test_inductor_all_reduce_coalesced ________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 587, in run
    self._callSetUp()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 546, in _callSetUp
    self.setUp()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_c10d_functional_native.py", line 782, in setUp
    torch.cuda.set_device("cuda:0")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 567, in set_device
    torch._C._cuda_setDevice(device)
AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
____________ CompileTest.test_inductor_all_reduce_non_contig_input _____________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 587, in run
    self._callSetUp()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 546, in _callSetUp
    self.setUp()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_c10d_functional_native.py", line 782, in setUp
    torch.cuda.set_device("cuda:0")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 567, in set_device
    torch._C._cuda_setDevice(device)
AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
_________________ CompileTest.test_inductor_all_reduce_single __________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 587, in run
    self._callSetUp()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 546, in _callSetUp
    self.setUp()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_c10d_functional_native.py", line 782, in setUp
    torch.cuda.set_device("cuda:0")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 567, in set_device
    torch._C._cuda_setDevice(device)
AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
_________________ CompileTest.test_inductor_all_to_all_single __________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 587, in run
    self._callSetUp()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 546, in _callSetUp
    self.setUp()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_c10d_functional_native.py", line 782, in setUp
    torch.cuda.set_device("cuda:0")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 567, in set_device
    torch._C._cuda_setDevice(device)
AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
_____________________ CompileTest.test_inductor_broadcast ______________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 587, in run
    self._callSetUp()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 546, in _callSetUp
    self.setUp()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_c10d_functional_native.py", line 782, in setUp
    torch.cuda.set_device("cuda:0")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 567, in set_device
    torch._C._cuda_setDevice(device)
AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
_________________ CompileTest.test_inductor_inplace_op_on_view _________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 587, in run
    self._callSetUp()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 546, in _callSetUp
    self.setUp()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_c10d_functional_native.py", line 782, in setUp
    torch.cuda.set_device("cuda:0")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 567, in set_device
    torch._C._cuda_setDevice(device)
AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
__________ CompileTest.test_inductor_reduce_scatter_tensor_coalesced ___________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 587, in run
    self._callSetUp()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 546, in _callSetUp
    self.setUp()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_c10d_functional_native.py", line 782, in setUp
    torch.cuda.set_device("cuda:0")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 567, in set_device
    torch._C._cuda_setDevice(device)
AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
____________ CompileTest.test_inductor_reduce_scatter_tensor_single ____________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 587, in run
    self._callSetUp()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 546, in _callSetUp
    self.setUp()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_c10d_functional_native.py", line 782, in setUp
    torch.cuda.set_device("cuda:0")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 567, in set_device
    torch._C._cuda_setDevice(device)
AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
_______ CompileTest.test_inductor_reuse_buffer_after_inplace_collective ________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 587, in run
    self._callSetUp()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 546, in _callSetUp
    self.setUp()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_c10d_functional_native.py", line 782, in setUp
    torch.cuda.set_device("cuda:0")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 567, in set_device
    torch._C._cuda_setDevice(device)
AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
________________________ CompileTest.test_ranks_and_tag ________________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 587, in run
    self._callSetUp()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 546, in _callSetUp
    self.setUp()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_c10d_functional_native.py", line 782, in setUp
    torch.cuda.set_device("cuda:0")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 567, in set_device
    torch._C._cuda_setDevice(device)
AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
_________________________ CompileTest.test_wait_tensor _________________________
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 587, in run
    self._callSetUp()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 546, in _callSetUp
    self.setUp()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_c10d_functional_native.py", line 782, in setUp
    torch.cuda.set_device("cuda:0")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 567, in set_device
    torch._C._cuda_setDevice(device)
AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
- generated xml file: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/op_ut_with_skip_test_distributed_test_c10d_functional_native.py.xml -
=========================== short test summary info ============================
FAILED [0.0006s] ../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_all_gather_into_tensor_coalesced - AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
FAILED [0.0004s] ../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_all_gather_into_tensor_single - AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
FAILED [0.0004s] ../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_all_reduce_coalesced - AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
FAILED [0.0004s] ../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_all_reduce_non_contig_input - AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
FAILED [0.0004s] ../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_all_reduce_single - AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
FAILED [0.0004s] ../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_all_to_all_single - AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
FAILED [0.0005s] ../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_broadcast - AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
FAILED [0.0004s] ../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_inplace_op_on_view - AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
FAILED [0.0004s] ../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_reduce_scatter_tensor_coalesced - AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
FAILED [0.0004s] ../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_reduce_scatter_tensor_single - AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
FAILED [0.0004s] ../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_inductor_reuse_buffer_after_inplace_collective - AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
FAILED [0.0004s] ../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_ranks_and_tag - AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
FAILED [0.0004s] ../../../../test/distributed/test_c10d_functional_native.py::CompileTest::test_wait_tensor - AttributeError: module 'torch._C' has no attribute '_cuda_setDevice'
================== 13 failed, 3 passed, 16 skipped in 29.71s ===================
============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /tmp/xpu-tool/Python/3.10.18/x64/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/third_party/torch-xpu-ops/test/xpu/.hypothesis/examples')
rootdir: /home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch
configfile: pytest.ini
plugins: cpp-2.3.0, xdist-3.8.0, timeout-2.4.0, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, subtests-0.13.1, hypothesis-5.35.1
collecting ... [2025-09-12 18:15:24.985] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
collected 8 items
Running 8 items in this shard

../../../../test/distributed/pipelining/test_stage.py::StageTest::test_custom_dw_with_fb_schedule [2025-09-12 18:15:27.070] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:15:27.082] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:15:27.096] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[2025-09-12 18:15:27.118] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
2025:09:12-18:15:27:1352714 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:15:27:1352714 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:15:27:1352715 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:15:27:1352715 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:15:27:1352712 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:15:27:1352712 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
2025:09:12-18:15:27:1352713 |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi
2025:09:12-18:15:27:1352713 |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
