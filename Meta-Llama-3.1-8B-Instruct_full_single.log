Running FullFinetuneRecipeSingleDevice with resolved config:

batch_size: 2
checkpointer:
  _component_: torchtune.training.FullModelHFCheckpointer
  checkpoint_dir: /tmp/Meta-Llama-3.1-8B-Instruct/
  checkpoint_files:
  - model-00001-of-00004.safetensors
  - model-00002-of-00004.safetensors
  - model-00003-of-00004.safetensors
  - model-00004-of-00004.safetensors
  model_type: LLAMA3
  output_dir: /tmp/torchtune/llama3_1_8B/full_single_device
  recipe_checkpoint: null
clip_grad_norm: null
compile: false
dataset:
  _component_: torchtune.datasets.alpaca_dataset
  packed: true
device: xpu
dtype: bf16
enable_activation_checkpointing: true
enable_activation_offloading: false
epochs: 1
gradient_accumulation_steps: 1
log_every_n_steps: 1
log_level: INFO
log_peak_memory_stats: true
loss:
  _component_: torchtune.modules.loss.LinearCrossEntropyLoss
max_steps_per_epoch: 10
metric_logger:
  _component_: torchtune.training.metric_logging.DiskLogger
  log_dir: /tmp/torchtune/llama3_1_8B/full_single_device/logs
model:
  _component_: torchtune.models.llama3_1.llama3_1_8b
optimizer:
  _component_: torchao.optim.AdamW8bit
  lr: 2.0e-05
optimizer_in_bwd: true
output_dir: /tmp/torchtune/llama3_1_8B/full_single_device
profiler:
  _component_: torchtune.training.setup_torch_profiler
  active_steps: 2
  cpu: true
  cuda: true
  enabled: false
  num_cycles: 1
  output_dir: /tmp/torchtune/llama3_1_8B/full_single_device/profiling_outputs
  profile_memory: false
  record_shapes: true
  wait_steps: 5
  warmup_steps: 3
  with_flops: false
  with_stack: false
resume_from_checkpoint: false
seed: 123
shuffle: true
tokenizer:
  _component_: torchtune.models.llama3.llama3_tokenizer
  max_seq_len: 512
  path: /tmp/Meta-Llama-3.1-8B-Instruct/original/tokenizer.model

Hint: enable_activation_checkpointing is True, but enable_activation_offloading isn't. Enabling activation offloading should reduce memory further.
Model is initialized with precision torch.bfloat16.
Memory stats after model init:
	XPU peak memory active: 15.02 GiB
	XPU peak memory alloc: 15.02 GiB
	XPU peak memory reserved: 15.14 GiB
Tokenizer is initialized from file.
Optimizer is initialized.
Loss is initialized.
Writing logs to /tmp/torchtune/llama3_1_8B/full_single_device/logs/log_1760954653.txt
Packing dataset:   0%|          | 0/52002 [00:00<?, ?it/s]Packing dataset:   1%|          | 413/52002 [00:00<00:12, 4125.24it/s]Packing dataset:   2%|▏         | 881/52002 [00:00<00:11, 4443.80it/s]Packing dataset:   3%|▎         | 1354/52002 [00:00<00:11, 4571.66it/s]Packing dataset:   3%|▎         | 1818/52002 [00:00<00:10, 4596.45it/s]Packing dataset:   4%|▍         | 2305/52002 [00:00<00:10, 4692.18it/s]Packing dataset:   5%|▌         | 2788/52002 [00:00<00:10, 4737.76it/s]Packing dataset:   6%|▋         | 3262/52002 [00:00<00:10, 4736.58it/s]Packing dataset:   7%|▋         | 3736/52002 [00:00<00:10, 4656.86it/s]Packing dataset:   8%|▊         | 4202/52002 [00:00<00:10, 4652.59it/s]Packing dataset:   9%|▉         | 4675/52002 [00:01<00:10, 4675.60it/s]Packing dataset:  10%|▉         | 5151/52002 [00:01<00:09, 4700.30it/s]Packing dataset:  11%|█         | 5627/52002 [00:01<00:09, 4714.80it/s]Packing dataset:  12%|█▏        | 6099/52002 [00:01<00:09, 4662.88it/s]Packing dataset:  13%|█▎        | 6566/52002 [00:01<00:09, 4655.68it/s]Packing dataset:  14%|█▎        | 7032/52002 [00:01<00:09, 4582.94it/s]Packing dataset:  14%|█▍        | 7491/52002 [00:01<00:09, 4549.21it/s]Packing dataset:  15%|█▌        | 7956/52002 [00:01<00:09, 4576.91it/s]Packing dataset:  16%|█▌        | 8414/52002 [00:01<00:09, 4565.49it/s]Packing dataset:  17%|█▋        | 8909/52002 [00:01<00:09, 4676.51it/s]Packing dataset:  18%|█▊        | 9379/52002 [00:02<00:09, 4683.27it/s]Packing dataset:  19%|█▉        | 9848/52002 [00:02<00:09, 4616.47it/s]Packing dataset:  20%|█▉        | 10321/52002 [00:02<00:08, 4647.83it/s]Packing dataset:  21%|██        | 10788/52002 [00:02<00:08, 4654.31it/s]Packing dataset:  22%|██▏       | 11254/52002 [00:02<00:08, 4601.27it/s]Packing dataset:  23%|██▎       | 11717/52002 [00:02<00:08, 4607.90it/s]Packing dataset:  23%|██▎       | 12178/52002 [00:02<00:08, 4585.87it/s]Packing dataset:  24%|██▍       | 12652/52002 [00:02<00:08, 4631.08it/s]Packing dataset:  25%|██▌       | 13116/52002 [00:02<00:08, 4627.22it/s]Packing dataset:  26%|██▌       | 13582/52002 [00:02<00:08, 4634.96it/s]Packing dataset:  27%|██▋       | 14046/52002 [00:03<00:08, 4580.69it/s]Packing dataset:  28%|██▊       | 14517/52002 [00:03<00:08, 4615.47it/s]Packing dataset:  29%|██▉       | 14979/52002 [00:03<00:08, 4603.12it/s]Packing dataset:  30%|██▉       | 15440/52002 [00:03<00:07, 4600.72it/s]Packing dataset:  31%|███       | 15901/52002 [00:03<00:07, 4551.93it/s]Packing dataset:  31%|███▏      | 16375/52002 [00:03<00:07, 4607.64it/s]Packing dataset:  32%|███▏      | 16853/52002 [00:03<00:07, 4656.94it/s]Packing dataset:  33%|███▎      | 17319/52002 [00:03<00:07, 4642.73it/s]Packing dataset:  34%|███▍      | 17784/52002 [00:03<00:07, 4643.70it/s]Packing dataset:  35%|███▌      | 18249/52002 [00:03<00:07, 4607.86it/s]Packing dataset:  36%|███▌      | 18710/52002 [00:04<00:07, 4548.70it/s]Packing dataset:  37%|███▋      | 19170/52002 [00:04<00:07, 4559.91it/s]Packing dataset:  38%|███▊      | 19631/52002 [00:04<00:07, 4572.51it/s]Packing dataset:  39%|███▊      | 20092/52002 [00:04<00:06, 4583.37it/s]Packing dataset:  40%|███▉      | 20553/52002 [00:04<00:06, 4589.50it/s]Packing dataset:  40%|████      | 21039/52002 [00:04<00:06, 4669.37it/s]Packing dataset:  41%|████▏     | 21517/52002 [00:04<00:06, 4697.69it/s]Packing dataset:  42%|████▏     | 21987/52002 [00:04<00:06, 4641.92it/s]Packing dataset:  43%|████▎     | 22453/52002 [00:04<00:06, 4644.70it/s]Packing dataset:  44%|████▍     | 22918/52002 [00:04<00:06, 4587.99it/s]Packing dataset:  45%|████▍     | 23393/52002 [00:05<00:06, 4634.55it/s]Packing dataset:  46%|████▌     | 23860/52002 [00:05<00:06, 4645.06it/s]Packing dataset:  47%|████▋     | 24325/52002 [00:05<00:05, 4625.77it/s]Packing dataset:  48%|████▊     | 24791/52002 [00:05<00:05, 4634.85it/s]Packing dataset:  49%|████▊     | 25255/52002 [00:05<00:05, 4634.98it/s]Packing dataset:  49%|████▉     | 25719/52002 [00:05<00:05, 4614.91it/s]Packing dataset:  50%|█████     | 26181/52002 [00:05<00:05, 4578.97it/s]Packing dataset:  51%|█████     | 26647/52002 [00:05<00:05, 4602.68it/s]Packing dataset:  52%|█████▏    | 27108/52002 [00:05<00:05, 4575.09it/s]Packing dataset:  53%|█████▎    | 27575/52002 [00:05<00:05, 4603.16it/s]Packing dataset:  54%|█████▍    | 28036/52002 [00:06<00:05, 4537.96it/s]Packing dataset:  55%|█████▍    | 28491/52002 [00:06<00:05, 4514.50it/s]Packing dataset:  56%|█████▌    | 28951/52002 [00:06<00:05, 4538.44it/s]Packing dataset:  57%|█████▋    | 29421/52002 [00:06<00:04, 4585.18it/s]Packing dataset:  57%|█████▋    | 29880/52002 [00:06<00:04, 4550.61it/s]Packing dataset:  58%|█████▊    | 30343/52002 [00:06<00:04, 4572.28it/s]Packing dataset:  59%|█████▉    | 30801/52002 [00:06<00:04, 4513.56it/s]Packing dataset:  60%|██████    | 31259/52002 [00:06<00:04, 4529.10it/s]Packing dataset:  61%|██████    | 31725/52002 [00:06<00:04, 4566.44it/s]Packing dataset:  62%|██████▏   | 32204/52002 [00:06<00:04, 4632.25it/s]Packing dataset:  63%|██████▎   | 32668/52002 [00:07<00:04, 4630.69it/s]Packing dataset:  64%|██████▎   | 33132/52002 [00:07<00:04, 4619.66it/s]Packing dataset:  65%|██████▍   | 33601/52002 [00:07<00:03, 4637.45it/s]Packing dataset:  66%|██████▌   | 34065/52002 [00:07<00:03, 4588.96it/s]Packing dataset:  66%|██████▋   | 34525/52002 [00:07<00:03, 4581.28it/s]Packing dataset:  67%|██████▋   | 34984/52002 [00:07<00:03, 4574.82it/s]Packing dataset:  68%|██████▊   | 35450/52002 [00:07<00:03, 4599.34it/s]Packing dataset:  69%|██████▉   | 35910/52002 [00:07<00:03, 4571.10it/s]Packing dataset:  70%|██████▉   | 36368/52002 [00:07<00:03, 4502.11it/s]Packing dataset:  71%|███████   | 36836/52002 [00:07<00:03, 4554.52it/s]Packing dataset:  72%|███████▏  | 37321/52002 [00:08<00:03, 4641.31it/s]Packing dataset:  73%|███████▎  | 37786/52002 [00:08<00:03, 4614.76it/s]Packing dataset:  74%|███████▎  | 38252/52002 [00:08<00:02, 4627.02it/s]Packing dataset:  74%|███████▍  | 38717/52002 [00:08<00:02, 4632.27it/s]Packing dataset:  75%|███████▌  | 39181/52002 [00:08<00:02, 4594.30it/s]Packing dataset:  76%|███████▌  | 39645/52002 [00:08<00:02, 4606.48it/s]Packing dataset:  77%|███████▋  | 40106/52002 [00:08<00:02, 4591.45it/s]Packing dataset:  78%|███████▊  | 40566/52002 [00:08<00:02, 4586.18it/s]Packing dataset:  79%|███████▉  | 41041/52002 [00:08<00:02, 4634.18it/s]Packing dataset:  80%|███████▉  | 41505/52002 [00:09<00:02, 4629.75it/s]Packing dataset:  81%|████████  | 41969/52002 [00:09<00:02, 4577.33it/s]Packing dataset:  82%|████████▏ | 42427/52002 [00:09<00:02, 4547.98it/s]Packing dataset:  82%|████████▏ | 42882/52002 [00:09<00:02, 4533.57it/s]Packing dataset:  83%|████████▎ | 43336/52002 [00:09<00:01, 4515.48it/s]Packing dataset:  84%|████████▍ | 43797/52002 [00:09<00:01, 4543.42it/s]Packing dataset:  85%|████████▌ | 44252/52002 [00:09<00:01, 4533.76it/s]Packing dataset:  86%|████████▌ | 44719/52002 [00:09<00:01, 4573.43it/s]Packing dataset:  87%|████████▋ | 45186/52002 [00:09<00:01, 4599.69it/s]Packing dataset:  88%|████████▊ | 45659/52002 [00:09<00:01, 4637.79it/s]Packing dataset:  89%|████████▊ | 46123/52002 [00:10<00:01, 4547.66it/s]Packing dataset:  90%|████████▉ | 46585/52002 [00:10<00:01, 4564.46it/s]Packing dataset:  90%|█████████ | 47054/52002 [00:10<00:01, 4600.56it/s]Packing dataset:  91%|█████████▏| 47515/52002 [00:10<00:00, 4569.80it/s]Packing dataset:  92%|█████████▏| 47973/52002 [00:10<00:00, 4528.57it/s]Packing dataset:  93%|█████████▎| 48431/52002 [00:10<00:00, 4537.68it/s]Packing dataset:  94%|█████████▍| 48890/52002 [00:10<00:00, 4552.13it/s]Packing dataset:  95%|█████████▍| 49352/52002 [00:10<00:00, 4572.12it/s]Packing dataset:  96%|█████████▌| 49810/52002 [00:10<00:00, 4551.14it/s]Packing dataset:  97%|█████████▋| 50266/52002 [00:10<00:00, 4533.98it/s]Packing dataset:  98%|█████████▊| 50720/52002 [00:11<00:00, 4492.45it/s]Packing dataset:  98%|█████████▊| 51192/52002 [00:11<00:00, 4556.47it/s]Packing dataset:  99%|█████████▉| 51654/52002 [00:11<00:00, 4575.09it/s]Packing dataset: 100%|██████████| 52002/52002 [00:11<00:00, 4596.55it/s]
 Profiling disabled.
 Profiler config after instantiation: {'enabled': False}
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [01:11<10:41, 71.25s/it]1|1|Loss: 1.6737:  10%|█         | 1/10 [01:11<10:41, 71.25s/it]1|1|Loss: 1.6737:  20%|██        | 2/10 [01:31<05:28, 41.11s/it]1|2|Loss: 1.3814:  20%|██        | 2/10 [01:31<05:28, 41.11s/it]1|2|Loss: 1.3814:  30%|███       | 3/10 [01:51<03:40, 31.51s/it]1|3|Loss: 1.2937:  30%|███       | 3/10 [01:51<03:40, 31.51s/it]1|3|Loss: 1.2937:  40%|████      | 4/10 [02:11<02:41, 26.96s/it]1|4|Loss: 1.1817:  40%|████      | 4/10 [02:11<02:41, 26.96s/it]1|4|Loss: 1.1817:  50%|█████     | 5/10 [02:31<02:02, 24.47s/it]1|5|Loss: 0.9926:  50%|█████     | 5/10 [02:31<02:02, 24.47s/it]1|5|Loss: 0.9926:  60%|██████    | 6/10 [02:51<01:31, 22.97s/it]1|6|Loss: 1.0009:  60%|██████    | 6/10 [02:51<01:31, 22.97s/it]1|6|Loss: 1.0009:  70%|███████   | 7/10 [03:11<01:05, 21.97s/it]1|7|Loss: 0.9844:  70%|███████   | 7/10 [03:11<01:05, 21.97s/it]1|7|Loss: 0.9844:  80%|████████  | 8/10 [03:31<00:42, 21.34s/it]1|8|Loss: 1.1825:  80%|████████  | 8/10 [03:31<00:42, 21.34s/it]1|8|Loss: 1.1825:  90%|█████████ | 9/10 [03:51<00:20, 20.93s/it]1|9|Loss: 0.9460:  90%|█████████ | 9/10 [03:51<00:20, 20.93s/it]1|9|Loss: 0.9460: 100%|██████████| 10/10 [04:11<00:00, 20.63s/it]1|10|Loss: 0.7470: 100%|██████████| 10/10 [04:11<00:00, 20.63s/it]1|10|Loss: 0.7470: 100%|██████████| 10/10 [04:11<00:00, 25.13s/it]
iteration:  1 tokens:  900 time:  71.24764939001761 tokens_per_second_on_single_device:  12.63
iteration:  2 tokens:  845 time:  20.005779955070466 tokens_per_second_on_single_device:  42.24
iteration:  3 tokens:  916 time:  20.084109374089167 tokens_per_second_on_single_device:  45.61
iteration:  4 tokens:  867 time:  19.987780686933547 tokens_per_second_on_single_device:  43.38
iteration:  5 tokens:  831 time:  20.038229066180065 tokens_per_second_on_single_device:  41.47
iteration:  6 tokens:  859 time:  20.07852873392403 tokens_per_second_on_single_device:  42.78
iteration:  7 tokens:  917 time:  19.894773385953158 tokens_per_second_on_single_device:  46.09
iteration:  8 tokens:  835 time:  20.010019412031397 tokens_per_second_on_single_device:  41.73
iteration:  9 tokens:  848 time:  20.009292141068727 tokens_per_second_on_single_device:  42.38
iteration:  10 tokens:  892 time:  19.94943517493084 tokens_per_second_on_single_device:  44.71
avg tokens_per_second_on_single_device:  34.66
