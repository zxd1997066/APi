<?xml version="1.0" encoding="utf-8"?><testsuites name="pytest tests"><testsuite name="pytest" errors="0" failures="13" skipped="0" tests="42" time="522.651" timestamp="2025-09-11T15:44:33.792749+00:00" hostname="dut7358"><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_device_mesh_compile" time="0.064" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dtensor_attribute_access_on_intermediate" time="0.293" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dtensor_basic" time="0.295" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dtensor_basic_export" time="0.152" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dtensor_constructor_w_dynamo_disable" time="0.099" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dtensor_constructor_w_graph_break" time="0.080" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dtensor_contiguous_dtensor_noncontiguous_local_as_tangent" time="1.663"><failure message="RuntimeError: No backend type associated with device type xpu&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_contiguous_dtensor_noncontiguous_local_as_tangent&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0">Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3226, in wrapper
    method(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 659, in test_dtensor_contiguous_dtensor_noncontiguous_local_as_tangent
    out_dt = torch.compile(fn)(x_dt)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 639, in fn
    def fn(x):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 339, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 103, in g
    return f(*args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 2118, in forward
    fw_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 690, in inner_fn
    unwrapped_outs = compiled_fn(unwrapped_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2959, in run
    out = model(new_inputs)
  File "/tmp/torchinductor_jenkins/hv/chvqroszckel7x6fti6tsgecxxlwr2alx2ayqdjnzwxaaecbfhud.py", line 157, in call
    buf1 = torch.ops._c10d_functional.reduce_scatter_tensor.default(buf0, 'sum', 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_contiguous_dtensor_noncontiguous_local_as_tangent

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0</failure></testcase><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dtensor_different_gradient_placement" time="2.605"><failure message="RuntimeError: No backend type associated with device type xpu&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_different_gradient_placement&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0">Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3226, in wrapper
    method(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 726, in test_dtensor_different_gradient_placement
    tmp_dt = opt_fn(x_dt, y_dt, z_dt)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
    return fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 709, in fn
    def fn(x, y, z):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
    return compiled_fn(full_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 339, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 103, in g
    return f(*args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 2118, in forward
    fw_outs = call_func_at_runtime_with_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
    return compiled_fn(runtime_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 690, in inner_fn
    unwrapped_outs = compiled_fn(unwrapped_args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
    outs = compiled_fn(args)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 613, in __call__
    return self.current_callable(inputs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2959, in run
    out = model(new_inputs)
  File "/tmp/torchinductor_jenkins/we/cwemathwgktrqwk6fs63nnetbssd3t6clasfyxwgsqqlw5jgrqo2.py", line 276, in call
    buf1 = torch.ops._c10d_functional.all_gather_into_tensor.default(buf0, 2, '0')
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_different_gradient_placement

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0</failure></testcase><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dtensor_dont_recompile_on_same_placement_devicemesh" time="0.127" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dtensor_dynamic" time="0.003"><failure message="RuntimeError: No backend type associated with device type xpu&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_dynamic&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0">Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3226, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 2012, in wrapper
    fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 312, in test_dtensor_dynamic
    ref = fn(x)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 303, in fn
    torch.mul(x, x)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 555, in redistribute
    return Redistribute.apply(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 319, in forward
    output = redistribute_local_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 211, in redistribute_local_tensor
    new_local_tensor = current_placement._to_replicate_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 253, in _to_replicate_tensor
    result = funcol.all_gather_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 203, in all_gather_tensor
    tensor = torch.ops._c10d_functional.all_gather_into_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_dynamic

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0</failure></testcase><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dtensor_dynamic_cat" time="0.003"><failure message="RuntimeError: No backend type associated with device type xpu&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_dynamic_cat&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0">Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3226, in wrapper
    method(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 378, in test_dtensor_dynamic_cat
    ref = fn(x, y)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 366, in fn
    torch.cat((x, y), dim=0)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 349, in __torch_dispatch__
    return DTensor._op_dispatcher.dispatch(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_dispatch.py", line 185, in dispatch
    self.redistribute_local_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_dispatch.py", line 353, in redistribute_local_args
    resharded_local_tensor = redistribute_local_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 211, in redistribute_local_tensor
    new_local_tensor = current_placement._to_replicate_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 253, in _to_replicate_tensor
    result = funcol.all_gather_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 203, in all_gather_tensor
    tensor = torch.ops._c10d_functional.all_gather_into_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_dynamic_cat

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0</failure></testcase><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dtensor_dynamic_loss_parallel_log_softmax" time="0.104"><failure message="RuntimeError: No backend type associated with device type xpu&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_dynamic_loss_parallel_log_softmax&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0">Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3226, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 2012, in wrapper
    fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 352, in test_dtensor_dynamic_loss_parallel_log_softmax
    ref = fn(x)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 345, in fn
    t = torch.nn.functional.log_softmax(x, x.ndim - 1, dtype=torch.float32)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/functional.py", line 2243, in log_softmax
    ret = input.log_softmax(dim, dtype=dtype)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 349, in __torch_dispatch__
    return DTensor._op_dispatcher.dispatch(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_dispatch.py", line 149, in dispatch
    return self._custom_op_handlers[op_call](op_call, args, kwargs)  # type: ignore[operator]
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/loss.py", line 169, in _log_softmax_handler
    res = _log_softmax(x._local_tensor, dim, half_to_float, spec.mesh, mesh_dim)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/loss.py", line 139, in _log_softmax
    x_max = funcol.all_reduce(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 174, in all_reduce
    tensor = torch.ops._c10d_functional.all_reduce(self, reduceOp.lower(), group_name)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_dynamic_loss_parallel_log_softmax

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0</failure></testcase><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dtensor_dynamic_slice" time="0.003"><failure message="RuntimeError: No backend type associated with device type xpu&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_dynamic_slice&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0">Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3226, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 2012, in wrapper
    fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 334, in test_dtensor_dynamic_slice
    ref = fn(x)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 328, in fn
    for t in torch.tensor_split(x, 2)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 349, in __torch_dispatch__
    return DTensor._op_dispatcher.dispatch(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_dispatch.py", line 185, in dispatch
    self.redistribute_local_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_dispatch.py", line 353, in redistribute_local_args
    resharded_local_tensor = redistribute_local_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 211, in redistribute_local_tensor
    new_local_tensor = current_placement._to_replicate_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 253, in _to_replicate_tensor
    result = funcol.all_gather_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 203, in all_gather_tensor
    tensor = torch.ops._c10d_functional.all_gather_into_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_dynamic_slice

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0</failure></testcase><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dtensor_dynamo_device_mesh_attrs" time="0.083" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dtensor_noncontiguous_output" time="0.361" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dtensor_partial_placement_graph_output" time="0.294"><failure message="RuntimeError: No backend type associated with device type xpu&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_partial_placement_graph_output&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0">Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3226, in wrapper
    method(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 911, in test_dtensor_partial_placement_graph_output
    out_dt = torch.matmul(tmp_dt, y_dt)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 349, in __torch_dispatch__
    return DTensor._op_dispatcher.dispatch(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_dispatch.py", line 185, in dispatch
    self.redistribute_local_args(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_dispatch.py", line 353, in redistribute_local_args
    resharded_local_tensor = redistribute_local_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 223, in redistribute_local_tensor
    new_local_tensor = partial_spec._reduce_shard_value(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 695, in _reduce_shard_value
    return shard_spec._reduce_shard_tensor(tensor, mesh, self.reduce_op, mesh_dim)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 221, in _reduce_shard_tensor
    output = funcol.reduce_scatter_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 282, in reduce_scatter_tensor
    tensor = torch.ops._c10d_functional.reduce_scatter_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_partial_placement_graph_output

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0</failure></testcase><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dtensor_partial_placement_redistribute_unbalanced_correct_strides" time="0.013"><failure message="RuntimeError: No backend type associated with device type xpu&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_partial_placement_redistribute_unbalanced_correct_strides&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0">Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3226, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 2012, in wrapper
    fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 619, in test_dtensor_partial_placement_redistribute_unbalanced_correct_strides
    tmp_dt = fn(x_dt)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 599, in fn
    out = x.redistribute(mesh, [placement])
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 555, in redistribute
    return Redistribute.apply(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 319, in forward
    output = redistribute_local_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 223, in redistribute_local_tensor
    new_local_tensor = partial_spec._reduce_shard_value(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 695, in _reduce_shard_value
    return shard_spec._reduce_shard_tensor(tensor, mesh, self.reduce_op, mesh_dim)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 221, in _reduce_shard_tensor
    output = funcol.reduce_scatter_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 282, in reduce_scatter_tensor
    tensor = torch.ops._c10d_functional.reduce_scatter_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dtensor_partial_placement_redistribute_unbalanced_correct_strides

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0</failure></testcase><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dynamo_dtensor" time="0.102" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dynamo_dtensor_from_local" time="0.131" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dynamo_dtensor_from_local_dynamic_shapes" time="1.388" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dynamo_dtensor_from_local_redistribute" time="0.002"><failure message="RuntimeError: No backend type associated with device type xpu&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dynamo_dtensor_from_local_redistribute&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0">Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3226, in wrapper
    method(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 740, in test_dynamo_dtensor_from_local_redistribute
    ref = fn(x)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 737, in fn
    return dt.redistribute(mesh, [Replicate()]).to_local() + 2
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 555, in redistribute
    return Redistribute.apply(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 319, in forward
    output = redistribute_local_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 211, in redistribute_local_tensor
    new_local_tensor = current_placement._to_replicate_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 253, in _to_replicate_tensor
    result = funcol.all_gather_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 203, in all_gather_tensor
    tensor = torch.ops._c10d_functional.all_gather_into_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dynamo_dtensor_from_local_redistribute

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0</failure></testcase><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dynamo_dtensor_from_local_redistribute_async" time="0.001"><failure message="RuntimeError: No backend type associated with device type xpu&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dynamo_dtensor_from_local_redistribute_async&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0">Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3226, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 2012, in wrapper
    fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 777, in test_dynamo_dtensor_from_local_redistribute_async
    ref = fn(x)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 770, in fn
    out = dt.redistribute(mesh, [Replicate()], async_op=True).to_local()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 555, in redistribute
    return Redistribute.apply(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 319, in forward
    output = redistribute_local_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 211, in redistribute_local_tensor
    new_local_tensor = current_placement._to_replicate_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 253, in _to_replicate_tensor
    result = funcol.all_gather_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 203, in all_gather_tensor
    tensor = torch.ops._c10d_functional.all_gather_into_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_dynamo_dtensor_from_local_redistribute_async

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0</failure></testcase><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dynamo_dtensor_recompile" time="0.123" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dynamo_to_local_kwargs" time="0.075" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_dynamo_to_local_kwargs_forward_hook" time="0.178" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_fakify_dtensor" time="0.069" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_graph_input_is_async" time="0.033"><failure message="RuntimeError: No backend type associated with device type xpu&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_graph_input_is_async&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0">Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3226, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 2012, in wrapper
    fn(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 846, in test_graph_input_is_async
    x2 = x_dt.redistribute(mesh, [Replicate()], async_op=True)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 555, in redistribute
    return Redistribute.apply(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 319, in forward
    output = redistribute_local_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py", line 211, in redistribute_local_tensor
    new_local_tensor = current_placement._to_replicate_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 253, in _to_replicate_tensor
    result = funcol.all_gather_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/_functional_collectives.py", line 203, in all_gather_tensor
    tensor = torch.ops._c10d_functional.all_gather_into_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/_ops.py", line 1255, in __call__
    return self._op(*args, **kwargs)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_graph_input_is_async

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0</failure></testcase><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_placement_compile" time="0.149" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_tp_compile_comm_reordering" time="0.002"><failure message="RuntimeError: No backend type associated with device type xpu&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_tp_compile_comm_reordering&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0">Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3226, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/mock.py", line 1379, in patched
    return func(*newargs, **newkeywargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 988, in test_tp_compile_comm_reordering
    self._test_tp_compile_comm_reordering()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 962, in _test_tp_compile_comm_reordering
    parallelize_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/api.py", line 122, in parallelize_module
    parallelize_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/api.py", line 130, in parallelize_module
    parallelize_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/api.py", line 86, in parallelize_module
    return parallelize_plan._apply(module, device_mesh)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/style.py", line 158, in _apply
    return distribute_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 931, in distribute_module
    partition_fn(name, submod, device_mesh)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/style.py", line 124, in _partition_linear_fn
    distribute_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 765, in distribute_tensor
    local_tensor = placement._shard_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 183, in _shard_tensor
    mesh_scatter(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_collective_utils.py", line 110, in mesh_scatter
    fut = scatter(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4361, in scatter
    work = group.scatter(output_tensors, input_tensors, opts)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_tp_compile_comm_reordering

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0</failure></testcase><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_tp_compile_comm_reordering_graph_partition" time="0.002"><failure message="RuntimeError: No backend type associated with device type xpu&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_tp_compile_comm_reordering_graph_partition&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0">Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3226, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/mock.py", line 1379, in patched
    return func(*newargs, **newkeywargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 997, in test_tp_compile_comm_reordering_graph_partition
    self._test_tp_compile_comm_reordering()
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_dtensor_compile.py", line 962, in _test_tp_compile_comm_reordering
    parallelize_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/api.py", line 122, in parallelize_module
    parallelize_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/api.py", line 130, in parallelize_module
    parallelize_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/api.py", line 86, in parallelize_module
    return parallelize_plan._apply(module, device_mesh)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/style.py", line 158, in _apply
    return distribute_module(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 931, in distribute_module
    partition_fn(name, submod, device_mesh)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/parallel/style.py", line 124, in _partition_linear_fn
    distribute_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_api.py", line 765, in distribute_tensor
    local_tensor = placement._shard_tensor(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/placement_types.py", line 183, in _shard_tensor
    mesh_scatter(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/tensor/_collective_utils.py", line 110, in mesh_scatter
    fut = scatter(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
    return func(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4361, in scatter
    work = group.scatter(output_tensors, input_tensors, opts)
RuntimeError: No backend type associated with device type xpu

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/tensor/test_dtensor_compile.py TestDTensorCompile.test_tp_compile_comm_reordering_graph_partition

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0</failure></testcase><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompile" name="test_unwrap_async_collective_tensor_tangent" time="0.587" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompileE2E" name="test_2d_fsdp_tp_ac_compile_use_ca_False" time="46.783" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompileE2E" name="test_2d_fsdp_tp_ac_compile_use_ca_True" time="54.374" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompileE2E" name="test_2d_fsdp_tp_compile_use_ca_False" time="46.782" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompileE2E" name="test_2d_fsdp_tp_compile_use_ca_True" time="50.173" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompileE2E" name="test_compile_dtensor_redistribute_backward_use_ca_False" time="45.466" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompileE2E" name="test_compile_dtensor_redistribute_backward_use_ca_True" time="48.185" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompileE2E" name="test_compile_embedding_redistribute" time="49.887" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompileE2E" name="test_tp_compile_fullgraph_is_seq_parallel_False_use_ca_False" time="30.253" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompileE2E" name="test_tp_compile_fullgraph_is_seq_parallel_False_use_ca_True" time="33.657" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompileE2E" name="test_tp_compile_fullgraph_is_seq_parallel_True_use_ca_False" time="45.679" /><testcase classname="test.distributed.tensor.test_dtensor_compile.TestDTensorCompileE2E" name="test_tp_compile_fullgraph_is_seq_parallel_True_use_ca_True" time="51.269" /></testsuite></testsuites>