<?xml version="1.0" encoding="utf-8"?><testsuites name="pytest tests"><testsuite name="pytest" errors="0" failures="0" skipped="6" tests="9" time="106.362" timestamp="2025-09-11T16:47:37.811123+00:00" hostname="dut7358"><testcase classname="test.distributed._composable.fsdp.test_fully_shard_mixed_precision.TestFullyShardMixedPrecisionTraining" name="test_compute_dtype" time="35.978" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_mixed_precision.TestFullyShardMixedPrecisionTraining" name="test_grad_acc_with_reduce_dtype" time="32.758" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_mixed_precision.TestFullyShardMixedPrecisionTraining" name="test_reduce_dtype" time="35.644" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_mixed_precision.TestFullyShardMixedPrecisionCasts" name="test_clamp_reduce_dtype" time="0.001"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py:562: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_mixed_precision.TestFullyShardMixedPrecisionCasts" name="test_dataclass_input" time="0.000"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py:595: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_mixed_precision.TestFullyShardMixedPrecisionCasts" name="test_float16_on_one_submodule" time="0.000"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py:393: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_mixed_precision.TestFullyShardMixedPrecisionCasts" name="test_norm_modules_bf16" time="0.000"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py:501: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_mixed_precision.TestFullyShardMixedPrecisionCasts" name="test_norm_modules_fp16" time="0.000"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py:507: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_mixed_precision.TestFullyShardMixedPrecisionCasts" name="test_submodules_with_external_inputs" time="0.000"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py:447: not-support-multithread</skipped></testcase></testsuite></testsuites>