<?xml version="1.0" encoding="utf-8"?><testsuites name="pytest tests"><testsuite name="pytest" errors="0" failures="0" skipped="62" tests="62" time="11.345" timestamp="2025-09-11T15:19:35.045962+00:00" hostname="dut7358"><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_all_to_all_recompute_is_always_banned_override_with_ac_False" time="0.001"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:593: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_all_to_all_recompute_is_always_banned_override_with_ac_True" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:593: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_all_to_all_single_inductor" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:517: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_all_to_all_single_inductor_split_sizes_none" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:778: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_allgather_contiguous_input" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:435: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_allgather_into_tensor_inductor" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:459: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_allgather_output_buffer_reuse" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:396: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_allgather_scalar_tensor_input" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:420: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_allreduce_inductor" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:113: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_allreduce_inductor_cudagraph_trees" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:146: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_allreduce_input_buffer_reuse" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:352: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_broadcast_inductor" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:81: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_c10d_functional_tagged_pt2_compliant" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:188: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_eager_allreduce_inductor_wait" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:194: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_eager_async_allreduce_inductor_wait" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:268: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_inductor_allreduce_eager_wait" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:233: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_permute_tensor" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:370: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_reduce_scatter_tensor_inductor" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:490: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_all_gather_bucket_bucket_mode_all" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1531: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_all_gather_bucket_bucket_mode_all_custom_ops" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1531: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_all_gather_bucket_path" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1609: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_backwards" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1330: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_get_world_group_source_GroupMember_WORLD" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1201: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_get_world_group_source__get_default_group" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1201: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_get_world_group_source_group_WORLD" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1201: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_graphbreaks_unsupported_async_op" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1260: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_pg_var" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1282: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_all_gather" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:997: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_all_gather_args_match" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1044: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_all_gather_list" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1022: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_all_to_all_single" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1145: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_pg_mode_kwargs" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1097: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_pg_mode_kwargs_none" time="0.001"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1097: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_pg_mode_positional" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1097: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_pg_mode_positional_none" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1097: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_pg_mode_unspecified" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1097: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_reduce_op_reduce_op0" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1163: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_reduce_op_reduce_op1" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1163: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_reduce_op_reduce_op2" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1163: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_reduce_op_reduce_op3" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1163: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_reduce_op_reduce_op4" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1163: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_reduce_scatter" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1072: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_support_collective_op_with_async_op_False" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1239: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_trace_all_gather_tensor" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:965: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_trace_all_gather_tensor_pg" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:981: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_trace_allgather_coalesced" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1314: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_trace_allreduce" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:949: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_trace_reduce_scatter_tensor" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1298: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_inductor_all_gather_coalesced" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1359: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_inductor_doesnt_mutate_shared" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:936: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_inductor_doesnt_mutate_shared_graph_partition" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:941: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_inductor_reduce_scatter_coalesced" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1405: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_inductor_single_op" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:835: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_inductor_steal_buffer" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:864: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_meta" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1354: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_reduce_scatter_bucket_bucket_mode_all" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1662: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_reduce_scatter_bucket_bucket_mode_all_custom_ops" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1662: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_reorder_peak_memory" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1451: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_reorder_peak_memory_bucketed_bucket_mode_all" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1730: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_reorder_peak_memory_bucketed_bucket_mode_all_custom_ops" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1730: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_reorder_respects_wait_dep" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1919: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestSyncDecisionCrossRanks" name="test_sync_decision_cross_ranks" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:2024: c10d was not compiled with the NCCL backend</skipped></testcase></testsuite></testsuites>