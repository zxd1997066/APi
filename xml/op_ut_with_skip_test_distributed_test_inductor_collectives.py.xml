<?xml version="1.0" encoding="utf-8"?><testsuites name="pytest tests"><testsuite name="pytest" errors="0" failures="0" skipped="62" tests="62" time="11.305" timestamp="2025-09-12T14:40:38.653270+00:00" hostname="dut7358"><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_all_to_all_recompute_is_always_banned_override_with_ac_False" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:596: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_all_to_all_recompute_is_always_banned_override_with_ac_True" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:596: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_all_to_all_single_inductor" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:520: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_all_to_all_single_inductor_split_sizes_none" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:781: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_allgather_contiguous_input" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:438: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_allgather_into_tensor_inductor" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:462: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_allgather_output_buffer_reuse" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:399: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_allgather_scalar_tensor_input" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:423: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_allreduce_inductor" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:115: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_allreduce_inductor_cudagraph_trees" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:148: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_allreduce_input_buffer_reuse" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:355: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_broadcast_inductor" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:83: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_c10d_functional_tagged_pt2_compliant" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:190: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_eager_allreduce_inductor_wait" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:196: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_eager_async_allreduce_inductor_wait" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:270: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_inductor_allreduce_eager_wait" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:235: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_permute_tensor" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:373: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesMultiProc" name="test_reduce_scatter_tensor_inductor" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:493: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_all_gather_bucket_bucket_mode_all" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1534: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_all_gather_bucket_bucket_mode_all_custom_ops" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1534: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_all_gather_bucket_path" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1612: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_backwards" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1333: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_get_world_group_source_GroupMember_WORLD" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1204: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_get_world_group_source__get_default_group" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1204: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_get_world_group_source_group_WORLD" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1204: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_graphbreaks_unsupported_async_op" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1263: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_pg_var" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1285: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_all_gather" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1000: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_all_gather_args_match" time="0.001"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1047: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_all_gather_list" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1025: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_all_to_all_single" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1148: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_pg_mode_kwargs" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1100: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_pg_mode_kwargs_none" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1100: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_pg_mode_positional" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1100: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_pg_mode_positional_none" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1100: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_pg_mode_unspecified" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1100: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_reduce_op_reduce_op0" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1166: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_reduce_op_reduce_op1" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1166: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_reduce_op_reduce_op2" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1166: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_reduce_op_reduce_op3" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1166: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_allreduce_reduce_op_reduce_op4" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1166: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_rewrite_dist_reduce_scatter" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1075: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_support_collective_op_with_async_op_False" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1242: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_trace_all_gather_tensor" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:968: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_trace_all_gather_tensor_pg" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:984: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_trace_allgather_coalesced" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1317: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_trace_allreduce" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:952: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_dynamo_trace_reduce_scatter_tensor" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1301: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_inductor_all_gather_coalesced" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1362: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_inductor_doesnt_mutate_shared" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:939: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_inductor_doesnt_mutate_shared_graph_partition" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:944: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_inductor_reduce_scatter_coalesced" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1408: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_inductor_single_op" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:838: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_inductor_steal_buffer" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:867: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_meta" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1357: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_reduce_scatter_bucket_bucket_mode_all" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1665: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_reduce_scatter_bucket_bucket_mode_all_custom_ops" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1665: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_reorder_peak_memory" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1454: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_reorder_peak_memory_bucketed_bucket_mode_all" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1733: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_reorder_peak_memory_bucketed_bucket_mode_all_custom_ops" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1733: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestCollectivesInductor" name="test_reorder_respects_wait_dep" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:1922: c10d was not compiled with the NCCL backend</skipped></testcase><testcase classname="test.distributed.test_inductor_collectives.TestSyncDecisionCrossRanks" name="test_sync_decision_cross_ranks" time="0.000"><skipped type="pytest.skip" message="c10d was not compiled with the NCCL backend">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/test_inductor_collectives.py:2027: c10d was not compiled with the NCCL backend</skipped></testcase></testsuite></testsuites>