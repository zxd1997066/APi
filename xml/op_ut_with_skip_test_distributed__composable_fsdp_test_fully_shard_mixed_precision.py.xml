<?xml version="1.0" encoding="utf-8"?><testsuites name="pytest tests"><testsuite name="pytest" errors="0" failures="0" skipped="6" tests="9" time="105.972" timestamp="2025-09-19T14:32:33.010266+00:00" hostname="dut7358"><testcase classname="test.distributed._composable.fsdp.test_fully_shard_mixed_precision.TestFullyShardMixedPrecisionTraining" name="test_compute_dtype" time="36.041" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_mixed_precision.TestFullyShardMixedPrecisionTraining" name="test_grad_acc_with_reduce_dtype" time="32.258" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_mixed_precision.TestFullyShardMixedPrecisionTraining" name="test_reduce_dtype" time="35.761" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_mixed_precision.TestFullyShardMixedPrecisionCasts" name="test_clamp_reduce_dtype" time="0.000"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py:568: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_mixed_precision.TestFullyShardMixedPrecisionCasts" name="test_dataclass_input" time="0.000"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py:601: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_mixed_precision.TestFullyShardMixedPrecisionCasts" name="test_float16_on_one_submodule" time="0.000"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py:399: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_mixed_precision.TestFullyShardMixedPrecisionCasts" name="test_norm_modules_bf16" time="0.000"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py:507: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_mixed_precision.TestFullyShardMixedPrecisionCasts" name="test_norm_modules_fp16" time="0.000"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py:513: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_mixed_precision.TestFullyShardMixedPrecisionCasts" name="test_submodules_with_external_inputs" time="0.000"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_mixed_precision.py:453: not-support-multithread</skipped></testcase></testsuite></testsuites>