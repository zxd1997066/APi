<?xml version="1.0" encoding="utf-8"?><testsuites name="pytest tests"><testsuite name="pytest" errors="0" failures="1" skipped="1" tests="7" time="100.588" timestamp="2025-09-19T14:34:22.834507+00:00" hostname="dut7358"><testcase classname="test.distributed._composable.fsdp.test_fully_shard_state_dict.TestFullyShardStateDictMultiProcess" name="test_2d_state_dict_correctness" time="16.640" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_state_dict.TestFullyShardStateDictMultiProcess" name="test_cached_state_dict" time="15.429"><failure message="RuntimeError: Process 3 exited with error code 10 and exception:&#10;Traceback (most recent call last):&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 901, in run_test&#10;    getattr(self, test_name)()&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 755, in wrapper&#10;    fn()&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py&quot;, line 3225, in wrapper&#10;    method(*args, **kwargs)&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 222, in wrapper&#10;    return func(*args, **kwargs)&#10;  File &quot;/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_state_dict.py&quot;, line 123, in test_cached_state_dict&#10;    self.run_subtests(&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py&quot;, line 1188, in run_subtests&#10;    return run_subtests(self, *args, **kwargs)&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 1184, in run_subtests&#10;    test_fn(*test_args, **test_kwargs, **subtest_kwargs)&#10;  File &quot;/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_state_dict.py&quot;, line 145, in _test_cached_state_dict&#10;    model = model.cuda()&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;, line 1084, in cuda&#10;    return self._apply(lambda t: t.cuda(device))&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/fsdp/_fully_shard/_fully_shard.py&quot;, line 631, in _apply&#10;    ret = super()._apply(*args, **kwargs)  # type: ignore[misc]&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;, line 957, in _apply&#10;    param_applied = fn(param)&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;, line 1084, in &lt;lambda&gt;&#10;    return self._apply(lambda t: t.cuda(device))&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py&quot;, line 403, in _lazy_init&#10;    raise AssertionError(&quot;Torch not compiled with CUDA enabled&quot;)&#10;AssertionError: Torch not compiled with CUDA enabled&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_state_dict.py TestFullyShardStateDictMultiProcess.test_cached_state_dict&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0">Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 753, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1017, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1057, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 901, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 755, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 222, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_state_dict.py", line 123, in test_cached_state_dict
    self.run_subtests(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_fsdp.py", line 1188, in run_subtests
    return run_subtests(self, *args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1184, in run_subtests
    test_fn(*test_args, **test_kwargs, **subtest_kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_state_dict.py", line 145, in _test_cached_state_dict
    model = model.cuda()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1084, in cuda
    return self._apply(lambda t: t.cuda(device))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/distributed/fsdp/_fully_shard/_fully_shard.py", line 631, in _apply
    ret = super()._apply(*args, **kwargs)  # type: ignore[misc]
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/modules/module.py", line 957, in _apply
    param_applied = fn(param)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1084, in &lt;lambda&gt;
    return self._apply(lambda t: t.cuda(device))
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_state_dict.py TestFullyShardStateDictMultiProcess.test_cached_state_dict

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0</failure></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_state_dict.TestFullyShardStateDictMultiProcess" name="test_dp_state_dict_cpu_offload" time="15.829" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_state_dict.TestFullyShardStateDictMultiProcess" name="test_dp_state_dict_save_load" time="17.936" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_state_dict.TestFullyShardStateDictMultiProcess" name="test_dp_tp_state_dict_save_load" time="16.430" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_state_dict.TestFullyShardStateDictMultiProcess" name="test_hsdp_tp_state_dict_save_load" time="16.330" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_state_dict.TestFullyShardStateDictMultiThread" name="test_rank0_offload_full_state_dict" time="0.000"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_state_dict.py:403: not-support-multithread</skipped></testcase></testsuite></testsuites>