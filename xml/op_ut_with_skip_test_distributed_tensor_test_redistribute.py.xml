<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="0" failures="0" skipped="2" tests="21" time="342.914" timestamp="2025-09-05T16:25:06.171389" hostname="dut7358"><testcase classname="test.distributed.tensor.test_redistribute.RedistributeTest" name="test_partial_to_replicate_forward_backward_complex64" time="16.008" /><testcase classname="test.distributed.tensor.test_redistribute.RedistributeTest" name="test_partial_to_replicate_forward_backward_float32" time="15.729" /><testcase classname="test.distributed.tensor.test_redistribute.RedistributeTest" name="test_partial_to_shard_complex64" time="31.139" /><testcase classname="test.distributed.tensor.test_redistribute.RedistributeTest" name="test_partial_to_shard_float32" time="31.055" /><testcase classname="test.distributed.tensor.test_redistribute.RedistributeTest" name="test_redistribute_negative_shard_dim" time="15.630" /><testcase classname="test.distributed.tensor.test_redistribute.RedistributeTest" name="test_redistribute_shard_dim_change_complex64" time="16.932" /><testcase classname="test.distributed.tensor.test_redistribute.RedistributeTest" name="test_redistribute_shard_dim_change_float32" time="16.832" /><testcase classname="test.distributed.tensor.test_redistribute.RedistributeTest" name="test_redistribute_uneven_sharding" time="16.631" /><testcase classname="test.distributed.tensor.test_redistribute.RedistributeTest" name="test_replicate_to_local_partial_grad_complex64" time="15.529" /><testcase classname="test.distributed.tensor.test_redistribute.RedistributeTest" name="test_replicate_to_local_partial_grad_float32" time="15.530" /><testcase classname="test.distributed.tensor.test_redistribute.RedistributeTest" name="test_replicate_to_partial" time="16.531" /><testcase classname="test.distributed.tensor.test_redistribute.RedistributeTest" name="test_replicate_to_replicate_forward_backward" time="15.831" /><testcase classname="test.distributed.tensor.test_redistribute.RedistributeTest" name="test_replicate_to_replicate_forward_backward_datatype_conversion" time="15.730" /><testcase classname="test.distributed.tensor.test_redistribute.RedistributeTest" name="test_replicate_to_shard_forward_backward" time="15.931" /><testcase classname="test.distributed.tensor.test_redistribute.RedistributeTest" name="test_shard_dim_alltoall_complex64" time="15.930" /><testcase classname="test.distributed.tensor.test_redistribute.RedistributeTest" name="test_shard_dim_alltoall_float32" time="16.031" /><testcase classname="test.distributed.tensor.test_redistribute.RedistributeTest" name="test_shard_to_replicate_forward_backward_complex64" time="16.031" /><testcase classname="test.distributed.tensor.test_redistribute.RedistributeTest" name="test_shard_to_replicate_forward_backward_datatype_conversion" time="16.131" /><testcase classname="test.distributed.tensor.test_redistribute.RedistributeTest" name="test_shard_to_replicate_forward_backward_float32" time="16.031" /><testcase classname="test.distributed.tensor.test_redistribute.MultiDimRedistributeTest" name="test_multi_dim_mesh" time="2.909"><skipped type="pytest.skip" message="Need at least 8 CUDA devices">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_redistribute.py:612: Need at least 8 CUDA devices</skipped></testcase><testcase classname="test.distributed.tensor.test_redistribute.MultiDimRedistributeTest" name="test_redistribute_shard_dim_multi_dim_mesh" time="2.908"><skipped type="pytest.skip" message="Need at least 8 CUDA devices">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/tensor/test_redistribute.py:662: Need at least 8 CUDA devices</skipped></testcase></testsuite></testsuites>