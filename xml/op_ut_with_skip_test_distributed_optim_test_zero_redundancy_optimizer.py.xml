<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="0" failures="1" skipped="0" tests="42" time="928.853" timestamp="2025-09-05T18:40:50.079642" hostname="dut7358"><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerSingleRank" name="test_constructor" time="2.987" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerSingleRank" name="test_lr_scheduler" time="3.307" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerSingleRank" name="test_same_dense_param_type" time="2.806" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerSingleRank" name="test_state_dict" time="3.408" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerSingleRank" name="test_step_with_extra_inner_key" time="3.407" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerSingleRank" name="test_step_with_kwargs" time="3.407" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerSingleRank" name="test_step_without_closure" time="3.407" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerSingleRank" name="test_zero_grad" time="2.706" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_add_param_group" time="3.109" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_collect_shards" time="4.511" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_False_gradient_as_bucket_view_False_static_graph_False_shard_buckets_False" time="40.880" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_False_gradient_as_bucket_view_False_static_graph_False_shard_buckets_True" time="40.769" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_False_gradient_as_bucket_view_False_static_graph_True_shard_buckets_False" time="41.172" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_False_gradient_as_bucket_view_False_static_graph_True_shard_buckets_True" time="41.177" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_False_gradient_as_bucket_view_True_static_graph_False_shard_buckets_False" time="41.174" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_False_gradient_as_bucket_view_True_static_graph_False_shard_buckets_True" time="40.672" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_False_gradient_as_bucket_view_True_static_graph_True_shard_buckets_False" time="41.178" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_False_gradient_as_bucket_view_True_static_graph_True_shard_buckets_True" time="41.282" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_True_gradient_as_bucket_view_False_static_graph_False_shard_buckets_False" time="40.775" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_True_gradient_as_bucket_view_False_static_graph_False_shard_buckets_True" time="41.462" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_True_gradient_as_bucket_view_False_static_graph_True_shard_buckets_False" time="41.585" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_True_gradient_as_bucket_view_False_static_graph_True_shard_buckets_True" time="41.672" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_True_gradient_as_bucket_view_True_static_graph_False_shard_buckets_False" time="40.974" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_True_gradient_as_bucket_view_True_static_graph_False_shard_buckets_True" time="40.971" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_True_gradient_as_bucket_view_True_static_graph_True_shard_buckets_False" time="40.677" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_ddp_zero_overlap_use_gpu_True_use_interleaved_hook_True_gradient_as_bucket_view_True_static_graph_True_shard_buckets_True" time="41.070" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_local_optimizer_parity_optimizer_class_str_AdamW_maximize_False" time="17.034" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_local_optimizer_parity_optimizer_class_str_AdamW_maximize_True" time="16.832" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_local_optimizer_parity_optimizer_class_str_Adam_maximize_False" time="17.033" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_local_optimizer_parity_optimizer_class_str_Adam_maximize_True" time="17.033" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_local_optimizer_parity_optimizer_class_str_SGD_maximize_False" time="16.932" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_local_optimizer_parity_optimizer_class_str_SGD_maximize_True" time="16.733" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_lr_scheduler" time="4.212" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_multiple_param_groups" time="4.712" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_nondefault_process_group" time="15.629" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_sharding" time="3.009" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_step" time="16.031" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_step_with_closure" time="15.930" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_zero_join_cpu" time="3.210" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_zero_join_gpu" time="16.833"><failure message="RuntimeError: Process 1 exited with error code 10 and exception:&#10;Traceback (most recent call last):&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 856, in run_test&#10;    getattr(self, test_name)()&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 710, in wrapper&#10;    fn()&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py&quot;, line 3226, in wrapper&#10;    method(*args, **kwargs)&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 139, in wrapper&#10;    return func(*args, **kwargs)&#10;  File &quot;/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py&quot;, line 1083, in test_zero_join_gpu&#10;    self._test_zero_join(self.device)&#10;  File &quot;/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py&quot;, line 1070, in _test_zero_join&#10;    torch.testing.assert_close(&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py&quot;, line 1589, in assert_close&#10;    raise error_metas[0].to_error(msg)&#10;AssertionError: Parameters differ between using ZeRO and local optimizer&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/optim/test_zero_redundancy_optimizer.py TestZeroRedundancyOptimizerDistributed.test_zero_join_gpu&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0&#10;&#10;Process 2 exited with error code 10 and exception:&#10;Traceback (most recent call last):&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 856, in run_test&#10;    getattr(self, test_name)()&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 710, in wrapper&#10;    fn()&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py&quot;, line 3226, in wrapper&#10;    method(*args, **kwargs)&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 139, in wrapper&#10;    return func(*args, **kwargs)&#10;  File &quot;/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py&quot;, line 1083, in test_zero_join_gpu&#10;    self._test_zero_join(self.device)&#10;  File &quot;/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py&quot;, line 1070, in _test_zero_join&#10;    torch.testing.assert_close(&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py&quot;, line 1589, in assert_close&#10;    raise error_metas[0].to_error(msg)&#10;AssertionError: Parameters differ between using ZeRO and local optimizer&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/optim/test_zero_redundancy_optimizer.py TestZeroRedundancyOptimizerDistributed.test_zero_join_gpu&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0&#10;&#10;Process 3 exited with error code 10 and exception:&#10;Traceback (most recent call last):&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 856, in run_test&#10;    getattr(self, test_name)()&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 710, in wrapper&#10;    fn()&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py&quot;, line 3226, in wrapper&#10;    method(*args, **kwargs)&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 139, in wrapper&#10;    return func(*args, **kwargs)&#10;  File &quot;/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py&quot;, line 1083, in test_zero_join_gpu&#10;    self._test_zero_join(self.device)&#10;  File &quot;/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py&quot;, line 1070, in _test_zero_join&#10;    torch.testing.assert_close(&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py&quot;, line 1589, in assert_close&#10;    raise error_metas[0].to_error(msg)&#10;AssertionError: Parameters differ between using ZeRO and local optimizer&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/optim/test_zero_redundancy_optimizer.py TestZeroRedundancyOptimizerDistributed.test_zero_join_gpu&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0">Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 708, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 972, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1012, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 856, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 710, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3226, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 139, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py", line 1083, in test_zero_join_gpu
    self._test_zero_join(self.device)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py", line 1070, in _test_zero_join
    torch.testing.assert_close(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Parameters differ between using ZeRO and local optimizer

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/optim/test_zero_redundancy_optimizer.py TestZeroRedundancyOptimizerDistributed.test_zero_join_gpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 856, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 710, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3226, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 139, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py", line 1083, in test_zero_join_gpu
    self._test_zero_join(self.device)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py", line 1070, in _test_zero_join
    torch.testing.assert_close(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Parameters differ between using ZeRO and local optimizer

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/optim/test_zero_redundancy_optimizer.py TestZeroRedundancyOptimizerDistributed.test_zero_join_gpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 856, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 710, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3226, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 139, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py", line 1083, in test_zero_join_gpu
    self._test_zero_join(self.device)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/optim/test_zero_redundancy_optimizer.py", line 1070, in _test_zero_join
    torch.testing.assert_close(
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_comparison.py", line 1589, in assert_close
    raise error_metas[0].to_error(msg)
AssertionError: Parameters differ between using ZeRO and local optimizer

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/optim/test_zero_redundancy_optimizer.py TestZeroRedundancyOptimizerDistributed.test_zero_join_gpu

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0</failure></testcase><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_zero_model_parallel_parameters_as_bucket_view_False" time="27.547" /><testcase classname="test.distributed.optim.test_zero_redundancy_optimizer.TestZeroRedundancyOptimizerDistributed" name="test_zero_model_parallel_parameters_as_bucket_view_True" time="27.447" /></testsuite></testsuites>