<?xml version="1.0" encoding="utf-8"?><testsuites name="pytest tests"><testsuite name="pytest" errors="0" failures="2" skipped="6" tests="20" time="376.741" timestamp="2025-09-12T15:46:04.205719+00:00" hostname="dut7358"><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardCollectiveOps" name="test_all_gather_fp32" time="0.000"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py:132: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardCollectiveOps" name="test_reduce_scatter_fp16" time="0.000"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py:236: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardCollectiveOps" name="test_reduce_scatter_fp32" time="0.000"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py:223: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardCommunication" name="test_fully_shard_communication_count" time="33.034" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardCommunication" name="test_manual_reshard_with_reshard_after_forward_false" time="31.457" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardCommunication" name="test_set_reshard_after_forward" time="31.844" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardPrefetch" name="test_backward_misprefetch" time="30.951" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardPrefetch" name="test_fully_shard_backward_prefetch" time="41.268" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardPrefetch" name="test_fully_shard_multi_module_backward_prefetch" time="31.857" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardPrefetch" name="test_fully_shard_multi_module_unused_module" time="31.152" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardPrefetch" name="test_set_modules_to_backward_prefetch" time="31.351" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardPrefetch" name="test_set_modules_to_forward_prefetch" time="31.856" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardUnshardMultiProcess" name="test_unshard_async" time="30.148" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardUnshardMultiThread" name="test_unshard_no_param_group" time="0.000"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py:1341: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardUnshardMultiThread" name="test_unshard_without_lazy_init" time="0.000"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py:1352: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardAllocFromPG" name="test_exception_when_used_together_with_comm_hooks" time="15.528" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardAllocFromPG" name="test_fully_shard_alloc_from_pg" time="0.000"><skipped type="pytest.skip" message="multicast support is not available">/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py:1380: multicast support is not available</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardForceSumReduction" name="test_fully_shard_force_sum_both_reductions" time="15.628"><failure message="RuntimeError: Process 0 exited with error code 10 and exception:&#10;Traceback (most recent call last):&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 864, in run_test&#10;    getattr(self, test_name)()&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 718, in wrapper&#10;    fn()&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py&quot;, line 3225, in wrapper&#10;    method(*args, **kwargs)&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 221, in wrapper&#10;    return func(*args, **kwargs)&#10;  File &quot;/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py&quot;, line 1540, in test_fully_shard_force_sum_both_reductions&#10;    inp = torch.randint(0, model_args.vocab_size, (2, 16), device=&quot;cuda&quot;)&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py&quot;, line 403, in _lazy_init&#10;    raise AssertionError(&quot;Torch not compiled with CUDA enabled&quot;)&#10;AssertionError: Torch not compiled with CUDA enabled&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_both_reductions&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0&#10;&#10;Process 1 exited with error code 10 and exception:&#10;Traceback (most recent call last):&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 864, in run_test&#10;    getattr(self, test_name)()&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 718, in wrapper&#10;    fn()&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py&quot;, line 3225, in wrapper&#10;    method(*args, **kwargs)&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 221, in wrapper&#10;    return func(*args, **kwargs)&#10;  File &quot;/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py&quot;, line 1540, in test_fully_shard_force_sum_both_reductions&#10;    inp = torch.randint(0, model_args.vocab_size, (2, 16), device=&quot;cuda&quot;)&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py&quot;, line 403, in _lazy_init&#10;    raise AssertionError(&quot;Torch not compiled with CUDA enabled&quot;)&#10;AssertionError: Torch not compiled with CUDA enabled&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_both_reductions&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0&#10;&#10;Process 2 exited with error code 10 and exception:&#10;Traceback (most recent call last):&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 864, in run_test&#10;    getattr(self, test_name)()&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 718, in wrapper&#10;    fn()&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py&quot;, line 3225, in wrapper&#10;    method(*args, **kwargs)&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 221, in wrapper&#10;    return func(*args, **kwargs)&#10;  File &quot;/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py&quot;, line 1540, in test_fully_shard_force_sum_both_reductions&#10;    inp = torch.randint(0, model_args.vocab_size, (2, 16), device=&quot;cuda&quot;)&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py&quot;, line 403, in _lazy_init&#10;    raise AssertionError(&quot;Torch not compiled with CUDA enabled&quot;)&#10;AssertionError: Torch not compiled with CUDA enabled&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_both_reductions&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0&#10;&#10;Process 3 exited with error code 10 and exception:&#10;Traceback (most recent call last):&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 864, in run_test&#10;    getattr(self, test_name)()&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 718, in wrapper&#10;    fn()&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py&quot;, line 3225, in wrapper&#10;    method(*args, **kwargs)&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 221, in wrapper&#10;    return func(*args, **kwargs)&#10;  File &quot;/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py&quot;, line 1540, in test_fully_shard_force_sum_both_reductions&#10;    inp = torch.randint(0, model_args.vocab_size, (2, 16), device=&quot;cuda&quot;)&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py&quot;, line 403, in _lazy_init&#10;    raise AssertionError(&quot;Torch not compiled with CUDA enabled&quot;)&#10;AssertionError: Torch not compiled with CUDA enabled&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_both_reductions&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0">Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 0 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py", line 1540, in test_fully_shard_force_sum_both_reductions
    inp = torch.randint(0, model_args.vocab_size, (2, 16), device="cuda")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_both_reductions

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py", line 1540, in test_fully_shard_force_sum_both_reductions
    inp = torch.randint(0, model_args.vocab_size, (2, 16), device="cuda")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_both_reductions

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 2 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py", line 1540, in test_fully_shard_force_sum_both_reductions
    inp = torch.randint(0, model_args.vocab_size, (2, 16), device="cuda")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_both_reductions

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0

Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py", line 1540, in test_fully_shard_force_sum_both_reductions
    inp = torch.randint(0, model_args.vocab_size, (2, 16), device="cuda")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_both_reductions

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0</failure></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardForceSumReduction" name="test_fully_shard_force_sum_reduce_scatter" time="15.322"><failure message="RuntimeError: Process 3 exited with error code 10 and exception:&#10;Traceback (most recent call last):&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 864, in run_test&#10;    getattr(self, test_name)()&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 718, in wrapper&#10;    fn()&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py&quot;, line 3225, in wrapper&#10;    method(*args, **kwargs)&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 221, in wrapper&#10;    return func(*args, **kwargs)&#10;  File &quot;/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py&quot;, line 1478, in test_fully_shard_force_sum_reduce_scatter&#10;    inp = torch.randint(0, model_args.vocab_size, (2, 16), device=&quot;cuda&quot;)&#10;  File &quot;/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py&quot;, line 403, in _lazy_init&#10;    raise AssertionError(&quot;Torch not compiled with CUDA enabled&quot;)&#10;AssertionError: Torch not compiled with CUDA enabled&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_reduce_scatter&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0">Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 59, in testPartExecutor
    yield
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 591, in run
    self._callTestMethod(testMethod)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
    method()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 3 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3225, in wrapper
    method(*args, **kwargs)
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py", line 1478, in test_fully_shard_force_sum_reduce_scatter
    inp = torch.randint(0, model_args.vocab_size, (2, 16), device="cuda")
  File "/tmp/xpu-tool/Python/3.10.18/x64/lib/python3.10/site-packages/torch/cuda/__init__.py", line 403, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardForceSumReduction.test_fully_shard_force_sum_reduce_scatter

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0</failure></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardReduceOpWorldSize1" name="test_size1_reduceop" time="3.408" /></testsuite></testsuites>