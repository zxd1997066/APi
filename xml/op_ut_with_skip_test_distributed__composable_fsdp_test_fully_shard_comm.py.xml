<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="0" failures="2" skipped="8" tests="20" time="340.394" timestamp="2025-08-22T13:54:37.491970" hostname="dut7358"><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardCollectiveOps" name="test_all_gather_fp32" time="0.001"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py:133: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardCollectiveOps" name="test_reduce_scatter_fp16" time="0.000"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py:237: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardCollectiveOps" name="test_reduce_scatter_fp32" time="0.000"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py:224: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardCommunication" name="test_fully_shard_communication_count" time="31.492" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardCommunication" name="test_manual_reshard_with_reshard_after_forward_false" time="30.683" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardCommunication" name="test_set_reshard_after_forward" time="30.984" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardPrefetch" name="test_backward_misprefetch" time="30.684" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardPrefetch" name="test_fully_shard_backward_prefetch" time="43.612" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardPrefetch" name="test_fully_shard_multi_module_backward_prefetch" time="31.485" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardPrefetch" name="test_fully_shard_multi_module_unused_module" time="30.778" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardPrefetch" name="test_set_modules_to_backward_prefetch" time="30.881" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardPrefetch" name="test_set_modules_to_forward_prefetch" time="30.367" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardUnshardMultiProcess" name="test_unshard_async" time="27.968"><failure message="RuntimeError: Process 1 exited with error code 10 and exception:&#10;Traceback (most recent call last):&#10;  File &quot;/home/jenkins/.conda/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 864, in run_test&#10;    getattr(self, test_name)()&#10;  File &quot;/home/jenkins/.conda/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 718, in wrapper&#10;    fn()&#10;  File &quot;/home/jenkins/.conda/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py&quot;, line 3226, in wrapper&#10;    method(*args, **kwargs)&#10;  File &quot;/home/jenkins/.conda/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py&quot;, line 221, in wrapper&#10;    return func(*args, **kwargs)&#10;  File &quot;/home/jenkins/actions-runner/_work/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py&quot;, line 1334, in test_unshard_async&#10;    self.assertEqual(losses[0], losses[1])&#10;  File &quot;/home/jenkins/.conda/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py&quot;, line 4181, in assertEqual&#10;    raise error_metas.pop()[0].to_error(  # type: ignore[index]&#10;AssertionError: Scalars are not close!&#10;&#10;Expected 2345.20751953125 but got 17.188919067382812.&#10;Absolute difference: 2328.018600463867 (up to 1e-05 allowed)&#10;Relative difference: 0.9926706191566287 (up to 1.3e-06 allowed)&#10;&#10;To execute this test, run the following from the base repo dir:&#10;    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardUnshardMultiProcess.test_unshard_async&#10;&#10;This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0">Traceback (most recent call last):
  File "/home/jenkins/.conda/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/home/jenkins/.conda/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/home/jenkins/.conda/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1020, in _check_return_codes
    raise RuntimeError(error)
RuntimeError: Process 1 exited with error code 10 and exception:
Traceback (most recent call last):
  File "/home/jenkins/.conda/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 864, in run_test
    getattr(self, test_name)()
  File "/home/jenkins/.conda/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 718, in wrapper
    fn()
  File "/home/jenkins/.conda/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 3226, in wrapper
    method(*args, **kwargs)
  File "/home/jenkins/.conda/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 221, in wrapper
    return func(*args, **kwargs)
  File "/home/jenkins/actions-runner/_work/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py", line 1334, in test_unshard_async
    self.assertEqual(losses[0], losses[1])
  File "/home/jenkins/.conda/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4181, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Scalars are not close!

Expected 2345.20751953125 but got 17.188919067382812.
Absolute difference: 2328.018600463867 (up to 1e-05 allowed)
Relative difference: 0.9926706191566287 (up to 1.3e-06 allowed)

To execute this test, run the following from the base repo dir:
    PYTORCH_TEST_WITH_SLOW=1 python test/distributed/_composable/fsdp/test_fully_shard_comm.py TestFullyShardUnshardMultiProcess.test_unshard_async

This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0</failure></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardUnshardMultiThread" name="test_unshard_no_param_group" time="0.002"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py:1342: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardUnshardMultiThread" name="test_unshard_without_lazy_init" time="0.001"><skipped type="pytest.skip" message="not-support-multithread">/home/jenkins/actions-runner/_work/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py:1353: not-support-multithread</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardAllocFromPG" name="test_exception_when_used_together_with_comm_hooks" time="15.147" /><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardAllocFromPG" name="test_fully_shard_alloc_from_pg" time="0.002"><skipped type="pytest.skip" message="multicast support is not available">/home/jenkins/actions-runner/_work/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py:1381: multicast support is not available</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardForceSumReduction" name="test_fully_shard_force_sum_both_reductions" time="0.002"><skipped type="pytest.skip" message="Related environment variable is not supported with XCCL">/home/jenkins/actions-runner/_work/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py:1511: Related environment variable is not supported with XCCL</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardForceSumReduction" name="test_fully_shard_force_sum_reduce_scatter" time="0.002"><skipped type="pytest.skip" message="Related environment variable is not supported with XCCL">/home/jenkins/actions-runner/_work/torch-xpu-ops/pytorch/test/distributed/_composable/fsdp/test_fully_shard_comm.py:1458: Related environment variable is not supported with XCCL</skipped></testcase><testcase classname="test.distributed._composable.fsdp.test_fully_shard_comm.TestFullyShardReduceOpWorldSize1" name="test_size1_reduceop" time="3.213"><failure message="AssertionError: Scalars are not equal!&#10;&#10;Expected 0 but got -11.&#10;Absolute difference: 11&#10;Relative difference: inf&#10;Expected exit code 0 but got -11 for pid: 427105">Traceback (most recent call last):
  File "/home/jenkins/.conda/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 716, in wrapper
    self._join_processes(fn)
  File "/home/jenkins/.conda/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 980, in _join_processes
    self._check_return_codes(fn, elapsed_time)
  File "/home/jenkins/.conda/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py", line 1056, in _check_return_codes
    self.assertEqual(
  File "/home/jenkins/.conda/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py", line 4181, in assertEqual
    raise error_metas.pop()[0].to_error(  # type: ignore[index]
AssertionError: Scalars are not equal!

Expected 0 but got -11.
Absolute difference: 11
Relative difference: inf
Expected exit code 0 but got -11 for pid: 427105</failure></testcase></testsuite></testsuites>